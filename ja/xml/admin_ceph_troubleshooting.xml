<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage-troubleshooting">
 <title>トラブルシューティング</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:translation>yes</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  この章では、Cephクラスタの操作時に発生する可能性があるいくかの問題について説明します。
 </para>
 <sect1 xml:id="storage-bp-report-bug">
  <title>ソフトウェアの問題のレポート</title>

  <para>
   SUSE Enterprise Storage 6の実行中に、CephやObject Gatewayなど、そのコンポーネントに関連する問題が発生した場合は、SUSEテクニカルサポートに問題をレポートしてください。その際、<command>supportconfig</command>ユーティリティを使用する方法をお勧めします。
  </para>

  <tip>
   <para>
    <command>supportconfig</command>はモジュラソフトウェアであるため、<systemitem>supportutils-plugin-ses</systemitem>パッケージがインストールされていることを確認してください。
   </para>
<screen><prompt>tux &gt; </prompt>rpm -q supportutils-plugin-ses</screen>
   <para>
    これがCephサーバにインストールされていない場合は、次のコマンドを使用してインストールします。
   </para>
<screen><prompt>root # </prompt>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   <command>supportconfig</command>はコマンドラインで使用できますが、関連するYaSTモジュールを使用することをお勧めします。<command>supportconfig</command>の詳細については、<link xlink:href="https://www.suse.com/documentation/sles-15/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/>を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-cluster-mntc-rados-striping">
  <title>満杯のOSDにおいて<command>rados</command>を使用した大容量オブジェクトの送信に失敗する</title>

  <para>
   <command>rados</command>は、RADOS Object Storageを管理するためのコマンドラインユーティリティです。詳細については、<command>man 8 rados</command>を参照してください。
  </para>

  <para>
   次のように、<command>rados</command>ユーティリティを使用して、大容量オブジェクトをCephクラスタに送信するとします。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>rados -p mypool put myobject /file/to/send</screen>

  <para>
   これによって、関連するOSDの全領域がいっぱいになり、クラスタのパフォーマンスに深刻な問題が発生する可能性があります。
  </para>
 </sect1>
 <sect1 xml:id="ceph-xfs-corruption">
  <title>XFSファイルシステムの破損</title>

  <para>
   カーネルのバグやハードウェアの破損/設定ミスなどのまれな状況では、OSDがデータを保存する基礎となるファイルシステム(XFS)が損傷したりアンマウント不能になったりすることがあります。
  </para>

  <para>
   ハードウェアに問題がなく、システムが適切に設定されていることがわかっている場合は、SUSE Linux Enterprise ServerカーネルのXFSサブシステムに対してバグを発生させて、該当する特定のOSDにダウン状態を示すマークを付けることができます。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd down <replaceable>OSD_ID</replaceable></screen>

  <warning>
   <title>損傷したデバイスが変更されるため、フォーマットはしない</title>
   <para>
    <command>xfs_repair</command>を使用してファイルシステムの問題を修復するのが適切に思われるかもしれませんが、このコマンドはファイルシステムを変更するので使用しないでください。OSDは起動しますが、その機能が影響を受ける場合があります。
   </para>
  </warning>

  <para>
   続いて、基礎となるディスクを消去し、次のコマンドを実行してOSDを再作成します。
  </para>

<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm zap --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm prepare --bluestore --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-recover-toomanypgs">
  <title>状態メッセージ「Too Many PGs per OSD」</title>

  <para>
   <command>ceph status</command>の実行後に「<literal>Too Many PGs per OSD</literal>」というメッセージが表示される場合、<option>mon_pg_warn_max_per_osd</option>の値(デフォルトは300)を超えていることを意味します。この値は、OSDあたりのPG数の比率と比較されています。つまり、クラスタセットアップが最適ではありません。
  </para>

  <para>
   プールの作成後にPGの数を減らすことはできません。まだデータが含まれていないプールは削除しても問題なく、その後、より少ない数のPGで再作成できます。プールにすでにデータが含まれる場合、唯一の解決策は、クラスタにOSDを追加し、OSDあたりのPGの比率を下げることです。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-stuckinactive">
  <title>状態メッセージ「<emphasis>nn</emphasis> pg stuck inactive」</title>

  <para>
   <command>ceph status</command>の実行後に状態メッセージ「<literal>stuck inactive</literal>」が表示される場合、Cephが保存データを複製する場所を認識できないため、レプリケーションルールを満足できないことを意味します。これは、Cephの初期セットアップ直後に発生し、自動的に自動修復される可能性があります。その他の場合、壊れたOSDをオンラインに戻す、新しいOSDをクラスタに追加するなどの手動操作が必要になることがあります。きわめてまれなケースでは、レプリケーションレベルを下げると有効な場合があります。
  </para>

  <para>
   配置グループが完全にスタックしている場合は、<command>ceph osd tree</command>の出力を確認する必要があります。この出力は、<xref linkend="storage-bp-recover-osddown"/>の例のようなツリー構造で表示される必要があります。
  </para>

  <para>
   <command>ceph osd tree</command>の出力が次の例のようにフラットな場合があります。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   この場合、関連するCRUSHマップがツリー構造になっていることを確認する必要があります。これもフラットである場合、または上の例のようにホストがない場合、クラスタ全体でホスト名解決が正しく機能していないことを意味することがあります。
  </para>

  <para>
   たとえば、ルートにホストが含まれているにもかかわらず、OSDが最上位レベルに存在していてホストが割り当てられていないなど、階層が間違っている場合、OSDを階層内の正しい場所に移動する必要があります。これを実行するには、<command>ceph osd crush move</command>または<command>ceph osd crush set</command>、あるいはその両方のコマンドを使用します。詳細については、<xref linkend="op-crush"/>を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osdweight">
  <title>OSDの重みが0</title>

  <para>
   OSDには起動時に重みが割り当てられます。重みが大きいほど、クラスタがそのOSDに書き込む可能性が高くなります。重みは、クラスタのCRUSHマップで指定するか、OSDの起動スクリプトによって計算されます。
  </para>

  <para>
   場合によっては、OSDの重みの計算値がゼロに切り捨てられることがあります。つまり、そのOSDはデータを保存するようスケジュールされておらず、データは一切書き込まれません。一般的には、ディスクが小さすぎて(15GB未満)、より容量の大きいディスクに交換する必要があることがその理由です。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osddown">
  <title>OSDがダウンしている</title>

  <para>
   OSDデーモンは、実行中か、停止/ダウンのいずれかです。OSDがダウンしている理由は、一般的に次の3つです。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     ハードディスクの障害。
    </para>
   </listitem>
   <listitem>
    <para>
     OSDがクラッシュした。
    </para>
   </listitem>
   <listitem>
    <para>
     サーバがクラッシュした。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   次のコマンドを実行することによって、OSDの詳しい状態を確認できます。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   このリストの例は、<literal>osd.2</literal>がダウンしていることを示しています。これに従って、そのOSDが配置されているディスクがマウントされているかどうかを確認できます。
  </para>

<screen><prompt>root # </prompt>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   ログファイル<filename>/var/log/ceph/ceph-osd.2.log</filename>を調べることにより、OSDがダウンしている理由を追跡できます。OSDが動作していない理由を特定して修復したら、次のコマンドを使用してOSDを起動します。
  </para>

<screen><prompt>root # </prompt>systemctl start ceph-osd@2.service</screen>

  <para>
   <literal>2</literal>は必ず、停止しているOSDの実際の番号に置き換えてください。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-slowosd">
  <title>低速なOSDの特定</title>

  <para>
   クラスタのパフォーマンスを調整する場合、クラスタ内の低速なストレージ/OSDを特定することが非常に重要です。その理由は、(最も)低速なディスクにデータが書き込まれた場合、すべての関連ディスクで操作が完了するまで常に書き込み操作が待機することになり、書き込み操作全体が低速化するためです。
  </para>

  <para>
   ストレージのボトルネックの特定は容易ではありません。すべてのOSDを調べて、書き込みプロセスを低速化させているOSDを特定する必要があります。1つのOSDでベンチマークを実行するには、次のコマンドを実行します。
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> osd.<replaceable>OSD_ID_NUMBER</replaceable> bench</screen>

  <para>
   次に例を示します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   その後、各OSDでこのコマンドを実行し、<literal>bytes_per_sec</literal>の値を比較して、(最も)低速なOSDを把握する必要があります。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-clockskew">
  <title>クロックスキュー警告の修復</title>

  <para>
   すべてのクラスタノードの時刻情報が同期されている必要があります。ノードの時刻が完全には同期していない場合、クラスタの状態を確認するとクロックスキューの警告が表示されることがあります。
  </para>

  <para>
   時刻同期はNTPで管理します(<link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>を参照してください)。1つ以上のNTPサーバ、できれば同じグループの複数のNTPサーバと時刻を同期するように各ノードを設定します。これでもまだノードで時間スキューが発生する場合は、次の手順に従って修復します。
  </para>

<screen><prompt>root # </prompt>systemctl stop chronyd.service
<prompt>root # </prompt>systemctl stop ceph-mon.target
<prompt>root # </prompt>systemctl start chronyd.service
<prompt>root # </prompt>systemctl start ceph-mon.target</screen>

  <para>
   その後、<command>chronyc sourcestats</command>を使用して時間オフセットを確認できます。
  </para>

  <para>
   Ceph Monitorでは、クロックがお互いに0.05秒未満に同期されている必要があります。詳細については、<xref linkend="Cluster-Time-Setting"/>を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-net-issues">
  <title>ネットワークの問題によるクラスタの低パフォーマンス</title>

  <para>
   クラスタのパフォーマンスの低下には、さまざまな理由があります。その1つとして考えられるのがネットワークの問題です。このような場合、クラスタが定数に達している、OSDおよびMonitorノードがオフラインになっている、データ転送に長時間かかる、大量の再接続試行といった症状が発生している可能性があります。
  </para>

  <para>
   クラスタのパフォーマンスがネットワークの問題が原因で低下しているかどうかを確認するには、<filename>/var/log/ceph</filename>ディレクトリにあるCephのログファイルを調べます。
  </para>

  <para>
   クラスタのネットワークの問題を修復するには、次の点に焦点を当てます。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     基本的なネットワーク診断。DeepSeaの診断ツールランナ<literal>net.ping</literal>を実行してクラスタノード間でpingを送信し、個々のインタフェースが特定のインタフェースに接続できるかどうかと、その平均応答時間を確認します。平均よりも大幅に遅い特定の応答時間もレポートされます。次に例を示します。
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     ジャンボフレームを有効にして、すべてのインタフェースを検証します。
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     ネットワークパフォーマンスのベンチマーク。DeepSeaのネットワークパフォーマンスランナ<literal>net.iperf</literal>を実行して、ノード間のネットワーク帯域幅をテストします。指定したクラスタノード上で、多数の<command>iperf</command>プロセス(CPUコアの数による)がサーバとして起動されます。残りのクラスタノードは、ネットワークトラフィックを生成するためのクライアントとして使用されます。各ノードのすべての<command>iperf</command>プロセスの累積帯域幅がレポートされます。これには、すべてのクラスタノード上で達成可能な最大ネットワークスループットが反映されています。次に例を示します。
    </para>
<screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     クラスタノードのファイアウォール設定を確認します。Cephの操作に必要なポート/プロトコルがファイアウォールによってブロックされていないことを確認します。ファイアウォール設定の詳細については、<xref linkend="storage-bp-net-firewall"/>を参照してください。
    </para>
   </listitem>
   <listitem>
    <para>
     ネットワークカード、ケーブル、スイッチなどのネットワーキングハードウェアが適切に動作していることを確認します。
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>別個のネットワーク</title>
   <para>
    クラスタノード間で高速かつ安全にネットワーク通信を行うには、クラスタのOSDノードおよびMonitorノード専用の別個のネットワークを設定します。
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="trouble-jobcache">
  <title><filename>/var</filename>の領域不足</title>

  <para>
   デフォルトでは、Salt Masterは、すべてのジョブに対するすべてのMinionの戻り値を「ジョブキャッシュ」<emphasis/>に保存します。これにより、後でこのキャッシュを使用して、前のジョブの結果を検索できます。キャッシュディレクトリは、デフォルトでは<filename>/var/cache/salt/master/jobs/</filename>です。
  </para>

  <para>
   すべてのMinionからの各ジョブ戻り値が1つのファイルに保存されます。発行されるジョブの数と、<filename>/etc/salt/master</filename>ファイルの<option>keep_jobs</option>オプションの値によっては、時間が経つに連れてこのディレクトリが非常に大きくなる可能性があります。<option>keep_jobs</option>は、Minionの過去のジョブに関する情報を保持する時間数(デフォルトは24)を設定します。
  </para>

<screen>keep_jobs: 24</screen>

  <important>
   <title><option>keep_jobs: 0</option>は設定しない</title>
   <para>
    <option>keep_jobs</option>を「0」に設定すると、ジョブキャッシュクリーナが「実行されない」<emphasis/>ため、パーティションが満杯になる可能性があります。
   </para>
  </important>

  <para>
   ジョブキャッシュを無効にする場合は、<option>job_cache</option>を「False」に設定します。
  </para>

<screen>job_cache: False</screen>

  <tip>
   <title>ジョブキャッシュが原因で満杯になったパーティションの復元</title>
   <para>
    間違った<option>keep_jobs</option>設定のために、ジョブキャッシュファイルが含まれるパーティションが満杯になった場合、次の手順に従ってディスク領域を解放し、ジョブキャッシュ設定を改善します。
   </para>
   <procedure>
    <step>
     <para>
      Salt Masterサービスを停止します。
     </para>
<screen><prompt>root@master # </prompt>systemctl stop salt-master</screen>
    </step>
    <step>
     <para>
      <filename>/etc/salt/master</filename>を変更することによって、ジョブキャッシュに関連するSalt Master設定を変更します。
     </para>
<screen>job_cache: False
keep_jobs: 1</screen>
    </step>
    <step>
     <para>
      Salt Masterのジョブキャッシュを消去します。
     </para>
<screen><prompt>root # </prompt>rm -rfv /var/cache/salt/master/jobs/*</screen>
    </step>
    <step>
     <para>
      Salt Masterサービスを起動します。
     </para>
<screen><prompt>root@master # </prompt>systemctl start salt-master</screen>
    </step>
   </procedure>
  </tip>
 </sect1>
</chapter>
