<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_rbd.xml" version="5.0" xml:id="ceph.rbd">
 <title>RADOS Block Device</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>○</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  ブロックとは連続するバイトのことで、たとえば512バイトブロックのデータなどです。ブロックベースのストレージインタフェースは、ハードディスク、CD、フロッピーディスクなどの回転型媒体にデータを保存する最も一般的な方法です。Block Deviceインタフェースはあらゆるところで利用されているため、仮想ブロックデバイスは、Cephのような大容量データストレージシステムを操作するための理想的な候補です。
 </para>
 <para>
  Ceph Block Deviceは物理リソースを共有でき、サイズの変更が可能です。データはCephクラスタ内の複数のOSD上にストライプされて保存されます。Ceph Block Deviceは、スナップショットの作成、レプリケーション、整合性などのRADOSの機能を利用します。CephのRBD (RADOS Block Device)は、カーネルモジュールまたは<systemitem>librbd</systemitem>ライブラリを使用してOSDと対話します。
 </para>
 <figure>
  <title>RADOSプロトコル</title>
  <mediaobject>
   <imageobject role="fo">
    <imagedata fileref="ceph_rbd_schema.png" width="70%" format="PNG"/>
   </imageobject>
   <imageobject role="html">
    <imagedata fileref="ceph_rbd_schema.png" width="70%" format="PNG"/>
   </imageobject>
  </mediaobject>
 </figure>
 <para>
  Cephのブロックデバイスは、高いパフォーマンスと無限のスケーラビリティをカーネルモジュールに提供します。これらは、QEMUなどの仮想化ソリューションや、OpenStackなど、<systemitem class="library">libvirt</systemitem>に依存するクラウドベースのコンピューティングシステムをサポートします。同じクラスタを使用して、Object Gateway、CephFS、およびRADOS Block Deviceを同時に運用できます。
 </para>
 <sect1 xml:id="ceph.rbd.commands">
  <title>Block Deviceのコマンド</title>

  <para>
   <command>rbd</command>コマンドを使用して、Block Deviceイメージを作成、一覧、イントロスペクト、および削除できます。さらに、イメージのクローン作成、スナップショットの作成、スナップショットへのイメージのロールバック、スナップショットの表示などの操作にも使用できます。
  </para>

  <tip>
   <title>クラスタへのアクセス</title>
   <para>
    RADOS Block Deviceのコマンドを使用するには、実行中のCephクラスタにアクセスできる必要があります。
   </para>
  </tip>

  <sect2 xml:id="ceph.rbd.cmds.create">
   <title>Block Deviceイメージの作成</title>
   <para>
    Block Deviceをノードに追加する前に、クラスタ内にそのイメージを作成する必要があります。Block Deviceイメージを作成するには、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd create --size <replaceable>megabytes</replaceable> <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
   <para>
    たとえば、「swimmingpool」という名前のプールに情報を保存する「bar」という名前の1GBのイメージを作成するには、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd create --size 1024 swimmingpool/bar</screen>
   <tip>
    <title>デフォルトのプール</title>
    <para>
     イメージの作成時にプールを指定しなかった場合、イメージはデフォルトのプール「rbd」に保存されます。
    </para>
   </tip>
   <note>
    <title>プールを最初に作成</title>
    <para>
     プールをソースとして指定する前に、まずプールを作成する必要があります。詳細については、<xref linkend="ceph.pools"/>を参照してください。
    </para>
   </note>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.create-ec">
   <title>イレージャコーディングプールでのBlock Deviceイメージの作成</title>
   <para>
    SUSE Enterprise Storage 5から、Block Deviceイメージのデータをイレージャコーディングプールに保存できます。イレージャコーディングプールに保存できるのは、RBDイメージの「データ」部分のみです。さらに、イレージャコーディングプールで「overwrite」フラグが「true」<emphasis/>に設定されている必要があります。このフラグを「true」<emphasis/>に設定できるのは、すべてのOSDがBlueStoreを使用している場合だけです。
   </para>
   <para>
    イメージのメタデータをイレージャコーディングプールに存在させることはできません。メタデータは、デフォルトの「rbd」プールか、ユーザがパラメータ <parameter>--pool=</parameter> を<command>rbd create</command>コマンドで明示的に指定したプールにのみ存在できます。
   </para>
   <note>
    <title>BlueStoreが必須</title>
    <para>
     Block Deviceイメージにイレージャコーディングプールを使用するには、すべてのノードにBlueStoreが必要です。
    </para>
   </note>
   <para>
    イレージャコーディングプール内にRBDイメージを作成するには、次の手順を使用します。
   </para>
<screen><prompt>root # </prompt><command>ceph</command> osd pool create <replaceable>POOL_NAME</replaceable> 12 12 erasure
<prompt>root # </prompt><command>ceph</command> osd pool set <replaceable>POOL_NAME</replaceable> allow_ec_overwrites true

# Metadata will reside in pool "rbd", and data in pool "<replaceable>POOL_NAME</replaceable>"
<prompt>root # </prompt><command>rbd</command> create <replaceable>IMAGE_NAME</replaceable> --size=1G --data-pool <replaceable>POOL_NAME</replaceable>

#Metadata will reside in pool "<replaceable>OTHER_POOL</replaceable>", and data in pool "<replaceable>POOL_NAME</replaceable>"
<prompt>root # </prompt><command>rbd</command> create <replaceable>IMAGE_NAME</replaceable> --size=1G --data-pool <replaceable>POOL_NAME</replaceable> --pool=<replaceable>OTHER_POOL</replaceable></screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.list">
   <title>Block Deviceイメージの一覧</title>
   <para>
    「rbd」プール内のBlock Deviceを一覧にするには、次のコマンドを実行します(「rbd」はデフォルトのプール名です)。
   </para>
<screen><prompt>root # </prompt>rbd ls</screen>
   <para>
    「swimmingpool」という名前のプール内のBlock Deviceを一覧にするには、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd ls swimmingpool</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.info">
   <title>イメージ情報の取得</title>
   <para>
    「swimmingpool」という名前のプール内のイメージ「bar」から情報を取得するには、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd info swimmingpool/bar</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.resize">
   <title>Block Deviceイメージのサイズの変更</title>
   <para>
    RADOS Block Deviceイメージはシンプロビジョニングされます。つまり、そこにデータを保存し始めるまでは、実際に物理ストレージを使用しません。ただし、<option>--size</option>オプションで設定する最大容量があります。イメージの最大サイズを増やす(または減らす)場合、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd resize --size 2048 foo # to increase
rbd resize --size 2048 foo --allow-shrink # to decrease</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.rm">
   <title>Block Deviceイメージの削除</title>
   <para>
    「swimmingpool」という名前のプール内にあるイメージ「bar」に対応するBlock Deviceを削除するには、次のコマンドを実行します。
   </para>
<screen><prompt>root # </prompt>rbd rm swimmingpool/bar</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="storage.bp.integration.mount_rbd">
  <title>RBDイメージのマウントとアンマウント</title>

  <para>
   RADOS Block Deviceを作成した後、デバイスをフォーマットし、マウントしてファイルを交換できるようにし、完了したらアンマウントできます。
  </para>

  <procedure>
   <step>
    <para>
     Cephクラスタに、マウントするディスクイメージが存在するプールが含まれることを確認します。プールは<literal>mypool</literal>、イメージは<literal>myimage</literal>という名前であると想定します。
    </para>
<screen>rbd list mypool</screen>
   </step>
   <step>
    <para>
     イメージを新しいBlock Deviceにマップします。
    </para>
<screen><prompt>root # </prompt>rbd map --pool mypool myimage</screen>
    <tip>
     <title>ユーザ名と認証</title>
     <para>
      ユーザ名を指定するには、<option>--id <replaceable>user-name</replaceable></option>を使用します。さらに、<systemitem>cephx</systemitem>認証を使用する場合は、秘密も指定する必要があります。秘密は、キーリング、または秘密が含まれるファイルから取得できます。
     </para>
<screen><prompt>root # </prompt>rbd map --pool rbd myimage --id admin --keyring /path/to/keyring</screen>
     <para>
      または
     </para>
<screen><prompt>root # </prompt>rbd map --pool rbd myimage --id admin --keyfile /path/to/file</screen>
    </tip>
   </step>
   <step>
    <para>
     すべてのマップ済みデバイスを一覧にします。
    </para>
<screen><prompt>root # </prompt>rbd showmapped
 id pool   image   snap device
 0  mypool myimage -    /dev/rbd0</screen>
    <para>
     作業対象のデバイスは<filename>/dev/rbd0</filename>です。
    </para>
   </step>
   <step>
    <para>
     <filename>/dev/rbd0</filename>デバイス上にXFSファイルシステムを作成します。
    </para>
<screen><prompt>root # </prompt>mkfs.xfs /dev/rbd0
 log stripe unit (4194304 bytes) is too large (maximum is 256KiB)
 log stripe unit adjusted to 32KiB
 meta-data=/dev/rbd0              isize=256    agcount=9, agsize=261120 blks
          =                       sectsz=512   attr=2, projid32bit=1
          =                       crc=0        finobt=0
 data     =                       bsize=4096   blocks=2097152, imaxpct=25
          =                       sunit=1024   swidth=1024 blks
 naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
 log      =internal log           bsize=4096   blocks=2560, version=2
          =                       sectsz=512   sunit=8 blks, lazy-count=1
 realtime =none                   extsz=4096   blocks=0, rtextents=0</screen>
   </step>
   <step>
    <para>
     デバイスをマウントして、正しくマウントされていることを確認します。<filename>/mnt</filename>は、使用するマウントポイントに置き換えてください。
    </para>
<screen><prompt>root # </prompt>mount /dev/rbd0 /mnt
<prompt>root # </prompt>mount | grep rbd0
/dev/rbd0 on /mnt type xfs (rw,relatime,attr2,inode64,sunit=8192,...</screen>
    <para>
     これで、ローカルディレクトリと同じように、このデバイスとの間でデータを移動できます。
    </para>
    <tip>
     <title>RBDデバイスのサイズの増加</title>
     <para>
      RBDデバイスのサイズが十分ではなくなった場合、簡単にサイズを増やすことができます。
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        RBDイメージのサイズを、たとえば10GBに増やします。
       </para>
<screen><prompt>root # </prompt>rbd resize --size 10000 mypool/myimage
 Resizing image: 100% complete...done.</screen>
      </listitem>
      <listitem>
       <para>
        デバイスの新しいサイズ全体を使用するようファイルシステムを拡張します。
       </para>
<screen><prompt>root # </prompt>xfs_growfs /mnt
 [...]
 data blocks changed from 2097152 to 2560000</screen>
      </listitem>
     </orderedlist>
    </tip>
   </step>
   <step>
    <para>
     デバイスへのアクセスが終わったら、デバイスをアンマウントできます。
    </para>
<screen><prompt>root # </prompt>unmount /mnt</screen>
   </step>
  </procedure>

  <tip>
   <title>手動でのマウントとアンマウント</title>
   <para>
    ブート後にRBDイメージを手動でマップしてマウントし、シャットダウン前にアンマウントしてマップ解除するのは煩雑であるため、<command>rbdmap</command>スクリプトと<systemitem class="daemon">systemd</systemitem>ユニットが提供されています。<xref linkend="ceph.rbd.rbdmap"/>を参照してください。
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="cha.ceph.snapshots.rbd">
  <title>Block Deviceのスナップショット</title>

  <para>
   RBDのスナップショットは、RADOS Block Deviceイメージのスナップショットです。スナップショットにより、イメージの状態の履歴を保持します。Cephはスナップショットの階層化もサポートしており、VMイメージのクローンを素早く簡単に作成できます。<command>rbd</command>コマンド、およびさまざまな高レベルのインタフェース(QEMU、<systemitem>libvirt</systemitem>、OpenStack、CloudStackなど)を使用したBlock Deviceのスナップショットをサポートしています。
  </para>

  <note>
   <para>
    イメージのスナップショットを作成する前に、入出力操作を停止してください。イメージにファイルシステムが含まれる場合、スナップショットを作成する「前」<emphasis/>に、そのファイルシステムが整合性のある状態である必要があります。
   </para>
  </note>

  <sect2>
   <title>Cephxに関する注意事項</title>
   <para>
    <systemitem>cephx</systemitem>が有効な場合(詳細については、<link xlink:href="http://ceph.com/docs/master/rados/configuration/auth-config-ref/"/>を参照)、ユーザ名またはIDと、そのユーザに対応する鍵が含まれるキーリングのパスを指定する必要があります。詳細については、「<link xlink:href="http://ceph.com/docs/master/rados/operations/user-management/">User Management</link>」を参照してください。以降のパラメータを再入力せずに済むよう、<systemitem>CEPH_ARGS</systemitem>環境変数を追加することもできます。
   </para>
<screen><prompt>root # </prompt>rbd --id <replaceable>user-ID</replaceable> --keyring=/path/to/secret <replaceable>commands</replaceable>
<prompt>root # </prompt>rbd --name <replaceable>username</replaceable> --keyring=/path/to/secret <replaceable>commands</replaceable></screen>
   <para>
    次に例を示します。
   </para>
<screen><prompt>root # </prompt>rbd --id admin --keyring=/etc/ceph/ceph.keyring <replaceable>commands</replaceable>
<prompt>root # </prompt>rbd --name client.admin --keyring=/etc/ceph/ceph.keyring <replaceable>commands</replaceable></screen>
   <tip>
    <para>
     <systemitem>CEPH_ARGS</systemitem>環境変数にユーザと秘密を追加して、毎回入力しなくて済むようにします。
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>スナップショットの基本</title>
   <para>
    次の手順では、コマンドラインで<command>rbd</command>を使用して、スナップショットを作成、一覧、および削除する方法を説明します。
   </para>
   <sect3>
    <title>スナップショットの作成</title>
    <para>
     <command>rbd</command>を使用してスナップショットを作成するには、<option>snap create</option>オプション、プール名、およびイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap create --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap create <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool rbd snap create --snap snapshot1 image1
<prompt>root # </prompt>rbd snap create rbd/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>スナップショットの一覧</title>
    <para>
     イメージのスナップショットを一覧にするには、プール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap ls <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap ls <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool rbd snap ls image1
<prompt>root # </prompt>rbd snap ls rbd/image1</screen>
   </sect3>
   <sect3>
    <title>スナップショットのロールバック</title>
    <para>
     <command>rbd</command>を使用して特定のスナップショットにロールバックするには、<option>snap rollback</option>オプション、プール名、イメージ名、およびスナップショット名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap rollback --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap rollback <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap rollback --snap snapshot1 image1
<prompt>root # </prompt>rbd snap rollback pool1/image1@snapshot1</screen>
    <note>
     <para>
      イメージをスナップショットにロールバックすることは、イメージの現在のバージョンをスナップショットのデータで上書きすることを意味します。ロールバックの実行にかかる時間は、イメージのサイズに応じて長くなります。イメージをスナップショットに「ロールバック」<emphasis/>するよりもスナップショットから「クローンを作成する方が高速」<emphasis/>であり、以前の状態に戻す場合はこの方法をお勧めします。
     </para>
    </note>
   </sect3>
   <sect3>
    <title>スナップショットの削除</title>
    <para>
     <command>rbd</command>を使用してスナップショットを削除するには、<option>snap rm</option>オプション、プール名、イメージ名、およびユーザ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap rm --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap rm <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap rm --snap snapshot1 image1
<prompt>root # </prompt>rbd snap rm pool1/image1@snapshot1</screen>
    <note>
     <para>
      Ceph OSDはデータを非同期で削除するので、スナップショットを削除してもディスク領域はすぐには解放されません。
     </para>
    </note>
   </sect3>
   <sect3>
    <title>スナップショットのパージ</title>
    <para>
     <command>rbd</command>を使用してイメージのすべてのスナップショットを削除するには、<option>snap purge</option>オプションとイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap purge <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap purge <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap purge image1
<prompt>root # </prompt>rbd snap purge pool1/image1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.snapshoti.layering">
   <title>階層化</title>
   <para>
    Cephでは、Block DeviceスナップショットのCOW (コピーオンライト)クローンを複数作成できます。スナップショットの階層化により、Ceph Block Deviceのクライアントはイメージを非常に素早く作成できます。たとえば、Linux VMが書き込まれたBlock Deviceイメージを作成してから、そのイメージのスナップショットを作成し、スナップショットを保護して、コピーオンライトクローンを必要な数だけ作成できます。スナップショットは読み込み専用なので、スナップショットのクローンを作成することでセマンティクスが簡素化され、クローンを素早く作成できます。
   </para>
   <note>
    <para>
     次のコマンドラインの例で使われている「親」および「子」という用語は、Ceph Block Deviceのスナップショット(親)と、そのスナップショットから作成された対応するクローンイメージ(子)を意味します。
    </para>
   </note>
   <para>
    クローンイメージ(子)にはその親イメージへの参照が保存されており、これによってクローンイメージから親のスナップショットを開いて読み込むことができます。
   </para>
   <para>
    スナップショットのCOWクローンは、他のCeph Block Deviceイメージとまったく同じように動作します。クローンイメージに対して読み書きを行ったり、クローンを作成したり、サイズを変更したりできます。クローンイメージに特別な制約はありません。ただし、スナップショットのコピーオンライトクローンはスナップショットを参照するので、クローンを作成する前に「必ず」<emphasis/>スナップショットを保護する必要があります。
   </para>
   <note>
    <para>
     Cephは、「フォーマット2」<emphasis/>イメージ(<command>rbd create --image-format 2</command>で作成されたイメージ)のクローンの作成のみをサポートしています。
    </para>
   </note>
   <sect3>
    <title>階層化の基本事項</title>
    <para>
     Ceph Block Deviceの階層化は簡単なプロセスです。まずイメージを用意する必要があります。続いて、イメージのスナップショットを作成し、スナップショットを保護する必要があります。これらの手順を実行した後、スナップショットのクローンの作成を開始できます。
    </para>
    <para>
     クローンイメージは親スナップショットへの参照を持ち、プールID、イメージID、およびスナップショットIDを含みます。プールIDが含まれることは、あるプールから別のプール内のイメージへスナップショットのクローンを作成できることを意味します。
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <para>
       「イメージテンプレート」<emphasis/>: Block Deviceの階層化の一般的な使用事例は、マスタイメージと、クローンのテンプレートとして機能するスナップショットを作成することです。たとえば、Linux配布パッケージ(たとえば、SUSE Linux Enterprise Server)のイメージを作成して、そのスナップショットを作成できます。定期的にイメージを更新して新しいスナップショットを作成できます(たとえば、<command>zypper ref &amp;&amp; zypper patch</command>の後に<command>rbd snap create</command>を実行します)。イメージが完成したら、いずれかのスナップショットのクローンを作成できます。
      </para>
     </listitem>
     <listitem>
      <para>
       「拡張テンプレート」<emphasis/>: より高度な使用事例として、ベースイメージより多くの情報を提供するテンプレートイメージを拡張することがあります。たとえば、イメージ(VMテンプレート)のクローンを作成して、他のソフトウェア(たとえば、データベース、コンテンツ管理システム、分析システム)をインストールしてから、拡張イメージのスナップショットを作成でき、このスナップショットそのものをベースイメージと同じ方法で更新できます。
      </para>
     </listitem>
     <listitem>
      <para>
       「テンプレートプール」<emphasis/>: Block Deviceの階層化を使用する方法の1つが、テンプレートとして機能するマスタイメージと、それらのテンプレートの各スナップショットが含まれるプールを作成することです。その後、読み込み専用特権をユーザに拡張し、プール内での書き込みまたは実行の能力を持たなくても、スナップショットのクローンを作成できるようにします。
      </para>
     </listitem>
     <listitem>
      <para>
       「イメージのマイグレーション/回復」<emphasis/>: Block Deviceの階層化を使用する方法の1つが、あるプールから別のプールへデータを移行または回復することです。
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3>
    <title>スナップショットの保護</title>
    <para>
     クローンは親スナップショットにアクセスします。ユーザが誤って親スナップショットを削除すると、すべてのクローンが壊れます。データの損失を防ぐため、クローンを作成する前に、スナップショットを保護する必要があります。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap protect \
 --image <replaceable>image-name</replaceable> --snap <replaceable>snapshot-name</replaceable>
<prompt>root # </prompt>rbd snap protect <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap protect --image image1 --snap snapshot1
<prompt>root # </prompt>rbd snap protect pool1/image1@snapshot1</screen>
    <note>
     <para>
      保護されたスナップショットは削除できません。
     </para>
    </note>
   </sect3>
   <sect3>
    <title>スナップショットのクローンの作成</title>
    <para>
     スナップショットのクローンを作成するには、親プール、イメージ、スナップショット、子プール、およびイメージ名を指定する必要があります。クローンを作成する前に、スナップショットを保護する必要があります。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> --image <replaceable>parent-image</replaceable> \
 --snap <replaceable>snap-name</replaceable> --dest-pool <replaceable>pool-name</replaceable> \
 --dest <replaceable>child-image</replaceable>
<prompt>root # </prompt>rbd clone <replaceable>pool-name</replaceable>/<replaceable>parent-image</replaceable>@<replaceable>snap-name</replaceable> \
<replaceable>pool-name</replaceable>/<replaceable>child-image-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd clone pool1/image1@snapshot1 pool1/image2</screen>
    <note>
     <para>
      あるプールから別のプール内のイメージへスナップショットのクローンを作成できます。たとえば、一方のプール内に読み込み専用のイメージとスナップショットをテンプレートとして維持しておき、別のプール内に書き込み可能クローンを維持できます。
     </para>
    </note>
   </sect3>
   <sect3>
    <title>スナップショットの保護の解除</title>
    <para>
     スナップショットを削除するには、まず保護を解除する必要があります。また、クローンから参照されているスナップショットは削除「できません」<emphasis/>。スナップショットを削除する前に、スナップショットの各クローンをフラット化する必要があります。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap unprotect --image <replaceable>image-name</replaceable> \
 --snap <replaceable>snapshot-name</replaceable>
<prompt>root # </prompt>rbd snap unprotect <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap unprotect --image image1 --snap snapshot1
<prompt>root # </prompt>rbd snap unprotect pool1/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>スナップショットの子の一覧</title>
    <para>
     スナップショットの子を一覧にするには、次のコマンドを実行します。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> children --image <replaceable>image-name</replaceable> --snap <replaceable>snap-name</replaceable>
<prompt>root # </prompt>rbd children <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 children --image image1 --snap snapshot1
<prompt>root # </prompt>rbd children pool1/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>クローンイメージのフラット化</title>
    <para>
     クローンイメージは親スナップショットへの参照を保持しています。子クローンから親スナップショットへの参照を削除する場合、スナップショットからクローンへ情報をコピーすることによって効果的にイメージを「フラット化」します。クローンのフラット化にかかる時間は、スナップショットのサイズに応じて長くなります。スナップショットを削除するには、まず子イメージをフラット化する必要があります。
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> flatten --image <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd flatten <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 flatten --image image1
<prompt>root # </prompt>rbd flatten pool1/image1</screen>
    <note>
     <para>
      フラット化されたイメージにはスナップショットからの情報がすべて含まれるため、階層化されたクローンよりも多くのストレージ領域を使用します。
     </para>
    </note>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rbd.rbdmap">
  <title>rbdmap: ブート時のRBDデバイスのマップ</title>

  <para>
   <command>rbdmap</command>は、1つ以上のRADOS Block Deviceイメージに対する<command>rbd map</command>および<command>rbd unmap</command>の操作を自動化するシェルスクリプトです。このスクリプトはいつでも手動で実行できますが、ブート時にRBDイメージを自動的にマップしてマウント(シャットダウン時にはアンマウントしてマップ解除)するのが主な使用事例です。これはInitシステムによってトリガされます。このために、<systemitem>ceph-common</systemitem>パッケージに<systemitem class="daemon">systemd</systemitem>のユニットファイルである<filename>rbdmap.service</filename>が含まれています。
  </para>

  <para>
   このスクリプトは引数を1つ取り、<option>map</option>または<option>unmap</option>のどちらかを指定できます。どちらの場合も、スクリプトは設定ファイルを解析します。デフォルトは<filename>/etc/ceph/rbdmap</filename>ですが、環境変数<literal>RBDMAPFILE</literal>で上書きできます。設定ファイルの各行が、マップまたはマップ解除する1つのRBDイメージに対応します。
  </para>

  <para>
   設定ファイルは次のような形式になっています。
  </para>

<screen>image_specification rbd_options</screen>

  <variablelist>
   <varlistentry>
    <term>image_specification</term>
    <listitem>
     <para>
      プール内のイメージのパス。<replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable>として指定します。<replaceable>pool_name</replaceable>を省略すると、デフォルトの「rbd」が想定されます。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rbd_options</term>
    <listitem>
     <para>
      基礎となる<command>rbd map</command>コマンドに渡されるパラメータのオプションのリスト。これらのパラメータとその値をコンマ区切り文字列として指定する必要があります。次に例を示します。
     </para>
<screen>PARAM1=VAL1,PARAM2=VAL2,...</screen>
     <para>
      次の例では、<command>rbdmap</command>スクリプトで次のコマンドを実行します。
     </para>
<screen>rbd map <replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable> --PARAM1 VAL1 --PARAM2 VAL2</screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   <command>rbdmap map</command>として実行すると、設定ファイルを解析し、指定されているRBDイメージそれぞれに対して、最初にイメージをマップし(<command>rbd map</command>を使用)、次にイメージをマウントしようと試みます。
  </para>

  <para>
   <command>rbdmap unmap</command>として実行すると、設定ファイルに一覧にされているイメージがアンマウントされてマップ解除されます。
  </para>

  <para>
   <command>rbdmap unmap-all</command>は、設定ファイルに一覧にされているかどうかに関係なく、現在マップされているRBDイメージをすべてアンマウントし、その後マップ解除しようと試みます。
  </para>

  <para>
   成功した場合、イメージはrbd map操作によって/dev/rbdXデバイスにマップされます。この時点でudevルールがトリガされ、実際にマップされたデバイスを指すフレンドリデバイス名のシンボリックリンク<filename>/dev/rbd/<replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable></filename>が作成されます。
  </para>

  <para>
   正常にマウントおよびアンマウントするには、<filename>/etc/fstab</filename>に「フレンドリ」デバイス名に対応するエントリが必要です。RBDイメージの<filename>/etc/fstab</filename>エントリを記述する場合、「noauto」(または「nofail」)マウントオプションを指定します。<filename>rbdmap.service</filename>は一般的にブートシーケンスのかなり遅い段階でトリガされるため、このオプションを指定することによって、Initシステムが、対象デバイスがまだ存在しない早すぎるタイミングでデバイスをマウントしないようにします。
  </para>

  <para>
   <command>rbd</command>オプションの完全なリストについては、<command>rbd</command>のマニュアルページ(<command>man 8 rbd</command>)を参照してください。
  </para>

  <para>
   <command>rbdmap</command>の使用法の例については、<command>rbdmap</command>のマニュアルページ(<command>man 8 rbdmap</command>)を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="ceph.rbd.mirror">
  <title>RADOS Block Deviceのミラーリング</title>

  <para>
   RBDイメージを2つのCephクラスタ間で非同期でミラーリングできます。この機能は、RBDイメージのジャーナリング機能を使用して、クラスタ間でのクラッシュコンシステントなレプリケーションを保証します。ミラーリングはピアクラスタ内でプールごとに設定します。また、プール内のすべてのイメージ、またはイメージの特定のサブセットを自動的にミラーリングするよう設定できます。ミラーリングは<command>rbd</command>コマンドを使用して設定します。<systemitem>rbd-mirror</systemitem>デーモンは、リモートのピアクラスタからイメージの更新を取得して、ローカルクラスタ内のイメージに適用する処理を受け持ちます。
  </para>

  <important>
   <title>rbd-mirrorデーモン</title>
   <para>
    RBDミラーリングを使用するには、それぞれが<systemitem>rbd-mirror</systemitem>デーモンを実行する2つのCephクラスタが必要です。
   </para>
  </important>

  <sect2 xml:id="rbd.mirror.daemon">
   <title>rbd-mirrorデーモン</title>
   <para>
    2つの<systemitem>rbd-mirror</systemitem>デーモンは、リモートのピアクラスタ上のイメージのジャーナルを監視し、そのジャーナルイベントをローカルクラスタに対して再生する処理を受け持ちます。RBDイメージのジャーナリング機能は、イメージに対するすべての変更を発生順に記録します。これにより、リモートイメージのクラッシュコンシステントなミラーをローカルで確実に利用できるようにします。
   </para>
   <para>
    <systemitem>rbd-mirror</systemitem>デーモンは<systemitem>rbd-mirror</systemitem>パッケージで提供されています。このデーモンをクラスタノードの1つにインストールし、有効にして起動します。
   </para>
<screen><prompt>root@minion &gt; </prompt>zypper install rbd-mirror
<prompt>root@minion &gt; </prompt>systemctl enable ceph-rbd-mirror@<replaceable>server_name</replaceable>.service
<prompt>root@minion &gt; </prompt>systemctl start ceph-rbd-mirror@<replaceable>server_name</replaceable>.service</screen>
   <important>
    <para>
     各<systemitem>rbd-mirror</systemitem>デーモンは、両方のクラスタに同時に接続できる必要があります。
    </para>
   </important>
  </sect2>

  <sect2 xml:id="ceph.rbd.mirror.poolconfig">
   <title>プールの設定</title>
   <para>
    次の手順では、<command>rbd</command>コマンドを使用してミラーリングを設定するための基本的な管理タスクを実行する方法を説明します。ミラーリングは、Cephクラスタ内のプールごとに設定します。
   </para>
   <para>
    これらのプール設定手順は、両方のピアクラスタで実行する必要があります。これらの手順では、わかりやすくするため、「local」および「remote」という名前の2つのクラスタが1つのホストからアクセス可能であることを想定しています。
   </para>
   <para>
    異なるCephクラスタに接続する方法の詳細については、<command>rbd</command>のマニュアルページ(<command>man 8 rbd</command>)を参照してください。
   </para>
   <tip>
    <title>複数のクラスタ</title>
    <para>
     次の例のクラスタ名は、同じ名前のCeph設定ファイル<filename>/etc/ceph/remote.conf</filename>に対応しています。複数のクラスタの設定方法については、<link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf/#running-multiple-clusters">ceph-conf</link>のドキュメントを参照してください。
    </para>
   </tip>
   <sect3>
    <title>ミラーリングの有効化</title>
    <para>
     プールのミラーリングを有効にするには、<command>mirror pool enable</command>サブコマンド、プール名、およびミラーリングモードを指定します。ミラーリングモードはpoolまたはimageにすることができます。
    </para>
    <variablelist>
     <varlistentry>
      <term>pool</term>
      <listitem>
       <para>
        ジャーナリング機能が有効な、プール内のすべてのイメージをミラーリングします。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>image</term>
      <listitem>
       <para>
        各イメージに対して明示的にミラーリングを有効にする必要があります。詳細については、<xref linkend="rbd.mirror.enable_image_mirroring"/>を参照してください。
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     次に例を示します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool enable image-pool pool
<prompt>root # </prompt>rbd --cluster remote mirror pool enable image-pool pool</screen>
   </sect3>
   <sect3>
    <title>ミラーリングの無効化</title>
    <para>
     プールのミラーリングを無効にするには、<command>mirror pool disable</command>サブコマンドとプール名を指定します。この方法でプールのミラーリングを無効にした場合、ミラーリングを明示的に有効にしたイメージ(プール内)のミラーリングも無効になります。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool disable image-pool
<prompt>root # </prompt>rbd --cluster remote mirror pool disable image-pool</screen>
   </sect3>
   <sect3>
    <title>クラスタピアの追加</title>
    <para>
     <systemitem>rbd-mirror</systemitem>デーモンがピアクラスタを検出するには、そのピアがプールに登録されている必要があります。ミラーリングピアクラスタを追加するには、<command>mirror pool peer add</command>サブコマンド、プール名、およびクラスタの仕様を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool peer add image-pool client.remote@remote
<prompt>root # </prompt>rbd --cluster remote mirror pool peer add image-pool client.local@local</screen>
   </sect3>
   <sect3>
    <title>クラスタピアの削除</title>
    <para>
     ミラーリングピアクラスタを削除するには、<command>mirror pool peer remove</command>サブコマンド、プール名、およびピアのUUID (<command>rbd mirror pool info</command>コマンドで参照可能)を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool peer remove image-pool \
 55672766-c02b-4729-8567-f13a66893445
<prompt>root # </prompt>rbd --cluster remote mirror pool peer remove image-pool \
 60c0e299-b38f-4234-91f6-eed0a367be08</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="rbd.mirror.imageconfig">
   <title>イメージ設定</title>
   <para>
    プール設定と異なり、イメージ設定はミラーリングピアの1つのCephクラスタのみで実行する必要があります。
   </para>
   <para>
    ミラーリングされたRBDイメージは、「プライマリ」<emphasis/>または「非プライマリ」<emphasis/>のいずれかとして指定されます。これはイメージのプロパティであり、プールのプロパティではありません。非プライマリとして指定されたイメージは変更できません。
   </para>
   <para>
    イメージに対して初めてミラーリングを有効にすると、イメージは自動的にプライマリに昇格します(プールのミラーモードが「pool」で、イメージのジャーナリング機能が有効な場合、ミラーリングは暗黙的に有効になります。または、<command>rbd</command>コマンドによって明示的に有効にします(<xref linkend="rbd.mirror.enable_image_mirroring"/>を参照してください))。
   </para>
   <sect3>
    <title>イメージのジャーナリングのサポートの有効化</title>
    <para>
     RBDのミラーリングは、RBDのジャーナリング機能を使用して、複製イメージが常にクラッシュコンシステントな状態を保つようにします。イメージをピアクラスタにミラーリングするには、ジャーナリング機能が有効である必要があります。この機能は、イメージの作成時に<command>rbd</command>コマンドで<option>--image-feature exclusive-lock,journaling</option>オプションを指定することによって有効にできます。
    </para>
    <para>
     または、既存のRBDイメージに対して動的にジャーナリング機能を有効にすることもできます。ジャーナリングを有効にするには、<command>feature enable</command>サブコマンド、プール名、イメージ名、および機能名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local feature enable image-pool/image-1 journaling</screen>
    <note>
     <title>オプションの依存関係</title>
     <para>
      <option>journaling</option>機能は<option>exclusive-lock</option>機能に依存します。<option>exclusive-lock</option>機能がまだ有効になっていない場合は、有効にしてから<option>journaling</option>機能を有効にする必要があります。
     </para>
    </note>
    <tip>
     <title>すべての新規イメージのジャーナリング</title>
     <para>
      Ceph設定ファイルに次の行を追加することにより、すべての新規イメージに対してデフォルトでジャーナリングを有効にできます。
     </para>
<screen>rbd default features = 125</screen>
    </tip>
   </sect3>
   <sect3 xml:id="rbd.mirror.enable_image_mirroring">
    <title>イメージのミラーリングの有効化</title>
    <para>
     ミラーリングがイメージのプールに「image」モードで設定されている場合、プール内の各イメージに対して明示的にミラーリングを有効にする必要があります。特定のイメージのミラーリングを有効にするには、<command>mirror image enable</command>サブコマンドと共にプール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image enable image-pool/image-1</screen>
   </sect3>
   <sect3>
    <title>イメージのミラーリングの無効化</title>
    <para>
     特定のイメージのミラーリングを無効にするには、<command>mirror image disable</command>サブコマンドと共にプール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image disable image-pool/image-1</screen>
   </sect3>
   <sect3>
    <title>イメージの昇格と降格</title>
    <para>
     プライマリ指定をピアクラスタ内のイメージに移動する必要があるフェールオーバーシナリオの場合、プライマリイメージへのアクセスを停止し、現在のプライマリイメージを降格してから、新しいプライマリイメージを昇格し、代替クラスタ上のイメージへのアクセスを再開する必要があります。
    </para>
    <para>
     特定のイメージを非プライマリに降格するには、<command>mirror image demote</command>サブコマンドと共にプール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image demote image-pool/image-1</screen>
    <para>
     プール内のすべてのプライマリイメージを非プライマリに降格するには、<command>mirror pool demote</command>サブコマンドと共にプール名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool demote image-pool</screen>
    <para>
     特定のイメージをプライマリに昇格するには、<command>mirror image promote</command>サブコマンドと共にプール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster remote mirror image promote image-pool/image-1</screen>
    <para>
     プール内のすべての非プライマリイメージをプライマリに昇格するには、<command>mirror pool promote</command>サブコマンドと共にプール名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool promote image-pool</screen>
    <tip>
     <title>I/O負荷の分割</title>
     <para>
      プライマリまたは非プライマリの状態はイメージごとなので、2つのクラスタでIO負荷を分割したり、フェールオーバーまたはフェールバックを実行したりできます。
     </para>
    </tip>
    <note>
     <title>強制昇格</title>
     <para>
      <option>--force</option>オプションを使用して昇格を強制できます。強制昇格は、降格をピアクラスタに伝搬できない場合(たとえば、クラスタ障害や通信停止が発生した場合)に必要です。この結果、2つのピア間でスプリットブレインシナリオが発生し、<command>resync</command>サブコマンドを発行するまでイメージは同期されなくなります。
     </para>
    </note>
   </sect3>
   <sect3>
    <title>イメージの再同期の強制</title>
    <para>
     <systemitem>rbd-mirror</systemitem>デーモンがスプリットブレインイベントを検出した場合、このデーモンは、イベントが修正されるまで、影響を受けるイメージのミラーリングを試行しません。イメージのミラーリングを再開するには、まず、古いと判定されたイメージを降格してから、プライマリイメージへの再同期を要求します。イメージの再同期を要求するには、<command>mirror image resync</command>サブコマンドと共にプール名とイメージ名を指定します。
    </para>
<screen><prompt>root # </prompt>rbd mirror image resync image-pool/image-1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="rbd.mirror.status">
   <title>ミラーの状態</title>
   <para>
    ピアクラスタのレプリケーションの状態は、ミラーリングされたすべてのプライマリイメージについて保存されます。この状態は、<command>mirror image status</command>および<command>mirror pool status</command>の各サブコマンドを使用して取得できます。
   </para>
   <para>
    ミラーイメージの状態を要求するには、<command>mirror image status</command>サブコマンドと共にプール名とイメージ名を指定します。
   </para>
<screen><prompt>root # </prompt>rbd mirror image status image-pool/image-1</screen>
   <para>
    ミラープールのサマリ状態を要求するには、<command>mirror pool status</command>サブコマンドと共にプール名を指定します。
   </para>
<screen><prompt>root # </prompt>rbd mirror pool status image-pool</screen>
   <tip>
    <title/>
    <para>
     <command>mirror pool status</command>サブコマンドに<option>--verbose</option>オプションを追加すると、プール内にあるすべてのミラーリングイメージについて状態の詳細も出力されます。
    </para>
   </tip>
  </sect2>
 </sect1>
</chapter>
