<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_nfsganesha.xml" version="5.0" xml:id="cha-ceph-nfsganesha">

 <title>NFS Ganesha: NFS経由でのCephデータのエクスポート</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>編集</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>yes</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  NFS Ganeshaは、オペレーティングシステムカーネルの一部としてではなく、ユーザアドレススペースで動作するNFSサーバです(「<link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-nfs.html">Sharing File Systems with NFS</link>」を参照してください)。NFS Ganeshaを使用することで、Cephなど独自のストレージメカニズムをプラグインして、任意のNFSクライアントからアクセスできます。
 </para>
 <para>
  S3バケットはユーザごとにNFSにエクスポートされます。たとえば、パス<filename><replaceable>GANESHA_NODE:</replaceable>/<replaceable>USERNAME</replaceable>/<replaceable>BUCKETNAME</replaceable></filename>を使用してエクスポートされます。
 </para>
 <para>
  CephFSは、デフォルトではパス<filename><replaceable>GANESHA_NODE:</replaceable>/cephfs</filename>を介してエクスポートされます。
 </para>
 <note>
  <title>NFS Ganeshaのパフォーマンス</title>
  <para>
   プロトコルオーバーヘッドが増加し、クライアントとストレージ間の余分なネットワークホップによって追加の遅延が発生するため、NFSゲートウェイ経由でCephにアクセスすると、ネイティブのCephFSまたはObject Gatewayクライアントと比較して、アプリケーションのパフォーマンスが大幅に低下する場合があります。
  </para>
 </note>
 <sect1 xml:id="ceph-nfsganesha-install">
  <title>インストール</title>

  <para>
   詳細については、<xref linkend="cha-as-ganesha"/>を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-config">
  <title>設定</title>

  <para>
   設定ファイルで利用可能なすべてのパラメータのリストについては、次のマニュアルページを参照してください。
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>man ganesha-config</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-ceph-config</command> (CephFS FSAL (File System Abstraction Layer)のオプション)
    </para>
   </listitem>
   <listitem>
    <para>
     <command>man ganesha-rgw-config</command> (Object GatewayのFSALのオプション)
    </para>
   </listitem>
  </itemizedlist>

  <para>
   このセクションには、Object GatewayとCephFSを介してアクセス可能なクラスタデータをエクスポートするようNFS Ganeshaサーバを設定する際に役立つ情報が記載されています。
  </para>

  <para>
   NFS Ganeshaの設定は、サービスの設定とエクスポートの設定の2つの部分で構成されます。サービスの設定は、<filename>/etc/ganesha/ganesha.conf</filename>で制御します。DeepSeaステージ4を実行すると、このファイルへの変更が上書きされることに注意してください。設定を永続的に変更するには、Salt Master上にあるファイル<filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename>を編集します。エクスポートの設定は、CephクラスタにRADOSオブジェクトとして保存されます。
  </para>

  <sect2 xml:id="ceph-nfsganesha-config-service-general">
   <title>サービスの設定</title>
   <para>
    サービスの設定は、<filename>/etc/ganesha/ganesha.conf</filename>に保存され、すべてのNFS Ganeshaデーモンの設定を制御します。これには、エクスポートの設定を保存するCephクラスタ内の場所も含まれます。DeepSeaステージ4を実行すると、このファイルへの変更が上書きされることに注意してください。設定を永続的に変更するには、Salt Master上にあるファイル<filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename>を編集します。
   </para>
   <sect3 xml:id="ceph-nfsganesha-config-service-rados">
    <title>RADOS_URLSセクション</title>
    <para>
     <literal>RADOS_URLS</literal>セクションでは、RADOSオブジェクトからNFS Ganeshaの設定を読み込むためのCephクラスタアクセスを設定します。
    </para>
<screen>RADOS_URLS {
  Ceph_Conf = /etc/ceph/ceph.conf;

  UserId = "ganesha.<replaceable>MINION_ID</replaceable>";
  watch_url = "rados://<replaceable>RADOS_POOL</replaceable>/ganesha/conf-<replaceable>MINION_ID</replaceable>";
}</screen>
    <variablelist>
     <varlistentry>
      <term>Ceph_Conf</term>
      <listitem>
       <para>
        Ceph設定ファイルパスの場所。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>UserId</term>
      <listitem>
       <para>
        CephXのユーザID。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>watch_url</term>
      <listitem>
       <para>
        リロード通知を監視するRADOSオブジェクトのURL。
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-service-rgw">
    <title>RGWセクション</title>
<screen>RGW {
  ceph_conf = "/etc/ceph/ceph.conf";
  name = "name";
  cluster = "ceph";
}</screen>
    <variablelist>
     <varlistentry>
      <term>ceph_conf</term>
      <listitem>
       <para>
        <filename>ceph.conf</filename>ファイルを指します。DeepSeaを使用して展開する場合は、この値を変更する必要はありません。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>name</term>
      <listitem>
       <para>
        NFS Ganeshaによって使用されるCephクライアントユーザの名前。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>cluster</term>
      <listitem>
       <para>
        Cephクラスタの名前。SUSE Enterprise Storage 6で現在サポートされているクラスタ名は1つだけです(デフォルトは<literal>ceph</literal>)。
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-service-url">
    <title>RADOSオブジェクトのURL</title>
<screen>%url rados://<replaceable>RADOS_POOL</replaceable>/ganesha/conf-<replaceable>MINION_ID</replaceable></screen>
    <para>
     NFS Ganeshaは、RADOSオブジェクトから設定を読み込むことができます。<literal>%url</literal>ディレクティブにより、RADOSオブジェクトの場所を特定するRADOS URLを指定できます。
    </para>
    <para>
     RADOS URLには、<literal>rados://&lt;POOL&gt;/&lt;OBJECT&gt;</literal>または<literal>rados://&lt;POOL&gt;/&lt;NAMESPACE&gt;/&lt;OBJECT&gt;</literal>の2つの形式があります。ここで、<literal>POOL</literal>はオブジェクトが保存されているRADOSプール、<literal>NAMESPACE</literal>はオブジェクトが保存されているプールネームスペース、<literal>OBJECT</literal>はオブジェクト名です。
    </para>
    <para>
     CephダッシュボードのNFS Ganesha管理機能をサポートするには、各サービスデーモンについてRADOSオブジェクトの名前の規則に従う必要があります。オブジェクトの名前は、<literal>conf-<replaceable>MINION_ID</replaceable></literal>の形式である必要があります。ここで、MINION_IDは、このサービスが実行されているノードのSalt Minion IDに対応します。
    </para>
    <para>
     このURLはDeepSeaによってすでに正しく生成されているので、変更する必要はありません。
    </para>
   </sect3>
   <sect3 xml:id="ganesha-nfsport">
    <title>NFS Ganeshaのデフォルトポートの変更</title>
    <para>
     NFS Ganeshaは、NFSにポート2049、rquotaサポートに875をデフォルトで使用します。デフォルトのポート番号を変更するには、<literal>NFS_CORE_PARAM</literal>セクション内で<option>NFS_Port</option>および<option>RQUOTA_Port</option>のオプションを使用します。次に例を示します。
    </para>
<screen>
NFS_CORE_PARAM
{
NFS_Port = 2060;
RQUOTA_Port = 876;
}
</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-config-exports-general">
   <title>エクスポートの設定</title>
   <para>
    エクスポートの設定は、Cephクラスタ内にRADOSオブジェクトとして保存されます。各エクスポートブロックは、専用のRADOSオブジェクトに<literal>export-&lt;id&gt;</literal>という名前で保存されます。ここで、<literal>&lt;id&gt;</literal>は、エクスポートの設定の<literal>Export_ID</literal>属性に一致する必要があります。エクスポートとNFS Ganeshaサービスとの間の関連付けは、<literal>conf-MINION_ID</literal>オブジェクトを介して実行されます。各サービスオブジェクトには、そのサービスによってエクスポートされる各エクスポートのRADOS URLのリストが含まれます。エクスポートブロックは次のようになります。
   </para>
<screen>EXPORT
{
  Export_Id = 1;
  Path = "/";
  Pseudo = "/";
  Access_Type = RW;
  Squash = No_Root_Squash;
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
   <para>
    上のエクスポートブロックに対してRADOSオブジェクトを作成するには、まず、このエクスポートブロックコードをファイルに保存する必要があります。次に、RADOS CLIツールを使用して、以前に保存したファイルの内容をRADOSオブジェクトに保存できます。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>rados -p <replaceable>POOL</replaceable> -N <replaceable>NAMESPACE</replaceable> put export-<replaceable>EXPORT_ID</replaceable> <replaceable>EXPORT_FILE</replaceable>
</screen>
   <para>
    エクスポートオブジェクトを作成したら、エクスポートオブジェクトの対応するRADOS URLをサービスオブジェクトに追加して、そのサービスインスタンスにエクスポートを関連付けることができます。以降のセクションでは、エクスポートブロックの設定方法について説明します。
   </para>
   <sect3 xml:id="ceph-nfsganesha-config-general-export">
    <title>Exportの主要セクション</title>
    <variablelist>
     <varlistentry>
      <term>Export_Id</term>
      <listitem>
       <para>
        各エクスポートには固有の「Export_Id」が必要です(必須)。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Path</term>
      <listitem>
       <para>
        関連するCephFSプール内のエクスポートパス(必須)。これにより、CephFSからサブディレクトリをエクスポートできます。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Pseudo</term>
      <listitem>
       <para>
        ターゲットNFSのエクスポートパス(NFSv4では必須)。エクスポートデータを利用可能なNFSのエクスポートパスを定義します。
       </para>
       <para>
        例: 値<literal>/cephfs/</literal>を使用して、次のコマンドを実行したとします。
       </para>
<screen>
<prompt>root # </prompt>mount <replaceable>GANESHA_IP</replaceable>:/cephfs/ /mnt/
</screen>
       <para>
        これにより、CephFSのデータがクライアントのディレクトリ<filename>/mnt/cephfs/</filename>で利用可能になります。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Access_Type</term>
      <listitem>
       <para>
        読み込み専用アクセスの場合は「RO」、読み込み/書き込みアクセスの場合は「RW」、アクセスなしの場合は「None」です。
       </para>
       <tip>
        <title>アクセスをクライアントに制限する</title>
        <para>
         メインの<literal>EXPORT</literal>セクションに<literal>Access_Type = RW</literal>を残し、特定のクライアントへのアクセスを<literal>CLIENT</literal>セクションで制限した場合、他のクライアントは接続できます。すべてのクライアントのアクセスを無効にし、特定のクライアントのアクセスのみを有効にするには、<literal>EXPORT</literal>セクションで<literal>Access_Type = None</literal>を設定し、<literal>CLIENT</literal>セクションで、1つ以上のクライアントに、より制限の少ないアクセスモードを指定します。
        </para>
<screen>
EXPORT {

	FSAL {
 access_type = "none";
 [...]
 }

 CLIENT {
		clients = 192.168.124.9;
		access_type = "RW";
		[...]
 }
[...]
}
</screen>
       </tip>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Squash</term>
      <listitem>
       <para>
        NFSのsquash (ルート権限無効化)オプション。
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>FSAL</term>
      <listitem>
       <para>
        「File System Abstraction Layer」をエクスポートします。詳細については、<xref linkend="ceph-nfsganesha-config-general-fsal"/>を参照してください。
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-nfsganesha-config-general-fsal">
    <title>FSALサブセクション</title>
<screen>EXPORT
{
  [...]
  FSAL {
    Name = CEPH;
  }
}</screen>
    <variablelist>
     <varlistentry>
      <term>Name</term>
      <listitem>
       <para>
        NFS Ganeshaが使用するバックエンドを定義します。使用できる値は、CephFSの場合は<literal>CEPH</literal>、Object Gatewayの場合は<literal>RGW</literal>です。選択した値に応じて、<filename>policy.cfg</filename>で<literal>role-mds</literal>または<literal>role-rgw</literal>を定義する必要があります。
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-customrole">
  <title>NFS Ganeshaのカスタムの役割</title>

  <para>
   クラスタノード用にNFS Ganeshaのカスタムの役割を定義できます。その後、これらの役割を<filename>policy.cfg</filename>でノードに割り当てます。これらの役割により、以下が可能になります。
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Object GatewayとCephFSにアクセスするために別々のNFS Ganeshaノードを使用する。
    </para>
   </listitem>
   <listitem>
    <para>
     複数のNFS Ganeshaノードに異なるObject Gatewayユーザを割り当てる。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   複数のObject Gatewayユーザを使用することで、複数のNFS Ganeshaノードから異なるS3バケットにアクセスできます。S3バケットをアクセス制御に使用できます。注: S3バケットを、CRUSHマップで使用されるCephのバケットと混同しないでください。
  </para>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-multiusers">
   <title>NFS Ganesha用の異なるObject Gatewayユーザ</title>
   <para>
    次に示すSalt Master用の手順の例では、異なるObject Gatewayユーザを持つ2つのNFS Ganeshaの役割を作成する方法について説明します。この例では、役割<literal>gold</literal>と<literal>silver</literal>を使用します。これらの役割には、DeepSeaによってサンプル設定ファイルがすでに用意されています。
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-rgw-multiusers">
    <step>
     <para>
      ファイル<filename>/srv/pillar/ceph/stack/global.yml</filename>を好みのエディタで開きます。ファイルが存在しない場合は作成します。
     </para>
    </step>
    <step>
     <para>
      このファイルには次の行が含まれる必要があります。
     </para>
<screen>rgw_configurations:
  - rgw
  - silver
  - gold
ganesha_configurations:
  - silver
  - gold</screen>
     <para>
      後で、これらの役割を<filename>policy.cfg</filename>で割り当てることができます。
     </para>
    </step>
    <step>
     <para>
      ファイル<filename>/srv/salt/ceph/rgw/users/users.d/gold.yml</filename>を作成して、次の内容を追加します。
     </para>
<screen>- { uid: "gold1", name: "gold1", email: "gold1@demo.nil" }</screen>
     <para>
      ファイル<filename>/srv/salt/ceph/rgw/users/users.d/silver.yml</filename>を作成して、次の内容を追加します。
     </para>
<screen>- { uid: "silver1", name: "silver1", email: "silver1@demo.nil" }</screen>
    </step>
    <step>
     <para>
      ここで、各役割に対して<filename>ganesha.conf</filename>のテンプレートを作成する必要があります。DeepSeaの元のテンプレートを利用するのが便利です。コピーを2つ作成します。
     </para>
<screen><prompt>root@master # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root@master # </prompt><command>cp</command> ganesha.conf.j2 silver.conf.j2
<prompt>root@master # </prompt><command>cp</command> ganesha.conf.j2 gold.conf.j2</screen>
    </step>
    <step>
     <para>
      新しい役割には、クラスタにアクセスするためのキーリングが必要です。アクセスを提供するため、<filename>ganesha.j2</filename>をコピーします。
     </para>
<screen><prompt>root@master # </prompt><command>cp</command> ganesha.j2 silver.j2
<prompt>root@master # </prompt><command>cp</command> ganesha.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Object Gatewayのキーリングをコピーします。
     </para>
<screen><prompt>root@master # </prompt><command>cd</command> /srv/salt/ceph/rgw/files/
<prompt>root@master # </prompt><command>cp</command> rgw.j2 silver.j2
<prompt>root@master # </prompt><command>cp</command> rgw.j2 gold.j2</screen>
    </step>
    <step>
     <para>
      Object Gatewayに、異なる役割用の設定も必要です。
     </para>
<screen><prompt>root@master # </prompt><command>cd</command> /srv/salt/ceph/configuration/files/
<prompt>root@master # </prompt><command>cp</command> ceph.conf.rgw silver.conf
<prompt>root@master # </prompt><command>cp</command> ceph.conf.rgw gold.conf</screen>
    </step>
    <step>
     <para>
      <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>で、新しく作成した役割をクラスタノードに割り当てます。
     </para>
<screen>role-silver/cluster/<replaceable>NODE1</replaceable>.sls
role-gold/cluster/<replaceable>NODE2</replaceable>.sls
 </screen>
     <para>
      <replaceable>NODE1</replaceable>および<replaceable>NODE2</replaceable>は、役割の割り当て先にするノードの名前に置き換えてください。
     </para>
    </step>
    <step>
     <para>
      DeepSeaステージ0～4を実行します。
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ceph-nfsganesha-customrole-rgw-cephfs">
   <title>CephFSとObject GatewayのFSALの分離</title>
   <para>
    次に示すSalt Master用の手順の例では、CephFSとObject Gatewayを使用する2つの異なる役割を新しく作成する方法について説明します。
   </para>
   <procedure xml:id="proc-ceph-nfsganesha-customrole">
    <step>
     <para>
      ファイル<filename>/srv/pillar/ceph/rgw.sls</filename>を好みのエディタで開きます。ファイルが存在しない場合は作成します。
     </para>
    </step>
    <step>
     <para>
      このファイルには次の行が含まれる必要があります。
     </para>
<screen>rgw_configurations:
  ganesha_cfs:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }
  ganesha_rgw:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }

ganesha_configurations:
  - ganesha_cfs
  - ganesha_rgw</screen>
     <para>
      後で、これらの役割を<filename>policy.cfg</filename>で割り当てることができます。
     </para>
    </step>
    <step>
     <para>
      ここで、各役割に対して<filename>ganesha.conf</filename>のテンプレートを作成する必要があります。DeepSeaの元のテンプレートを利用するのが便利です。コピーを2つ作成します。
     </para>
<screen><prompt>root@master # </prompt><command>cd</command> /srv/salt/ceph/ganesha/files/
<prompt>root@master # </prompt><command>cp</command> ganesha.conf.j2 ganesha_rgw.conf.j2
<prompt>root@master # </prompt><command>cp</command> ganesha.conf.j2 ganesha_cfs.conf.j2</screen>
    </step>
    <step>
     <para>
      <filename>ganesha_rgw.conf.j2</filename>を編集して次のセクションを削除します。
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles='mds') != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      <filename>ganesha_cfs.conf.j2</filename>を編集して次のセクションを削除します。
     </para>
<screen>{% if salt.saltutil.runner('select.minions', cluster='ceph', roles=role) != [] %}
        [...]
{% endif %}</screen>
    </step>
    <step>
     <para>
      新しい役割には、クラスタにアクセスするためのキーリングが必要です。アクセスを提供するため、<filename>ganesha.j2</filename>をコピーします。
     </para>
<screen><prompt>root@master # </prompt><command>cp</command> ganesha.j2 ganesha_rgw.j2
<prompt>root@master # </prompt><command>cp</command> ganesha.j2 ganesha_cfs.j2</screen>
     <para>
      行<literal>caps mds = "allow *"</literal>は<filename>ganesha_rgw.j2</filename>から削除できます。
     </para>
    </step>
    <step>
     <para>
      Object Gatewayのキーリングをコピーします。
     </para>
<screen><prompt>root@master # </prompt><command>cp</command> /srv/salt/ceph/rgw/files/rgw.j2 \
/srv/salt/ceph/rgw/files/ganesha_rgw.j2</screen>
    </step>
    <step>
     <para>
      Object Gatewayに、新しい役割用の設定が必要です。
     </para>
<screen><prompt>root@master # </prompt><command>cp</command> /srv/salt/ceph/configuration/files/ceph.conf.rgw \
/srv/salt/ceph/configuration/files/ceph.conf.ganesha_rgw</screen>
    </step>
    <step>
     <para>
      <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>で、新しく作成した役割をクラスタノードに割り当てます。
     </para>
<screen>role-ganesha_rgw/cluster/<replaceable>NODE1</replaceable>.sls
role-ganesha_cfs/cluster/<replaceable>NODE1</replaceable>.sls
 </screen>
     <para>
      <replaceable>NODE1</replaceable>および<replaceable>NODE2</replaceable>は、役割の割り当て先にするノードの名前に置き換えてください。
     </para>
    </step>
    <step>
     <para>
      DeepSeaステージ0～4を実行します。
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ganesha-rgw-supported-operations">
   <title>サポートされている操作</title>
   <para>
    RGW NFSインタフェースは、ファイルおよびディレクトリに対するほとんどの操作をサポートしていますが、次の制限があります。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis/>シンボリックリンクを含むリンクはサポートされていません。
     </para>
    </listitem>
    <listitem>
     <para>
      NFSのACL (アクセス制御リスト)はサポートされていません。<emphasis/>Unixのユーザ、グループ所有権、およびグループ許可はサポートされて「います」。<emphasis/>
     </para>
    </listitem>
    <listitem>
     <para>
      ディレクトリを移動または名前変更することはできません。<emphasis/>ディレクトリ間でファイルを移動することは「できます」。<emphasis/>
     </para>
    </listitem>
    <listitem>
     <para>
      完全なシーケンシャル書き込みI/Oのみがサポートされています。<emphasis/>したがって、書き込み操作は強制的にアップロードになります。ファイルの編集などの多くの一般的なI/O操作は、非シーケンシャルストアを実行するため必ず失敗します。明らかにシーケンシャルな書き込みを行うファイルユーティリティがありますが(たとえば、GNU <command>tar </command>の一部のバージョンなど)、頻度の低い非シーケンシャルストアのために失敗することがあります。NFS経由でマウントする場合、アプリケーションのシーケンシャルI/Oは通常、同期マウント(<option>-o sync</option>オプション)によって、NFSサーバへのシーケンシャル書き込みを強制的に実行することができます。同期マウントできないNFSクライアント(Microsoft Windowsなど*)はファイルをアップロードできません。
     </para>
    </listitem>
    <listitem>
     <para>
      NFS RGWは、4MB未満のブロックサイズの読み書き操作のみをサポートします。
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-services">
  <title>NFS Ganeshaの起動または再起動</title>

  <para>
   NFS Ganeshaサービスを有効にして起動するには、次のコマンドを実行します。
  </para>

<screen><prompt>root@minion &gt; </prompt><command>systemctl</command> enable nfs-ganesha
<prompt>root@minion &gt; </prompt><command>systemctl</command> start nfs-ganesha</screen>

  <para>
   次のコマンドを使用して、NFS Ganeshaを再起動します。
  </para>

<screen><prompt>root@minion &gt; </prompt><command>systemctl</command> restart nfs-ganesha</screen>

  <para>
   NFS Ganeshaが起動または再起動した時点では、NFS v4に90秒の猶予タイムアウトが設定されています。猶予期間中、クライアントからの新しい要求はアクティブに拒否されます。したがって、NFSが猶予状態の場合、クライアントで要求の低速化が発生することがあります。
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-loglevel">
  <title>ログレベルの設定</title>

  <para>
   デフォルトのデバッグレベル<literal>NIV_EVENT</literal>を変更するには、ファイル<filename>/etc/sysconfig/nfs-ganesha</filename>を編集します。<literal>NIV_EVENT</literal>を<literal>NIV_DEBUG</literal>または<literal>NIV_FULL_DEBUG</literal>に置き換えます。ログの詳細度を上げると、ログファイル内に大量のデータが生成される可能性があります。
  </para>

<screen>OPTIONS="-L /var/log/ganesha/ganesha.log -f /etc/ganesha/ganesha.conf -N NIV_EVENT"</screen>

  <para>
   ログレベルを変更した場合、サービスの再起動が必要です。
  </para>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-verify">
  <title>エクスポートされたNFS共有の検証</title>

  <para>
   NFS v3を使用する場合、NFS共有がNFS Ganeshaサーバノード上にエクスポートされているかどうかを検証できます。
  </para>

<screen><prompt>root@minion &gt; </prompt><command>showmount</command> -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph-nfsganesha-mount">
  <title>エクスポートされたNFS共有のマウント</title>

  <para>
   エクスポートされたNFS共有(<xref linkend="ceph-nfsganesha-config"/>で設定)をクライアントホストにマウントするには、次のコマンドを実行します。
  </para>

<screen><prompt>root # </prompt><command>mount</command> -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
</chapter>
