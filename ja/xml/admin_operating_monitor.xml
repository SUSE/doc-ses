<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>クラスタの状態の判断</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:translation>yes</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  実行中のクラスタがある場合、<command>ceph</command>ツールを使用して監視できます。一般的に、クラスタの状態の判断には、Ceph OSD、Ceph Monitor、配置グループ、およびMetadata Serverのステータスを確認します。
 </para>
 <tip>
  <title>インタラクティブモード</title>
  <para>
   <command>ceph</command>ツールをインタラクティブモードで実行するには、コマンドラインで引数を付けずに「<command>ceph</command>」と入力します。インタラクティブモードは、1行に多くの<command>ceph</command>コマンドを入力する場合に便利です。次に例を示します。
  </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon_status</screen>
 </tip>
 <sect1 xml:id="monitor-status">
  <title>クラスタの状態の確認</title>

  <para>
   クラスタの状態を確認するには、次のコマンドを実行します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph status</screen>

  <para>
   または
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph -s</screen>

  <para>
   インタラクティブモードで、「<command>status</command>」と入力して<keycap function="enter"/>キーを押します。
  </para>

<screen>ceph&gt; status</screen>

  <para>
   クラスタの状態が出力されます。たとえば、1つのMonitorと2つのOSDで構成される小規模なCephクラスタでは、次の内容が出力される場合があります。
  </para>

<screen>cluster b370a29d-9287-4ca3-ab57-3d824f65e339
 health HEALTH_OK
 monmap e1: 1 mons at {ceph1=10.0.0.8:6789/0}, election epoch 2, quorum 0 ceph1
 osdmap e63: 2 osds: 2 up, 2 in
  pgmap v41332: 952 pgs, 20 pools, 17130 MB data, 2199 objects
        115 GB used, 167 GB / 297 GB avail
               1 active+clean+scrubbing+deep
             951 active+clean</screen>
 </sect1>
 <sect1 xml:id="monitor-health">
  <title>クラスタのヘルスの確認</title>

  <para>
   クラスタの起動後、データの読み込みや書き込みを開始する前に、クラスタのヘルスを確認します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <tip>
   <para>
    設定またはキーリングにデフォルト以外の場所を指定した場合、その場所を指定できます。
   </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>

  <para>
   Cephクラスタは、次のいずれかのヘルスコードを返します。
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      1つ以上のOSDにダウン状態を示すマークが付いています。OSDデーモンが停止されているか、ピアOSDがネットワーク経由でOSDに接続できない可能性があります。一般的な原因として、デーモンの停止またはクラッシュ、ホストのダウン、ネットワークの停止などがあります。
     </para>
     <para>
      ホストが正常である場合、デーモンは起動していて、ネットワークは機能しています。デーモンがクラッシュした場合は、そのデーモンのログファイル(<filename>/var/log/ceph/ceph-osd.*</filename>)にデバッグ情報が記述されていることがあります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>crush type</replaceable>_DOWN (例: OSD_HOST_DOWN)</term>
    <listitem>
     <para>
      特定のCRUSHサブツリー内のすべてのOSD (たとえば、特定のホスト上のすべてのOSD)にダウン状態を示すマークが付いています。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      OSDがCRUSHマップ階層で参照されていますが、存在しません。次のコマンドを使用して、OSDをCRUSH階層から削除できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      <emphasis/>「backfillfull」(デフォルトは0.90)、<emphasis/>「nearfull」(デフォルトは0.85)、<emphasis/>「full」(デフォルトは0.95)、または<emphasis/>「failsafe_full」、あるいはこれらすべての使用量のしきい値が昇順になっていません。特に、<emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>、<emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis>、<emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>となっている必要があります。
     </para>
     <para>
      現在の値を読み込むには、次のコマンドを実行します。
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph health detail
HEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)
osd.3 is full at 97%
osd.4 is backfill full at 91%
osd.2 is near full at 87%
</screen>
     <para>
      次のコマンドを使用してしきい値を調整できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>full</emphasis>のしきい値を超えており、クラスタは書き込みを実行できません。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph df</screen>
     <para>
      次のコマンドを使用して、現在定義されている<emphasis>full</emphasis>の比率を確認できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      書き込み可用性を復元するための短期的な回避策は、fullのしきい値を少し高くすることです。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      さらにOSDを展開してクラスタに新しいストレージを追加するか、既存のデータを削除して領域を解放します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>backfillfull</emphasis>のしきい値を超えており、データをこのデバイスにリバランスできません。これは、リバランスを完了できないこと、およびクラスタが満杯に近付いていることを示す早期警告です。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      1つ以上のOSDが<emphasis>nearfull</emphasis>のしきい値を超えています。これは、クラスタが満杯に近付いていることを示す早期警告です。次のコマンドを使用して、プールごとの使用量を確認できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      関心のあるクラスタフラグが1つ以上設定されています。「full」<emphasis/>を除き、これらのフラグは次のコマンドを使用して設定またはクリアできます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      次のようなフラグがあります。
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         クラスタにfullのフラグが付いており、書き込みを実行できません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd、pausewr</term>
       <listitem>
        <para>
         読み込みまたは書き込みを一時停止しました。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         OSDの起動が許可されていません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         OSD障害レポートが無視されているため、MonitorはOSDに「down」<emphasis/>のマークを付けません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         以前に「out」<emphasis/>のマークが付けられているOSDには、起動時に「in」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         設定した間隔が経過した後、「down」<emphasis/>状態のOSDに自動的に「out」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill、norecover、norebalance</term>
       <listitem>
        <para>
         回復またはデータリバランスは中断されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub、nodeep_scrub</term>
       <listitem>
        <para>
         スクラブ(<xref linkend="scrubbing"/>を参照)は無効化されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         キャッシュ階層化アクティビティは中断されます。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      1つ以上のOSDに、関心のあるOSDごとのフラグが付いています。次のようなフラグがあります。
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         OSDの起動が許可されていません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         このOSD障害レポートは無視されます。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         障害後に、このOSDにすでに自動的に「out」<emphasis/>のマークが付けられている場合、起動時に「in」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         このOSDがダウンしている場合、設定した間隔が経過した後に自動的に「out」<emphasis/>のマークは付けられません。
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      次のコマンドを使用して、OSDごとのフラグを設定およびクリアできます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      CRUSHマップは非常に古い設定を使用しており、更新する必要があります。このヘルス警告をトリガさせることなく使用できる最も古い調整可能パラメータ(すなわち、クラスタに接続できる最も古いクライアントバージョン)は、<option>mon_crush_min_required_version</option>設定オプションで指定します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      CRUSHマップは、strawバケットの中間重み値の計算に、最適ではない古い手法を使用しています。新しい手法を使用するようCRUSHマップを更新する必要があります(<option>straw_calc_version</option>=1)。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      使用量を追跡するためのヒットセットが1つ以上のキャッシュプールに設定されておらず、階層化エージェントはキャッシュからフラッシュまたは削除するコールドオブジェクトを識別できません。次のコマンドを使用して、キャッシュプールにヒットセットを設定できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
     <para>
      キャッシュ階層化の詳細については、<xref linkend="cha-ceph-tiered"/>を参照してください。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      Luminous v12より前のOSDは実行されていませんが、<option>sortbitwise</option>フラグが付いていません。Luminous v12以上のOSDを起動する前に、<option>sortbitwise</option>フラグを設定する必要があります。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに達しており、書き込みをこれ以上許可していません。次のコマンドを使用して、プールのクォータと使用量を設定できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph df detail</screen>
     <para>
      次のコマンドを使用して、プールのクォータを増加できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      または、既存のデータを削除して使用量を削減できます。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      データ可用性が低下しています。つまり、クラスタは、クラスタ内の一部のデータに対する潜在的な読み込みまたは書き込み要求を実行できません。具体的には、1つ以上のPGがI/O要求の実行を許可していない状態です。問題があるPGの状態には、「peering」<emphasis/>、「stale」<emphasis/>、「incomplete」<emphasis/>、および「active」の欠如<emphasis/>などがあります(これらの状態がすぐにはクリアされない場合)。影響を受けるPGについての詳しい情報は、次のコマンドを使用して参照できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph health detail</screen>
     <para>
      ほとんどの場合、根本原因は、現在1つ以上のOSDがダウンしていることです。次のコマンドを使用して、問題がある特定のPGの状態を問い合わせることができます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      一部のデータのデータ冗長性が低下しています。つまり、一部のデータについて必要な数のレプリカがクラスタにないか(複製プールの場合)、イレージャコードのフラグメントがクラスタにありません(イレージャコーディングプールの場合)。具体的には、1つ以上のPGに「degraded」<emphasis/>または「undersized」<emphasis/>のフラグが付いているか(クラスタ内にその配置グループの十分なインスタンスがありません)、またはしばらくの間「clean」<emphasis/>フラグが付いていません。影響を受けるPGについての詳しい情報は、次のコマンドを使用して参照できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph health detail</screen>
     <para>
      ほとんどの場合、根本原因は、現在1つ以上のOSDがダウンしていることです。次のコマンドを使用して、問題がある特定のPGの状態を問い合わせることができます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      クラスタに空き領域がないため、一部のデータのデータ冗長性が低下しているか、危険な状態である可能性があります。具体的には、1つ以上のPGに「backfill_toofull」<emphasis/>または「recovery_toofull」<emphasis/>のフラグが付いています。つまり、1つ以上のOSDが<emphasis>backfillfull</emphasis>のしきい値を超えているため、クラスタはデータを移行または回復できません。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      データスクラブ(<xref linkend="scrubbing"/>を参照)によってクラスタのデータ整合性に問題が検出されました。具体的には、1つ以上のPGに「inconsistent」<emphasis/>または「snaptrim_error」<emphasis/>のフラグが付いています。これは、前のスクラブ操作で問題が見つかったか、「repair」<emphasis/>フラグが設定されていることを示しており、現在その不整合の修復が進行中であることを意味します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      最近のOSDスクラブで不整合が発見されました。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      キャッシュ層プールがほぼ満杯です。このコンテキストにおける「満杯」は、キャッシュプールの「target_max_bytes」<emphasis/>および「target_max_objects」<emphasis/>のプロパティによって判断されます。プールがターゲットしきい値に達した場合、データがキャッシュからフラッシュまたは削除される間、プールへの書き込み要求がブロックされることがあり、通常はレイテンシが非常に高くなり、パフォーマンスが低下する状態になります。次のコマンドを使用して、キャッシュプールのターゲットサイズを調整できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      通常のキャッシュフラッシュおよび削除アクティビティは、基本層の可用性またはパフォーマンスの低下、あるいはクラスタ全体の負荷によっても低速になることがあります。
     </para>
     <para>
      キャッシュ階層化の詳細については、<xref linkend="cha-ceph-tiered"/>を参照してください。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      使用中のPGの数が、設定可能なしきい値である、OSDあたりの<option>mon_pg_warn_min_per_osd</option>のPG数未満です。このため、クラスタ内のOSDへのデータの分散とバランスが最適ではなくなり、全体的なパフォーマンスが低下します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      使用中のPGの数が、設定可能なしきい値である、OSDあたりの<option>mon_pg_warn_max_per_osd</option>のPG数を超えています。このため、OSDデーモンのメモリ使用量が増加する、クラスタの状態が変化(たとえば、OSDの再起動、追加、削除)した後にピアリングの速度が低下する、Ceph ManagerとCeph Monitorの負荷が増加するなどの可能性があります。
     </para>
     <para>
      既存のプールの<option>pg_num</option>の値を下げることはできませんが、<option>pgp_num</option>の値は下げることができます。これによって、同じOSDセットの複数のPGを効果的に一緒に配置して、前に説明した悪影響を多少緩和できます。次のコマンドを使用して、<option>pgp_num</option>の値を調整できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      1つ以上のプールの<option>pgp_num</option>の値が<option>pg_num</option>未満です。これは通常、配置動作を同時に増やさずにPG数を増やしたことを示します。通常は、次のコマンドを使用して、<option>pgp_num</option>を<option>pg_num</option>に一致するよう設定し、データマイグレーションをトリガすることによって解決します。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      1つ以上のプールで、PGあたりの平均オブジェクト数がクラスタの全体の平均を大幅に超過しています。具体的なしきい値は、<option>mon_pg_warn_max_object_skew</option>の設定値で制御します。これは通常、クラスタ内のほとんどのデータを含むプールのPGが少なすぎるか、それほど多くのデータを含まない他のプールのPGが多すぎるか、またはその両方であることを示します。Monitorの<option>mon_pg_warn_max_object_skew</option>設定オプションを調整することによって、しきい値を上げてヘルス警告を停止できます。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      1つ以上のオブジェクトが含まれるプールが存在しますが、特定のアプリケーション用のタグが付けられていません。この警告を解決するには、プールにアプリケーション用のラベルを付けます。たとえば、プールがRBDによって使用される場合は、次のコマンドを実行します。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      プールがカスタムアプリケーション「foo」によって使用されている場合、次の低レベルのコマンドを使用してラベルを付けることもできます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに達しています(またはクォータに非常に近付いています)。このエラー条件をトリガするためのしきい値は、<option>mon_pool_quota_crit_threshold</option>設定オプションで制御します。次のコマンドを使用して、プールクォータを増減(または削除)できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      クォータの値を0に設定すると、クォータは無効になります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      1つ以上のプールがクォータに近付いています。この警告条件をトリガするためのしきい値は、<option>mon_pool_quota_warn_threshold</option>設定オプションで制御します。次のコマンドを使用して、プールクォータを増減(または削除)できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      クォータの値を0に設定すると、クォータは無効になります。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      クラスタ内の1つ以上のオブジェクトが、クラスタで保存場所に指定されているノードに保存されていません。これは、クラスタに最近加えられた変更によって発生したデータマイグレーションがまだ完了していないことを示します。データの誤配置そのものは危険な状態ではありません。データ整合性は危険な状態ではなく、必要な数の新しいコピーが(必要な場所に)存在する限り、オブジェクトの古いコピーが削除されることはありません。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      クラスタ内の1つ以上のオブジェクトが見つかりません。具体的には、OSDはオブジェクトの新しいコピーまたは更新されたコピーが存在していることを認識していますが、現在動作しているOSD上にオブジェクトのそのバージョンのコピーが見つかりません。「見つからない」オブジェクトに対する読み込みまたは書き込み要求はブロックされます。検出されなかったオブジェクトの最新のコピーがある、ダウンしているOSDを稼働状態に戻すのが理想的です。見つからないオブジェクトを受け持っているPGのピアリング状態から、候補のOSDを特定できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      OSDの1つ以上の要求の処理に長い時間がかかっています。これは、極端な負荷、低速なストレージデバイス、またはソフトウェアのバグを示している可能性があります。OSDホストから次のコマンドを実行して、対象のOSDの要求キューを問い合わせることができます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      最も低速な最近の要求のサマリが表示されます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      次のコマンドを使用して、OSDの場所を特定できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      1つ以上のOSD要求が比較的長時間ブロックされています(たとえば、4096秒)。これは、クラスタが長時間にわたって正常でないか(たとえば、十分な数のOSDが実行されていないか、PGが非アクティブ)、OSDに何らかの内部的な問題があることを示します。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      最近、1つ以上のPGがスクラブ(<xref linkend="scrubbing"/>を参照)されていません。PGは通常、<option>mon_scrub_interval</option>の秒数ごとにスクラブされ、スクラブなしに<option>mon_warn_not_scrubbed</option>の間隔が経過した場合、この警告がトリガされます。cleanフラグが付いていない場合、PGはスクラブされません。これは、PGが誤配置されているか機能が低下している場合に発生することがあります(前のPG_AVAILABILITYおよびPG_DEGRADEDを参照してください)。次のコマンドを使用して、クリーンなPGのスクラブを手動で開始できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      最近、1つ以上のPGが詳細スクラブ(<xref linkend="scrubbing"/>を参照)されていません。PGは通常、<option>osd_deep_mon_scrub_interval</option>の秒数ごとにスクラブされ、スクラブなしに<option>mon_warn_not_deep_scrubbed</option>秒が経過した場合、この警告がトリガされます。cleanフラグが付いていない場合、PGは詳細スクラブされません。これは、PGが誤配置されているか機能が低下している場合に発生することがあります(前のPG_AVAILABILITYおよびPG_DEGRADEDを参照してください)。次のコマンドを使用して、クリーンなPGのスクラブを手動で開始できます。
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    設定またはキーリングにデフォルト以外の場所を指定した場合、その場所を指定できます。
   </para>
<screen><prompt>root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-watch">
  <title>クラスタの監視</title>

  <para>
   <command>ceph -s</command>を使用して、クラスタの直近の状態を確認できます。たとえば、1つのMonitorと2つのOSDで構成される小規模なCephクラスタでは、ワークロードが実行中の場合、次の内容が出力される場合があります。
  </para>

<screen>
<prompt>cephadm@adm &gt; </prompt>ceph -s
cluster:
  id:     ea4cf6ce-80c6-3583-bb5e-95fa303c893f
  health: HEALTH_WARN
          too many PGs per OSD (408 &gt; max 300)

services:
  mon: 3 daemons, quorum ses5min1,ses5min3,ses5min2
  mgr: ses5min1(active), standbys: ses5min3, ses5min2
  mds: cephfs-1/1/1 up  {0=ses5min3=up:active}
  osd: 4 osds: 4 up, 4 in
  rgw: 1 daemon active

data:
  pools:   8 pools, 544 pgs
  objects: 253 objects, 3821 bytes
  usage:   6252 MB used, 13823 MB / 20075 MB avail
  pgs:     544 active+clean
</screen>

  <para>
   出力に表示される情報は、次のとおりです。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     クラスタID
    </para>
   </listitem>
   <listitem>
    <para>
     クラスタのヘルス状態
    </para>
   </listitem>
   <listitem>
    <para>
     Monitorマップのエポック、およびMonitor定数の状態
    </para>
   </listitem>
   <listitem>
    <para>
     Monitorマップのエポック、およびOSDの状態
    </para>
   </listitem>
   <listitem>
    <para>
     Ceph Managerのステータス
    </para>
   </listitem>
   <listitem>
    <para>
     Object Gatewayのステータス
    </para>
   </listitem>
   <listitem>
    <para>
     配置グループのマップバージョン
    </para>
   </listitem>
   <listitem>
    <para>
     配置グループとプールの数
    </para>
   </listitem>
   <listitem>
    <para>
     保存データの「名目上」の<emphasis/>量と、保存オブジェクトの数
    </para>
   </listitem>
   <listitem>
    <para>
     保存データの合計量
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Cephによるデータ使用量の計算方法</title>
   <para>
    <literal>used</literal>の値は、未加工ストレージの実際の使用量を反映します。<literal>xxx GB / xxx GB</literal>の値は、クラスタの全体的なストレージ容量の利用可能な量(より少ない数)を意味します。名目上の数は、複製、クローン作成、またはスナップショット作成前の保存データのサイズを反映します。したがって、実際の保存データの量は名目上の量より大きくなるのが一般的です。Cephは、データのレプリカを作成し、クローンやスナップショットの作成にもストレージ容量を使用することがあるためです。
   </para>
  </tip>

  <para>
   直近の状態を表示するその他のコマンドは次のとおりです。
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   リアルタイムに更新された情報を取得するには、次のコマンドのいずれか(<command>ceph -s</command>を含む)を<command>watch</command>コマンドの引数として実行します。
  </para>

<screen><prompt>root # </prompt>watch -n 10 'ceph -s'</screen>

  <para>
   監視を終了する場合は、<keycombo><keycap function="control"/><keycap>C</keycap></keycombo>キーを押します。
  </para>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>クラスタの使用量統計の確認</title>

  <para>
   クラスタのデータ使用量とプール間での分散を確認するには、<command>ceph df</command>コマンドを使用します。詳細を取得するには、<command>ceph df detail</command>を使用します。
  </para>

<screen>
<prompt>cephadm@adm &gt; </prompt>ceph df
RAW STORAGE:
    CLASS     SIZE       AVAIL      USED        RAW USED     %RAW USED
    hdd       40 GiB     32 GiB     137 MiB      8.1 GiB         20.33
    TOTAL     40 GiB     32 GiB     137 MiB      8.1 GiB         20.33
POOLS:
    POOL             ID     STORED     OBJECTS    USED       %USED    MAX AVAIL
    iscsi-images      1     3.9 KiB          8    769 KiB        0       10 GiB
    cephfs_data       2     1.6 KiB          5    960 KiB        0       10 GiB
    cephfs_metadata   3      54 KiB         22    1.5 MiB        0       10 GiB
[...]
</screen>

  <para>
   出力の<literal>RAW STORAGE</literal>セクションには、クラスタがデータに使用しているストレージの量の概要が表示されます。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>CLASS</literal>: デバイスのストレージクラス。デバイスクラスの詳細については、<xref linkend="crush-devclasses"/>を参照してください。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>SIZE</literal>: クラスタの全体的なストレージ容量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>: クラスタで利用可能な空き領域の量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: ブロックデバイスに保持されている、純粋にデータオブジェクト用として割り当てられている領域(すべてのOSDの累積)。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>: 「USED」領域と、Ceph用としてブロックデバイスで割り当て/予約されている領域(BlueStoreのBlueFSの部分など)。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>: 使用済みの未加工ストレージの割合。この数字を<literal>full ratio</literal>および<literal>near full ratio</literal>と組み合わせて使用して、クラスタの容量に達していないことを確認します。詳細については、<xref linkend="storage-capacity"/>を参照してください。
    </para>
    <note>
     <title>クラスタの充足レベル</title>
     <para>
      未加工ストレージの充足レベルが100%に近付いている場合は、クラスタに新しいストレージを追加する必要があります。使用量がさらに多くなると、1つのOSDが満杯になり、クラスタのヘルスに問題が発生することがあります。
     </para>
     <para>
      すべてのOSDの充足レベルを一覧にするには、コマンド<command>ceph osd df tree</command>を使用します。
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   出力の<literal>POOLS</literal>セクションには、プールのリストと各プールの名目上の使用量が表示されます。このセクションの出力には、レプリカ、クローン、またはスナップショットは反映されて「いません」。<emphasis/>たとえば、1MBのデータを持つオブジェクトを保存した場合、名目上の使用量は1MBですが、実際の使用量は、レプリカ、クローン、およびスナップショットの数によっては2MB以上になることがあります。
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>POOL</literal>: プールの名前。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>: プールのID。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>STORED</literal>: ユーザが保存したデータの量。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>: プールごとの保存オブジェクトの名目上の数。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: すべてのOSDノードによって純粋にデータ用として割り当てられている領域の量(KB単位)。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>: プールごとの使用済みストレージの名目上の割合。
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>: 特定のプールで利用可能な最大領域。
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    POOLSセクションの数字は名目上の数字です。レプリカ、スナップショット、またはクローンの数は含まれません。そのため、<literal>USED</literal>の量や%<literal>USED</literal>の量を合計しても、出力の<literal>RAW STORAGE</literal>セクションの<literal>RAW USED</literal>の量や<literal>%RAW USED</literal>の量にはなりません。
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>OSDの状態の確認</title>

  <para>
   次のコマンドを実行して、OSDが動作中であることを確認します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd stat</screen>

  <para>
   または
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd dump</screen>

  <para>
   CRUSHマップ内での位置に従ってOSDを表示することもできます。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree</screen>

  <para>
   CRUSHツリーと共に、ホスト、そのOSD、動作中かどうか、および重みが出力されます。
  </para>

<screen># id    weight  type name       up/down reweight
-1      3       pool default
-3      3               rack mainrack
-2      3                       host osd-host
0       1                               osd.0   up      1
1       1                               osd.1   up      1
2       1                               osd.2   up      1</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>満杯のOSDの確認</title>

  <para>
   Cephでは、データが失われないようにするため、満杯のOSDに書き込むことはできません。運用クラスタでは、クラスタが満杯率に近付くと警告が表示されます。<command>mon osd full ratio</command>のデフォルトは0.95です。すなわち、容量の95%に達すると、クライアントによるデータの書き込みが停止されます。<command>mon osd nearfull ratio</command>のデフォルトは0.85です。すなわち、容量の85%に達するとヘルス警告が生成されます。
  </para>

  <para>
   満杯のOSDノードは<command>ceph health</command>でレポートされます。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   または
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   満杯のクラスタへの最適な対応方法は、新しいOSDホスト/ディスクを追加して、クラスタが新しく利用可能になったストレージにデータを再分散できるようにする方法です。
  </para>

  <tip>
   <title>満杯のOSDの防止</title>
   <para>
    OSDが満杯になると(ディスク領域の100%を使用すると)、通常は警告なしにすぐにクラッシュします。次に、OSDノードを管理する際に覚えておくべきヒントをいくつか示します。
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      各OSDのディスク領域(通常は<filename>/var/lib/ceph/osd/osd-{1,2..}</filename>にマウント)は、基礎となる専用のディスクまたはパーティションに配置する必要があります。
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph設定ファイルを確認して、CephがOSD専用のディスク/パーティションにログファイルを保存しないようにします。
     </para>
    </listitem>
    <listitem>
     <para>
      他のプロセスがOSD専用のディスク/パーティションに書き込まないようにします。
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Monitorの状態の確認</title>

  <para>
   クラスタの起動後、最初にデータを読み書きする前に、Ceph Monitorの定数のステータスを確認します。クラスタがすでに要求を処理している場合は、Ceph Monitorのステータスを定期的に確認して、それらが実行されていることを確認します。
  </para>

  <para>
   Monitorマップを表示するには、次のコマンドを実行します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph mon stat</screen>

  <para>
   または
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph mon dump</screen>

  <para>
   Monitorクラスタの定数の状態を確認するには、次のコマンドを実行します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph quorum_status</screen>

  <para>
   定数の状態が返されます。たとえば、3つのMonitorで構成されるCephクラスタは、次の状態を返す場合があります。
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "192.168.1.10:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "192.168.1.11:6789\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "192.168.1.12:6789\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>配置グループの状態の確認</title>

  <para>
   配置グループはオブジェクトをOSDにマップします。配置グループを監視する場合、配置グループが<literal>active</literal>および<literal>clean</literal>である必要があります。詳細については、<xref linkend="op-mon-osd-pg"/>を参照してください。
  </para>
 </sect1>
 <sect1 xml:id="monitor-adminsocket">
  <title>管理ソケットの使用</title>

  <para>
   <remark role="fixme">Maybe give an example use case? No obvious difference to normal ceph command?!</remark>Ceph管理ソケットを使用すると、ソケットインタフェース経由でデーモンに問い合わせることができます。デフォルトでは、Cephソケットは<filename>/var/run/ceph</filename>にあります。管理ソケット経由でデーモンにアクセスするには、デーモンが実行されているホストにログインして、次のコマンドを使用します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable></screen>

  <para>
   利用可能な管理ソケットコマンドを表示するには、次のコマンドを実行します。
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph --admin-daemon /var/run/ceph/<replaceable>socket-name</replaceable> help</screen>

  <para>
   管理ソケットコマンドでは、ランタイム時に設定を表示および設定できます。詳細については、<xref linkend="ceph-config-runtime"/>を参照してください。
  </para>

  <para>
   さらに、ランタイム時に設定値を直接設定することもできます(管理ソケットは、<command>ceph tell</command>
   <replaceable>daemon-type</replaceable>.<replaceable>id</replaceable> injectargsとは異なり、Monitorをバイパスします。これは、Monitorに依存しますが、対象のホストに直接ログインする必要はありません)。
  </para>
 </sect1>
 <sect1 xml:id="storage-capacity">
  <title>ストレージの容量</title>

  <para>
   Cephストレージクラスタがその最大容量に近付くと、Cephは、データ損失を防止するための安全対策として、Ceph OSDに対して書き込みや読み込みを行えないようにします。したがって、運用クラスタをその満杯率に近付けることは、高可用性が犠牲になるため、適切な方法ではありません。デフォルトの満杯率は0.95、つまり容量の95%に設定されています。これは、OSDの数が少ないテストクラスタでは非常に積極的な設定です。
  </para>

  <tip>
   <title>ストレージ容量の増加</title>
   <para>
    クラスタを監視する際には、<literal>nearfull</literal>の比率に関連する警告に注意してください。これは、1つ以上のOSDに障害が発生している場合に、複数のOSDに障害が発生すると、サービスが一時的に中断する可能性があることを意味します。OSDを追加してストレージ容量を増やすことを検討してください。
   </para>
  </tip>

  <para>
   テストクラスタの一般的なシナリオには、システム管理者がCephストレージクラスタからCeph OSDを1つ削除して、クラスタの再バランスを監視することが含まれます。次に、別のCeph OSDを削除し、最終的にクラスタが満杯率に達してロックするまで削除を続けます。テストクラスタでも、何らかの容量計画を立てることをお勧めします。計画を立てることにより、高可用性を維持するために必要なスペア容量を見積もることができます。理想的には、Ceph OSDに一連の障害が発生した場合に、これらのCeph OSDをすぐに交換しなくてもクラスタが<literal>active + clean</literal>の状態に回復できるような計画を立てます。<literal>active + degraded</literal>の状態でクラスタを実行することはできますが、これは通常の動作条件には適しません。
  </para>

  <para>
   次の図は、ホストあたり1つのCeph OSDが存在する33個のCephノードで構成されるシンプルなCephストレージクラスタを表していて、各ノードは3TBドライブに対して読み書きを行います。この例で使用するクラスタの実際の最大容量は99TBです。<option>mon osd full ratio</option>オプションは0.95に設定されています。クラスタの残り容量が5TBまで低下すると、クライアントはデータを読み書きできなくなります。したがって、このストレージクラスタの動作容量は、99TBではなく95TBです。
  </para>

  <figure>
   <title>Cephクラスタ</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   このようなクラスタで、1つまたは2つのOSDに障害が発生することはよくあります。それほど頻繁ではないものの妥当なシナリオとして、ラックのルータまたは電源装置に障害が発生して、同時に複数のOSD (OSD 7～12など)がダウンする状況があります。このようなシナリオでは、たとえ数台のホストと追加のOSDを早急に追加することになるとしても、稼働状態を維持して<literal>active + clean</literal>状態を達成できるクラスタを目指す必要があります。容量使用率が高すぎても、データが失われることはありません。ただし、クラスタの容量使用率が満杯率を超える場合は、障害ドメイン内の停止を解決しても、データ可用性が犠牲になる可能性が依然としてあります。この理由のため、少なくとも大まかな容量計画を立てることをお勧めします。
  </para>

  <para>
   クラスタの次の2つ数量を特定します。
  </para>

  <orderedlist>
   <listitem>
    <para>
     OSDの数。
    </para>
   </listitem>
   <listitem>
    <para>
     クラスタの合計容量。
    </para>
   </listitem>
  </orderedlist>

  <para>
   クラスタの合計容量をクラスタのOSDの数で割ると、クラスタ内のOSDの平均容量がわかります。この平均容量に、通常の操作時に同時に障害が発生すると予想するODSの数(比較的少数)を掛けることを検討してください。最後に、クラスタの容量に満杯率を掛ると、最大動作容量が得られます。次に、妥当な満杯率に達しないと予想されるOSDのデータの量を引きます。OSD障害(OSDのラック)の数を増やして上の手順を繰り返し、ほぼ満杯率に近い妥当な数を得ます。
  </para>

  <para>
   次の設定はクラスタの作成時にのみ適用され、その後OSDマップに保存されます。
  </para>

<screen>
[global]
 mon osd full ratio = .80
 mon osd backfillfull ratio = .75
 mon osd nearfull ratio = .70
</screen>

  <tip>
   <para>
    これらの設定はクラスタの作成中にのみ適用されます。後で、<command>ceph osd set-nearfull-ratio</command>コマンドと<command>ceph osd set-full-ratio</command>コマンドを使用して、OSDマップで変更する必要があります。
   </para>
  </tip>

  <variablelist>
   <varlistentry>
    <term>mon osd full ratio</term>
    <listitem>
     <para>
      OSDを<literal>full</literal>と見なす使用済みディスク容量の割合。デフォルトは0.95です。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd backfillfull ratio</term>
    <listitem>
     <para>
      OSDが過剰に<literal>full</literal>であるためバックフィルできないと見なす使用済みディスク容量の割合。デフォルトは0.90です。
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd nearfull ratio</term>
    <listitem>
     <para>
      OSDを<literal>nearfull</literal>と見なす使用済みディスク容量の割合。デフォルトは0.85です。
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <title>OSDの重みの確認</title>
   <para>
    一部のOSDは<literal>nearfull</literal>であるのに他のOSDには十分な容量がある場合、<literal>nearfull</literal>のOSDのCRUSHの重みに問題がある可能性があります。
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="op-mon-osd-pg">
  <title>OSDと配置グループの監視</title>

  <para>
   高可用性と高信頼性を実現するには、ハードウェアとソフトウェアの問題を管理する耐障害性を持つアプローチが必要です。Cephには単一障害点がなく、データに対する要求を「degraded」モードで処理できます。Cephのデータ配置には、データが特定のOSDアドレスに直接バインドされないようにする間接層が導入されています。つまり、システム障害を追跡するには、問題の根本にある配置グループとその基礎となるOSDを見つける必要があります。
  </para>

  <tip>
   <title>障害が発生した場合のアクセス</title>
   <para>
    クラスタの一部に障害が発生すると、特定のオブジェクトにアクセスできなくなる場合があります。これは、他のオブジェクトにアクセスできないという意味ではありません。障害が発生したら、OSDおよび配置グループを監視するための手順に従います。次にトラブルシューティングを開始します。
   </para>
  </tip>

  <para>
   Cephは通常、自己修復します。ただし、問題が続く場合は、OSDと配置グループを監視すると問題を特定するのに役立ちます。
  </para>

  <sect2 xml:id="op-mon-osds">
   <title>OSDの監視</title>
   <para>
    OSDのステータスは、<emphasis/>「クラスタ内」(「in」)または<emphasis/>「クラスタ外」(「out」)のいずれかです。それと同時に、<emphasis/>「稼働中」(「up」)または<emphasis/>「ダウンしていて実行中でない」(「down」)のいずれかにもなります。OSDが「up」の場合、クラスタ内(データを読み書きできる)またはクラスタ外のいずれかの可能性があります。OSDがクラスタ内に存在していて、最近クラスタ外に移動した場合、Cephは配置グループを他のOSDに移行します。OSDがクラスタ外の場合、CRUSHは配置グループをOSDに割り当てません。OSDは、「down」の場合、「out」にもなります。
   </para>
   <note>
    <title>正常でない状態</title>
    <para>
     OSDが「down」で「in」の場合は問題があり、クラスタは正常な状態ではありません。
    </para>
   </note>
   <para>
    <command>ceph health</command>、<command>ceph -s</command>、<command>ceph -w</command>などのコマンドを実行する場合、クラスタは常に<literal>HEALTH OK</literal>をエコーバックするわけではないことに気付くことがあります。OSDに関しては、次の状況ではクラスタが<emphasis/><literal>HEALTH OK</literal>をエコーしないことを予期する必要があります。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      まだクラスタを起動していない(クラスタは応答しない)。
     </para>
    </listitem>
    <listitem>
     <para>
      クラスタを起動または再起動したばかりで、配置グループを作成中で、OSDがピアリングプロセス中であるため、まだ準備ができていない。
     </para>
    </listitem>
    <listitem>
     <para>
      OSDを追加または削除したばかりである場合。
     </para>
    </listitem>
    <listitem>
     <para>
      クラスタマップを変更したばかりである場合。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    OSDの監視の重要な側面は、クラスタが稼働中であるときに、クラスタ内のすべてのOSDも稼働中であることを確認することです。すべてのOSDが実行中であるかどうかを確認するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>root # </prompt>ceph osd stat
x osds: y up, z in; epoch: eNNNN
</screen>
   <para>
    この結果から、OSDの合計数(x)、「up」のOSDの数(y)、「in」のOSDの数(z)、およびマップのエポック(eNNNN)がわかります。クラスタ内にある「in」のOSDの数が「up」であるOSDの数より多い場合は、次のコマンドを実行して、実行中でない<literal>ceph-osd</literal>デーモンを特定します。
   </para>
<screen>
<prompt>root # </prompt>ceph osd tree
#ID CLASS WEIGHT  TYPE NAME             STATUS REWEIGHT PRI-AFF
-1       2.00000 pool openstack
-3       2.00000 rack dell-2950-rack-A
-2       2.00000 host dell-2950-A1
0   ssd 1.00000      osd.0                up  1.00000 1.00000
1   ssd 1.00000      osd.1              down  1.00000 1.00000
</screen>
   <para>
    OSDがダウンしている場合は(上の例ではID 1)、起動します。
   </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>sudo systemctl start ceph-osd@1.service
</screen>
   <para>
    停止しているOSDや再起動しないOSDに関連する問題については、<xref linkend="op-osd-not-running"/>を参照してください。
   </para>
  </sect2>

  <sect2 xml:id="op-pgsets">
   <title>配置グループセット</title>
   <para>
    CRUSHが配置グループをOSDに割り当てる場合、CRUSHはプールのレプリカの数を確認し、配置グループの各レプリカが異なるOSDに割り当てられるように配置グループをOSDに割り当てます。たとえば、プールに配置グループのレプリカが3つ必要な場合、CRUSHはこれらをそれぞれ<literal>osd.1</literal>、<literal>osd.2</literal>、<literal>osd.3</literal>に割り当てることがあります。CRUSHは実際には、CRUSHマップで設定した障害ドメインを考慮した擬似的にランダムな配置にしようとします。そのため、大規模なクラスタで複数の配置グループが最も近隣にあるOSDに割り当てられることはほとんどありません。特定の配置グループのレプリカを含む必要があるOSDのセットを<emphasis/>「動作セット」と呼びます。動作セットのOSDがダウンしているか、または他の理由で配置グループのオブジェクトの要求を処理できない場合があります。このような状況が生じた場合は、次のシナリオの1つに一致する可能性があります。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      OSDを追加または削除した。これにより、CRUSHが配置グループを他のOSDに再割り当てしたため、「動作セット」の構成が変更され、「バックフィル」プロセスによってデータのマイグレーションが実行された。<emphasis/>
     </para>
    </listitem>
    <listitem>
     <para>
      OSDが「down」状態であったため再起動され、現在回復中である。
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis/>「動作セット」のOSDが「down」状態であるか、要求を処理できないため、別のOSDが一時的にその権限を引き継いだ。
     </para>
     <para>
      Cephは<emphasis/>、要求を実際に処理するOSDのセットである「アップセット」を使用してクライアント要求を処理します。ほとんどの場合、<emphasis/>「アップセット」と<emphasis/>「動作セット」は事実上同一です。これらが同一ではない場合、Cephがデータを移行中であるか、OSDが回復中であるか、または問題があることを示している場合があります(たとえば、このようなシナリオでは、Cephでは通常<literal>HEALTH WARN</literal>状態と「stuck stale」メッセージをエコーします)。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    配置グループのリストを取得するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>;ceph pg dump
</screen>
   <para>
    指定した配置グループの<emphasis/>「動作セット」または「アップセット」<emphasis/>内にあるOSDを表示するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg map<replaceable>PG_NUM</replaceable>
osdmap eNNN pg <replaceable>RAW_PG_NUM</replaceable> (<replaceable>PG_NUM</replaceable>) -&gt; up [0,1,2] acting [0,1,2]
</screen>
   <para>
    この結果から、osdmapエポック(eNNN)、配置グループの数(<replaceable>PG_NUM</replaceable>)、<emphasis/>「アップセット」(「up」)のOSD、および「動作セット」(「acting」)のOSD<emphasis/>がわかります。
   </para>
   <tip>
    <title>クラスタの問題の指標</title>
    <para>
     <emphasis/>「アップセット」と<emphasis/>「動作セット」が一致しない場合、これはクラスタの再バランスそのものか、クラスタの潜在的な問題の指標である可能性があります。
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="op-peering">
   <title>ピアリング</title>
   <para>
    配置グループにデータを書き込むには、データが「active」状態で、かつ「clean」状態である必要があります。Cephが配置グループの現在の状態を判断するために、配置グループのプライマリOSD (「動作セット」の最初のOSD)は、セカンダリおよび3番目のOSDとピアリングして、配置グループの現在の状態に関する合意を確立します(PGの3つのレプリカがプールにあることを想定)。<emphasis/>
   </para>
   <figure>
    <title>ピアリングスキーマ</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="op-mon-pg-states">
   <title>配置グループの状態の監視</title>
   <para>
    <command>ceph health</command>、<command>ceph -s</command>、<command>ceph -w</command>などのコマンドを実行する場合、クラスタは常に<literal>HEALTH OK</literal>メッセージをエコーバックするわけでないことに気付くことがあります。OSDが実行中であるかどうかを確認した後で、配置グループの状態も確認する必要があります。
   </para>
   <para>
    配置グループのピアリングに関係する次のような多くの状況では、クラスタは<emphasis role="bold"/><literal>HEALTH OK</literal>をエコー「しない」ことを予期してください。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      プールを作成したばかりで、配置グループがまだピアリングされていない。
     </para>
    </listitem>
    <listitem>
     <para>
      配置グループが回復中である。
     </para>
    </listitem>
    <listitem>
     <para>
      クラスタにOSDを追加したばかりか、クラスタからOSDを削除したばかりである。
     </para>
    </listitem>
    <listitem>
     <para>
      CRUSHマップを変更したばかりで、配置グループが移行中である。
     </para>
    </listitem>
    <listitem>
     <para>
      配置グループの異なるレプリカに整合性のないデータがある。
     </para>
    </listitem>
    <listitem>
     <para>
      Cephが配置グループのレプリカをスクラブしている。
     </para>
    </listitem>
    <listitem>
     <para>
      Cephにバックフィル操作を完了するための十分なストレージ容量がない。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    上のいずれかの状況でCephが<literal>HEALTH WARN</literal>をエコーしても慌てないでください。多くの場合、クラスタは単独で回復します。場合によっては、対処が必要です。配置グループの監視の重要な側面は、クラスタが稼働しているときに、すべての配置グループが「active」であり、できれば「clean」状態であることを確認することです。すべての配置グループのステータスを確認するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg stat
x pgs: y active+clean; z bytes data, aa MB used, bb GB / cc GB avail
</screen>
   <para>
    この結果から、配置グループの合計数(x)、特定の状態(「active+clean」など)である配置グループの数(y)、および保存データの量(z)がわかります。
   </para>
   <para>
    配置グループの状態に加えて、Cephでは、使用済みのストレージ容量(aa)、残りのストレージ容量(bb)、および配置グループの合計ストレージ容量もエコーバックされます。次のようないくつかのケースでは、これらの数値が重要になる可能性があります。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <option>near full ratio</option>または<option>full ratio</option>に達しつつある。
     </para>
    </listitem>
    <listitem>
     <para>
      CRUSH設定のエラーのため、データがクラスタ間で分散されている。
     </para>
    </listitem>
   </itemizedlist>
   <tip>
    <title>配置グループID</title>
    <para>
     配置グループIDは、プール番号(プール名ではない)、それに続くピリオド(.)、および配置グループID (16進数)で構成されます。プール番号とプールの名前は、<command>ceph osd lspools</command>の出力で参照できます。たとえば、デフォルトのプール<literal>rbd</literal>はプール番号0に対応します。完全修飾形式の配置グループIDは次の形式です。
    </para>
<screen>
<replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable>
</screen>
    <para>
     これは通常、次のようになります。
    </para>
<screen>
0.1f
</screen>
   </tip>
   <para>
    配置グループのリストを取得するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump
</screen>
   <para>
    出力をJSON形式でフォーマットしてファイルに保存することもできます。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump -o <replaceable>FILE_NAME</replaceable> --format=json
</screen>
   <para>
    特定の配置グループに対してクエリを実行するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg <replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable> query
</screen>
   <para>
    次のリストでは、配置グループの一般的な状態について詳しく説明します。
   </para>
   <variablelist>
    <varlistentry>
     <term>作成中</term>
     <listitem>
      <para>
       プールを作成すると、指定した数の配置グループが作成されます。Cephは、1つ以上の配置グループを作成している場合に「creating」をエコーします。配置グループが作成されると、その配置グループの「動作セット」に属するOSDがピアリングされます。<emphasis/>ピアリングが完了したら、配置グループのステータスは「active+clean」になります。これは、Cephクライアントがその配置グループへの書き込みを開始できることを意味します。
      </para>
      <figure>
       <title>配置グループのステータス</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
       </mediaobject>
      </figure>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>ピアリング</term>
     <listitem>
      <para>
       Cephは、配置グループのピアリング中に、配置グループのレプリカを保存するOSDを、その配置グループ内にあるオブジェクトとメタデータの状態について合意状態にします。つまり、Cephがピアリングを完了すると、その配置グループを保存するOSDは配置グループの現在の状態に関して合意したことになります。ただし、ピアリングプロセスが完了しても、各レプリカの内容が最新であるという意味には「なりません」。<emphasis role="bold"/>
      </para>
      <note>
       <title>信頼できる履歴</title>
       <para>
        Cephでは、「動作セット」のすべてのOSDが書き込み操作を永続化するまで、クライアントへの書き込み操作を確認「しません」。<emphasis role="bold"/><emphasis/>この動作により、ピアリング操作が最後に正常に完了した後に確認されたすべての書き込み操作のレコードが、「動作セット」の少なくとも1つのメンバーに確実に存在するようになります。<emphasis/>
       </para>
       <para>
        確認された書き込み操作それぞれの正確なレコードにより、Cephは、配置グループの信頼できる新しい履歴を構築および拡張できます。この履歴には、一連の操作の順序が完全かつ全面的に記録されているため、この履歴を実行すれば、配置グループのOSDのコピーを最新の状態にすることができます。
       </para>
      </note>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>アクティブ</term>
     <listitem>
      <para>
       Cephがピアリングプロセスを完了すると、配置グループは「active」になります。「active」状態とは、プライマリ配置グループとレプリカで配置グループのデータを読み込み操作と書き込み操作に一般的に使用できることを意味します。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>クリーン</term>
     <listitem>
      <para>
       配置グループが「clean」状態である場合、プライマリOSDとレプリカOSDは正常にピアリングされていて、その配置グループに未処理のレプリカは存在しません。配置グループ内のすべてのオブジェクトは、Cephによって正確な回数複製されています。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>DEGRADED</term>
     <listitem>
      <para>
       クライアントがプライマリOSDにオブジェクトを書き込む場合、プライマリOSDが、レプリカをレプリカOSDに書き込む責任を持ちます。プライマリOSDがオブジェクトをストレージに書き込んだ後も、配置グループは「degraded」状態のままです。この状態は、Cephがレプリカオブジェクトを正常に作成したという確認をプライマリOSDがレプリカOSDから受け取るまで続きます。
      </para>
      <para>
       配置グループが「active+degraded」になる可能性がある理由は、OSDにまだオブジェクトがすべて格納されていなくてもOSDが「active」になる可能性があるためです。OSDがダウンした場合、CephはそのOSDに割り当てられた各配置グループを「degraded」としてマークします。OSDが稼働状態に戻ったら、OSDをもう一度ピアリングする必要があります。ただし、「degraded」状態の配置グループが「active」であれば、クライアントは引き続きその配置グループに新しいオブジェクトを書き込むことができます。
      </para>
      <para>
       OSDが「down」で、「degraded」状態が解決しない場合、Cephは、ダウンしているOSをクラスタの「out」としてマークし、「down」状態のOSDから別のOSDにデータを再マップします。「down」とマークされてから「out」とマークされるまでの時間は、<option>mon osd down out interval</option>オプションで制御します。デフォルトでは600秒に設定されています。
      </para>
      <para>
       配置グループに含める必要がある1つ以上のオブジェクトをCephが見つけることができないという理由で、配置グループが「degraded」状態になる可能性もあります。見つからないオブジェクトに対して読み書きを行うことはできませんが、「degraded」状態の配置グループ内にある他のすべてのオブジェクトには今までどおりアクセスできます。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>回復中</term>
     <listitem>
      <para>
       Cephは、ハードウェアやソフトウェアの問題が継続している場合に大規模な耐障害性を実現するように設計されています。OSDが「down」になった場合、その内容が、配置グループ内にある他のレプリカの現在の状態よりも遅れることがあります。OSDが「up」に戻ったら、現在の状態を反映するように配置グループの内容を更新する必要があります。その間、OSDに「recovering」状態が反映される場合があります。
      </para>
      <para>
       ハードウェアの障害によって複数のOSDのカスケード障害が発生する可能性があるため、回復は常に簡単であるとは限りません。たとえば、ラックまたはキャビネットのネットワークスイッチに障害が発生することがあります。これにより、多数のホストマシンのOSDがクラスタの現在の状態より遅れる可能性があります。障害が解決されたら、各OSDを回復する必要があります。
      </para>
      <para>
       Cephには、新しいサービス要求と、データオブジェクトを回復して配置グループを現在の状態に復元する必要性との間のリソース競合のバランスを取るための設定が多数用意されています。<option>osd recovery delay start</option>設定を使用すると、回復プロセスを開始する前に、OSDを再起動して再ピアリングを行い、さらに一部の再生要求を処理することもできます。<option>osd recovery thread timeout</option>は、スレッドのタイムアウトを設定します。これは、複数のOSDが失敗した場合に、時間差で再起動および再ピアリングするためです。<option>osd recovery max active</option>設定は、OSDが同時に処理する回復要求の数を制限して、OSDが要求を処理できなくなるのを防ぎます。<option>osd recovery max chunk</option>設定は、回復されたデータチャンクのサイズを制限し、ネットワークの輻輳を防ぎます。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>バックフィル</term>
     <listitem>
      <para>
       新しいOSDがクラスタに参加すると、CRUSHは、クラスタ内のOSDから、新しく追加されたOSDに配置グループを再割り当てします。再割り当てされた配置グループをただちに受け入れるよう新しいOSDに強制すると、新しいOSDに過度な負荷がかかる可能性があります。OSDに配置グループをバックフィルすることで、このプロセスをバックグラウンドで開始できます。バックフィルが完了して準備が整ったら、新しいOSDは処理を開始します。
      </para>
      <para>
       バックフィル操作中に、次のいずれかの状態が表示されることがあります。「backfill_wait」は、バックフィル操作が保留中で、まだ進行中ではないことを示します。「backfill」は、バックフィル操作が進行中であることを示します。「backfill_too_full」は、バックフィル操作が要求されたものの、ストレージ容量が十分でないため完了できなかったことを示します。配置グループをバックフィルできない場合、「incomplete」と見なされることがあります。
      </para>
      <para>
       Cephには、配置グループをOSD (特に新しいOSD)に再割り当てすることに伴う負荷を管理するための設定が多数用意されています。デフォルトでは、<option>osd max backfills</option>は、OSDに対する同時バックフィルの最大数を10に設定します。<option>backfill full ratio</option>を使用すると、OSDがその満杯率(デフォルトでは90%)に近付いている場合にバックフィル要求を拒否できます。変更するには、<command>ceph osd set-backfillfull-ratio</command>コマンドを使用します。OSDがバックフィル要求を拒否する場合、<option>osd backfill retry interval</option>を使用すると、OSDは要求を再試行できます(デフォルトでは10秒後)。OSDに<option>osd backfill scan min</option>および<option>osd backfill scan max</option>を設定して、スキャン間隔を管理することもできます(デフォルトでは64と512)。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>REMAPPED (再マップ)</term>
     <listitem>
      <para>
       配置グループの変更を処理する「動作セット」が変更されると、古い「動作セット」から新しい「動作セット」にデータが移行されます。<emphasis/><emphasis/><emphasis/>新しいプライマリOSDが要求を処理するまでにしばらく時間がかかる場合があります。そのため、配置グループのマイグレーションが完了するまで、古いプライマリに対して引き続き要求を処理するよう求めることができます。データマイグレーションが完了したら、新しい「動作セット」のプライマリOSDがマッピングで使用されます。<emphasis/>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>STALE</term>
     <listitem>
      <para>
       Cephは、ハートビートを使用して、ホストとデーモンが確実に実行されるようにしていますが、<literal>ceph-osd</literal>デーモンが「stuck」状態になり、統計情報がタイムリーにレポートされないこともあります(たとえば、一時的なネットワーク障害)。デフォルトでは、OSDデーモンはその配置グループ、およびブートと障害の統計情報を0.5秒ごとにレポートします。これは、ハートビートのしきい値よりも高い頻度です。配置グループの「動作セット」のプライマリOSDがモニターにレポートしない場合、または他のOSDが、プライマリOSDが「down」しているとレポートした場合、モニターは配置グループを「stale」としてマークします。<emphasis/>
      </para>
      <para>
       クラスタの起動時には、ピアリングプロセスが完了するまで「stale」状態が表示されることがよくあります。クラスタがしばらく動作した後で配置グループが「stale」状態になっている場合は、その配置グループのプライマリOSDがダウンしているか、配置グループの統計情報をモニターにレポートしていないことを示します。
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="op-pg-stuck-states">
   <title>問題のある配置グループの特定</title>
   <para>
    前述のように、配置グループの状態が「active+clean」であるからと言って、必ずしも配置グループに問題があるわけではありません。一般的に、Cephの自己修復機能は、配置グループがスタックしていると機能しない場合があります。スタック状態には次のものがあります。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis role="bold">Unclean</emphasis>: 配置グループに、必要な回数複製されていないオブジェクトが含まれます。これらは回復中である必要があります。
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold">Inactive</emphasis>: 配置グループは、OSDが最新のデータで復帰するのを待機しているため、読み込みまたは書き込みを処理できません。
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold">Stale</emphasis>: 配置グループをホストするOSDがしばらくの間(<option>mon osd report timeout</option>オプションで設定)モニタークラスタにレポートしていないため、配置グループは不明な状態です。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    スタックしている配置グループを特定するには、次のコマンドを実行します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]
</screen>
  </sect2>

  <sect2 xml:id="op-pg-objectfinding">
   <title>オブジェクトの場所の検出</title>
   <para>
    オブジェクトデータをCephオブジェクトストアに保存するには、Cephクライアントは、オブジェクトを名を設定して、関連するプールを指定する必要があります。Cephクライアントは最新のクラスタマップを取得し、CRUSHアルゴリズムは、オブジェクトを配置グループにマップする方法を計算し、続いて配置グループをOSDに動的に割り当てる方法を計算します。オブジェクトの場所を見つけるには、オブジェクト名とプール名があれば十分です。次に例を示します。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd map <replaceable>POOL_NAME</replaceable> <replaceable>OBJECT_NAME</replaceable> [<replaceable>NAMESPACE</replaceable>]
</screen>
   <example>
    <title>オブジェクトの場所の特定</title>
    <para>
     一例として、オブジェクトを作成しましょう。コマンドラインで<command>rados put</command>コマンドを使用して、オブジェクト名「test-object-1」、いくつかのオブジェクトデータを含むサンプルファイル「testfile.txt」へのパス、およびプール名「data」を指定します。
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>rados put test-object-1 testfile.txt --pool=data
</screen>
    <para>
     Cephオブジェクトストアにオブジェクトが保存されたことを確認するため、次のコマンドを実行します。
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>rados -p data ls
</screen>
    <para>
     続いて、オブジェクトの場所を特定します。Cephによってオブジェクトの場所が出力されます。
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd map data test-object-1
osdmap e537 pool 'data' (0) object 'test-object-1' -&gt; pg 0.d1743484 \
(0.4) -&gt; up ([1,0], p0) acting ([1,0], p0)
</screen>
    <para>
     サンプルオブジェクトを削除するには、単に<command>rados rm</command>コマンドを使用して削除します。
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>rados rm test-object-1 --pool=data
</screen>
   </example>
  </sect2>
 </sect1>
 <sect1 xml:id="op-osd-not-running">
  <title>OSDが実行されていない場合</title>

  <para>
   通常の状況では、単に<literal>ceph-osd</literal>デーモンを再起動すれば、クラスタに再参加して回復できます。
  </para>

  <sect2 xml:id="op-osd-not-start">
   <title>OSDが起動しない場合</title>
   <para>
    クラスタを起動してもOSDが起動しない場合は、以下を確認してください。
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis role="bold"/>「設定ファイル」: 新しいインストール環境からOSDを実行できなかった場合は、設定ファイルの内容が正しいことを確認します(たとえば、<literal>hostname</literal>ではなく<literal>host</literal>を使用している)。
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"/>「パスの確認」: データとジャーナルについて、設定に記述されているパスと、実際のパスそのものを確認します。OSDデータをジャーナルデータから分離している場合に、設定ファイルまたは実際のマウントでエラーが発生するときは、OSDの起動に問題がある可能性があります。ジャーナルをブロックデバイスに保存する場合、ジャーナルディスクをパーティション分割し、OSDごとに1つのパーティションを割り当てる必要があります。
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"/>「最大スレッド数の確認」: 大量のOSDが含まれるノードがある場合、デフォルトの最大スレッド数(通常は32,000)に達している可能性があります。これは特に回復中に発生します。<command>sysctl</command>コマンドを使用してスレッド数を増やし、最大スレッド数を、設定可能な最大スレッド数(たとえば、4194303)に増やすと役立つかどうかを確認できます。
     </para>
<screen>
<prompt>root # </prompt>sysctl -w kernel.pid_max=4194303
</screen>
     <para>
      最大スレッド数を増やすと問題が解決する場合は、<filename>/etc/sysctl.conf</filename>ファイルに<option>kernel.pid_max</option>設定を含めると、設定を固定できます。
     </para>
<screen>
kernel.pid_max = 4194303
</screen>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="op-osd-failed">
   <title>OSDに障害が発生した場合</title>
   <para>
    <literal>ceph-osd</literal>プロセスが終了した場合、存続している<literal>ceph-osd</literal>デーモンからモニターが障害を学習し、<command>ceph health</command>コマンドを介して障害をレポートします。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph health
HEALTH_WARN 1/3 in osds are down
</screen>
   <para>
    具体的には、「in」および「down」としてマークされた<literal>ceph-osd</literal>プロセスがある場合は、常に警告がレポートされます。次のコマンドを使用して、ダウンしている<literal>ceph-osds</literal>を特定できます。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph health detail
HEALTH_WARN 1/3 in osds are down
osd.0 is down since epoch 23, last address 192.168.106.220:6800/11080
</screen>
   <para>
    ディスクに障害が発生した場合や、他の障害により<literal>ceph-osd</literal>が機能または再起動できない場合は、<filename>/var/log/ceph</filename>にあるログファイルにエラーメッセージが存在します。
   </para>
   <para>
    ハートビートの障害のためにデーモンが停止した場合は、基礎となるカーネルファイルシステムが応答していない可能性があります。ディスクまたは他のカーネルエラーの場合は、<command>dmesg</command>コマンドの出力を確認します。
   </para>
  </sect2>

  <sect2 xml:id="op-no-disk-space">
   <title>空きディスク容量がない場合</title>
   <para>
    Cephでは、データが失われないようにするため、満杯のOSDに書き込むことはできません。運用クラスタでは、クラスタが満杯率に近付くと警告が表示されます。<option>mon osd full ratio</option>オプションは、デフォルトでは0.95です。すなわち、容量の95%に達すると、クライアントによるデータの書き込みが停止されます。<option>mon osd backfillfull ratio</option>は、デフォルトでは0.90です。すなわち、容量の90%に達すると、バックフィルの開始がブロックされます。OSDのnearfullの比率は、デフォルトでは0.85です。すなわち、容量の85%に達するとヘルス警告が生成されます。次のコマンドを使用して、「nearfull」の値を変更できます。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-nearfull-ratio <replaceable>0.0 to 1.0</replaceable>
</screen>
   <para>
    フルクラスタで起きる問題は、通常、Cephが小規模クラスタのOSD障害をどのように処理するかをテストしているときに発生します。クラスタのデータの割合が高いノードが1つある場合は、簡単にクラスタの「nearfull」と「full」の比率をただちに下げることができます。Cephが小規模クラスタのOSD障害にどのように反応するかをテストする場合は、十分な空きディスク容量を残し、次のコマンドを使用してOSDの満杯率、OSDのbackfillfull の比率、およびOSDのnearfullの比率を一時的に下げることを検討してください。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-nearfull-ratio <replaceable>0.0 to 1.0</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>0.0 to 1.0</replaceable>
<prompt>cephadm@adm &gt; </prompt>ceph osd set-backfillfull-ratio <replaceable>0.0 to 1.0</replaceable>
</screen>
   <para>
    満杯のOSDは<command>ceph health</command>でレポートされます。
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph health
HEALTH_WARN 1 nearfull osd(s)
</screen>
   <para>
    プロンプトまたは
   </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph health detail
HEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)
osd.3 is full at 97%
osd.4 is backfill full at 91%
osd.2 is near full at 87%
</screen>
   <para>
    満杯のクラスタへの最適な対応方法は、新しいCeph OSDノードを追加して、クラスタが新しく利用可能になったストレージにデータを再分散できるようにする方法です。
   </para>
   <para>
    満杯のためにOSDを起動できない場合は、満杯のOSDにある配置グループのディレクトリをいくつか削除することによって、一部のデータを削除できます。
   </para>
   <important>
    <title>配置グループディレクトリの削除</title>
    <para>
     満杯のOSDにある配置グループディレクトリを削除する場合、別の満杯のOSD上にある同じ配置グループディレクトリを削除「しない」でください<emphasis role="bold"/> <emphasis role="bold"/>。<emphasis role="bold"/>少なくとも1つのデータのコピーを少なくとも1つのOSDに保持する「必要があります」。
    </para>
   </important>
  </sect2>
 </sect1>
</chapter>
