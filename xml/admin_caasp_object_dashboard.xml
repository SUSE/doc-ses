<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "generic-entities.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
  xml:id="admin-caasp-dashboard">
<!-- ============================================================== -->
 <title>&dashboard;</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <sect1 xml:id="caasp-ceph-dashboard">
  <title>&dashboard;</title>

  <para>
   The &dashboard; is a helpful tool to give you an overview of the status of
   your &ceph; cluster, including overall health, status of the MOPN quorum,
   status of the MGR, OSD, and other &ceph; daemons, view pools and PG status,
   show logs for the daemons, and more. &rook; makes it simple to enable the
   dashboard.
  </para>

  <figure>
   <title>The &dashboard;</title>
   <mediaobject>
    <imageobject>
     <imagedata fileref="dashboard_homepage.png" />
    </imageobject>
   </mediaobject>
  </figure>

  <sect2 xml:id="enable-the-ceph-dashboard">
   <title>Enabling the &dashboard;</title>
   <para>
    The
    <link xlink:href="http://docs.ceph.com/docs/mimic/mgr/dashboard/">dashboard</link>
    can be enabled with settings in the CephCluster CRD. The CephCluster CRD
    must have the dashboard <literal>enabled</literal> setting set to
    <literal>true</literal>. This is the default setting in the example
    manifests.
   </para>
<screen>
  spec:
    dashboard:
      enabled: true
</screen>
   <para>
    The &rook; operator will enable the <literal>ceph-mgr</literal> dashboard
    module. A service object will be created to expose that port inside the
    &kube; cluster. &rook; will enable port 8443 for HTTPS access.
   </para>
   <para>
    This example shows that port 8443 was configured:
   </para>
<screen>&prompt.kubeuser;kubectl -n rook-ceph get service
NAME                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
rook-ceph-mgr                ClusterIP   10.108.111.192   &lt;none&gt;        9283/TCP         3h
rook-ceph-mgr-dashboard      ClusterIP   10.110.113.240   &lt;none&gt;        8443/TCP         3h
</screen>
   <para>
    The first service is for reporting the &prometheus; metrics, while the
    latter service is for the dashboard. If you are on a node in the cluster,
    you will be able to connect to the dashboard by using either the DNS name
    of the service at
    <literal>https://rook-ceph-mgr-dashboard-https:8443</literal> or by
    connecting to the cluster IP, in this example at
    <literal>https://10.110.113.240:8443</literal>.
   </para>
   <important>
    <para>
     The dashboard will only be enabled for the first &ceph; object store
     created by &rook;.
    </para>
   </important>
   <sect3 xml:id="login-credentials">
    <title>Creating login credentials</title>
    <para>
     After you connect to the dashboard, you will need to login for secure
     access. &rook; creates a default user named <literal>admin</literal> and
     generates a secret called
     <literal>rook-ceph-dashboard-admin-password</literal> in the namespace
     where the &rookceph; cluster is running. To retrieve the generated
     password, you can run the following:
    </para>
<screen>
&prompt.kubeuser;kubectl -n rook-ceph get secret rook-ceph-dashboard-password \
 -o jsonpath=&quot;{['data']['password']}&quot; | base64 --decode &amp;&amp; echo
</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="configure-the-dashboard">
   <title>Configuring the &dashboard;</title>
   <para>
    The following dashboard configuration settings are supported:
   </para>
<screen>
  spec:
    dashboard:
      urlPrefix: /ceph-dashboard
      port: 8443
      ssl: true
</screen>
   <itemizedlist spacing="compact">
    <listitem>
     <para>
      <literal>urlPrefix</literal> If you are accessing the dashboard via a
      reverse proxy, you may wish to serve it under a URL prefix. To get the
      dashboard to use hyperlinks that include your prefix, you can set the
      <literal>urlPrefix</literal> setting.
     </para>
    </listitem>
    <listitem>
     <para>
      <literal>port</literal> The port that the dashboard is served on may be
      changed from the default using the <literal>port</literal> setting. The
      corresponding K8s service exposing the port will automatically be
      updated.
     </para>
    </listitem>
    <listitem>
     <para>
      <literal>ssl</literal> The dashboard may be served without SSL by setting
      the <literal>ssl</literal> option to be false.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="viewing-the-dashboard-external-to-the-cluster">
   <title>Viewing the &dashboard; external to the cluster</title>
   <para>
    Commonly, you will want to view the dashboard from outside the cluster. For
    example, on a development machine with the cluster running inside minikube,
    you will want to access the dashboard from the host.
   </para>
   <para>
    There are several ways to expose a service, which will depend on the
    environment you are running in. You can use an Ingress Controller or other
    methods for exposing services such as NodePort, LoadBalancer, or
    ExternalIPs.
   </para>
   <sect3 xml:id="node-port">
    <title>Node port</title>
    <para>
     The simplest way to expose the service in minikube or similar environments
     is using the NodePort to open a port on the VM that can be accessed by the
     host. To create a service with the NodePort, save this YAML file as
     <filename>dashboard-external-https.yaml</filename>.
    </para>
<screen>
  apiVersion: v1
  kind: Service
  metadata:
    name: rook-ceph-mgr-dashboard-external-https
    namespace: rook-ceph
    labels:
      app: rook-ceph-mgr
      rook_cluster: rook-ceph
  spec:
    ports:
    - name: dashboard
      port: 8443
      protocol: TCP
      targetPort: 8443
    selector:
      app: rook-ceph-mgr
      rook_cluster: rook-ceph
    sessionAffinity: None
    type: NodePort
</screen>
    <para>
     Now create the service:
    </para>
<screen>&prompt.kubeuser;kubectl create -f dashboard-external-https.yaml</screen>
    <para>
     You will see the new service
     <literal>rook-ceph-mgr-dashboard-external-https</literal> created:
    </para>
<screen>&prompt.kubeuser;kubectl -n rook-ceph get service
NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
rook-ceph-mgr                           ClusterIP   10.108.111.192   &lt;none&gt;        9283/TCP         4h
rook-ceph-mgr-dashboard                 ClusterIP   10.110.113.240   &lt;none&gt;        8443/TCP         4h
rook-ceph-mgr-dashboard-external-https  NodePort    10.101.209.6     &lt;none&gt;        8443:31176/TCP   4h
</screen>
    <para>
     In this example, port <literal>31176</literal> will be opened to expose
     port <literal>8443</literal> from the ceph-mgr pod. Find the IP address of
     the VM. If using minikube, you can run <literal>minikube ip</literal> to
     find the IP address. Now you can enter the URL in your browser such as
     <literal>https://192.168.99.110:31176</literal> and the dashboard will
     appear.
    </para>
   </sect3>
   <sect3 xml:id="load-balancer">
    <title>Creating the load balancer service</title>
    <para>
     If you have a cluster on a cloud provider that supports load balancers,
     you can create a service that is provisioned with a public hostname. The
     yaml is the same as <literal>dashboard-external-https.yaml</literal>
     except for the following property:
    </para>
<screen>
  spec:
  [...]
    type: LoadBalancer
</screen>
    <para>
     Now create the service:
    </para>
<screen>&prompt.kubeuser;kubectl create -f dashboard-loadbalancer.yaml</screen>
    <para>
     You will see the new service
     <literal>rook-ceph-mgr-dashboard-loadbalancer</literal> created:
    </para>
<screen>&prompt.kubeuser;kubectl -n rook-ceph get service
NAME                                     TYPE           CLUSTER-IP       EXTERNAL-IP                                                               PORT(S)             AGE
rook-ceph-mgr                            ClusterIP      172.30.11.40     &lt;none&gt;                                                                    9283/TCP      4h
rook-ceph-mgr-dashboard                  ClusterIP      172.30.203.185   &lt;none&gt;                                                                    8443/TCP      4h
rook-ceph-mgr-dashboard-loadbalancer     LoadBalancer   172.30.27.242    a7f23e8e2839511e9b7a5122b08f2038-1251669398.us-east-1.elb.amazonaws.com   8443:32747/TCP      4h
</screen>
    <para>
     Now you can enter the URL in your browser such as
     <literal>https://a7f23e8e2839511e9b7a5122b08f2038-1251669398.us-east-1.elb.amazonaws.com:8443</literal>
     and the dashboard will appear.
    </para>
   </sect3>
   <sect3 xml:id="ingress-controller">
    <title>Ingress controller</title>
    <para>
     If you have a cluster with an Nginx Ingress Controller and a certificate
     manager, then you can create an ingress like the one below. This example
     achieves four things:
    </para>
    <orderedlist numeration="arabic" spacing="compact">
     <listitem>
      <para>
       Exposes the dashboard on the Internet (using an reverse proxy).
      </para>
     </listitem>
     <listitem>
      <para>
       Issues an valid TLS Certificate for the specified domain name.
      </para>
     </listitem>
     <listitem>
      <para>
       Tells the reverse proxy that the dashboard itself uses HTTPS.
      </para>
     </listitem>
     <listitem>
      <para>
       Tells the reverse proxy that the dashboard itself does not have a valid
       certificate (it is self-signed).
      </para>
     </listitem>
    </orderedlist>
<screen>
  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    name: rook-ceph-mgr-dashboard
    namespace: rook-ceph
    annotations:
      kubernetes.io/ingress.class: "nginx"
      kubernetes.io/tls-acme: "true"
      nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
      nginx.ingress.kubernetes.io/server-snippet: |
        proxy_ssl_verify off;
  spec:
    tls:
     - hosts:
       - rook-ceph.example.com
       secretName: rook-ceph.example.com
    rules:
    - host: rook-ceph.example.com
      http:
        paths:
        - path: /
          backend:
            serviceName: rook-ceph-mgr-dashboard
            servicePort: https-dashboard
</screen>
    <para>
     Customise the ingress resource to match your cluster. Replace the example
     domain name <literal>rook-ceph.example.com</literal> with a domain name
     that will resolve to your Ingress Controller (creating the DNS entry if
     required).
    </para>
    <para>
     Now create the ingress:
    </para>
<screen>&prompt.kubeuser;kubectl create -f dashboard-ingress-https.yaml</screen>
    <para>
     You will see the new ingress <literal>rook-ceph-mgr-dashboard</literal>
     created:
    </para>
<screen>&prompt.kubeuser;kubectl -n rook-ceph get ingress
NAME                      HOSTS                      ADDRESS   PORTS     AGE
rook-ceph-mgr-dashboard   rook-ceph.example.com      80, 443   5m
</screen>
    <para>
     And the new secret for the TLS certificate:
    </para>
<screen>&prompt.kubeuser;kubectl -n rook-ceph get secret rook-ceph.example.com
NAME                       TYPE                DATA      AGE
rook-ceph.example.com      kubernetes.io/tls   2         4m
</screen>
    <para>
     You can now browse to <literal>https://rook-ceph.example.com/</literal> to
     log into the dashboard.
    </para>
   </sect3>
  </sect2>
 </sect1>
</chapter>
