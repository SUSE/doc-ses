<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"  xml:id="monitoring-alerting">
 <title>Monitoring and Alerting</title>
 <para>
  In &productname; 6, &deepsea; no longer deploys a monitoring and alerting
  stack on the &smaster;. Users have to define the &prometheus; role
  for &prometheus; and &alertmanager;, and the &grafana; role for &grafana;.
  When multiple nodes are assigned with the &prometheus; or &grafana; role, a
  highly available setup is deployed.
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis role="bold">&prometheus;</emphasis> is the monitoring and alerting
    toolkit.
   </para>
 </listitem>
 <listitem>
  <para>
   <emphasis role="bold">&alertmanager;</emphasis> handles alerts sent by
   the &prometheus; server.
  </para>
 </listitem>
  <listitem>
   <para>
    <emphasis role="bold">&grafana;</emphasis> is the visualization and alerting
    software.
   </para>
  </listitem>
  <listitem>
   <para>
    The <systemitem class="daemon">prometheus-node_exporter</systemitem>
    is the service running on all &sminion;s.
   </para>
  </listitem>
 </itemizedlist>
 <para>
  The &prometheus; configuration and <emphasis>scrape</emphasis> targets
  (exporting daemons) are setup automatically by &deepsea;. &deepsea; also
  deploys a list of default alerts, for example <literal>health
  error</literal>, <literal>10% OSDs down</literal>, or <literal>pgs
  inactive</literal>.
 </para>

 <sect1 xml:id="pillar-variables">
  <title>Pillar Variables</title>
  <para>The &spillar; is a key-value store that provides information and
    configuration values to minions. It is available to all minions, each
    with differing content. The &spillar; is pre-populated with default
    values and can be customized in two different ways:</para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis role="bold"><filename>/srv/pillar/ceph/stack/global.yml</filename></emphasis>:
      to change pillar variables for all nodes.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"><filename>/srv/pillar/ceph/stack/<replaceable>CLUSTER_NAME</replaceable>/minions/<replaceable>HOST</replaceable></filename></emphasis>:
      to change specific minion configurations.
     </para>
    </listitem>
   </itemizedlist>
  <para>
    The pillar variables below are available to all nodes by default:
  </para>
<screen>
  monitoring:
  alertmanager:
    config: salt://path/to/config
    additional_flags: ''
  grafana:
    ssl_cert: False # self-signed certs are created by default
    ssl_key: False # self-signed certs are created by default
  prometheus:
    # pass additional configration to prometheus
    additional_flags: ''
    alert_relabel_config: []
    rule_files: []
    # per exporter config variables
    scrape_interval:
      ceph: 10
      node_exporter: 10
      prometheus: 10
      grafana: 10
    relabel_config:
      alertmanager: []
      ceph: []
      node_exporter: []
      prometheus: []
      grafana: []
    metric_relabel_config:
      ceph: []
      node_exporter: []
      prometheus: []
      grafana: []
    target_partition:
      ceph: '1/1'
      node_exporter: '1/1'
      prometheus: '1/1'
      grafana: '1/1'
</screen>
</sect1>

<sect1 xml:id="grafana">
  <title>&grafana;</title>
  <para>
    All traffic is encrypted through &grafana;. You can either supply your
    own SSL certs or create self-signed one.</para>
  <para>&grafana; uses the following variables:</para>
  <itemizedlist>
    <listitem>
      <para>
        <emphasis role="bold"><literal>ssl_cert</literal></emphasis>
      </para>
    </listitem>
    <listitem>
      <para>
        <emphasis role="bold"><literal>ssl_key</literal></emphasis>
      </para>
    </listitem>
  </itemizedlist>
  <para>For more information on supplying your own SSL certificates, see <xref linkend="cert-sign-CA"/>
    or for creating your own, see <xref linkend="self-sign-certificates"/>.
  </para>
</sect1>

 <sect1 xml:id="prometheus">
   <title>&prometheus;</title>
  <para>The exporter based configuration that can be passed through the pillar.
    These groups map to exporters that provide data. The node exporter is
    present on all nodes, &ceph; is exported by the &mgr; nodes, &prometheus;
    and &grafana; is exported by the respective &prometheus; and &grafana; nodes.</para>
  <para>&prometheus; uses the following variables:</para>
    <itemizedlist>
    <listitem>
     <para>
      <emphasis role="bold"><literal>scrape_interval</literal></emphasis>:
       change the scrape interval, how often an exporter is to be scraped.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"><literal>target_partition</literal></emphasis>:
       partition scrape targets when multiple &prometheus; instnaces are
       deployed and have some instances scrape only part of all
       exporter instances.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"><literal>relabel_config</literal></emphasis>:
       dynamically rewrites the label set of a target before it gets scraped.
       Multiple relabeling steps can be configured per scrape configuration.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis role="bold"><literal>metrics_relabel_config</literal></emphasis>:
       applied to samples as the last step before ingestion.
     </para>
    </listitem>
   </itemizedlist>
 </sect1>

 <sect1 xml:id="alerting-alertmanager">
  <title>&alertmanager;</title>
  <para>
   The &alertmanager; handles alerts sent by the &prometheus; server. It takes
   care of deduplicating, grouping, and routing them to the correct receiver.
   It also takes care of silencing of alerts. &alertmanager; is configured via
   the command line flags and a configuration file that defines inhibition
   rules, notification routing and notification receivers.
  </para>
  <sect2>
   <title>Configuration File</title>
   <para>
    &alertmanager;'s configuration is different for each deployment. Therefore,
    &deepsea; does not ship any related defaults. You need to provide your own
    <filename>alertmanager.yml</filename> configuration file. The
    <package>alertmanager</package> package by default installs a
    configuration file <filename>/etc/prometheus/alertmanager.yml</filename>
    which can serve as an example configuration. If you prefer to have your
    &alertmanager; configuration managed by &deepsea;, add the following key to
    your pillar, for example to the
    <filename>/srv/pillar/ceph/stack/ceph/minions/<replaceable>YOUR_SALT_MASTER_MINION_ID</replaceable>.sls</filename>
    file:
   </para>
   <para>
    For a complete example of &alertmanager;'s configuration file, see
    <xref linkend="troubleshooting-alerts"/>.
   </para>
<screen>
monitoring:
 alertmanager_config:
   /path/to/your/alertmanager/config.yml
</screen>
   <para>
    &alertmanager;'s configuration file is written in the YAML format. It
    follows the scheme described below. Parameters in brackets are optional.
    For non-list parameters the default value is used. The following generic
    placeholders are used in the scheme:
   </para>
   <variablelist>
    <varlistentry>
     <term><replaceable>DURATION</replaceable></term>
     <listitem>
      <para>
       A duration matching the regular expression
       <literal>[0-9]+(ms|[smhdwy])</literal>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>LABELNAME</replaceable></term>
     <listitem>
      <para>
       A string matching the regular expression
       <literal>[a-zA-Z_][a-zA-Z0-9_]*</literal>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>LABELVALUE</replaceable></term>
     <listitem>
      <para>
       A string of Unicode characters.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>FILEPATH</replaceable></term>
     <listitem>
      <para>
       A valid path in the current working directory.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>BOOLEAN</replaceable></term>
     <listitem>
      <para>
       A Boolean that can take the values 'true' or 'false'.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>STRING</replaceable></term>
     <listitem>
      <para>
       A regular string.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>SECRET</replaceable></term>
     <listitem>
      <para>
       A regular string that is a secret, for example a password.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>TMPL_STRING</replaceable></term>
     <listitem>
      <para>
       A string which is template-expanded before usage.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><replaceable>TMPL_SECRET</replaceable></term>
     <listitem>
      <para>
       A secret string which is template-expanded before usage.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <example>
    <title>Global Configuration</title>
    <para>
     Parameters in the <literal>global:</literal> configuration are valid in
     all other configuration contexts. They also serve as defaults for other
     configuration sections.
    </para>
<screen>
global:
# the time after which an alert is declared resolved if it has not been updated
[ resolve_timeout: <replaceable>DURATION</replaceable> | default = 5m ]

# The default SMTP From header field.
[ smtp_from: <replaceable>TMPL_STRING</replaceable> ]
# The default SMTP smarthost used for sending emails, including port number.
# Port number usually is 25, or 587 for SMTP over TLS
# (sometimes referred to as STARTTLS).
# Example: smtp.example.org:587
[ smtp_smarthost: <replaceable>STRING</replaceable> ]
# The default host name to identify to the SMTP server.
[ smtp_hello: <replaceable>STRING</replaceable> | default = "localhost" ]
[ smtp_auth_username: <replaceable>STRING</replaceable> ]
# SMTP Auth using LOGIN and PLAIN.
[ smtp_auth_password: <replaceable>SECRET</replaceable> ]
# SMTP Auth using PLAIN.
[ smtp_auth_identity: <replaceable>STRING</replaceable> ]
# SMTP Auth using CRAM-MD5.
[ smtp_auth_secret: <replaceable>SECRET</replaceable> ]
# The default SMTP TLS requirement.
[ smtp_require_tls: <replaceable>BOOL</replaceable> | default = true ]

# The API URL to use for Slack notifications.
[ slack_api_url: <replaceable>STRING</replaceable> ]
[ victorops_api_key: <replaceable>STRING</replaceable> ]
[ victorops_api_url: <replaceable>STRING</replaceable> | default = "https://victorops.example.com/integrations/alert/" ]
[ pagerduty_url: <replaceable>STRING</replaceable> | default = "https://pagerduty.example.com/v2/enqueue" ]
[ opsgenie_api_key: <replaceable>STRING</replaceable> ]
[ opsgenie_api_url: <replaceable>STRING</replaceable> | default = "https://opsgenie.example.com/" ]
[ hipchat_api_url: <replaceable>STRING</replaceable> | default = "https://hipchat.example.com/" ]
[ hipchat_auth_token: <replaceable>SECRET</replaceable> ]
[ wechat_api_url: <replaceable>STRING</replaceable> | default = "https://wechat.example.com/cgi-bin/" ]
[ wechat_api_secret: <replaceable>SECRET</replaceable> ]
[ wechat_api_corp_id: <replaceable>STRING</replaceable> ]

# The default HTTP client configuration
[ http_config: <replaceable>HTTP_CONFIG</replaceable> ]

# Files from which custom notification template definitions are read.
# The last component may use a wildcard matcher, e.g. 'templates/*.tmpl'.
templates:
[ - <replaceable>FILEPATH</replaceable> ... ]

# The root node of the routing tree.
route: <replaceable>ROUTE</replaceable>

# A list of notification receivers.
receivers:
- <replaceable>RECEIVER</replaceable> ...

# A list of inhibition rules.
inhibit_rules:
[ - <replaceable>INHIBIT_RULE</replaceable> ... ]
</screen>
   </example>
   <example>
    <title><replaceable>ROUTE</replaceable></title>
    <para>
     A <replaceable>ROUTE</replaceable> block defines a node in a routing
     tree. Unspecified parameters are inherited from its parent node. Every
     alert enters the routing tree at the configured top-level route, which
     needs to match all alerts. It then traverses the child nodes. If the
     <option>continue</option> option is set to 'false', the traversing stops
     after the first matched child. Setting the option to 'true' on a matched
     node, the alert will continue matching against subsequent siblings. If an
     alert does not match any children of a node, the alert is handled based
     on the configuration parameters of the current node.
    </para>
<screen>
[ receiver: <replaceable>STRING</replaceable> ]
[ group_by: '[' <replaceable>LABELNAME</replaceable>, ... ']' ]

# If an alert should continue matching subsequent sibling nodes.
[ continue: <replaceable>BOOLEAN</replaceable> | default = false ]

# A set of equality matchers an alert has to fulfill to match a node.
match:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>LABELVALUE</replaceable>, ... ]

# A set of regex-matchers an alert has to fulfill to match a node.
match_re:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>REGEX</replaceable>, ... ]

# Time to wait before sending a notification for a group of alerts.
[ group_wait: <replaceable>DURATION</replaceable> | default = 30s ]

# Time to wait before sending a notification about new alerts
# added to a group of alerts for which an initial notification has
# already been sent.
[ group_interval: <replaceable>DURATION</replaceable> | default = 5m ]

# Time to wait before re-sending a notification
[ repeat_interval: <replaceable>DURATION</replaceable> | default = 4h ]

# Possible child routes.
routes:
 [ - <replaceable>ROUTE</replaceable> ... ]
</screen>
   </example>
   <example>
    <title><replaceable>INHIBIT_RULE</replaceable></title>
    <para>
     An inhibition rule mutes a target alert that matches a set of matchers
     when a source alert exists that matches another set of matchers. Both
     alerts need to share the same label values for the label names in the
     <option>equal</option> list.
    </para>
    <para>
     Alerts can match and therefore inhibit themselves. Do not write
     inhibition rules where an alert matches both source and target.
    </para>
<screen>
# Matchers that need to be fulfilled for the alerts to be muted.
target_match:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>LABELVALUE</replaceable>, ... ]
target_match_re:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>REGEX</replaceable>, ... ]

# Matchers for which at least one alert needs to exist so that the
# inhibition occurs.
source_match:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>LABELVALUE</replaceable>, ... ]
source_match_re:
 [ <replaceable>LABELNAME</replaceable>: <replaceable>REGEX</replaceable>, ... ]

# Labels with an equal value in the source and target
# alert for the inhibition to take effect.
[ equal: '[' <replaceable>LABELNAME</replaceable>, ... ']' ]
</screen>
   </example>
   <example>
    <title><replaceable>HTTP_CONFIG</replaceable></title>
    <para>
     <replaceable>HTTP_CONFIG</replaceable> configures the HTTP client used by
     the receiver to communicate with API services.
    </para>
    <para>
     Note that <option>basic_auth</option>, <option>bearer_token</option> and
     <option>bearer_token_file</option> options are mutually exclusive.
    </para>
<screen>
# Sets the 'Authorization' header with the user name and password.
basic_auth:
[ username: <replaceable>STRING</replaceable> ]
[ password: <replaceable>SECRET</replaceable> ]

# Sets the 'Authorization' header with the bearer token.
[ bearer_token: <replaceable>SECRET</replaceable> ]

# Sets the 'Authorization' header with the bearer token read from a file.
[ bearer_token_file: <replaceable>FILEPATH</replaceable> ]

# TLS settings.
tls_config:
# CA certificate to validate the server certificate with.
[ ca_file: <replaceable>FILEPATH</replaceable> ]
# Certificate and key files for client cert authentication to the server.
[ cert_file: <replaceable>FILEPATH</replaceable> ]
[ key_file: <replaceable>FILEPATH</replaceable> ]
# ServerName extension to indicate the name of the server.
# http://tools.ietf.org/html/rfc4366#section-3.1
[ server_name: <replaceable>STRING</replaceable> ]
# Disable validation of the server certificate.
[ insecure_skip_verify: <replaceable>BOOLEAN</replaceable> | default = false]

# Optional proxy URL.
[ proxy_url: <replaceable>STRING</replaceable> ]
</screen>
   </example>
   <example>
    <title><replaceable>RECEIVER</replaceable></title>
    <para>
     Receiver is a named configuration for one or more notification
     integrations.
    </para>
    <para>
     Instead of adding new receivers, we recommend implementing custom
     notification integrations using the webhook receiver (see
     <xref linkend="alert-webhook"/>).
    </para>
<screen>
# The unique name of the receiver.
name: <replaceable>STRING</replaceable>

# Configurations for several notification integrations.
email_configs:
[ - <replaceable>EMAIL_CONFIG</replaceable>, ... ]
hipchat_configs:
[ - <replaceable>HIPCHAT_CONFIG</replaceable>, ... ]
pagerduty_configs:
[ - <replaceable>PAGERDUTY_CONFIG</replaceable>, ... ]
pushover_configs:
[ - <replaceable>PUSHOVER_CONFIG</replaceable>, ... ]
slack_configs:
[ - <replaceable>SLACK_CONFIG</replaceable>, ... ]
opsgenie_configs:
[ - <replaceable>OPSGENIE_CONFIG</replaceable>, ... ]
webhook_configs:
[ - <replaceable>WEBHOOK_CONFIG</replaceable>, ... ]
victorops_configs:
[ - <replaceable>VICTOROPS_CONFIG</replaceable>, ... ]
wechat_configs:
[ - <replaceable>WECHAT_CONFIG</replaceable>, ... ]
</screen>
   </example>
   <example>
    <title><replaceable>EMAIL_CONFIG</replaceable></title>
<screen>
# Whether to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = false ]

# The email address to send notifications to.
to: <replaceable>TMPL_STRING</replaceable>

# The sender address.
[ from: <replaceable>TMPL_STRING</replaceable> | default = global.smtp_from ]

# The SMTP host through which emails are sent.
[ smarthost: <replaceable>STRING</replaceable> | default = global.smtp_smarthost ]

# The host name to identify to the SMTP server.
[ hello: <replaceable>STRING</replaceable> | default = global.smtp_hello ]

# SMTP authentication details.
[ auth_username: <replaceable>STRING</replaceable> | default = global.smtp_auth_username ]
[ auth_password: <replaceable>SECRET</replaceable> | default = global.smtp_auth_password ]
[ auth_secret: <replaceable>SECRET</replaceable> | default = global.smtp_auth_secret ]
[ auth_identity: <replaceable>STRING</replaceable> | default = global.smtp_auth_identity ]

# The SMTP TLS requirement.
[ require_tls: <replaceable>BOOL</replaceable> | default = global.smtp_require_tls ]

# The HTML body of the email notification.
[ html: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "email.default.html" . }}' ]
# The text body of the email notification.
[ text: <replaceable>TMPL_STRING</replaceable> ]

# Further headers email header key/value pairs. Overrides any headers
# previously set by the notification implementation.
[ headers: { <replaceable>STRING</replaceable>: <replaceable>TMPL_STRING</replaceable>, ... } ]
</screen>
   </example>
   <example>
    <title><replaceable>HIPCHAT_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = false ]

# The HipChat Room ID.
room_id: <replaceable>TMPL_STRING</replaceable>
# The authentication token.
[ auth_token: <replaceable>SECRET</replaceable> | default = global.hipchat_auth_token ]
# The URL to send API requests to.
[ api_url: <replaceable>STRING</replaceable> | default = global.hipchat_api_url ]

# A label to be shown in addition to the sender's name.
[ from:  <replaceable>TMPL_STRING</replaceable> | default = '{{ template "hipchat.default.from" . }}' ]
# The message body.
[ message:  <replaceable>TMPL_STRING</replaceable> | default = '{{ template "hipchat.default.message" . }}' ]
# Whether this message will trigger a user notification.
[ notify:  <replaceable>BOOLEAN</replaceable> | default = false ]
# Determines how the message is treated by the alertmanager and rendered inside HipChat. Valid values are 'text' and 'html'.
[ message_format:  <replaceable>STRING</replaceable> | default = 'text' ]
# Background color for message.
[ color:  <replaceable>TMPL_STRING</replaceable> | default = '{{ if eq .Status "firing" }}red{{ else }}green{{ end }}' ]

# Configuration of the HTTP client.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example>
    <title><replaceable>PAGERDUTY_CONFIG</replaceable></title>
    <para>
     The <option>routing_key</option> and <option>service_key</option> options
     are mutually exclusive.
    </para>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = true ]

# The PagerDuty integration key (when using 'Events API v2').
routing_key: <replaceable>TMPL_SECRET</replaceable>
# The PagerDuty integration key (when using 'Prometheus').
service_key: <replaceable>TMPL_SECRET</replaceable>

# The URL to send API requests to.
[ url: <replaceable>STRING</replaceable> | default = global.pagerduty_url ]

# The client identification of the Alertmanager.
[ client:  <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pagerduty.default.client" . }}' ]
# A backlink to the notification sender.
[ client_url:  <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pagerduty.default.clientURL" . }}' ]

# The incident description.
[ description: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pagerduty.default.description" .}}' ]

# Severity of the incident.
[ severity: <replaceable>TMPL_STRING</replaceable> | default = 'error' ]

# A set of arbitrary key/value pairs that provide further details.
[ details: { <replaceable>STRING</replaceable>: <replaceable>TMPL_STRING</replaceable>, ... } | default = {
 firing:       '{{ template "pagerduty.default.instances" .Alerts.Firing }}'
 resolved:     '{{ template "pagerduty.default.instances" .Alerts.Resolved }}'
 num_firing:   '{{ .Alerts.Firing | len }}'
 num_resolved: '{{ .Alerts.Resolved | len }}'
} ]

# The HTTP client's configuration.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example>
    <title><replaceable>PUSHOVER_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = true ]

# The recipient user key.
user_key: <replaceable>SECRET</replaceable>

# Registered application’s API token.
token: <replaceable>SECRET</replaceable>

# Notification title.
[ title: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pushover.default.title" . }}' ]

# Notification message.
[ message: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pushover.default.message" . }}' ]

# A supplementary URL displayed together with the message.
[ url: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "pushover.default.url" . }}' ]

# Priority.
[ priority: <replaceable>TMPL_STRING</replaceable> | default = '{{ if eq .Status "firing" }}2{{ else }}0{{ end }}' ]

# How often the Pushover servers will send the same notification (at least 30 seconds).
[ retry: <replaceable>DURATION</replaceable> | default = 1m ]

# How long your notification will continue to be retried (unless the user
# acknowledges the notification).
[ expire: <replaceable>DURATION</replaceable> | default = 1h ]

# Configuration of the HTTP client.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example>
    <title><replaceable>SLACK_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = false ]

# The Slack webhook URL.
[ api_url: <replaceable>SECRET</replaceable> | default = global.slack_api_url ]

# The channel or user to send notifications to.
channel: <replaceable>TMPL_STRING</replaceable>

# API request data as defined by the Slack webhook API.
[ icon_emoji: <replaceable>TMPL_STRING</replaceable> ]
[ icon_url: <replaceable>TMPL_STRING</replaceable> ]
[ link_names: <replaceable>BOOLEAN</replaceable> | default = false ]
[ username: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.username" . }}' ]
# The following parameters define the attachment.
actions:
[ <replaceable>ACTION_CONFIG</replaceable> ... ]
[ color: <replaceable>TMPL_STRING</replaceable> | default = '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}' ]
[ fallback: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.fallback" . }}' ]
fields:
[ <replaceable>FIELD_CONFIG</replaceable> ... ]
[ footer: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.footer" . }}' ]
[ pretext: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.pretext" . }}' ]
[ short_fields: <replaceable>BOOLEAN</replaceable> | default = false ]
[ text: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.text" . }}' ]
[ title: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.title" . }}' ]
[ title_link: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "slack.default.titlelink" . }}' ]
[ image_url: <replaceable>TMPL_STRING</replaceable> ]
[ thumb_url: <replaceable>TMPL_STRING</replaceable> ]

# Configuration of the HTTP client.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example>
    <title><replaceable>ACTION_CONFIG</replaceable> for <replaceable>SLACK_CONFIG</replaceable></title>
<screen>
# Provide a button to tell Slack you want to render a button.
type: <replaceable>TMPL_STRING</replaceable>
# Label for the button.
text: <replaceable>TMPL_STRING</replaceable>
# http or https URL to deliver users to. If you specify invalid URLs, the message will be posted with no button.
url: <replaceable>TMPL_STRING</replaceable>
#  If set to 'primary', the button will be green, indicating the best forward action to take
#  'danger' turns the button red, indicating a destructive action.
[ style: <replaceable>TMPL_STRING</replaceable> [ default = '' ]
</screen>
   </example>
   <example>
    <title><replaceable>FIELD_CONFIG</replaceable> for <replaceable>SLACK_CONFIG</replaceable></title>
<screen>
# A bold heading without markup above the <option>value</option> text.
title: <replaceable>TMPL_STRING</replaceable>
# The text of the field. It can span across several lines.
value: <replaceable>TMPL_STRING</replaceable>
# A flag indicating if <option>value</option> is short enough to be displayed together with other values.
[ short: <replaceable>BOOLEAN</replaceable> | default = slack_config.short_fields ]
</screen>
   </example>
   <example>
    <title><replaceable>OPSGENIE_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = true ]

# The API key to use with the OpsGenie API.
[ api_key: <replaceable>SECRET</replaceable> | default = global.opsgenie_api_key ]

# The host to send OpsGenie API requests to.
[ api_url: <replaceable>STRING</replaceable> | default = global.opsgenie_api_url ]

# Alert text (maximum is 130 characters).
[ message: <replaceable>TMPL_STRING</replaceable> ]

# A description of the incident.
[ description: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "opsgenie.default.description" . }}' ]

# A backlink to the sender.
[ source: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "opsgenie.default.source" . }}' ]

# A set of arbitrary key/value pairs that provide further detail.
[ details: { <replaceable>STRING</replaceable>: <replaceable>TMPL_STRING</replaceable>, ... } ]

# Comma separated list of team responsible for notifications.
[ teams: <replaceable>TMPL_STRING</replaceable> ]

# Comma separated list of tags attached to the notifications.
[ tags: <replaceable>TMPL_STRING</replaceable> ]

# Additional alert note.
[ note: <replaceable>TMPL_STRING</replaceable> ]

# Priority level of alert, one of P1, P2, P3, P4, and P5.
[ priority: <replaceable>TMPL_STRING</replaceable> ]

# Configuration of the HTTP.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example>
    <title><replaceable>VICTOROPS_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = true ]

# The API key for talking to the VictorOps API.
[ api_key: <replaceable>SECRET</replaceable> | default = global.victorops_api_key ]

# The VictorOps API URL.
[ api_url: <replaceable>STRING</replaceable> | default = global.victorops_api_url ]

# A key used to map the alert to a team.
routing_key: <replaceable>TMPL_STRING</replaceable>

# Describes the behavior of the alert (one of 'CRITICAL', 'WARNING', 'INFO').
[ message_type: <replaceable>TMPL_STRING</replaceable> | default = 'CRITICAL' ]

# Summary of the alerted problem.
[ entity_display_name: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "victorops.default.entity_display_name" . }}' ]

# Long explanation of the alerted problem.
[ state_message: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "victorops.default.state_message" . }}' ]

# The monitoring tool the state message is from.
[ monitoring_tool: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "victorops.default.monitoring_tool" . }}' ]

# Configuration of the HTTP client.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
   </example>
   <example xml:id="alert-webhook">
    <title><replaceable>WEBHOOK_CONFIG</replaceable></title>
    <para>
     You can use the webhook receiver to configure a generic receiver.
    </para>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = true ]

# The endpoint for sending HTTP POST requests.
url: <replaceable>STRING</replaceable>

# Configuration of the HTTP client.
[ http_config: <replaceable>HTTP_CONFIG</replaceable> | default = global.http_config ]
</screen>
    <para>
     &alertmanager; sends HTTP POST requests in the following JSON format:
    </para>
<screen>
{
 "version": "4",
 "groupKey": <replaceable>STRING</replaceable>, // identifycation of the group of alerts (to deduplicate)
 "status": "&lt;resolved|firing>",
 "receiver": <replaceable>STRING</replaceable>,
 "groupLabels": <replaceable>OBJECT</replaceable>,
 "commonLabels": <replaceable>OBJECT</replaceable>,
 "commonAnnotations": <replaceable>OBJECT</replaceable>,
 "externalURL": <replaceable>STRING</replaceable>, // backlink to Alertmanager.
 "alerts": [
   {
     "status": "&lt;resolved|firing>",
     "labels": <replaceable>OBJECT</replaceable>,
     "annotations": <replaceable>OBJECT</replaceable>,
     "startsAt": "&lt;rfc3339>",
     "endsAt": "&lt;rfc3339>",
     "generatorURL": <replaceable>STRING</replaceable> // identifies the entity that caused the alert
   },
   ...
 ]
}
</screen>
    <para>
     The webhook receiver allows for integration with the following
     notification mechanisms:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       DingTalk (https://github.com/timonwong/prometheus-webhook-dingtalk)
      </para>
     </listitem>
     <listitem>
      <para>
       IRC Bot (https://github.com/multimfi/bot)
      </para>
     </listitem>
     <listitem>
      <para>
       JIRAlert (https://github.com/free/jiralert)
      </para>
     </listitem>
     <listitem>
      <para>
       Phabricator / Maniphest (https://github.com/knyar/phalerts)
      </para>
     </listitem>
     <listitem>
      <para>
       prom2teams: forwards notifications to Microsoft Teams
       (https://github.com/idealista/prom2teams)
      </para>
     </listitem>
     <listitem>
      <para>
       SMS: supports multiple providers
       (https://github.com/messagebird/sachet)
      </para>
     </listitem>
     <listitem>
      <para>
       Telegram bot (https://github.com/inCaller/prometheus_bot)
      </para>
     </listitem>
     <listitem>
      <para>
       SNMP trap (https://github.com/SUSE/prometheus-webhook-snmp)
      </para>
     </listitem>
    </itemizedlist>
   </example>
   <example>
    <title><replaceable>WECHAT_CONFIG</replaceable></title>
<screen>
# Whether or not to notify about resolved alerts.
[ send_resolved: <replaceable>BOOLEAN</replaceable> | default = false ]

# The API key to use for the WeChat API.
[ api_secret: <replaceable>SECRET</replaceable> | default = global.wechat_api_secret ]

# The WeChat API URL.
[ api_url: <replaceable>STRING</replaceable> | default = global.wechat_api_url ]

# The corp id used to authenticate.
[ corp_id: <replaceable>STRING</replaceable> | default = global.wechat_api_corp_id ]

# API request data as defined by the WeChat API.
[ message: <replaceable>TMPL_STRING</replaceable> | default = '{{ template "wechat.default.message" . }}' ]
[ agent_id: <replaceable>STRING</replaceable> | default = '{{ template "wechat.default.agent_id" . }}' ]
[ to_user: <replaceable>STRING</replaceable> | default = '{{ template "wechat.default.to_user" . }}' ]
[ to_party: <replaceable>STRING</replaceable> | default = '{{ template "wechat.default.to_party" . }}' ]
[ to_tag: <replaceable>STRING</replaceable> | default = '{{ template "wechat.default.to_tag" . }}' ]
</screen>
   </example>
  </sect2>
  <sect2>
   <title>Custom Alerts</title>
   <para>
    You can define your custom alert conditions to send notifications to an
    external service. &prometheus; uses its own expression language for
    defining custom alerts. Following is an example of a rule with an alert:
   </para>
<screen>
groups:
- name: example
 rules:
  # alert on high deviation from average PG count
  - alert: high pg count deviation
   expr: abs(((ceph_osd_pgs > 0) - on (job) group_left avg(ceph_osd_pgs > 0) by (job)) / on (job) group_left avg(ceph_osd_pgs > 0) by (job)) > 0.35
   for: 5m
   labels:
    severity: warning
    type: ses_default
   annotations:
   description: >
    OSD {{ $labels.osd }} deviates by more then 30% from average PG count
</screen>
   <para>
    The optional <literal>for</literal> clause specifies the time &prometheus;
    will wait between first encountering a new expression output vector
    element and counting an alert as firing. In this case, &prometheus; will
    check that the alert continues to be active for 5 minutes before firing
    the alert. Elements in a pending state are active, but not firing yet.
   </para>
   <para>
    The <literal>labels</literal> clause specifies a set of additional labels
    attached to the alert. Conflicting labels will be overwritten. Labels can
    be templated (see <xref linkend="alertmanager-templates"/> for more
    details on templating).
   </para>
   <para>
    The <literal>annotations</literal> clause specifies informational labels.
    You can use them to store additional information, for example alert
    descriptions or runbook links. Annotations can be templated (see
    <xref linkend="alertmanager-templates"/> for more details on templating).
   </para>
   <para>
    To add your custom alerts to &productname; &productnumber;, either
   </para>
   <itemizedlist>
    <listitem>
     <para>
      place your YAML files with custom alerts in the
      <filename>/etc/prometheus/alerts</filename> directory
     </para>
    </listitem>
   </itemizedlist>
   <para>
    or
   </para>
   <itemizedlist>
    <listitem>
     <para>
      provide a list of paths to your custom alert files in the Pillar under
      the <option>monitoring:custom_alerts</option> key. &deepsea; Stage 2 or
      the <command>salt <replaceable>SALT_MASTER</replaceable> state.apply
      ceph.monitoring.prometheus</command> command will add your alert files
      in the right place.
     </para>
     <example>
      <title>Adding Custom Alerts to &productname;</title>
      <para>
       A file with custom alerts is in
       <filename>/root/my_alerts/my_alerts.yml</filename> on the Salt master.
       If you add
      </para>
<screen>
monitoring:
 custom_alerts:
   - /root/my_alerts/my_alerts.yml
</screen>
      <para>
       to the
       <filename>/srv/pillar/ceph/cluster/<replaceable>YOUR_SALT_MASTER_MINION_ID</replaceable>.sls</filename>
       file, &deepsea; will create the
       <filename>/etc/prometheus/alerts/my_alerts.yml</filename> file and
       restart &prometheus;.
      </para>
     </example>
    </listitem>
   </itemizedlist>
   <sect3 xml:id="alertmanager-templates">
    <title>Templates</title>
    <para>
     You can use templates for label and annotation values. The
     <varname>$labels</varname> variable includes the label key/value pairs of
     an alert instance, while <varname>$value</varname> holds the evaluated
     value of an alert instance.
    </para>
    <para>
     The following example inserts a firing element label and value:
    </para>
<screen>
{{ $labels.<replaceable>LABELNAME</replaceable> }}
{{ $value }}
</screen>
   </sect3>
   <sect3>
    <title>Inspecting Alerts at Runtime</title>
    <para>
     If you need to verify which alerts are active, you have several options:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Navigate to the <guimenu>Alerts</guimenu> tab of &prometheus;. It will
       show you the exact label sets for which defined alerts are active.
       &prometheus; also stores synthetic time series for pending and firing
       alerts. They have the following form:
      </para>
<screen>
ALERTS{alertname="<replaceable>ALERT_NAME</replaceable>", alertstate="pending|firing", <replaceable>ADDITIONAL_ALERT_LABELS</replaceable>}
</screen>
      <para>
       The sample value is 1 if the alert is active (pending or firing). The
       series is marked 'stale' when the alert is inactive.
      </para>
     </listitem>
     <listitem>
      <para>
       In the &prometheus; Web interface at the URL address
       http://<replaceable>PROMETHEUS_HOST_IP</replaceable>:9090/alerts,
       inspect alerts and their state (INACTIVE, PENDING or FIRING).
      </para>
     </listitem>
     <listitem>
      <para>
       In the &alertmanager; Web interface at the URL address
       http://:<replaceable>PROMETHEUS_HOST_IP</replaceable>9093/#/alerts,
       inspect alerts and silence them if desired.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
  </sect2>
  <sect2>
   <title>SNMP Trap Receiver</title>
   <para>
    If you want to get notified about &prometheus; alerts via SNMP traps, then
    you can install the &prometheus; &alertmanager; SNMP trap receiver via
    &deepsea;. To do so you need to enable it in the Pillar under the
    <option>monitoring:alertmanager_receiver_snmp:enabled</option> key. The
    configuration of the receiver must be set under the
    <option>monitoring:alertmanager_receiver_snmp:config</option> key.
    &deepsea; Stage 2 or the <command>salt
    <replaceable>SALT_MASTER</replaceable> state.apply
    ceph.monitoring.alertmanager</command> command will install and configure
    the receiver in the appropriate location.
   </para>
   <example>
    <title>SNMP Trap Configuration</title>
<screen>
monitoring:
 alertmanager:
   receiver:
      snmp:
        enabled: True
        config:
          host: localhost
          port: 9099
          snmp_host: snmp.foo-bar.com
          snmp_community: private
          metrics: True
</screen>
     <para>
      Refer to the receiver manual at
      <link xlink:href="https://github.com/SUSE/prometheus-webhook-snmp#global-configuration-file" />.
      for more details about the configuration options.
     </para>
    </example>
  </sect2>
</sect1>
<sect1 xml:id="troubleshooting-alerts">
 <title>Troubleshooting Alerts</title>
 <para>The following section details the alert that has been triggered and
   actions to take when the alert is displayed.</para>
   <variablelist><title>MONITOR</title>
     <varlistentry>
       <term><option>MON_DOWN</option></term>
       <listitem>
         <para>One or more monitor daemons is currently down.
           The cluster requires a majority (more than 1/2) of
           the monitors in order to function. When one or more
           monitors are down, clients may have a harder time
           forming their initial connection to the cluster as
           they may need to try more addresses before they
           reach an operating monitor.</para>
         <para>The down monitor daemon should generally be
           restarted as soon as possible to reduce the risk
           of a subsequen monitor failure leading to a service outage.</para>
       </listitem>
     </varlistentry>
     <varlistentry>
       <term><option>MON_CLOCK_SKEW</option></term>
       <listitem>
         <para>
           The clocks on the hosts running the <systemitem class="daemon">ceph-mon</systemitem> monitor daemons are
           not sufficiently well synchronized. This health alert is raised
           if the cluster detects a clock skew greater than
           <option>mon_clock_drift_allowed</option>.
           This is best resolved by synchronizing the clocks using a
           tool like ntpd or chrony.
           If it is impractical to keep the clocks closely synchronized,
           the <option>mon_clock_drift_allowed</option> threshold can also
           be increased, but this value must stay significantly below the
           <option>mon_lease</option> interval in order for monitor cluster
           to function properly.
         </para>
       </listitem>
     </varlistentry>
     <varlistentry>
       <term><option>MON_MSGR2_NOT_ENABLED</option></term>
       <listitem>
         <para>
           The <option>ms_bind_msgr2</option> option is enabled but one
           or more monitors is not configured to bind to a v2 port in the
           cluster’s monmap. This means that features specific to the msgr2
           protocol (for example, encryption) are not available on some or all connections.
           In most cases this can be corrected by issuing the command:</para>
<screen>&prompt.cephuser;ceph mon enable-msgr2</screen>
        <para>That command changes any monitor configured for the old default
           port 6789 to continue to listen for v1 connections on 6789 and also
           listen for v2 connections on the new default 3300 port.
           If a monitor is configured to listen for v1 connections on a
           non-standard port (not 6789), then the monmap will need to be modified manually.</para>
       </listitem>
     </varlistentry>
    </variablelist>
    <variablelist><title>MANAGER</title>
      <varlistentry>
        <term><option>MGR_MODULE_DEPENDENCY</option></term>
        <listitem>
          <para>An enabled manager module is failing its dependency check.
            This health check should come with an explanatory message from
            the module about the problem. For example, a module might report
            that a required package is not installed: install the required
            package and restart your manager daemons. This health check is only
            applied to enabled modules. If a module is not enabled, you
            can see whether it is reporting dependency issues in the
            output of <command>ceph module ls</command>.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>MGR_MODULE_ERROR</option></term>
        <listitem>
          <para>A manager module has experienced an unexpected error. Typically,
            this means an unhandled exception was raised from the module’s
            serve function. The human readable description of the error may
            be obscurely worded if the exception did not provide a useful
            description of itself. This health check may indicate a bug, open
            a bug report if you think you have encountered a bug.
            If you believe the error is transient, you may restart your manager
            daemon(s), or use <command>ceph mgr fail</command> on the active daemon to prompt a
            failover to another daemon.</para>
        </listitem>
      </varlistentry>
    </variablelist>
    <variablelist><title>OSDS</title>
      <varlistentry>
        <term><option>OSD_DOWN</option></term>
        <listitem>
          <para>One or more OSDs are marked down. The <systemitem class="daemon">ceph-osd</systemitem> daemon may have
            been stopped, or peer OSDs may be unable to reach the OSD over the
            network. Common causes include a stopped or crashed daemon, a
            down host, or a network outage.
           Verify the host is healthy, the daemon is started, and network is
           functioning. If the daemon has crashed, the daemon log file
           (<filename>/var/log/ceph/ceph-osd.*</filename>) may contain debugging information.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_<replaceable>CRUSH TYPE</replaceable>_DOWN</option></term>
        <listitem>
          <para>For example, <filename>OSD_HOST_DOWN</filename> or
          <filename>OSD_ROOT_DOWN</filename>.
          All the OSDs within a particular CRUSH subtree are marked down,
          for example all OSDs on a host.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_ORPHAN</option></term>
        <listitem>
          <para>An OSD is referenced in the &crushmap; hierarchy but does not exist.
            The OSD can be removed from the CRUSH hierarchy with:</para>
<screen>&prompt.cephuser;ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_OUT_OF_ORDER_FULL</option></term>
        <listitem>
          <para>The utilization thresholds for <literal>backfillfull</literal>, <literal>nearfull</literal>, <literal>full</literal>,
            and <option>failsafe_full</option> are not ascending.
            The thresholds can be adjusted with:</para>
<screen>&prompt.cephuser;ceph osd set-backfillfull-ratio <replaceable>RATIO</replaceable>
&prompt.cephuser;ceph osd set-nearfull-ratio <replaceable>RATIO</replaceable>
&prompt.cephuser;ceph osd set-full-ratio <replaceable>RATIO</replaceable></screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_FULL</option></term>
        <listitem>
          <para>One or more OSDs has exceeded the full threshold and is
            preventing the cluster from servicing writes.
            Utilization by pool can be checked with:</para>
<screen>&prompt.cephuser;ceph df</screen>
          <para>The currently defined <literal>full</literal> ratio can be seen with:</para>
<screen>&prompt.cephuser;ceph osd dump | grep full_ratio</screen>
          <para>A short-term workaround to restore write availability is to raise the full threshold by a small amount:</para>
<screen>&prompt.cephuser;ceph osd set-full-ratio <replaceable>RATIO</replaceable></screen>
          <para>New storage should be added to the cluster by deploying more
            OSDs or existing data should be deleted in order to free up space.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_BACKFILLFULL</option></term>
        <listitem>
          <para>One or more OSDs has exceeded the backfillfull threshold, which
            prevents data from being allowed to rebalance to this device.
            This is an early warning that rebalancing may not be able to
            complete and that the cluster is approaching full.
            Utilization by pool can be checked with:</para>
<screen>&prompt.cephuser;ceph df</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_NEARFULL</option></term>
        <listitem>
          <para>One or more OSDs has exceeded the nearfull threshold. This is
            an early warning that the cluster is approaching full.
            Utilization by pool can be checked with:</para>
<screen>&prompt.cephuser;ceph df</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSDMAP_FLAGS</option></term>
        <listitem>
          <para>One or more cluster flags of interest has been set.
            These flags include:</para>
            <itemizedlist>
              <listitem>
                <para>
                  <literal>full</literal> - the cluster is flagged as full and cannot serve writes
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>pauserd, pausewr</literal> - paused reads or writes
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noup</literal> - OSDs are not allowed to start
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>nodown</literal> - OSD failure reports are being ignored, such that the monitors will not mark OSDs down
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noin</literal> - OSDs that were previously marked out will not be marked back in when they start
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noout</literal> - down OSDs will not automatically be marked out after the configured interval
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>nobackfill, norecover, norebalance</literal> - recovery or data rebalancing is suspended
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noscrub, nodeep_scrub</literal> - scrubbing is disabled
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>notieragent</literal> - cache tiering activity is suspended
                </para>
              </listitem>
            </itemizedlist>
          <para>With the exception of full, these flags can be set or cleared with:</para>
<screen>&prompt.cephuser;ceph osd set <replaceable>FLAG</replaceable>
&prompt.cephuser;ceph osd unset <replaceable>FLAG</replaceable></screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_FLAGS</option></term>
        <listitem>
          <para>One or more OSDs or CRUSH <literal>{nodes,device classes}</literal> has a
            flag of interest set. These flags include:</para>
            <itemizedlist>
              <listitem>
                <para>
                  <literal>noup</literal> - these OSDs are not allowed to start
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>nodown</literal> - failure reports for these OSDs will be ignored
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noin</literal> - if these OSDs were previously marked
                 out automatically after a failure, they will not be marked in when they start
                </para>
              </listitem>
              <listitem>
                <para>
                 <literal>noout</literal> - if these OSDs are down they will
                 not automatically be marked out after the configured interval
                </para>
              </listitem>
            </itemizedlist>
          <para>These flags can be set and cleared in batch with:</para>
<screen>&prompt.cephuser;ceph osd set-group <replaceable>FLAG</replaceable> <replaceable>WHO</replaceable>
&prompt.cephuser;ceph osd unset-group <replaceable>FLAG</replaceable> <replaceable>WHO</replaceable></screen>
          <para>For example:</para>
<screen>&prompt.cephuser;ceph osd set-group noup,noout osd.0 osd.1
&prompt.cephuser;ceph osd unset-group noup,noout osd.0 osd.1
&prompt.cephuser;ceph osd set-group noup,noout host-foo
&prompt.cephuser;ceph osd unset-group noup,noout host-foo
&prompt.cephuser;ceph osd set-group noup,noout class-hdd
&prompt.cephuser;ceph osd unset-group noup,noout class-hdd
</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OLD_CRUSH_TUNABLES</option></term>
        <listitem>
          <para>
            The &crushmap; is using very old settings and should be updated.
            The oldest tunables that can be used (for example, the oldest client
            version that can connect to the cluster) without triggering this
            health warning are determined by the <option>mon_crush_min_required_version</option> config option.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OLD_CRUSH_STRAW_CALC_VERSION</option></term>
        <listitem>
          <para>
            The &crushmap; is using an older, non-optimal method for calculating
            intermediate weight values for straw buckets. The &crushmap; should
            be updated to use the newer method (<literal>straw_calc_version=1</literal>).
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>CACHE_POOL_NO_HIT_SET</option></term>
        <listitem>
          <para>One or more cache pools is not configured with a hit set to
            track utilization, which will prevent the tiering agent from
            identifying cold objects to flush and evict from the cache.
            Hit sets can be configured on the cache pool with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOLNAME</replaceable> hit_set_type <replaceable>TYPE</replaceable>
&prompt.cephuser;ceph osd pool set <replaceable>POOLNAME</replaceable> hit_set_period <replaceable>PERIOD-IN-SECONDS</replaceable>
&prompt.cephuser;ceph osd pool set <replaceable>POOLNAME</replaceable> hit_set_count <replaceable>NUMBER-OF-HITSETS</replaceable>
&prompt.cephuser;ceph osd pool set <replaceable>POOLNAME</replaceable> hit_set_fpp <replaceable>TARGET-FALSE-POSITIVE-RATE</replaceable></screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>OSD_NO_SORTBITWISE</option></term>
        <listitem>
          <para>
            No pre-Luminous v12.y.z OSDs are running but the sortbitwise flag
            has not been set. The sortbitwise flag must be set before Luminous
            v12.y.z or newer OSDs can start. You can safely set the flag with:
          </para>
<screen>&prompt.cephuser;ceph osd set sortbitwise</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>POOL_FULL</option></term>
        <listitem>
          <para>One or more pools has reached its quota and is no longer allowing writes.
            Pool quotas and utilization can be seen with:</para>
<screen>&prompt.cephuser;ceph df detail</screen>
          <para>You can either raise the pool quota with:</para>
<screen>&prompt.cephuser;ceph osd pool set-quota <replaceable>POOLNAME</replaceable> max_objects <replaceable>NUM-OBJECTS</replaceable>
&prompt.cephuser;ceph osd pool set-quota <replaceable>POOLNAME</replaceable> max_bytes <replaceable>NUM-BYTES</replaceable></screen>
          <para>Or delete some existing data to reduce utilization.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUEFS_SPILLOVER</option></term>
        <listitem>
          <para>One or more OSDs that use the &bluestore; backend have been
            allocated db partitions (storage space for metadata, normally on
            a faster device) but that space has filled, such that metadata has
            “spilled over” onto the normal slow device. This is not
            necessarily an error condition or even unexpected, but if the
            administrator’s expectation was that all metadata would fit on
            the faster device, it indicates that not enough space was provided.
            This warning can be disabled on all OSDs with:</para>
<screen>&prompt.cephuser;ceph config set osd bluestore_warn_on_bluefs_spillover false</screen>
          <para>Alternatively, it can be disabled on a specific OSD with:</para>
<screen>&prompt.cephuser;ceph config set osd.123 bluestore_warn_on_bluefs_spillover false</screen>
          <para>To provide more metadata space, the OSD in question could be
            destroyed and reprovisioned. This will involve data migration and recovery.
            It may also be possible to expand the LVM logical volume backing the db
            storage. If the underlying LV has been expanded, the OSD daemon needs
            to be stopped and BlueFS informed of the device size change with:</para>
<screen>&prompt.cephuser;ceph-bluestore-tool bluefs-bdev-expand --path /var/lib/ceph/osd/ceph-$ID</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUEFS_AVAILABLE_SPACE</option></term>
        <listitem>
          <para>To check how much space is free for BlueFS do:</para>
<screen>&prompt.cephuser;ceph daemon osd.123 bluestore bluefs available</screen>
          <para>This will output up to 3 values: <literal>BDEV_DB free</literal>, <literal>BDEV_SLOW free</literal> and
            <option>available_from_bluestore</option>. <literal>BDEV_DB</literal> and <literal>BDEV_SLOW</literal> report amount of space
            that has been acquired by BlueFS and is considered free. Value
            <option>available_from_bluestore</option> denotes ability of &bluestore; to leave
            more space to BlueFS. It is normal that this value is different from
            amount of &bluestore; free space, as BlueFS allocation unit is
            typically larger than &bluestore; allocation unit. This means that
            only part of &bluestore; free space will be acceptable for BlueFS.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUEFS_LOW_SPACE</option></term>
        <listitem>
          <para>If BlueFS is running low on available free space and there is little
            <option>available_from_bluestore</option> you can consider reducing BlueFS allocation
            unit size. To simulate available space when allocation unit is different do:</para>
<screen>&prompt.cephuser;ceph daemon osd.123 bluestore bluefs available <replaceable>ALLOC-UNIT-SIZE</replaceable></screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUESTORE_FRAGMENTATION</option></term>
        <listitem>
          <para>As &bluestore; works, free space on underlying storage will get
            fragmented. This is normal and unavoidable but excessive fragmentation
            will cause slowdown. To inspect &bluestore; fragmentation one can do:</para>
<screen>&prompt.cephuser;ceph daemon osd.123 bluestore allocator score block</screen>
          <para>Score is given in [0-1] range. [0.0 .. 0.4] tiny fragmentation [0.4 .. 0.7]
            small, acceptable fragmentation [0.7 .. 0.9] considerable, but safe
            fragmentation [0.9 .. 1.0] severe fragmentation, may impact BlueFS
            ability to get space from &bluestore;.
            If detailed report of free fragments is required do:</para>
<screen>&prompt.cephuser;ceph daemon osd.123 bluestore allocator dump block</screen>
          <para>In case when handling OSD process that is not running fragmentation
           can be inspected with <command>ceph-bluestore-tool</command>. Get fragmentation score:</para>
<screen>&prompt.cephuser;ceph-bluestore-tool --path /var/lib/ceph/osd/ceph-123 --allocator block free-score</screen>
          <para>And dump detailed free chunks:</para>
<screen>&prompt.cephuser;ceph-bluestore-tool --path /var/lib/ceph/osd/ceph-123 --allocator block free-dump</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUESTORE_LEGACY_STATFS</option></term>
        <listitem>
          <para>In the Nautilus release, &bluestore; tracks its internal usage
            statistics on a per-pool granular basis, and one or more OSDs have
            &bluestore; volumes that were created prior to Nautilus. If all OSDs
            are older than Nautilus, this just means that the per-pool metrics
            are not available. However, if there is a mix of pre-Nautilus and
           post-Nautilus OSDs, the cluster usage statistics reported by <command>ceph
           df</command> will not be accurate.
            The old OSDs can be updated to use the new usage tracking scheme by
            stopping each OSD, running a repair operation, and the restarting it.
            For example, if osd.123 needed to be updated:</para>
<screen>&prompt.root;systemctl stop ceph-osd@123
&prompt.cephuser;ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-123
&prompt.root;systemctl start ceph-osd@123</screen>
         <para>This warning can be disabled with:</para>
<screen>&prompt.cephuser;ceph config set global bluestore_warn_on_legacy_statfs false</screen>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term><option>BLUESTORE_DISK_SIZE_MISMATCH</option></term>
        <listitem>
          <para>One or more OSDs using &bluestore; has an internal inconsistency
            between the size of the physical device and the metadata tracking
            its size. This can lead to the OSD crashing in the future.
            The OSDs in question should be destroyed and re-deployed.
            To avoid putting any data at risk, re-deploy only  one OSD at a time.
            For example, if osd $N has the error:</para>
<screen>&prompt.cephuser;ceph osd out osd.$N
while ! ceph osd safe-to-destroy osd.$N ; do sleep 1m ; done
ceph osd destroy osd.$N
ceph-volume lvm zap /path/to/device
ceph-volume lvm create --osd-id $N --data /path/to/device</screen>
        </listitem>
      </varlistentry>
    </variablelist>
  <variablelist><title>DEVICE HEALTH</title>
    <varlistentry>
      <term><option>DEVICE_HEALTH</option></term>
      <listitem>
        <para>One or more devices is expected to fail soon, where the warning
        threshold is controlled by the <literal>mgr/devicehealth/warn_threshold</literal> config option.
        This warning only applies to OSDs that are currently marked “in”, so the
        expected response to this failure is to mark the device “out” so that data
        is migrated off of the device, and then to remove the hardware from the
        system. Note that the marking out is normally done automatically if
        <literal>mgr/devicehealth/self_heal</literal> is enabled based on the
        <literal>mgr/devicehealth/mark_out_threshold</literal>.
        Device health can be checked with:</para>
<screen>&prompt.cephuser;ceph device info <replaceable>DEVICE-ID</replaceable></screen>
      <para>Device life expectancy is set by a prediction model run by the &mgr;
        or by an external tool via the command:</para>
<screen>&prompt.cephuser;ceph device set-life-expectancy <replaceable>DEVICE-ID</replaceable> <replaceable>FROM</replaceable> <replaceable>TO</replaceable></screen>
      <para>You can change the stored life expectancy manually, but that usually
        does not remain&mdash;the tool that originally set it will
        probably set it again, and changing the stored value does not affect
        the actual health of the hardware device.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>DEVICE_HEALTH_IN_USE</option></term>
      <listitem>
        <para>One or more devices is expected to fail soon and has been marked
          “out” of the cluster based on <literal>mgr/devicehealth/mark_out_threshold</literal>,
          but it is still participating in one more PGs. This may be because it
          was only recently marked “out” and data is still migrating, or because
          data cannot be migrated off for some reason (for example, the cluster is
          nearly full, or the CRUSH hierarchy is such that there is not another
          suitable OSD to migrate the data too).
          This message can be silenced by disabling the self heal behavior
          (setting <literal>mgr/devicehealth/self_heal</literal> to false), by adjusting the
          <literal>mgr/devicehealth/mark_out_threshold</literal>, or by addressing what is
          preventing data from being migrated off of the ailing device.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>DEVICE_HEALTH_TOOMANY</option></term>
      <listitem>
        <para>Too many devices is expected to fail soon and the <literal>mgr/devicehealth/self_heal</literal>
          behavior is enabled, such that marking out all of the ailing devices
          would exceed the clusters <option>mon_osd_min_in_ratio</option> ratio that prevents
          too many OSDs from being automatically marked “out”.
          This generally indicates that too many devices in your cluster are
          expected to fail soon and you should take action to add newer
          (healthier) devices before too many devices fail and data is lost.
          The health message can also be silenced by adjusting parameters like
          <option>mon_osd_min_in_ratio</option> or <literal>mgr/devicehealth/mark_out_threshold</literal>, but
          be warned that this will increase the likelihood of unrecoverable
          data loss in the cluster.
        </para>
      </listitem>
    </varlistentry>
  </variablelist>
  <variablelist><title>DATA HEALTH (POOLS AND PLACEMENT GROUPS)</title>
    <varlistentry>
      <term><option>PG_AVAILABILITY</option></term>
      <listitem>
        <para>Data availability is reduced, meaning that the cluster is unable
          to service potential read or write requests for some data in the
          cluster. Specifically, one or more PGs is in a state that does
          not allow IO requests to be serviced. Problematic PG states
          include peering, stale, incomplete, and the lack of active
          (if those conditions do not clear quickly).
          Detailed information about which PGs are affected is available from:
        </para>
<screen>&prompt.cephuser;ceph health detail</screen>
        <para>In most cases the root cause is that one or more OSDs is
          currently down; see the discussion for <option>OSD_DOWN</option> above.
          The state of specific problematic PGs can be queried with:</para>
<screen>&prompt.cephuser;ceph tell <replaceable>PG_ID</replaceable> query</screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_DEGRADED</option></term>
      <listitem>
        <para>Data redundancy is reduced for some data, meaning the cluster
          does not have the desired number of replicas for all data (for
          replicated pools) or erasure code fragments (for erasure coded
          pools). Specifically, one or more PGs:</para>
          <itemizedlist>
            <listitem>
              <para>
                has the degraded or undersized flag set, meaning there are
                not enough instances of that placement group in the cluster;
              </para>
            </listitem>
            <listitem>
              <para>
                has not had the clean flag set for some time.
              </para>
            </listitem>
          </itemizedlist>
          <para>Detailed information about which PGs are affected is available from:</para>
<screen>&prompt.cephuser;ceph health detail</screen>
          <para>In most cases the root cause is that one or more OSDs is
            currently down; see the dicussion for <option>OSD_DOWN</option> above.
            The state of specific problematic PGs can be queried with:</para>
<screen>&prompt.cephuser;ceph tell <replaceable>PG_ID</replaceable> query</screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_RECOVERY_FULL</option></term>
      <listitem>
        <para>Data redundancy may be reduced or at risk for some data due to
          a lack of free space in the cluster. Specifically, one or more
          PGs has the <option>recovery_toofull</option> flag set, meaning that the cluster
          is unable to migrate or recover data because one or more OSDs is
          above the full threshold.
          See the discussion for <option>OSD_FULL</option> above for steps to resolve
          this condition.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_BACKFILL_FULL</option></term>
      <listitem>
        <para>Data redundancy may be reduced or at risk for some data due to
          a lack of free space in the cluster. Specifically, one or more PGs
          has the <option>backfill_toofull</option> flag set, meaning that the cluster is
          unable to migrate or recover data because one or more OSDs is
          above the backfillfull threshold.
          See the discussion for <option>OSD_BACKFILLFULL</option> above for steps to
          resolve this condition.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_DAMAGED</option></term>
      <listitem>
        <para>Data scrubbing has discovered some problems with data consistency
          in the cluster. Specifically, one or more PGs has the inconsistent
          or <option>snaptrim_error</option> flag is set, indicating an earlier scrub operation
          found a problem, or that the repair flag is set, meaning a repair
          for such an inconsistency is currently in progress.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>OSD_SCRUB_ERRORS</option></term>
      <listitem>
        <para>Recent OSD scrubs have uncovered inconsistencies. This error is
          generally paired with <option>PG_DAMAGED</option> (see above).</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>LARGE_OMAP_OBJECTS</option></term>
      <listitem>
        <para>One or more pools contain large omap objects as determined by
          <option>osd_deep_scrub_large_omap_object_key_threshold</option> (threshold for number
          of keys to determine a large omap object) or
          <option>osd_deep_scrub_large_omap_object_value_sum_threshold</option>
          (the threshold for summed size (bytes) of all key values to
          determine a large omap object) or both. More information on the
          object name, key count, and size in bytes can be found by searching
          the cluster log for ‘Large omap object found’. Large omap objects
          can be caused by RGW bucket index objects that do not have
          automatic resharding enabled.
          The thresholds can be adjusted with:
        </para>
<screen>&prompt.cephuser;ceph config set osd osd_deep_scrub_large_omap_object_key_threshold <replaceable>KEYS</replaceable>
&prompt.cephuser;ceph config set osd osd_deep_scrub_large_omap_object_value_sum_threshold <replaceable>BYTES</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>CACHE_POOL_NEAR_FULL</option></term>
      <listitem>
        <para>A cache tier pool is nearly full. Full in this context is
          determined by the <option>target_max_bytes</option> and <option>target_max_objects</option> properties
          on the cache pool. Once the pool reaches the target threshold, write
          requests to the pool may block while data is flushed and evicted
          from the cache, a state that normally leads to very high latencies and poor performance.
          The cache pool target size can be adjusted with:
        </para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>CACHE-POOL-NAME</replaceable> target_max_bytes <replaceable>BYTES</replaceable>
&prompt.cephuser;ceph osd pool set <replaceable>CACHE-POOL-NAME</replaceable> target_max_objects <replaceable>OBJECTS</replaceable></screen>
        <para>Normal cache flush and evict activity may also be throttled due
          to reduced availability or performance of the base tier, or overall cluster load.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_TOO_FEW_PGS</option></term>
      <listitem>
        <para>One or more pools should probably have more PGs, based on the
          amount of data that is currently stored in the pool. This can lead
          to suboptimal distribution and balance of data across the OSDs in
          the cluster, and similarly reduce overall performance. This warning
          is generated if the <option>pg_autoscale_mode</option> property on the pool is set to warn.
          To disable the warning, you can disable auto-scaling of PGs for the pool entirely with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_autoscale_mode off</screen>
        <para>To allow the cluster to automatically adjust the number of PGs:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_autoscale_mode on</screen>
        <para>You can also manually set the number of PGs for the pool to the recommended amount with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_num <replaceable>NEW-PG-NUM</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>TOO_MANY_PGS</option></term>
      <listitem>
        <para>The number of PGs in use in the cluster is above the configurable
          threshold of <option>mon_max_pg_per_osd</option> PGs per OSD. If this threshold is
          exceeded, the cluster will not allow new pools to be created, pool <option>pg_num</option>
          to be increased, or pool replication to be increased (any of which
          would lead to more PGs in the cluster). A large number of PGs can
          lead to higher memory utilization for OSD daemons, slower peering
          after cluster state changes (like OSD restarts, additions, or
          removals), and higher load on the &mgr; and &mon; daemons.
          The simplest way to mitigate the problem is to increase the number
          of OSDs in the cluster by adding more hardware. Note that the OSD
          count used for the purposes of this health check is the number
          of “in” OSDs, so marking “out” OSDs “in” (if there are any) can also help:</para>
<screen>&prompt.cephuser;ceph osd in <replaceable>OSD_IDs</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_TOO_MANY_PGS</option></term>
      <listitem>
        <para>One or more pools should probably have more PGs, based on the
          amount of data that is currently stored in the pool. This can lead
          to higher memory utilization for OSD daemons, slower peering after
          cluster state changes (like OSD restarts, additions, or removals),
          and higher load on the Manager and Monitor daemons. This warning
          is generated if the <option>pg_autoscale_mode</option> property on the pool is
          set to warn.
          To disable the warning, you can disable auto-scaling of PGs for
          the pool entirely with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_autoscale_mode off</screen>
        <para>To allow the cluster to automatically adjust the number of PGs:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_autoscale_mode on</screen>
        <para>You can also manually set the number of PGs for the pool to the recommended amount with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> pg_num <replaceable>NEW-PG-NUM</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_TARGET_SIZE_RATIO_OVERCOMMITTED</option></term>
      <listitem>
        <para>One or more pools have a <option>target_size_ratio</option> property set to
          estimate the expected size of the pool as a fraction of total
          storage, but the value(s) exceed the total available storage
          (either by themselves or in combination with other pools’ actual usage).
          This is usually an indication that the <option>target_size_ratio</option> value
          for the pool is too large and should be reduced or set to zero with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> target_size_ratio 0</screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_TARGET_SIZE_BYTES_OVERCOMMITTED</option></term>
      <listitem>
        <para>One or more pools have a <option>target_size_bytes</option> property set to
          estimate the expected size of the pool, but the value(s) exceed
          the total available storage (either by themselves or in
          combination with other pools’ actual usage).
          This is usually an indication that the <option>target_size_bytes</option> value
          for the pool is too large and should be reduced or set to zero with:</para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL-NAME</replaceable> target_size_bytes 0</screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>TOO_FEW_OSDS</option></term>
      <listitem>
        <para>The number of OSDs in the cluster is below the configurable
          threshold of <option>osd_pool_default_size</option>.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>SMALLER_PGP_NUM</option></term>
      <listitem>
        <para>One or more pools has a <option>pgp_num</option> value less than <option>pg_num</option>.
          This is normally an indication that the PG count was increased
          without also increasing the placement behavior.
          This is sometimes done deliberately to separate out the split step
          when the PG count is adjusted from the data migration that is needed
          when <option>pgp_num</option> is changed.
          This is normally resolved by setting <option>pgp_num</option> to
          match <option>pg_num</option>, triggering the data migration, with:
        </para>
<screen>&prompt.cephuser;ceph osd pool set <replaceable>POOL</replaceable> pgp_num <replaceable>PG-NUM-VALUE</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>MANY_OBJECTS_PER_PG</option></term>
      <listitem>
        <para>One or more pools has an average number of objects per PG that
          is significantly higher than the overall cluster average. The
          specific threshold is controlled by the <option>mon_pg_warn_max_object_skew</option>
          configuration value.
          This is usually an indication that the pool(s) containing most of
          the data in the cluster have too few PGs, and/or that other pools
          that do not contain as much data have too many PGs.
          The threshold can be raised to silence the health warning by
          adjusting the <option>mon_pg_warn_max_object_skew</option> configuration option on the monitors.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_APP_NOT_ENABLED</option></term>
      <listitem>
        <para>A pool exists that contains one or more objects but has not
          been tagged for use by a particular application.
          Resolve this warning by labeling the pool for use by an application.
          For example, if the pool is used by RBD:
        </para>
<screen>&prompt.cephuser;rbd pool init <replaceable>POOLNAME</replaceable></screen>
        <para>If the pool is being used by a custom application <replaceable>FOO</replaceable>,
          you can also label via the low-level command:</para>
<screen>&prompt.cephuser;ceph osd pool application enable <replaceable>FOO</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_FULL</option></term>
      <listitem>
        <para>One or more pools has reached (or is very close to reaching) its
          quota. The threshold to trigger this error condition is controlled
          by the <option>mon_pool_quota_crit_threshold</option> configuration option.
          Pool quotas can be adjusted up or down (or removed) with:
        </para>
<screen>&prompt.cephuser;ceph osd pool set-quota <replaceable>POOL</replaceable> max_bytes <replaceable>BYTES</replaceable>
&prompt.cephuser;ceph osd pool set-quota <replaceable>POOL</replaceable> max_objects <replaceable>OBJECTS</replaceable>
</screen>
        <para>Setting the quota value to 0 will disable the quota.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>POOL_NEAR_FULL</option></term>
      <listitem>
        <para>One or more pools is approaching is quota. The threshold to
          trigger this warning condition is controlled by the
          <option>mon_pool_quota_warn_threshold</option> configuration option.
          Pool quotas can be adjusted up or down (or removed) with:
        </para>
<screen>&prompt.cephuser;ceph osd pool set-quota <replaceable>POOL</replaceable> max_bytes <replaceable>BYTES</replaceable>
&prompt.cephuser;ceph osd pool set-quota <replaceable>POOL</replaceable> max_objects <replaceable>OBJECTS</replaceable>
</screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>OBJECT_MISPLACED</option></term>
      <listitem>
        <para>One or more objects in the cluster is not stored on the node the
          cluster would like it to be stored on. This is an indication that
          data migration due to some recent cluster change has not yet completed.
          Misplaced data is not a dangerous condition in and of itself; data
          consistency is never at risk, and old copies of objects are never
          removed until the desired number of new copies (in the desired
          locations) are present.
        </para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>OBJECT_UNFOUND</option></term>
      <listitem>
        <para>One or more objects in the cluster cannot be found. Specifically,
          the OSDs know that a new or updated copy of an object should exist,
          but a copy of that version of the object has not been found on OSDs
          that are currently online.
          Read or write requests to unfound objects will block.
          Ideally, a down OSD can be brought back online that has the more
          recent copy of the unfound object. Candidate OSDs can be identified
          from the peering state for the PG(s) responsible for the unfound object:
        </para>
<screen>&prompt.cephuser;ceph tell <replaceable>PG_ID</replaceable> query</screen>
        <para>If the latest copy of the object is not available, the cluster
          can be told to roll back to a previous version of the object.</para>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>SLOW_OPS</option></term>
      <listitem>
        <para>One or more OSD requests is taking a long time to process. This
          can be an indication of extreme load, a slow storage device, or a
          software bug.
          The request queue on the OSD(s) in question can be queried with the
          following command, executed from the OSD host:
        </para>
<screen>&prompt.cephuser;ceph daemon osd.<replaceable>ID</replaceable> ops</screen>
        <para>A summary of the slowest recent requests can be seen with:</para>
<screen>&prompt.cephuser;ceph daemon osd.<replaceable>ID</replaceable> dump_historic_ops</screen>
        <para>The location of an OSD can be found with:</para>
<screen>&prompt.cephuser;ceph osd find osd.<replaceable>ID</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_NOT_SCRUBBED</option></term>
      <listitem>
        <para>One or more PGs has not been scrubbed recently. PGs are normally
          scrubbed every <option>mon_scrub_interval</option> seconds, and this warning triggers
          when <option>mon_warn_pg_not_deep_scrubbed_ratio</option> percentage of interval has
          elapsed without a scrub since it was due.
          PGs will not scrub if they are not flagged as clean, which may
          happen if they are misplaced or degraded (see <option>PG_AVAILABILITY</option>
          and <option>PG_DEGRADED</option> above).
          You can manually initiate a scrub of a clean PG with:
        </para>
<screen>&prompt.cephuser;ceph pg scrub <replaceable>PG_ID</replaceable></screen>
      </listitem>
    </varlistentry>
    <varlistentry>
      <term><option>PG_NOT_DEEP_SCRUBBED</option></term>
      <listitem>
        <para>One or more PGs has not been deep scrubbed recently. PGs are
          normally scrubbed every <option>osd_deep_scrub_interval</option> seconds, and
          this warning triggers when <option>mon_warn_pg_not_deep_scrubbed_ratio</option>
          percentage of interval has elapsed without a scrub since it was due.
          PGs will not (deep) scrub if they are not flagged as clean, which may
          happen if they are misplaced or degraded (see <option>PG_AVAILABILITY</option>
          and <option>PG_DEGRADED</option> above).
          You can manually initiate a scrub of a clean PG with:
        </para>
<screen>&prompt.cephuser;ceph pg deep-scrub <replaceable>PG_ID</replaceable></screen>
      </listitem>
    </varlistentry>
  </variablelist>
  <variablelist><title>MISCELLANEOUS</title>
  <varlistentry>
    <term><option>RECENT_CRASH</option></term>
    <listitem>
      <para>One or more &ceph; daemons has crashed recently, and the
        crash has not yet been archived (acknowledged) by the
        administrator. This may indicate a software bug, a hardware
        problem (for example, a failing disk), or some other problem.
        New crashes can be listed with:
      </para>
<screen>&prompt.cephuser;ceph crash ls-new</screen>
      <para>Information about a specific crash can be examined with:</para>
<screen>&prompt.cephuser;ceph crash info <replaceable>CRASH-ID</replaceable></screen>
      <para>This warning can be silenced by “archiving” the crash (perhaps
        after being examined by an administrator) so that it does not
        generate this warning:</para>
<screen>&prompt.cephuser;ceph crash archive <replaceable>CRASH-ID</replaceable></screen>
      <para>Similarly, all new crashes can be archived with:</para>
<screen>&prompt.cephuser;ceph crash archive-all</screen>
      <para>Archived crashes will still be visible via <command>ceph crash ls</command> but
        not <command>ceph crash ls-new</command>. The time period for what
        “recent” means is controlled by the option
        <literal>mgr/crash/warn_recent_interval</literal> (default: two weeks).
        These warnings can be disabled entirely with:</para>
<screen>&prompt.cephuser;ceph config set mgr/crash/warn_recent_interval 0</screen>
    </listitem>
  </varlistentry>
    <varlistentry>
      <term><option>TELEMETRY_CHANGED</option></term>
      <listitem>
        <para>Telemetry has been enabled, but the contents of the telemetry
          report have changed since that time, so telemetry reports will not be sent.
          The &ceph; developers periodically revise the telemetry feature to
          include new and useful information, or to remove information found
          to be useless or sensitive. If any new information is included in
          the report, &ceph; will require the administrator to re-enable
          telemetry to ensure they have an opportunity to (re)review what
          information will be shared.
          To review the contents of the telemetry report:</para>
<screen>&prompt.cephuser;ceph telemetry show</screen>
        <para>Note that the telemetry report consists of several optional
          channels that may be independently enabled or disabled.
          To re-enable telemetry (and make this warning go away):</para>
<screen>&prompt.cephuser;ceph telemetry on</screen>
          <para>To disable telemetry (and make this warning go away):</para>
<screen>&prompt.cephuser;ceph telemetry soff</screen>
      </listitem>
    </varlistentry>
  </variablelist>
 <screen>
 groups:
  - name: cluster health
   rules:
    - alert: health error
     expr: ceph_health_status == 2
     for: 5m
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: Ceph in error for > 5m
    - alert: unhealthy
     expr: ceph_health_status != 0
     for: 15m
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: Ceph not healthy for > 5m
  - name: mon
   rules:
    - alert: low monitor quorum count
     expr: ceph_monitor_quorum_count &lt; 3
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: Monitor count in quorum is low
  - name: osd
   rules:
    - alert: 10% OSDs down
     expr: sum(ceph_osd_down) / count(ceph_osd_in) >= 0.1
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: More then 10% of OSDS are down
    - alert: OSD down
     expr: sum(ceph_osd_down) > 1
     for: 15m
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: One or more OSDS down for more then 15 minutes
    - alert: OSDs near full
     expr: (ceph_osd_utilization unless on(osd) ceph_osd_down) > 80
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: OSD {{ $labels.osd }} is dangerously full, over 80%
    # alert on single OSDs flapping
    - alert: flap osd
     expr: rate(ceph_osd_up[5m])*60 > 1
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
        OSD {{ $label.osd }} was marked down at back up at least once a
        minute for 5 minutes.
    # alert on high deviation from average PG count
    - alert: high pg count deviation
     expr: abs(((ceph_osd_pgs > 0) - on (job) group_left avg(ceph_osd_pgs > 0) by (job)) / on (job) group_left avg(ceph_osd_pgs > 0) by (job)) > 0.35
     for: 5m
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
        OSD {{ $labels.osd }} deviates by more then 30% from
        average PG count
    # alert on high commit latency...but how high is too high
  - name: mds
   rules:
   # no mds metrics are exported yet
  - name: mgr
   rules:
   # no mgr metrics are exported yet
  - name: pgs
   rules:
    - alert: pgs inactive
     expr: ceph_total_pgs - ceph_active_pgs > 0
     for: 5m
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: One or more PGs are inactive for more then 5 minutes.
    - alert: pgs unclean
     expr: ceph_total_pgs - ceph_clean_pgs > 0
     for: 15m
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: One or more PGs are not clean for more then 15 minutes.
  - name: nodes
   rules:
    - alert: root volume full
     expr: node_filesystem_avail{mountpoint="/"} / node_filesystem_size{mountpoint="/"} &lt; 0.1
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: Root volume (OSD and MON store) is dangerously full (&lt; 10% free)
    # alert on nic packet errors and drops rates > 1 packet/s
    - alert: network packets dropped
     expr: irate(node_network_receive_drop{device!="lo"}[5m]) + irate(node_network_transmit_drop{device!="lo"}[5m]) > 1
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
       Node {{ $labels.instance }} experiences packet drop > 1
       packet/s on interface {{ $lables.device }}
    - alert: network packet errors
     expr: irate(node_network_receive_errs{device!="lo"}[5m]) + irate(node_network_transmit_errs{device!="lo"}[5m]) > 1
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
       Node {{ $labels.instance }} experiences packet errors > 1
       packet/s on interface {{ $lables.device }}
    # predict fs fillup times
    - alert: storage filling
     expr: ((node_filesystem_free - node_filesystem_size) / deriv(node_filesystem_free[2d]) &lt;= 5) > 0
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
       Mountpoint {{ $lables.mountpoint }} will be full in less then 5 days
       assuming the average fillup rate of the past 48 hours.
  - name: pools
   rules:
    - alert: pool full
     expr: ceph_pool_used_bytes / ceph_pool_available_bytes > 0.9
     labels:
      severity: critical
      type: ses_default
     annotations:
      description: Pool {{ $labels.pool }} at 90% capacity or over
    - alert: pool filling up
     expr: (-ceph_pool_used_bytes / deriv(ceph_pool_available_bytes[2d]) &lt;= 5 ) > 0
     labels:
      severity: warning
      type: ses_default
     annotations:
      description: >
       Pool {{ $labels.pool }} will be full in less then 5 days
       assuming the average fillup rate of the past 48 hours.
 </screen>
</sect1>
</chapter>
