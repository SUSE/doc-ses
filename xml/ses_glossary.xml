<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE glossary
[
  <!ENTITY % entities SYSTEM "generic-entities.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<glossary xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
<!-- === CEPH ====================================================== -->
 <title>Glossary</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/master/xml/</dm:editurl>
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <glossdiv>
  <title>General</title>
  <glossentry><glossterm>Admin node</glossterm>
   <glossdef>
    <para>
     The host from which you run the &ceph;-related commands to administer
     cluster hosts.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&alertmanager;</glossterm>
   <glossdef>
    <para>
     A single binary which handles alerts sent by the &prometheus; server and
     notifies end user.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>archive sync module</glossterm>
   <glossdef>
    <para>
     Module that enables creating an &ogw; zone for keeping the history of S3
     object versions.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Bucket</glossterm>
   <glossdef>
    <para>
     A point that aggregates other nodes into a hierarchy of physical
     locations.
    </para>
    <important>
     <title>Do not mix with S3 buckets</title>
     <para>
      S3 <emphasis>buckets</emphasis> or <emphasis>containers</emphasis>
      represent different terms meaning <emphasis>folders</emphasis> for
      storing objects.
     </para>
    </important>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&cephadm;</glossterm>
   <glossdef>
    <para>
     &cephadm; deploys and manages a &ceph; cluster by connecting to hosts from
     the manager daemon via SSH to add, remove, or update &ceph; daemon
     containers.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&cephfs;</glossterm>
   <glossdef>
    <para>
     The &ceph; filesystem.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>CephX</glossterm>
   <glossdef>
    <para>
     The &ceph; authentication protocol. Cephx operates like Kerberos, but it
     has no single point of failure.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&ceph; Client</glossterm>
   <glossdef>
    <para>
     The collection of &ceph; components which can access a &ceph; Storage
     Cluster. These include the &ogw;, the Ceph Block Device, the &cephfs;, and
     their corresponding libraries, kernel modules, and FUSEs.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&cephsalt;</glossterm>
   <glossdef>
    <para>
     Provides tooling for deploying &ceph; clusters managed by &cephadm; using
     Salt.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&ceph; Storage Cluster</glossterm>
   <glossdef>
    <para>
     The core set of storage software which stores the user’s data. Such a set
     consists of &ceph; monitors and OSDs.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>CRUSH, &crushmap;</glossterm>
   <glossdef>
    <para>
     <emphasis>Controlled Replication Under Scalable Hashing</emphasis>: An
     algorithm that determines how to store and retrieve data by computing data
     storage locations. CRUSH requires a map of the cluster to pseudo-randomly
     store and retrieve data in OSDs with a uniform distribution of data across
     the cluster.The threa
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>CRUSH rule</glossterm>
   <glossdef>
    <para>
     The CRUSH data placement rule that applies to a particular pool(s).
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&dashboard;</glossterm>
   <glossdef>
    <para>
     A built-in web-based &ceph; management and monitoring application to
     administer various aspects and objects of the cluster. The dashboard is
     implemented as a &mgr; module.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&drvgrps;</glossterm>
   <glossdef>
    <para>
     &drvgrps; are a declaration of one or more OSD layouts that can be mapped
     to physical drives. An OSD layout defines how &ceph; physically allocates
     OSD storage on the media matching the specified criteria.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&grafana;</glossterm>
   <glossdef>
    <para>
     Database analytics and monitoring solution.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&mds;</glossterm>
   <glossdef>
    <para>
     &mds; or MDS is the &ceph; metadata software.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&mon;</glossterm>
   <glossdef>
    <para>
     &mon; or MON is the &ceph; monitor software.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&mgr;</glossterm>
   <glossdef>
    <para>
     &mgr; or MGR is the &ceph; manager software, which collects all the state
     from the whole cluster in one place.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Node</glossterm>
   <glossdef>
    <para>
     Any single machine or server in a Ceph cluster.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>OSD</glossterm>
   <glossdef>
    <para>
     <emphasis>Object Storage Device</emphasis>: A physical or logical storage
     unit.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&ceph; OSD Daemon</glossterm>
   <glossdef>
    <para>
     The <command>ceph-osd</command> daemon is the component of &ceph; that is
     responsible for storing objects on a local file system and providing
     access to them over the network.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>OSD node</glossterm>
   <glossdef>
    <para>
     A cluster node that stores data, handles data replication, recovery,
     backfilling, rebalancing, and provides some monitoring information to
     &ceph; monitors by checking other &ceph; OSD daemons.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&ceph; Object Storage</glossterm>
   <glossdef>
    <para>
     The object storage “product”, service or capabilities, which consists of a
     &ceph; Storage Cluster and a &ceph; &ogw;.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&ogw;</glossterm>
   <glossdef>
    <para>
     The S3/Swift gateway component for &ceph; Object Store. Also known as the
     &rados; Gateway (RGW).
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>PG</glossterm>
   <glossdef>
    <para>
     Placement Group: a sub-division of a <emphasis>pool</emphasis>, used for
     performance tuning.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Point Release</glossterm>
   <glossdef>
    <para>
     Any ad-hoc release that includes only bug or security fixes.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Pool</glossterm>
   <glossdef>
    <para>
     Logical partitions for storing objects such as disk images.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&prometheus;</glossterm>
   <glossdef>
    <para>
     Systems monitoring and alerting toolkit.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Reliable Autonomic Distributed Object Store (&rados;)</glossterm>
   <glossdef>
    <para>
     The core set of storage software which stores the user’s data (MON+OSD).
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&rbd; (RBD)</glossterm>
   <glossdef>
    <para>
     The block storage component of &ceph;. Also known as the &ceph; block
     device.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Rule Set</glossterm>
   <glossdef>
    <para>
     Rules to determine data placement for a pool.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Routing tree</glossterm>
   <glossdef>
    <para>
     A term given to any diagram that shows the various routes a receiver can
     run.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&samba;</glossterm>
   <glossdef>
    <para>
     Windows integration software.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&sgw;</glossterm>
   <glossdef>
    <para>
     The &sgw; joins the Active Directory in the Windows domain to authenticate
     and authorize users.
    </para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>Multi-zone</glossterm>
   <glossdef>
    <para></para>
   </glossdef>
  </glossentry>
  <glossentry><glossterm>&zgroup;</glossterm>
   <glossdef>
    <para></para>
   </glossdef>
  </glossentry>
 </glossdiv>
</glossary>
