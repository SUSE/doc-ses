<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
 xml:id="cha.ceph.nfsganesha">
<!-- ============================================================== -->
 <title>&ganesha;: Export &ceph; Data via NFS</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editing</dm:status>
   <dm:deadline></dm:deadline>
   <dm:priority></dm:priority>
   <dm:translation></dm:translation>
   <dm:languages></dm:languages>
   <dm:release>SES4</dm:release>
  </dm:docmanager>
 </info>
 <warning os="ses4">
  <title>Technology Preview</title>
  <para>
   As of &storage; 4, &ganesha; is considered a technology preview and is not
   supported.
  </para>
 </warning>
 <para>
  &ganesha; is an NFS server (refer to
  <link
   xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_nfs.html">Sharing
  File Systems with NFS</link> ) that runs in a user address space instead of
  as part of the operating system kernel. With &ganesha; you can plug in your
  own storage mechanism&mdash;such as &ceph;&mdash;and access it from any NFS
  client.
 </para>
 <sect1 xml:id="ceph.nfsganesha.install">
  <title>Installation</title>

  <para>
   Although it is possible to install and run the &ganesha; server on an
   already existing &ceph; node, we recommend running it on a dedicated host
   with an access to the &ceph; cluster. The client hosts are typically not
   part of the cluster, but they need to have network access to the &ganesha;
   server.
  </para>

  <para>
   To run the &ganesha; server, you need to install the
   <systemitem>nfs-ganesha</systemitem> package:
  </para>

<screen>sudo zypper in nfs-ganesha</screen>

  <para>
   If you plan to export &cephfs; via NFS, install the
   <systemitem>nfs-ganesha-ceph</systemitem> package:
  </para>

<screen>sudo zypper in nfs-ganesha-ceph</screen>

  <para>
   If you plan to export &rgw; buckets via NFS, install the
   <systemitem>nfs-ganesha-rgw</systemitem> package:
  </para>

<screen>sudo zypper in nfs-ganesha-rgw</screen>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.config">
  <title>Configuration</title>

  <para>
   This section includes information to help you configure the &ganesha; server
   to export the cluster data accessible via &rgw; and &cephfs;.
  </para>

  <sect2 xml:id="ceph.nfsganesha.config.general">
   <title>&ganesha; Common Configuration</title>
   <para>
    &ganesha; configuration is controlled by
    <filename>/etc/ganesha/ganesha.conf</filename>. Edit it and change as
    required:
   </para>
<screen>EXPORT
{
  Export_Id = 1; # Each export needs to have a unique 'Export_Id' (mandatory)
  Path = "/"; # Export path in the related &cephfs; pool (mandatory)
  Pseudo = "/"; # Target NFS export path (mandatory for NFSv4)
  Access_Type = RW; # 'RO' for read-only access, default is 'None'
  Squash = No_Root_Squash; # NFS squash option
  [...]
  FSAL { # Exporting 'File System Abstraction Layer'
    Name = CEPH; # Ganesha backend, 'CEPH' for &cephfs; or 'RGW' for &rgw;
  }
}</screen>
  </sect2>

  <sect2 xml:id="ceph.nfsganesha.config.cephfs">
   <title>NFS Access to &cephfs; Data</title>
   <tip>
    <para>
     Before you start configuring &ganesha; for &cephfs;, an instance of
     &cephfs; needs to be already configured and running. Refer to
     <xref
     linkend="cha.ceph.cephfs"/> for more information on &cephfs;.
    </para>
   </tip>
   <para>
    To be able to export data stored on the active &cephfs;, edit
    <filename>/etc/ganesha/ganesha.conf</filename> and check that it includes
    the following snippets (configured to your needs):
   </para>
<screen>EXPORT
{
[...]
  FSAL {
    Name = CEPH;
  }
}</screen>
  </sect2>

  <sect2 xml:id="ceph.nfsganesha.config.rgw">
   <title>NFS Access to &rgw; Buckets</title>
   <tip>
    <para>
     Before you start configuring &ganesha; for &rgw;, an instance of &rgw;
     needs to be already configured and running. Refer to
     <xref
     linkend="cha.ceph.gw"/> for more information on &rgw;.
    </para>
   </tip>
   <para>
    To export data stored in &rgw; buckets via NFS, do the following:
   </para>
   <procedure>
    <step>
     <para>
      Add a keyring entry to the <literal>[global]</literal> section of
      <filename>/etc/ceph/ceph.conf</filename>. &ganesha; needs it to
      communicate with <systemitem>librados</systemitem>:
     </para>
<screen>keyring = /etc/ceph/ceph.client.admin.keyring</screen>
    </step>
    <step>
     <para>
      &ganesha; is controlled by <filename>/etc/ganesha/ganesha.conf</filename>
      by default. The package <systemitem>nfs-ganesha-rgw</systemitem> installs
      a new file <filename>/etc/ganesha/rgw.conf</filename>. You can either
      merge its content to <filename>/etc/ganesha/ganesha.conf</filename>, or
      make a backup of both files and create the following symbolic link:
     </para>
<screen>sudo cp /etc/ganesha/ganesha.conf /etc/ganesha/ganesha.conf.orig
sudo cp /etc/ganesha/rgw.conf /etc/ganesha/rgw.conf.orig
sudo ln -sf /etc/ganesha/rgw.conf /etc/ganesha/ganesha.conf</screen>
    </step>
    <step>
     <para>
      Edit <filename>/etc/ganesha/ganesha.conf</filename> and check that it
      includes the following snippets (configured to your needs):
     </para>
<screen>EXPORT
{
[...]
  FSAL {
    Name = RGW;
    User_Id = "<replaceable>s3_user_id</replaceable>";
    Access_Key_Id = "<replaceable>s3_access_key</replaceable>";
    Secret_Access_Key = "<replaceable>s3_secret_key</replaceable>";
  }
  RGW {
   ceph_conf = "/etc/ceph/ceph.conf";
  }
}</screen>
    </step>
   </procedure>
   <important os="ses4">
    <title>Limitations for Access to &rgw; Buckets</title>
    <para>
     This technology preview feature has several limitations in usage. Refer to
     the relevant
     <link
      xlink:href="https://www.suse.com/releasenotes/x86_64/SUSE-Enterprise-Storage/4/#fate-321078">Release
     Notes</link> section to get more detailed information.
    </para>
   </important>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.services">
  <title>Starting &ganesha; Related Services</title>

  <para>
   Enable and start the RPC service required by &ganesha;:
  </para>

<screen>sudo systemctl enable rpcbind rpc-statd
sudo systemctl start rpcbind rpc-statd</screen>

  <para>
   Enable and start the &ganesha; service:
  </para>

<screen>sudo systemctl enable nfs-ganesha
sudo systemctl start nfs-ganesha</screen>

  <tip>
   <title>Starting the &ganesha; Service Manually</title>
   <para>
    Instead of using &systemd; targets, you can start &ganesha; manually. The
    following command starts &ganesha; with the debugging information enabled:
   </para>
<screen>sudo /usr/bin/ganesha.nfsd -L /var/log/ganesha.log \
 -f /etc/ganesha/ganesha.conf -N NIV_DEBUG</screen>
  </tip>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.verify">
  <title>Verifying the Exported NFS Share</title>

  <para>
   After you configure and start &ganesha;, you can verify whether the NFS
   shares are exported on the &ganesha; server node:
  </para>

<screen>sudo showmount -e
/ (everything)</screen>
 </sect1>
 <sect1 xml:id="ceph.nfsganesha.mount">
  <title>Mounting the Exported NFS Share</title>

  <para>
   To mount the exported NFS share (as configured in
   <xref
    linkend="ceph.nfsganesha.config"/>) on a client host, run:
  </para>

<screen>sudo mount -t nfs -o rw,noatime,sync \
 <replaceable>nfs_ganesha_server_hostname:/ /path/to/local/mountpoint</replaceable></screen>
 </sect1>
</chapter>
