<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE appendix
[
  <!ENTITY % entities SYSTEM "generic-entities.ent">
    %entities;
]>
<appendix xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
 <title>&ceph; maintenance updates based on upstream '&cephname;' point releases</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Several key packages in &productname; &productnumber; are based on the
  &cephname; release series of &ceph;. When the &ceph; project
  (<link xlink:href="https://github.com/ceph/ceph"/>) publishes new point
  releases in the &cephname; series, &productname; &productnumber; is updated
  to ensure that the product benefits from the latest upstream bug fixes and
  feature backports.
 </para>
 <para>
  This chapter contains summaries of notable changes contained in each upstream
  point release that has been&mdash;or is planned to be&mdash;included in the
  product.
 </para>
 <bridgehead renderas="sect1">&cephname; 15.2.11 Point Release</bridgehead>
 <para>
  This release includes a security fix that ensures the
  <option>global_id</option> value (a numeric value that should be unique for
  every authenticated client or daemon in the cluster) is reclaimed after a
  network disconnect or ticket renewal in a secure fashion. Two new health
  alerts may appear during the upgrade indicating that there are clients or
  daemons that are not yet patched with the appropriate fix.
 </para>
 <para>
  To temporarily mute the health alerts around insecure clients for the duration
  of the upgrade, you may want to run:
 </para>
<screen>
&prompt.cephuser;ceph health mute AUTH_INSECURE_GLOBAL_ID_RECLAIM 1h
&prompt.cephuser;ceph health mute AUTH_INSECURE_GLOBAL_ID_RECLAIM_ALLOWED 1h
</screen>
 <para>
  When all clients are updated, enable the new secure behavior, not allowing
  old insecure clients to join the cluster:
 </para>
<screen>&prompt.cephuser;ceph config set mon auth_allow_insecure_global_id_reclaim false</screen>
 <bridgehead renderas="sect1">&cephname; 15.2.10 Point Release</bridgehead>
 <para>
  This backport release includes the following fixes:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    The containers include an updated <literal>tcmalloc</literal> that avoids crashes seen on 15.2.9.
   </para>
  </listitem>
  <listitem>
   <para>
    RADOS: &bluestore; handling of huge (&gt;4GB) writes from RocksDB to BlueFS
    has been fixed.
   </para>
  </listitem>
  <listitem>
   <para>
    When upgrading from a previous &cephadm; release,
    <command>systemctl</command> may hang when trying to start or restart the
    monitoring containers. This is caused by a change in the &systemd; unit to
    use <option>type=forking</option>.) After the upgrade, please run:
   </para>
<screen>
&prompt.cephuser;ceph orch redeploy nfs
&prompt.cephuser;ceph orch redeploy iscsi
&prompt.cephuser;ceph orch redeploy node-exporter
&prompt.cephuser;ceph orch redeploy prometheus
&prompt.cephuser;ceph orch redeploy grafana
&prompt.cephuser;ceph orch redeploy alertmanager
</screen>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.9 Point Release</bridgehead>
 <para>
  This backport release includes the following fixes:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    MGR: progress module can now be turned on/off, using the commands:
    <command>ceph progress on</command> and <command>ceph progress
    off</command>.
   </para>
  </listitem>
  <listitem>
   <para>
    OSD: PG removal has been optimized in this release.
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.8 Point Release</bridgehead>
 <para>
  This release fixes a security flaw in &cephfs; and includes a number of bug
  fixes:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    OpenStack Manila use of <filename>ceph_volume_client.py</filename> library
    allowed tenant access to any &ceph; credential’s secret.
   </para>
  </listitem>
  <listitem>
   <para>
    <command>ceph-volume</command>: The <command>lvm batch</command> subcommand
    received a major rewrite. This closed a number of bugs and improves
    usability in terms of size specification and calculation, as well as
    idempotency behaviour and disk replacement process. Please refer to
    <link
        xlink:href="https://docs.ceph.com/en/latest/ceph-volume/lvm/batch/"/>
    for more detailed information.
   </para>
  </listitem>
  <listitem>
   <para>
    MON: The cluster log now logs health detail every
    <option>mon_health_to_clog_interval</option>, which has been changed from
    1hr to 10min. Logging of health detail will be skipped if there is no change
    in health summary since last known.
   </para>
  </listitem>
  <listitem>
   <para>
    The <command>ceph df</command> command now lists the number of PGs in each
    pool.
   </para>
  </listitem>
  <listitem>
   <para>
    The <option>bluefs_preextend_wal_files</option> option has been removed.
   </para>
  </listitem>
  <listitem>
   <para>
    It is now possible to specify the initial monitor to contact for &ceph;
    tools and daemons using the <option>mon_host_override</option> config option
    or <option>--mon-host-override</option> command line switch. This generally
    should only be used for debugging and only affects initial communication
    with &ceph;'s monitor cluster.
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.7 Point Release</bridgehead>
 <para>
  This release fixes a serious bug in RGW that has been shown to cause data loss
  when a read of a large RGW object (for example, one with at least one tail
  segment) takes longer than one half the time specified in the configuration
  option <option>rgw_gc_obj_min_wait</option>. The bug causes the tail segments
  of that read object to be added to the RGW garbage collection queue, which
  will in turn cause them to be deleted after a period of time.
 </para>
 <bridgehead renderas="sect1">&cephname; 15.2.6 Point Release</bridgehead>
 <para>
  This releases fixes a security flaw affecting Messenger V2 for Octopus and
  Nautilus.
 </para>
 <bridgehead renderas="sect1">&cephname; 15.2.5 Point Release</bridgehead>
 <para>
  The &cephname; point release 15.2.5 brought the following fixes and other
  changes:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    &cephfs;: Automatic static sub-tree partitioning policies may now be
    configured using the new distributed and random ephemeral pinning extended
    attributes on directories. See the following documentation for more
    information:
    <link xlink:href="https://docs.ceph.com/docs/master/cephfs/multimds/"/>
   </para>
  </listitem>
  <listitem>
   <para>
    Monitors now have a configuration option
    <option>mon_osd_warn_num_repaired</option>, which is set to 10 by default.
    If any OSD has repaired more than this many I/O errors in stored data a
    <literal>OSD_TOO_MANY_REPAIRS</literal> health warning is generated.
   </para>
  </listitem>
  <listitem>
   <para>
    Now, when <literal>no scrub</literal> and/or <literal>no
    deep-scrub</literal> flags are set globally or per pool, scheduled scrubs of
    the type disabled will be aborted. All user initiated scrubs are NOT
    interrupted.
   </para>
  </listitem>
  <listitem>
   <para>
    Fixed an issue with osdmaps not being trimmed in a healthy cluster.
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.4 Point Release</bridgehead>
 <para>
  The &cephname; point release 15.2.4 brought the following fixes and other
  changes:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    CVE-2020-10753: rgw: sanitize newlines in s3 CORSConfiguration’s
    ExposeHeader
   </para>
  </listitem>
  <listitem>
   <para>
    &ogw;: The <command>radosgw-admin</command> sub-commands dealing with
    orphans&mdash;<command>radosgw-admin orphans find</command>,
    <command>radosgw-admin orphans finish</command>, and <command>radosgw-admin
    orphans list-jobs</command>&mdash;have been deprecated. They had not been
    actively maintained, and since they store intermediate results on the
    cluster, they could potentially fill a nearly-full cluster. They have been
    replaced by a tool, <command>rgw-orphan-list</command>, which is currently
    considered experimental.
   </para>
  </listitem>
  <listitem>
   <para>
    RBD: The name of the RBD pool object that is used to store RBD trash purge
    schedule is changed from <literal>rbd_trash_trash_purge_schedule</literal>
    to <literal>rbd_trash_purge_schedule</literal>. Users that have already
    started using RBD trash purge schedule functionality and have per pool or
    name space schedules configured should copy the
    <literal>rbd_trash_trash_purge_schedule</literal> object to
    <literal>rbd_trash_purge_schedule</literal> before the upgrade and remove
    <literal>rbd_trash_purge_schedule</literal> using the following commands in
    every RBD pool and name space where a trash purge schedule was previously
    configured:
   </para>
<screen>
rados -p <replaceable>pool-name</replaceable> [-N namespace] cp rbd_trash_trash_purge_schedule rbd_trash_purge_schedule
rados -p <replaceable>pool-name</replaceable> [-N namespace] rm rbd_trash_trash_purge_schedule
</screen>
   <para>
    Alternatively, use any other convenient way to restore the schedule after
    the upgrade.
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.3 Point Release</bridgehead>
 <itemizedlist>
  <listitem>
   <para>
    The &cephname; point release 15.2.3 was a hot-fix release to address an
    issue where WAL corruption was seen when
    <option>bluefs_preextend_wal_files</option> and
    <option>bluefs_buffered_io</option> were enabled at the same time. The fix
    in 15.2.3 is only a temporary measure (changing the default value of
    <option>bluefs_preextend_wal_files</option> to <literal>false</literal>).
    The permanent fix will be to remove the
    <option>bluefs_preextend_wal_files</option> option completely: this fix
    will most likely arrive in the 15.2.6 point release.
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.2 Point Release</bridgehead>
 <para>
  The &cephname; point release 15.2.2 patched one security vulnerability:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    CVE-2020-10736: Fixed an authorization bypass in MONs and MGRs
   </para>
  </listitem>
 </itemizedlist>
 <bridgehead renderas="sect1">&cephname; 15.2.1 Point Release</bridgehead>
 <para>
  The &cephname; point release 15.2.1 fixed an issue where upgrading quickly
  from Luminous (SES5.5) to Nautilus (SES6) to &cephname; (SES7) caused OSDs to
  crash. In addition, it patched two security vulnerabilities that were present
  in the initial &cephname; (15.2.0) release:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    CVE-2020-1759: Fixed nonce reuse in msgr V2 secure mode
   </para>
  </listitem>
  <listitem>
   <para>
    CVE-2020-1760: Fixed XSS because of RGW GetObject header-splitting
   </para>
  </listitem>
 </itemizedlist>
</appendix>
