<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "generic-entities.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="storage-salt-cluster">
  <title>Operational tasks</title>
  <info>
    <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
      <dm:translation>yes</dm:translation>
      <dm:release>SES 7</dm:release>
    </dm:docmanager>
  </info>
  <sect1 xml:id="modifying-cluster-configuration">
    <title>Modifying the cluster configuration</title>

    <para>
      To modify the configuration of an existing &ceph; cluster, follow these
      steps:
    </para>

    <procedure>
      <step>
        <para>
          Export the current configuration of the cluster to a file:
        </para>
<screen>&prompt.cephuser;ceph orch ls --export --format yaml > cluster.yaml</screen>
      </step>
      <step>
        <para>
          Edit the file with the configuration and update the relevant lines.
          Find specification examples in <xref linkend="deploy-core"/> and
          <xref linkend="drive-groups"/>.
        </para>
      </step>
      <step>
        <para>
          Apply the new configuration:
        </para>
<screen>&prompt.cephuser;ceph orch apply -i cluster.yaml</screen>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="adding-node">
    <title>Adding nodes</title>

    <para>
      To add a new node to a &ceph; cluster, follow these steps:
    </para>

    <procedure>
      <step>
        <para>
          Install &sls; and &productname; on the new host. Refer to
          <xref linkend="deploy-sles"/> for more information.
        </para>
      </step>
      <step>
        <para>
          Configure the host as a &sminion; of an already existing &smaster;.
          Refer to <xref linkend="deploy-salt"/> for more information.
        </para>
      </step>
      <step>
        <para>
          Add the new host to &cephsalt; and make &cephadm; aware of it, for
          example:
        </para>
<screen>
&prompt.smaster;ceph-salt config /ceph_cluster/minions add ses-node5.example.com
&prompt.smaster;ceph-salt config /ceph_cluster/roles/cephadm add ses-node5.example.com
</screen>
        <para>
          Refer to <xref linkend="deploy-cephadm-configure-minions"/> for more
          information.
        </para>
      </step>
      <step>
        <para>
          Verify that the node was added to &cephsalt;:
        </para>
<screen>
&prompt.smaster;ceph-salt config /ceph_cluster/minions ls
o- minions ................................................. [Minions: 5]
[...]
  o- ses-node5.example.com ................................... [no roles]
</screen>
      </step>
      <step>
        <para>
          Apply the configuration to the new cluster host:
        </para>
<screen>
&prompt.smaster;ceph-salt apply ses-node5.example.com
</screen>
      </step>
      <step>
        <para>
          Verify that the newly added host now belongs to the &cephadm;
          environment:
        </para>
<screen>
&prompt.cephuser;ceph orch host ls
HOST                    ADDR                    LABELS   STATUS
[...]
ses-node5.example.com   ses-node5.example.com
</screen>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="salt-node-removing">
    <title>Removing nodes</title>

    <tip>
      <title>Remove OSDs</title>
      <para>
        If the node that you are going to remove runs OSDs, remove the OSDs
        from it first and check that no OSDs are running on that node. Refer to
        <xref linkend="removing-node-osds"/> for more details on removing OSDs.
      </para>
    </tip>

    <para>
      To remove a node from a cluster, do the following:
    </para>

    <procedure xml:id="removing-node">
      <step>
        <para>
          For all &ceph; service types except for
          <literal>node-exporter</literal> and <literal>crash</literal>, remove
          the node's host name from the cluster placement specification file
          (for example, <filename>cluster.yml</filename>). Refer to
          <xref linkend="cephadm-service-and-placement-specs"/> for more
          details. For example, if you are removing the host named
          <literal>ses-node2</literal>, remove all occurrences of <literal>-
          ses-node2</literal> from all <literal>placement:</literal> sections:
        </para>
        <para>
          Update
        </para>
<screen>
service_type: rgw
service_id: <replaceable>EXAMPLE_NFS</replaceable>
placement:
  hosts:
  - ses-node2
  - ses-node3
</screen>
        <para>
          to
        </para>
<screen>
service_type: rgw
service_id: <replaceable>EXAMPLE_NFS</replaceable>
placement:
  hosts:
  - ses-node3
</screen>
        <para>
          Apply your changes to the configuration file:
        </para>
<screen>&prompt.cephuser;ceph orch apply -i <replaceable>rgw-example.yaml</replaceable></screen>
      </step>
      <step>
        <para>
          If the node is running <literal>crash.osd.1</literal> and
          <literal>crash.osd.2</literal> services, remove them by running the
          following command on the host:
        </para>
<screen>
&prompt.sminion;cephadm rm-daemon --fsid <replaceable>CLUSTER_ID</replaceable> --name <replaceable>SERVICE_NAME</replaceable>
</screen>
        <para>
          For example:
        </para>
<screen>
&prompt.sminion;cephadm rm-daemon --fsid b4b30c6e... --name crash.osd.1
&prompt.sminion;cephadm rm-daemon --fsid b4b30c6e... --name crash.osd.2
</screen>
      </step>
      <step>
        <para>
          Remove the node from &cephadm;'s environment:
        </para>
<screen>&prompt.cephuser;ceph orch host rm ses-node2</screen>
      </step>
      <step>
        <para>
          Remove all the roles from the minion you want to delete:
        </para>
<screen>&prompt.cephuser;ceph-salt config /ceph_cluster/roles/tuned/throughput remove ses-node2
&prompt.cephuser;ceph-salt config /ceph_cluster/roles/tuned/latency remove ses-node2
&prompt.cephuser;ceph-salt config /ceph_cluster/roles/cephadm remove ses-node2
&prompt.cephuser;ceph-salt config /ceph_cluster/roles/admin remove ses-node2</screen>
        <para>
          If the minion you want to remove is the bootstrap minion, you also
          need to remove the bootstrap role:
        </para>
<screen>&prompt.cephuser;ceph-salt config /ceph_cluster/roles/bootstrap reset</screen>
      </step>
      <step>
        <para>
          After removing all OSDs on a single host, remove the host from the
          CRUSH map:
        </para>
<screen>&prompt.cephuser;ceph osd crush remove <replaceable>bucket-name</replaceable></screen>
        <note>
          <para>
            The bucket name should be the same as the host name.
          </para>
        </note>
      </step>
      <step>
        <para>
          You can now remove the minion from the cluster:
        </para>
<screen>&prompt.cephuser;ceph-salt config /ceph_cluster/minions remove ses-node2</screen>
      </step>
    </procedure>

    <important>
      <para>
        In the event of a failure and the minion you are trying to remove is in
        a permanently powered-off state, you will need to remove the node from
        the &smaster;:
      </para>
<screen>&prompt.smaster;salt-key -d <replaceable>minion_id</replaceable></screen>
      <para>
        Then, manually remove the node from
        <filename><replaceable>pillar_root</replaceable>/ceph-salt.sls</filename>.
        This is typically located in
        <filename>/srv/pillar/ceph-salt.sls</filename>.
      </para>
    </important>
  </sect1>
  <sect1 xml:id="osd-management">
    <title>OSD management</title>

    <para>
      This section describes how to add, erase, or remove OSDs in a &ceph;
      cluster.
    </para>

    <sect2 xml:id="osd-management-listing">
      <title>Listing disk devices</title>
      <para>
        To identify used and unused disk devices on all cluster nodes, list
        them by running the following command:
      </para>
<screen>
&prompt.cephuser;ceph orch device ls
HOST       PATH      TYPE SIZE  DEVICE  AVAIL REJECT REASONS
ses-admin  /dev/vda  hdd  42.0G         False locked
ses-node1  /dev/vda  hdd  42.0G         False locked
ses-node1  /dev/vdb  hdd  8192M  387836 False locked, LVM detected, Insufficient space (&lt;5GB) on vgs
ses-node2  /dev/vdc  hdd  8192M  450575 True
</screen>
    </sect2>

    <sect2 xml:id="osd-management-erasing">
      <title>Erasing disk devices</title>
      <para>
        To re-use a disk device, you need to erase (or
        <emphasis>zap</emphasis>) it first:
      </para>
<screen>ceph orch device zap <replaceable>HOST_NAME</replaceable> <replaceable>DISK_DEVICE</replaceable></screen>
      <para>
        For example:
      </para>
<screen>&prompt.cephuser;ceph orch device zap ses-node2 /dev/vdc</screen>
      <note>
        <para>
          If you previously deployed OSDs by using &drvgrps; or the
          <option>--all-available-devices</option> option while the
          <literal>unmanaged</literal> flag was not set, &cephadm; will deploy
          these OSDs automatically after you erase them.
        </para>
      </note>
    </sect2>

    <sect2 xml:id="drive-groups">
      <title>Adding OSDs using &drvgrps; specification</title>
      <para>
        <emphasis>&drvgrps;</emphasis> specify the layouts of OSDs in the
        &ceph; cluster. They are defined in a single YAML file. In this
        section, we will use <filename>drive_groups.yml</filename> as an
        example.
      </para>
      <para>
        An administrator should manually specify a group of OSDs that are
        interrelated (hybrid OSDs that are deployed on a mixture of HDDs and
        SDDs) or share identical deployment options (for example, the same
        object store, same encryption option, stand-alone OSDs). To avoid
        explicitly listing devices, &drvgrps; use a list of filter items that
        correspond to a few selected fields of <command>ceph-volume</command>'s
        inventory reports. &cephadm; will provide code that translates these
        &drvgrps; into actual device lists for inspection by the user.
      </para>
      <para>
        The command to apply the OSD specification to the cluster is:
      </para>
<screen>&prompt.cephuser;ceph orch apply osd -i <filename>drive_groups.yml</filename></screen>
      <para>
        To see a preview of actions and test your application, you can use the
        <option>--dry-run</option> option together with the <command>ceph orch
        apply osd</command> command. For example:
      </para>
<screen>&prompt.cephuser;ceph orch apply osd -i <filename>drive_groups.yml</filename> --dry-run
...
+---------+------+------+----------+----+-----+
|SERVICE  |NAME  |HOST  |DATA      |DB  |WAL  |
+---------+------+------+----------+----+-----+
|osd      |test  |mgr0  |/dev/sda  |-   |-    |
|osd      |test  |mgr0  |/dev/sdb  |-   |-    |
+---------+------+------+----------+----+-----+</screen>
      <para>
        If the <option>--dry-run</option> output matches your expectations,
        then simply re-run the command without the <option>--dry-run</option>
        option.
      </para>
      <sect3 xml:id="unmanaged-osds">
        <title>Unmanaged OSDs</title>
        <para>
          All available clean disk devices that match the &drvgrps;
          specification will be used as OSDs automatically after you add them
          to the cluster. This behavior is called a
          <emphasis>managed</emphasis> mode.
        </para>
        <para>
          To disable the <emphasis>managed</emphasis> mode, add the
          <literal>unmanaged: true</literal> line to the relevant
          specifications, for example:
        </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
 hosts:
 - ses-node2
 - ses-node3
encrypted: true
unmanaged: true
</screen>
        <tip>
          <para>
            To change already deployed OSDs from the
            <emphasis>managed</emphasis> to <emphasis>unmanaged</emphasis>
            mode, add the <literal>unmanaged: true</literal> lines where
            applicable during the procedure described in
            <xref linkend="modifying-cluster-configuration"/>.
          </para>
        </tip>
      </sect3>
      <sect3 xml:id="drive-groups-specs">
        <title>&drvgrps; specification</title>
        <para>
          Following is an example &drvgrps; specification file:
        </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  drive_spec: <replaceable>DEVICE_SPECIFICATION</replaceable>
db_devices:
  drive_spec: <replaceable>DEVICE_SPECIFICATION</replaceable>
wal_devices:
  drive_spec: <replaceable>DEVICE_SPECIFICATION</replaceable>
block_wal_size: '5G'  # (optional, unit suffixes permitted)
block_db_size: '5G'   # (optional, unit suffixes permitted)
encrypted: true       # 'True' or 'False' (defaults to 'False')
</screen>
        <note>
          <para>
            The option previously called "encryption" in &deepsea; has been
            renamed to "encrypted". When applying &drvgrps; in &productname; 7,
            ensure you use this new terminology in your service specification,
            otherwise the <command>ceph orch apply</command> operation will
            fail.
          </para>
        </note>
      </sect3>
      <sect3 xml:id="matching-disk-devices">
        <title>Matching disk devices</title>
        <para>
          You can describe the specification using the following filters:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              By a disk model:
            </para>
<screen>
model: <replaceable>DISK_MODEL_STRING</replaceable>
</screen>
          </listitem>
          <listitem>
            <para>
              By a disk vendor:
            </para>
<screen>
vendor: <replaceable>DISK_VENDOR_STRING</replaceable>
</screen>
            <tip>
              <para>
                Always enter the <replaceable>DISK_VENDOR_STRING</replaceable>
                in lowercase.
              </para>
            </tip>
            <para>
              To obtain details about disk model and vendor, examine the output
              of the following command:
            </para>
<screen>
&prompt.cephuser;ceph orch device ls
HOST      PATH     TYPE  SIZE DEVICE_ID                  MODEL            VENDOR
ses-node1 /dev/sdb ssd  29.8G SATA_SSD_AF34075704240015  SATA SSD         ATA
ses-node2 /dev/sda ssd   223G Micron_5200_MTFDDAK240TDN  Micron_5200_MTFD ATA
[...]
</screen>
          </listitem>
          <listitem>
            <para>
              Whether a disk is rotational or not. SSDs and NVMe drives are not
              rotational.
            </para>
<screen>
rotational: 0
</screen>
          </listitem>
          <listitem>
            <para>
              Deploy a node using <emphasis>all</emphasis> available drives for
              OSDs:
            </para>
<screen>
data_devices:
  all: true
</screen>
          </listitem>
          <listitem>
            <para>
              Additionally, by limiting the number of matching disks:
            </para>
<screen>
limit: 10
</screen>
          </listitem>
        </itemizedlist>
      </sect3>
      <sect3 xml:id="filtering-devices-size">
        <title>Filtering devices by size</title>
        <para>
          You can filter disk devices by their size&mdash;either by an exact
          size, or a size range. The <option>size:</option> parameter accepts
          arguments in the following form:
        </para>
        <itemizedlist>
          <listitem>
            <para>
              '10G' - Includes disks of an exact size.
            </para>
          </listitem>
          <listitem>
            <para>
              '10G:40G' - Includes disks whose size is within the range.
            </para>
          </listitem>
          <listitem>
            <para>
              ':10G' - Includes disks less than or equal to 10&nbsp;GB in size.
            </para>
          </listitem>
          <listitem>
            <para>
              '40G:' - Includes disks equal to or greater than 40&nbsp;GB in
              size.
            </para>
          </listitem>
        </itemizedlist>
        <example>
          <title>Matching by disk size</title>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  size: '40TB:'
db_devices:
  size: ':2TB'
</screen>
        </example>
        <note>
          <title>Quotes required</title>
          <para>
            When using the ':' delimiter, you need to enclose the size in
            quotes, otherwise the ':' sign will be interpreted as a new
            configuration hash.
          </para>
        </note>
        <tip>
          <title>Unit shortcuts</title>
          <para>
            Instead of Gigabytes (G), you can specify the sizes in Megabytes
            (M) or Terabytes (T).
          </para>
        </tip>
      </sect3>
      <sect3 xml:id="ds-drive-groups-examples">
        <title>&drvgrps; examples</title>
        <para>
          This section includes examples of different OSD setups.
        </para>
        <example>
          <title>Simple setup</title>
          <para>
            This example describes two nodes with the same setup:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                20 HDDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                2 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>
            The corresponding <filename>drive_groups.yml</filename> file will
            be as follows:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  model: SSD-123-foo
db_devices:
  model: MC-55-44-XZ
</screen>
          <para>
            Such a configuration is simple and valid. The problem is that an
            administrator may add disks from different vendors in the future,
            and these will not be included. You can improve it by reducing the
            filters on core properties of the drives:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  rotational: 1
db_devices:
  rotational: 0
</screen>
          <para>
            In the previous example, we are enforcing all rotating devices to
            be declared as 'data devices' and all non-rotating devices will be
            used as 'shared devices' (wal, db).
          </para>
          <para>
            If you know that drives with more than 2&nbsp;TB will always be the
            slower data devices, you can filter by size:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  size: '2TB:'
db_devices:
  size: ':2TB'
</screen>
        </example>
        <example>
          <title>Advanced setup</title>
          <para>
            This example describes two distinct setups: 20 HDDs should share 2
            SSDs, while 10 SSDs should share 2 NVMes.
          </para>
          <itemizedlist>
            <listitem>
              <para>
                20 HDDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                12 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                2 NVMes
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Samsung
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: NVME-QQQQ-987
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 256&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>
            Such a setup can be defined with two layouts as follows:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  rotational: 0
db_devices:
  model: MC-55-44-XZ
</screen>
<screen>
service_type: osd
service_id: example_drvgrp_name2
placement:
  host_pattern: '*'
data_devices:
  model: MC-55-44-XZ
db_devices:
  vendor: samsung
  size: 256GB
</screen>
        </example>
        <example>
          <title>Advanced setup with non-uniform nodes</title>
          <para>
            The previous examples assumed that all nodes have the same drives.
            However, that is not always the case:
          </para>
          <para>
            Nodes 1-5:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                20 HDDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                2 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>
            Nodes 6-10:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                5 NVMes
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                20 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>
            You can use the 'target' key in the layout to target specific
            nodes. &salt; target notation helps to keep things simple:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_one2five
placement:
  host_pattern: 'node[1-5]'
data_devices:
  rotational: 1
db_devices:
  rotational: 0
</screen>
          <para>
            followed by
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_rest
placement:
  host_pattern: 'node[6-10]'
data_devices:
  model: MC-55-44-XZ
db_devices:
  model: SSD-123-foo
</screen>
        </example>
        <example>
          <title>Expert setup</title>
          <para>
            All previous cases assumed that the WALs and DBs use the same
            device. It is however possible to deploy the WAL on a dedicated
            device as well:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                20 HDDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                2 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                2 NVMes
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Samsung
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: NVME-QQQQ-987
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 256&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
<screen>
service_type: osd
service_id: example_drvgrp_name
placement:
  host_pattern: '*'
data_devices:
  model: MC-55-44-XZ
db_devices:
  model: SSD-123-foo
wal_devices:
  model: NVME-QQQQ-987
</screen>
        </example>
        <example>
          <title>Complex (and unlikely) setup</title>
          <para>
            In the following setup, we are trying to define:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                20 HDDs backed by 1 NVMe
              </para>
            </listitem>
            <listitem>
              <para>
                2 HDDs backed by 1 SSD(db) and 1 NVMe (wal)
              </para>
            </listitem>
            <listitem>
              <para>
                8 SSDs backed by 1 NVMe
              </para>
            </listitem>
            <listitem>
              <para>
                2 SSDs stand-alone (encrypted)
              </para>
            </listitem>
            <listitem>
              <para>
                1 HDD is spare and should not be deployed
              </para>
            </listitem>
          </itemizedlist>
          <para>
            The summary of used drives is as follows:
          </para>
          <itemizedlist>
            <listitem>
              <para>
                23 HDDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Intel
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: SSD-123-foo
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 4&nbsp;TB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                10 SSDs
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Micron
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: MC-55-44-ZX
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 512&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
            <listitem>
              <para>
                1 NVMe
              </para>
              <itemizedlist>
                <listitem>
                  <para>
                    Vendor: Samsung
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Model: NVME-QQQQ-987
                  </para>
                </listitem>
                <listitem>
                  <para>
                    Size: 256&nbsp;GB
                  </para>
                </listitem>
              </itemizedlist>
            </listitem>
          </itemizedlist>
          <para>
            The &drvgrps; definition will be the following:
          </para>
<screen>
service_type: osd
service_id: example_drvgrp_hdd_nvme
placement:
  host_pattern: '*'
data_devices:
  rotational: 0
db_devices:
  model: NVME-QQQQ-987
</screen>
<screen>
service_type: osd
service_id: example_drvgrp_hdd_ssd_nvme
placement:
  host_pattern: '*'
data_devices:
  rotational: 0
db_devices:
  model: MC-55-44-XZ
wal_devices:
  model: NVME-QQQQ-987
</screen>
<screen>
service_type: osd
service_id: example_drvgrp_ssd_nvme
placement:
  host_pattern: '*'
data_devices:
  model: SSD-123-foo
db_devices:
  model: NVME-QQQQ-987
</screen>
<screen>
service_type: osd
service_id: example_drvgrp_standalone_encrypted
placement:
  host_pattern: '*'
data_devices:
  model: SSD-123-foo
encrypted: True
</screen>
          <para>
            One HDD will remain as the file is being parsed from top to bottom.
          </para>
        </example>
      </sect3>
    </sect2>

    <sect2 xml:id="removing-node-osds">
      <title>Removing OSDs</title>
      <para>
        Before removing an OSD node from the cluster, verify that the cluster
        has more free disk space than the OSD disk you are going to remove. Be
        aware that removing an OSD results in rebalancing of the whole cluster.
      </para>
      <procedure>
        <step>
          <para>
            Identify which OSD to remove by getting its ID:
          </para>
<screen>
&prompt.cephuser;ceph orch ps --daemon_type osd
NAME   HOST            STATUS        REFRESHED  AGE  VERSION
osd.0  target-ses-090  running (3h)  7m ago     3h   15.2.7.689 ...
osd.1  target-ses-090  running (3h)  7m ago     3h   15.2.7.689 ...
osd.2  target-ses-090  running (3h)  7m ago     3h   15.2.7.689 ...
osd.3  target-ses-090  running (3h)  7m ago     3h   15.2.7.689 ...
</screen>
        </step>
        <step>
          <para>
            Remove one or more OSDs from the cluster:
          </para>
<screen>
&prompt.cephuser;ceph orch osd rm <replaceable>OSD1_ID</replaceable> <replaceable>OSD2_ID</replaceable> ...
</screen>
          <para>
            For example:
          </para>
<screen>
&prompt.cephuser;ceph orch osd rm 1 2
</screen>
        </step>
        <step>
          <para>
            You can query the state of the removal operation:
          </para>
<screen>
&prompt.cephuser;ceph orch osd rm status
OSD_ID  HOST         STATE                    PG_COUNT  REPLACE  FORCE  STARTED_AT
2       cephadm-dev  done, waiting for purge  0         True     False  2020-07-17 13:01:43.147684
3       cephadm-dev  draining                 17        False    True   2020-07-17 13:01:45.162158
4       cephadm-dev  started                  42        False    True   2020-07-17 13:01:45.162158
</screen>
        </step>
      </procedure>
      <sect3 xml:id="removing-node-osds-stop">
        <title>Stopping OSD removal</title>
        <para>
          After you have scheduled an OSD removal, you can stop the removal if
          needed. The following command will reset the initial state of the OSD
          and remove it from the queue:
        </para>
<screen>&prompt.cephuser;ceph orch osd rm stop <replaceable>OSD_SERVICE_ID</replaceable></screen>
      </sect3>
    </sect2>

    <sect2 xml:id="removing-node-osds-replace">
      <title>Replacing OSDs</title>
      <para>
        There are several reasons why you may need to replace an OSD disk. For
        example:
      </para>
      <itemizedlist>
        <listitem>
          <para>
            The OSD disk failed or is soon going to fail based on SMART
            information, and can no longer be used to store data safely.
          </para>
        </listitem>
        <listitem>
          <para>
            You need to upgrade the OSD disk, for example to increase its size.
          </para>
        </listitem>
        <listitem>
          <para>
            You need to change the OSD disk layout.
          </para>
        </listitem>
        <listitem>
          <para>
            You plan to move from a non-LVM to a LVM-based layout.
          </para>
        </listitem>
      </itemizedlist>
      <para>
        To replace an OSD while preserving its ID, run:
      </para>
<screen>&prompt.cephuser;ceph orch osd rm <replaceable>OSD_SERVICE_ID</replaceable> --replace</screen>
      <para>
        For example:
      </para>
<screen>&prompt.cephuser;ceph orch osd rm 4 --replace</screen>
      <para>
        Replacing an OSD is identical to removing an OSD (see
        <xref linkend="removing-node-osds"/> for more details) with the
        exception that the OSD is not permanently removed from the CRUSH
        hierarchy and is assigned a <literal>destroyed</literal> flag instead.
      </para>
      <para>
        The <literal>destroyed</literal> flag is used to determined OSD IDs
        that will be reused during the next OSD deployment. Newly added disks
        that match the &drvgrps; specification (see
        <xref linkend="drive-groups"/> for more details) will be assigned OSD
        IDs of their replaced counterpart.
      </para>
      <tip>
        <para>
          Appending the <option>--dry-run</option> option will not execute the
          actual replacement, but will preview the steps that would normally
          happen.
        </para>
      </tip>
      <note>
        <para>
          In the case of replacing an OSD after a failure, we highly recommend
          triggering a deep scrub of the placement groups. See
          <xref linkend="scrubbing-pgs"/> for more details.
        </para>
        <para>
          Run the following command to initiate a deep scrub:
        </para>
<screen>&prompt.cephuser;ceph osd deep-scrub osd.<replaceable>OSD_NUMBER</replaceable></screen>
      </note>
      <important>
        <title>Shared device failure</title>
        <para>
          If a shared device for DB/WAL fails you will need to perform the
          replacement procedure for all OSDs that share the failed device.
        </para>
      </important>
    </sect2>

    <sect2 xml:id="migrating-db-device">
      <title>Migrating OSD's DB device</title>
      <para>
        DB device belongs to an OSD and stores its metadata (see
        <xref linkend="about-bluestore"/> for more details). There are several
        reasons why you may want to migrate an existing DB device to a new
        one&mdash;for example, when OSDs have different DB sizes and you need
        to align them.
      </para>
      <tip>
        <title><command>ceph-volume</command> naming convention</title>
        <para>
          Some clusters may have old volume group (VG) or logical volume (LV)
          names prefixed with <literal>ceph-block-dbs</literal> and
          <literal>osd-block-db</literal>, for example:
        </para>
<screen>ceph-block-dbs-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-block-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c</screen>
        <para>
          The current naming convention is as follows:
        </para>
<screen>ceph-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c</screen>
      </tip>
      <procedure>
        <title>Migrating a DB device to a new device</title>
        <step>
          <para>
            Identify the <option>db device</option> and <option>osd
            fsid</option> values by running the following command:
          </para>
<screen>&prompt.cephuser;cephadm ceph-volume lvm list
[...]
====== osd.0 =======

[block]       /dev/ceph-b03b5ad4-98e8-446a-9a9f-840ecd90215c/osd-block-c276d2a4-5578-4847-94c6-8e2e6abf81c4

block device              /dev/ceph-b03b5ad4-98e8-446a-9a9f-840ecd90215c/osd-block-c276d2a4-5578-4847-94c6-8e2e6abf81c4
block uuid                Kg3ySP-ykP8-adFE-UrHY-OSiv-0WQ5-uuUEJ9
cephx lockbox secret
cluster fsid              9c8d3126-9faf-11ec-a2cf-52540035cdc1
cluster name              ceph
crush device class
db device                 /dev/ceph-block-dbs-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-block-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c
encrypted                 0
osd fsid                  c276d2a4-5578-4847-94c6-8e2e6abf81c4
osd id                    0
osdspec affinity          sesdev_osd_deployment
type                      block
vdo                       0
devices                   /dev/vdb
[...]</screen>
        </step>
        <step>
          <para>
            Create a new logical volume (LV) for the new DB device. Refer to
            <xref linkend="rec-waldb-size"/> when determining the right size
            for the DB device. For example:
          </para>
<screen>&prompt.root;lvcreate -n osd-db-$(cat /proc/sys/kernel/random/uuid) \
 ceph-c3dc9227-ca3e-49bc-992c-00602cb3eec7 --size <replaceable>DB_SIZE</replaceable></screen>
        </step>
        <step>
          <para>
            Stop the OSD. Run the following command on the OSD node where the
            OSD daemon runs:
          </para>
<screen>&prompt.cephuser.osd;cephadm unit stop --name osd.0</screen>
        </step>
        <step>
          <para>
            Enter the shell on the stopped OSD container:
          </para>
<screen>&prompt.cephuser.osd;cephadm shell --name osd.0</screen>
        </step>
        <step>
          <para>
            If the OSD does not have a pre-existing DB device, create new DB with the <command>new-db</command> command:
          </para>
<screen>[ceph: root@pacific /]ceph-volume lvm new-db --osd-id 0 \
 --osd-fsid c276d2a4-5578-4847-94c6-8e2e6abf81c4 \
 --target ceph-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c</screen>
          <para>
            Then, migrate data using the <option>--from data</option> flag:
          </para>
<screen>[ceph: root@pacific /]ceph-volume lvm migrate --osd-id 0 \
 --osd-fsid c276d2a4-5578-4847-94c6-8e2e6abf81c4 --from data \
 --target ceph-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c</screen>
          <para>
          If the OSD does have a pre-existing DB device, migrate the DB using the <option>--from db</option> flag:
          </para>
<screen>[ceph: root@pacific /]ceph-volume lvm migrate --osd-id 0 \
 --osd-fsid c276d2a4-5578-4847-94c6-8e2e6abf81c4 --from db \
 --target ceph-c3dc9227-ca3e-49bc-992c-00602cb3eec7/osd-db-b346b9ff-dbbe-40db-a95e-2419ccd31f2c</screen>
        </step>
        <step>
          <para>
            Exit the &cephadm; shell:
          </para>
<screen>[ceph: root@pacific /]exit</screen>
        </step>
        <step>
          <para>
            Start the OSD. Run the following command on the OSD node where the
            OSD daemon runs:
          </para>
<screen>&prompt.cephuser.osd;cephadm unit --name osd.0 start</screen>
        </step>
        <step>
          <para>
            Remove the old DB logical volume.
          </para>
        </step>
      </procedure>
    </sect2>
  </sect1>
  <sect1 xml:id="moving-saltmaster">
    <title>Moving the &smaster; to a new node</title>

    <para>
      If you need to replace the &smaster; host with a new one, follow these
      steps:
    </para>

    <procedure>
      <step>
        <para>
          Export the cluster configuration and back up the exported JSON file.
          Find more details in
          <xref linkend="deploy-cephadm-configure-export"/>.
        </para>
      </step>
      <step>
        <para>
          If the old &smaster; is also the only administration node in the
          cluster, then manually move
          <filename>/etc/ceph/ceph.client.admin.keyring</filename> and
          <filename>/etc/ceph/ceph.conf</filename> to the new &smaster;.
        </para>
      </step>
      <step>
        <para>
          Stop and disable the &smaster; &systemd; service on the old &smaster;
          node:
        </para>
<screen>
&prompt.smaster;systemctl stop salt-master.service
&prompt.smaster;systemctl disable salt-master.service
</screen>
      </step>
      <step>
        <para>
          If the old &smaster; node is no longer in the cluster, also stop and
          disable the &sminion; &systemd; service:
        </para>
<screen>
&prompt.smaster;systemctl stop salt-minion.service
&prompt.smaster;systemctl disable salt-minion.service
</screen>
        <warning>
          <para>
            Do not stop or disable the <literal>salt-minion.service</literal>
            if the old &smaster; node has any &ceph; daemons (MON, MGR, OSD,
            MDS, gateway, monitoring) running on it.
          </para>
        </warning>
      </step>
      <step>
        <para>
          Install &cephos; on the new &smaster; following the procedure
          described in <xref linkend="deploy-sles"/>.
        </para>
        <tip>
          <title>Transition of &sminion;</title>
          <para>
            To simplify the transition of &sminion;s to the new &smaster;,
            remove the original &smaster;'s public key from each of them:
          </para>
<screen>
&prompt.sminion;rm /etc/salt/pki/minion/minion_master.pub
&prompt.sminion;systemctl restart salt-minion.service
</screen>
        </tip>
      </step>
      <step>
        <para>
          Install the <package>salt-master</package> package and, if
          applicable, the <package>salt-minion</package> package on the new
          &smaster;.
        </para>
      </step>
      <step>
        <para>
          Install &cephsalt; on the new &smaster; node:
        </para>
<screen>
&prompt.smaster;zypper install ceph-salt
&prompt.smaster;systemctl restart salt-master.service
&prompt.smaster;salt '*' saltutil.sync_all
</screen>
        <important>
          <para>
            Make sure to run all three commands before continuing. The commands
            are idempotent; it does not matter if they get repeated.
          </para>
        </important>
      </step>
      <step>
        <para>
          Include the new &smaster; in the cluster as described in
          <xref linkend="deploy-cephadm-cephsalt"/>,
          <xref linkend="deploy-cephadm-configure-minions"/> and
          <xref linkend="deploy-cephadm-configure-admin"/>.
        </para>
      </step>
      <step>
        <para>
          Import the backed up cluster configuration and apply it:
        </para>
<screen>
&prompt.smaster;ceph-salt import <replaceable>CLUSTER_CONFIG</replaceable>.json
&prompt.smaster;ceph-salt apply
</screen>
        <important>
          <para>
            Rename the &smaster;'s <literal>minion id</literal> in the exported
            <filename><replaceable>CLUSTER_CONFIG</replaceable>.json</filename>
            file before importing it.
          </para>
        </important>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="cephadm-rolling-updates">
    <title>Updating the cluster nodes</title>

    <para>
      Keep the &ceph; cluster nodes up-to-date by applying rolling updates
      regularly.
    </para>

    <sect2 xml:id="rolling-updates-repos">
      <title>Software repositories</title>
      <para>
        Before patching the cluster with the latest software packages, verify
        that all the cluster's nodes have access to the relevant repositories.
        Refer to <xref linkend="verify-previous-upgrade-patch-repos-repos"/>
        for a complete list of the required repositories.
      </para>
    </sect2>

    <sect2 xml:id="rolling-upgrades-staging">
      <title>Repository staging</title>
      <para>
        If you use a staging tool&mdash;for example, &susemgr;, &smtool;, or
        &rmt;&mdash;that serves software repositories to the cluster nodes,
        verify that stages for both 'Updates' repositories for &sls; and
        &productname; are created at the same point in time.
      </para>
      <para>
        We strongly recommend to use a staging tool to apply patches which have
        <literal>frozen</literal> or <literal>staged</literal> patch levels.
        This ensures that new nodes joining the cluster have the same patch
        level as the nodes already running in the cluster. This way you avoid
        the need to apply the latest patches to all the cluster's nodes before
        new nodes can join the cluster.
      </para>
    </sect2>

    <sect2>
      <title>Downtime of &ceph; services</title>
      <para>
        Depending on the configuration, cluster nodes may be rebooted during
        the update. If there is a single point of failure for services such as
        &ogw;, &sgw;, &ganesha;, or &iscsi;, the client machines may be
        temporarily disconnected from services whose nodes are being rebooted.
      </para>
    </sect2>

    <sect2 xml:id="rolling-updates-running">
      <title>Running the update</title>
      <para>
        To update the software packages on all cluster nodes to the latest
        version, run the following command:
      </para>
<screen>&prompt.smaster;ceph-salt update</screen>
    </sect2>
  </sect1>
  <sect1 xml:id="deploy-cephadm-day2-cephupdate">
    <title>Updating &ceph;</title>

    <para>
      You can instruct &cephadm; to update &ceph; from one bugfix release to
      another. The automated update of &ceph; services respects the recommended
      order&mdash;it starts with &mgr;s, &mon;s, and then continues on to other
      services such as &osd;s, &mds;s, and &ogw;s. Each daemon is restarted
      only after &ceph; indicates that the cluster will remain available.
    </para>

    <note>
      <para>
        The following update procedure uses the <command>ceph orch
        upgrade</command> command. Keep in mind that the following instructions
        detail how to update your &ceph; cluster with a product version (for
        example, a maintenance update), and <emphasis>does not</emphasis>
        provide instructions on how to upgrade your cluster from one product
        version to another.
      </para>
    </note>

    <sect2 xml:id="deploy-cephadm-day2-cephupdate-start">
      <title>Starting the update</title>
      <para>
        Before you start the update, verify that all nodes are currently online
        and your cluster is healthy:
      </para>
<screen>&prompt.cephuser;cephadm shell -- ceph -s</screen>
      <para>
        To update to a specific &ceph; release:
      </para>
<screen>&prompt.cephuser;ceph orch upgrade start --image <replaceable>REGISTRY_URL</replaceable></screen>
      <para>
        For example:
      </para>
<screen>&prompt.cephuser;ceph orch upgrade start --image registry.suse.com/ses/7.1/ceph/ceph:latest</screen>
      <para>
        Upgrade packages on the hosts:
      </para>
<screen>&prompt.cephuser;ceph-salt update</screen>
    </sect2>

    <sect2 xml:id="deploy-cephadm-day2-cephupdate-monitor">
      <title>Monitoring the update</title>
      <para>
        Run the following command to determine whether an update is in
        progress:
      </para>
<screen>&prompt.cephuser;ceph orch upgrade status</screen>
      <para>
        While the update is in progress, you will see a progress bar in the
        &ceph; status output:
      </para>
<screen>&prompt.cephuser;ceph -s
[...]
  progress:
    Upgrade to registry.suse.com/ses/7.1/ceph/ceph:latest (00h 20m 12s)
      [=======.....................] (time remaining: 01h 43m 31s)</screen>
      <para>
        You can also watch the &cephadm; log:
      </para>
<screen>&prompt.cephuser;ceph -W cephadm</screen>
    </sect2>

    <sect2 xml:id="deploy-cephadm-day2-cephupdate-stop">
      <title>Cancelling an update</title>
      <para>
        You can stop the update process at any time:
      </para>
<screen>&prompt.cephuser;ceph orch upgrade stop</screen>
    </sect2>
  </sect1>
  <sect1 xml:id="sec-salt-cluster-reboot">
    <title>Halting or rebooting cluster</title>

    <para>
      In some cases it may be necessary to halt or reboot the whole cluster. We
      recommended carefully checking for dependencies of running services. The
      following steps provide an outline for stopping and starting the cluster:
    </para>

    <procedure>
      <step>
        <para>
          Tell the &ceph; cluster not to mark OSDs as out:
        </para>
<screen>&prompt.cephuser;<command>ceph</command> osd set noout</screen>
      </step>
      <step>
        <para>
          Stop daemons and nodes in the following order:
        </para>
        <orderedlist>
          <listitem>
            <para>
              Storage clients
            </para>
          </listitem>
          <listitem>
            <para>
              Gateways, for example &ganesha; or &ogw;
            </para>
          </listitem>
          <listitem>
            <para>
              &mds;
            </para>
          </listitem>
          <listitem>
            <para>
              &osd;
            </para>
          </listitem>
          <listitem>
            <para>
              &mgr;
            </para>
          </listitem>
          <listitem>
            <para>
              &mon;
            </para>
          </listitem>
        </orderedlist>
      </step>
      <step>
        <para>
          If required, perform maintenance tasks.
        </para>
      </step>
      <step>
        <para>
          Start the nodes and servers in the reverse order of the shutdown
          process:
        </para>
        <orderedlist>
          <listitem>
            <para>
              &mon;
            </para>
          </listitem>
          <listitem>
            <para>
              &mgr;
            </para>
          </listitem>
          <listitem>
            <para>
              &osd;
            </para>
          </listitem>
          <listitem>
            <para>
              &mds;
            </para>
          </listitem>
          <listitem>
            <para>
              Gateways, for example &ganesha; or &ogw;
            </para>
          </listitem>
          <listitem>
            <para>
              Storage clients
            </para>
          </listitem>
        </orderedlist>
      </step>
      <step>
        <para>
          Remove the noout flag:
        </para>
<screen>&prompt.cephuser;<command>ceph</command> osd unset noout</screen>
      </step>
    </procedure>
  </sect1>
  <sect1 xml:id="ceph-cluster-purge">
    <title>Removing an entire &ceph; cluster</title>

    <para>
      The <command>ceph-salt purge</command> command removes the entire &ceph;
      cluster. If there are more &ceph; clusters deployed, the one reported by
      <command>ceph -s</command> is purged. This way you can clean the cluster
      environment when testing different setups.
    </para>

    <para>
      To prevent accidental deletion, the orchestration checks if the safety is
      disengaged. You can disengage the safety measures and remove the &ceph;
      cluster by running:
    </para>

<screen>
&prompt.smaster;ceph-salt disengage-safety
&prompt.smaster;ceph-salt purge
</screen>
  </sect1>
  <sect1 xml:id="ceph-offline-container-management">
    <title>Offline container management</title>

    <para>
      You can run specific commands, for example,
      <command>ceph-objectstore-tool</command> and
      <command>ceph-monstore-tool</command>, inside stopped containers by
      calling a &cephadm; shell. The following examples illustrate common use
      cases:
    </para>

    <tip>
      <para>
        When stopping an OSD daemon, we recommend setting the
        <literal>noout</literal> flag to prevent unnecessary data movement:
      </para>
<screen>&prompt.cephuser;ceph osd add-noout osd.<replaceable>DAEMON_ID</replaceable></screen>
      <para>
        Remember to unset the <literal>noout</literal> flag after you finish
        maintaining the OSD:
      </para>
<screen>&prompt.cephuser;ceph osd rm-noout osd.<replaceable>DAEMON_ID</replaceable></screen>
    </tip>

    <para>
      To query an OSD, run the following:
    </para>

<screen>
&prompt.cephuser;ceph osd add-noout osd.1
&prompt.cephuser;cephadm unit stop --name osd.1
&prompt.cephuser;cephadm shell --name osd.1
[ceph: root@pacific /]# ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-1/ --op list
&prompt.cephuser;cephadm unit start --name osd.1
&prompt.cephuser;ceph osd rm-noout osd.1
</screen>

    <para>
      To query a MON, run the following:
    </para>

<screen>
&prompt.cephuser;cephadm unit stop --name mon.pacific
&prompt.cephuser;cephadm shell --name mon.pacific
[ceph: root@pacific /]# ceph-monstore-tool /var/lib/ceph/mon/ceph-pacific/ dump-keys
&prompt.cephuser;cephadm unit start --name mon.pacific
</screen>

    <para>
      To print a MON map, run the following:
    </para>

<screen>
&prompt.cephuser;cephadm unit stop --name mon.pacific
&prompt.cephuser;cephadm shell --name mon.pacific
[ceph: root@pacific /]# ceph-monstore-tool /var/lib/ceph/mon/ceph-pacific get monmap > /tmp/monmap
[ceph: root@pacific /]# monmaptool --print /tmp/monmap
monmaptool: monmap file /tmp/monmap
epoch 1
fsid 28596f44-3b56-11ec-9034-482ae35a5fbb
last_changed 2021-11-01T20:57:19.755111+0000
created 2021-11-01T20:57:19.755111+0000
min_mon_release 17 (quincy)
election_strategy: 1
0: [v2:127.0.0.1:3300/0,v1:127.0.0.1:6789/0] mon.pacific
&prompt.cephuser;cephadm unit start --name mon.pacific
</screen>

    <para>
      An example of migrating OSD's DB device is in
      <xref linkend="migrating-db-device"/>.
    </para>
  </sect1>
  <sect1 xml:id="refreshing-ssl-certificates">
    <title>Refreshing expired SSL certificates</title>

    <para>
      Multiple &ceph; services use SSL certificates to secure communication
      between the client and the server. The validity of an SSL certificate is
      normally limited and expires after the time period specified at its
      creation. The following are procedures to renew SSL certificates for
      affected &ceph; services.
    </para>

    <tip>
      <para>
        The following procedures start with <emphasis>renewing</emphasis> an
        expired certificate. By <emphasis>renewing</emphasis>, we mean
        obtaining a valid certificate and key file with the expiration time in
        the future. A certificate authority (CA) can provide one for you, or
        you can create a self-signed certificate yourself.
      </para>
    </tip>

    <sect2 xml:id="renewing-ssl-certificates-igw">
      <title>&igw;</title>
      <procedure>
        <step>
          <para>
            Renew the certificate.
          </para>
        </step>
        <step>
          <para>
            Insert the new certificate and key into an &igw; service
            specification file as described in <xref linkend="deploy-igw-ssl"/>
            and save it as <filename>iscsi.yaml</filename>, for example.
          </para>
        </step>
        <step>
          <para>
            Apply the new &igw; service specification by running the following
            command:
          </para>
<screen>&prompt.cephuser;<command>ceph orch apply -i iscsi.yaml</command></screen>
        </step>
        <step>
          <para>
            Reconfigure the &igw; service to use the new certificate:
          </para>
<screen>&prompt.cephuser;ceph orch reconfig <replaceable>NAME_OF_ISCSI_SERVICE</replaceable></screen>
        </step>
      </procedure>
    </sect2>

    <sect2 xml:id="renewing-ssl-certificates-rgw">
      <title>&ogw;</title>
      <procedure>
        <step>
          <para>
            Renew the certificate.
          </para>
        </step>
        <step>
          <para>
            Concatenate the certificate and key files into a single file if
            they are in separate files.
          </para>
        </step>
        <step>
          <para>
            Apply the new certificate to the &ogw;:
          </para>
<screen>&prompt.cephuser;<command>ceph config-key set rgw/cert/<replaceable>REALM_NAME</replaceable>/<replaceable>ZONE_NAME</replaceable>.crt \
-i <replaceable>SSL_CERT_FILE</replaceable></command></screen>
        </step>
        <step>
          <para>
            Restart the &ogw; by running the following command:
          </para>
<screen>&prompt.cephuser;ceph orch restart <replaceable>NAME_OF_RGW_SERVICE</replaceable></screen>
        </step>
      </procedure>
      <note>
        <para>
          If you originally deployed the SSL certificate by specifying the
          <option>rgw_frontend_ssl_certificate</option> option in the &ogw;
          specification file, delete it from the specification to avoid having
          two different certificate specifications.
        </para>
      </note>
    </sect2>

    <sect2 xml:id="renewing-ssl-certificates-dashboard">
      <title>&dashboard;</title>
      <para>
        The procedure of refreshing the &dashboard; SSL certificate is detailed
        in <xref linkend="dashboard-ssl"/>:
      </para>
      <itemizedlist>
        <listitem>
          <para>
            If you are using a self-signed certificate, generate a new one and
            restart the &mgr; by disabling and re-enabling the dashboard
            module:
          </para>
<screen>
&prompt.cephuser;<command>ceph dashboard create-self-signed-cert</command>
&prompt.cephuser;<command>ceph mgr module disable dashboard</command>
&prompt.cephuser;<command>ceph mgr module enable dashboard</command>
</screen>
        </listitem>
        <listitem>
          <para>
            If you are using a certificate signed by a CA, obtain a renewed
            certificate and key files and configure &dashboard; to use them.
            Then restart the &mgr; by disabling and re-enabling the dashboard
            module:
          </para>
<screen>
&prompt.cephuser;<command>ceph dashboard set-ssl-certificate -i dashboard.crt</command>
&prompt.cephuser;<command>ceph dashboard set-ssl-certificate-key -i dashboard.key</command>
&prompt.cephuser;<command>ceph mgr module disable dashboard</command>
&prompt.cephuser;<command>ceph mgr module enable dashboard</command>
</screen>
        </listitem>
      </itemizedlist>
    </sect2>

    <sect2 xml:id="renewing-ssl-certificates-grafana">
      <title>&grafana;</title>
      <para>
        Renewing the &grafana; SSL certificate is almost identical to initial
        Renewing the &grafana; SSL certificate is almost identical to the
        initial SSL certificate setup mentioned in
      </para>
      <itemizedlist>
        <listitem>
          <para>
            If you are using a self-signed certificate, remove the existing one
            from the &ceph; configuration and reconfigure the &grafana; service
            to have a new certificate and key files automatically generated and
            applied:
          </para>
          <important>
            <para>
              &ceph; Pacific prior to version 16.2.11 uses old configuration
              paths for specifying certificate files&mdash;it lacks the
              <literal>/admin</literal> path. For example, the path to
              &grafana; SSL certificate key file was as follows:
            </para>
<screen>mgr/cephadm/grafana_key</screen>
            <para>
              instead of
            </para>
<screen>mgr/cephadm/admin/grafana_key</screen>
          </important>
<screen>
&prompt.cephuser;<command>ceph config-key rm mgr/cephadm/admin/grafana_key</command>
&prompt.cephuser;<command>ceph config-key rm mgr/cephadm/admin/grafana_crt</command>
&prompt.cephuser;<command>ceph orch reconfig grafana</command>
</screen>
        </listitem>
        <listitem>
          <para>
            If you are using a certificate signed by a CA, obtain a renewed
            certificate and key files, specify them, and apply the changes:
          </para>
<screen>
&prompt.cephuser;<command>ceph config-key set mgr/cephadm/admin/grafana_key -i key.pem</command>
&prompt.cephuser;<command>ceph config-key set mgr/cephadm/admin/grafana_crt -i certificate.pem</command>
&prompt.cephuser;<command>ceph orch reconfig grafana</command>
</screen>
        </listitem>
      </itemizedlist>
    </sect2>

    <sect2 xml:id="renewing-ssl-certificates-igw-ha">
      <title>&igw; HA (behind &haproxy;/&keepalived;)</title>
      <procedure>
        <step>
          <para>
            Renew the certificate.
          </para>
        </step>
        <step>
          <para>
            Insert the new certificate and key into an &ingress; service
            specification file as described in <xref linkend="ceph-ogw-ha"/>
            and save it as <filename>ingress.yaml</filename>, for example.
          </para>
        </step>
        <step>
          <para>
            Apply the new &ingress; service specification by running the
            following command:
          </para>
<screen>&prompt.cephuser;<command>ceph orch apply -i ingress.yaml</command></screen>
        </step>
        <step>
          <para>
            Reconfigure the &ingress; service to use the new certificate:
          </para>
<screen>&prompt.cephuser;ceph orch reconfig <replaceable>NAME_OF_INGRESS_SERVICE</replaceable></screen>
        </step>
      </procedure>
    </sect2>
  </sect1>
</chapter>
