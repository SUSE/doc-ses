<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="storage.salt.cluster">
 <title>&salt; Cluster Administration</title>
 <para>
  After you deploy your &storage; cluster by using &salt; you may need to
  perform several modifications to your cluster like adding new disks, adding
  nodes or removing nodes or disks. This chapter describes how you can achieve
  these basic administration tasks.
 </para>
 <sect1 xml:id="salt.adding.nodes">
  <title>Adding Nodes</title>

  <para>
   The procedure of adding nodes to the cluster is similar for all node types.
   Basically you just update your <filename>policy.cfg</filename>, then you run
   the deployment stages 1, 2 and 3 as described in
   <xref linkend="deepsea.description"/>.
  </para>

  <tip>
   <para>
    When adding an OSD to an existing cluster, bear in mind that the cluster
    will be rebalancing for some time afterward. To minimize the rebalancing
    periods, it is best to add all the OSDs you intend to add at the same time.
   </para>
  </tip>

  <note>
   <title>Prerequisites</title>
   <para>
    Before you follow the procedure below you need to install
    <literal>salt-minion</literal> on the node, for details refer to
    <xref linkend="ceph.install.stack"/>.
   </para>
  </note>

  <procedure>
   <title>Adding an OSD Host</title>
   <step>
    <para>
     Change your <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> to
     include a new profile with the new node's disks.
    </para>
   </step>
   <step>
    <para>
     Run the discovery stage (stage 1).
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.1</screen>
    <para>
     The stage creates a new profile for the node. The previous configuration
     is not overwritten as in cases like network problems it could reconfigure
     the whole cluster.
    </para>
   </step>
   <step>
    <para>
     Run the configuration stage to apply changes to the profile.
    </para>
<screen>salt-run state.orch ceph.stage.2</screen>
    <para>
     The &salt; pillar will be updated during this stage.
    </para>
   </step>
  </procedure>

  <sect2 xml:id="salt.adding.disks">
   <title>Adding New OSD Disks</title>
  </sect2>
 </sect1>
 <sect1 xml:id="salt.node.removing">
  <title>Removing and Reinstalling &salt; Cluster Nodes</title>

  <note>
   <title>Removing OSD from Your Cluster</title>
   <para>
    In case you need to remoe a particular OSD node from your cluster, ensure
    that your cluster has sufficient disk space for its operating. Bear in mind
    that removing an OSD results in rebalancing of the whole cluster.
   </para>
  </note>

  <para>
   You may want remove a role from your minion, to do so use the Stage 5
   command:
  </para>

<screen>&prompt.root;salt-run state.orch ceph.stage.5</screen>

  <para>
   When a role is removed from a minion, the objective is to undo all changes
   related to that role. For most of the roles, the task is simple, but there
   may be problems with package dependencies. If a package is uninstalled, its
   dependencies are not.
  </para>

  <para>
   Removed OSDs appear as blank drives. The related tasks overwrite the
   beginning of the file systems and remove backup partitions in addition to
   wiping the partition tables.
  </para>

  <note>
   <title>Preserving Partitions Created by Other Methods</title>
   <para>
    Disk drives previously configured by other methods, such as
    <command>ceph-deploy</command>, may still contain partitions. &deepsea;
    will not automatically destroy these. Currently, the administrator must
    reclaim these drives.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="salt.automated.installation">
  <title>Automated Installation via &salt;</title>

  <para>
   The installation can be automated by using the &salt; reactor. For virtual
   environments or consistent hardware environments, this configuration will
   allow the creation of a &ceph; cluster with the specified behavior.
  </para>

  <warning>
   <para>
    &salt; cannot perform dependency checks based on reactor events. Putting
    your &salt; master into a death spiral is a real risk.
   </para>
  </warning>

  <para>
   The automated installation requires the following:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     A properly created
     <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     Prepared custom configuration, placed to the
     <filename>/srv/pillar/ceph/stack</filename> directory.
    </para>
   </listitem>
   <listitem>
    <para>
     The example reactor file
     <filename>/usr/share/doc/packages/deepsea/reactor.conf</filename> must be
     copied to <filename>/etc/salt/master.d/reactor.conf</filename>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   The default reactor configuration will only run Stages 0 and 1. This allows
   testing of the reactor without waiting for subsequent stages to complete.
  </para>

  <para>
   When the first salt-minion starts, Stage 0 will begin. A lock prevents
   multiple instances. When all minions complete Stage 0, Stage 1 will begin.
  </para>

  <para>
   If the operation is performed properly, change the last line in the
   <filename>/etc/salt/master.d/reactor.conf</filename>:
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   to
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="Deepsea.restart">
  <title>Restarting &ceph; services using &deepsea;</title>

  <para>
   When you install updates, specifically ceph-&lt;mon,osd etc&gt; you need to
   restart the services to make use of the recently installed version. To do
   so, run:
  </para>

<screen>salt-run state.orch ceph.restart</screen>

  <para>
   The script iterates over all roles you have configured in the following
   order: MON, OSD, MDS, RGW, IGW. To keep the downtime low and to find
   potential issues as early as possible, nodes are restarted sequentially. For
   example, only one monitoring node is restarted at a time. The command also
   waits for the cluster to recover if the cluster is in a degraded unhealthy
   state.
  </para>

  <note>
   <title>Watching the Restarting</title>
   <para>
    The process of restarting the cluster may take some time. You can watch the
    events by using the &salt; event bus by running:
   </para>
<screen>salt-run state.event pretty=True</screen>
  </note>
 </sect1>
</chapter>
