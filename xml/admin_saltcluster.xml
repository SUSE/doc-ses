<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0" xml:id="storage.salt.cluster">
 <title>&salt; Cluster Administration</title>
 <para>
  After you deploy &ceph; cluster, you will probably need to perform several
  modifications to it occasionally. These include adding or removing new nodes,
  disks, or services. This chapter describes how you can achieve these
  administration tasks.
 </para>
 <sect1 xml:id="salt.adding.nodes">
  <title>Adding New Cluster Nodes</title>

  <para>
   The procedure of adding new nodes to the cluster is almost identical to the
   initial cluster node deployment described in
   <xref
    linkend="ceph.install.saltstack"/>:
  </para>

  <procedure>
   <step>
    <para>
     Install &cephos; on the new node, configure its network setting so that it
     resolves the &smaster; host name correctly, and install the
     <systemitem>salt-minion</systemitem> package:
    </para>
<screen>&prompt.sminion;zypper in salt-minion</screen>
    <para>
     If the &smaster;'s host name is different from <literal>salt</literal>,
     edit <filename>/etc/salt/minion</filename> and add the following:
    </para>
<screen>master:<replaceable>DNS_name_of_your_salt_master</replaceable></screen>
    <para>
     If you performed any changes to the configuration files mentioned above,
     restart the <systemitem>salt.minion</systemitem> service:
    </para>
<screen>&prompt.sminion;systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     Accept all salt keys on the &smaster;:
    </para>
<screen>&prompt.smaster;salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     Run the preparation stage. It synchronizes modules and grains so that the
     new minion can provide all the information &deepsea; expects:
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.0</screen>
   </step>
   <step>
    <para>
     Run the discovery stage. It will write new file entries in the
     <filename>/srv/pillar/ceph/proposals</filename> directory where you can
     edit relevant .yml files:
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Optionally change
     <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> if the newly
     added host does not match the existing naming scheme.
    </para>
   </step>
   <step>
    <para>
     Run the configuration stage. It reads everything under
     <filename>/srv/pillar/ceph</filename> and updates the pillar accordingly.
     Pillar stores data you can access with <command>salt '*'
     pillar.items</command>.
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     The configuration and deployment stages include newly added nodes:
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.3
&prompt.smaster;salt-run state.orch ceph.stage.4</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt.adding.services">
  <title>Adding New Roles to Nodes</title>

  <para>
   You can deploy all types of supported roles with &deepsea;. See
   <xref
    linkend="policy.role.assignment"/> for more information on
   supported role types and examples of matching them.
  </para>

  <tip>
   <title>Required and Optional Roles and Stages</title>
   <para>
    Generally, we recommend running all deployment stages 0 to 5 when adding
    new role to a cluster node. To save some time, you can skip Stage 3 or 4,
    depending on which type of role you intend to deploy. While OSD and MON
    roles include core services and are required by &ceph;, other roles such as
    &rgw; are optional. &deepsea; deployment stages reflect hierarchy: while
    Stage 3 deploys core services, Stage 4 deploys the optional ones.
   </para>
   <para>
    Therefore, you need to run Stage 3 when deploying core roles, such as MON
    on an existing OSD node, while you may skip Stage 4.
   </para>
   <para>
    Similarly, you can skip Stage 3 when deploying optional services such as
    &rgw;, but you need to run Stage 4 in that case.
   </para>
  </tip>

  <para>
   To add a new service to an existing node, follow these steps:
  </para>

  <procedure>
   <step>
    <para>
     Adapt <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> to match
     the existing host with a new role. For example if you need to run a &rgw;
     on a MON node, the line is similar to
    </para>
<screen>role-rgw/xx/x/example.mon-1.sls</screen>
   </step>
   <step>
    <para>
     Run Stage 2 to update the pillar:
    </para>
<screen>&prompt.smaster;salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Run Stage 3 to deploy core service, or Stage 4 to deploy optional
     services. Running both stages does not hurt.
    </para>
   </step>
  </procedure>

  <tip>
   <para>
    When adding an OSD to the existing cluster, bear in mind that the cluster
    will be rebalancing for some time afterward. To minimize the rebalancing
    periods, we recommend adding all the OSDs you intend to add at the same
    time.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="salt.node.removing">
  <title>Removing and Reinstalling Cluster Nodes</title>

  <para>
   To remove a role from from a cluster, edit
   <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> and remove the
   corresponding line(s). The re-run Stage 2 to 5 as described in <xref
    linkend="ceph.install.stack"/>.
  </para>

  <note>
   <title>Removing OSDs from Your Cluster</title>
   <para>
    In case you need to remove a particular OSD node from your cluster, ensure
    that your cluster has more free disk space than the disk you intend to
    remove. Bear in mind that removing an OSD results in rebalancing of the
    whole cluster.
   </para>
  </note>

<screen>&prompt.smaster;salt-run state.orch ceph.stage.5</screen>

  <para>
   When a role is removed from a minion, the objective is to undo all changes
   related to that role. For most of the roles, the task is simple, but there
   may be problems with package dependencies. If a package is uninstalled, its
   dependencies are not.
  </para>

  <para>
   Removed OSDs appear as blank drives. The related tasks overwrite the
   beginning of the file systems and remove backup partitions in addition to
   wiping the partition tables.
  </para>

  <note>
   <title>Preserving Partitions Created by Other Methods</title>
   <para>
    Disk drives previously configured by other methods, such as
    <command>ceph-deploy</command>, may still contain partitions. &deepsea;
    will not automatically destroy these. The administrator must reclaim these
    drives.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="salt.automated.installation">
  <title>Automated Installation via &salt;</title>

  <para>
   The installation can be automated by using the &salt; reactor. For virtual
   environments or consistent hardware environments, this configuration will
   allow the creation of a &ceph; cluster with the specified behavior.
  </para>

  <warning>
   <para>
    &salt; cannot perform dependency checks based on reactor events. Putting
    your &salt; master into a death spiral is a real risk.
   </para>
  </warning>

  <para>
   The automated installation requires the following:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     A properly created
     <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     Prepared custom configuration, placed to the
     <filename>/srv/pillar/ceph/stack</filename> directory.
    </para>
   </listitem>
   <listitem>
    <para>
     The example reactor file
     <filename>/usr/share/doc/packages/deepsea/reactor.conf</filename> must be
     copied to <filename>/etc/salt/master.d/reactor.conf</filename>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   The default reactor configuration will only run Stages 0 and 1. This allows
   testing of the reactor without waiting for subsequent stages to complete.
  </para>

  <para>
   When the first salt-minion starts, Stage 0 will begin. A lock prevents
   multiple instances. When all minions complete Stage 0, Stage 1 will begin.
  </para>

  <para>
   If the operation is performed properly, change the last line in the
   <filename>/etc/salt/master.d/reactor.conf</filename>:
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   to
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="Deepsea.restart">
  <title>Restarting &ceph; services using &deepsea;</title>

  <para>
   After you applied updates to the cluster nodes, you need to restart the
   assigned services to make use of the recently installed version.
  </para>

  <note>
   <title>Watching the Restarting</title>
   <para>
    The process of restarting the cluster may take some time. You can watch the
    events by using the &salt; event bus by running:
   </para>
<screen>&prompt.smaster;salt-run state.event pretty=True</screen>
  </note>

  <sect2 xml:id="deepsea.restart.all">
   <title>Restarting All Services</title>
   <para>
    To restart <emphasis>all</emphasis> services on the cluster, run
   </para>
<screen>&prompt.smaster;salt-run state.orch ceph.restart</screen>
   <para>
    The script iterates over all roles you have configured in the following
    order: MON, OSD, MDS, &rgw;, &igw;, &ganesha;. To keep the downtime low and
    to find potential issues as early as possible, nodes are restarted
    sequentially. For example, only one monitoring node is restarted at a time.
    The command also waits for the cluster to recover if the cluster is in a
    degraded unhealthy state.
   </para>
  </sect2>

  <sect2 xml:id="deepsea.restart.specific">
   <title>Restarting Specific Services</title>
   <para>
    To restart a specific service on the cluster, run:
   </para>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.<replaceable>service_name</replaceable></screen>
   <para>
    For example to restart all &rgw;s, run:
   </para>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.rgw</screen>
   <para>
    You can use the following targets:
   </para>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.mon</screen>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.osd</screen>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.mds</screen>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.rgw</screen>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.igw</screen>
<screen>&prompt.smaster;salt-run state.orch ceph.restart.ganesha</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="deepsea.rolling_updates">
  <title>Updating the Cluster Nodes</title>

  <para>
   It is a good idea to apply rolling updates to your cluster's nodes
   regularly. To apply the updates, run Stage 0:
  </para>

<screen>&prompt.smaster;salt-run state.orch ceph.stage.0</screen>

  <para>
   If &deepsea; detects a running &ceph; cluster, it applies updates and
   restarts nodes sequentially. &deepsea; follows &ceph;'s official
   recommendation of first updating the monitors, then the OSDs and lastly
   additional services, such as MDS, &rgw;, &igw; or &ganesha;. &deepsea; stops
   the update process if it detects an issue in the cluster. A trigger for that
   can be:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     &ceph; reports 'HEALTH_ERR' for longer then 300 seconds.
    </para>
   </listitem>
   <listitem>
    <para>
     &sminion;s are queried for their assigned services to be still up and
     running after an update. The update fails if the services are down for
     more than 900 seconds.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Making these arrangements ensures that even with corrupted or failing
   updates, the &ceph; cluster is still operational.
  </para>

  <para>
   You can change the default reboot behavior of &deepsea; stage 0 by adding
   the following lines to the <filename>/srv/pillar/ceph/stack/global.yml</filename>:
  </para>
<screen>stage_prep_master: default-update-no-reboot
stage_prep_minion: default-update-no-reboot</screen>

  <para>
   <literal>stage_prep_master</literal> sets the stage 0 behavior of the
   &smaster;, while <literal>stage_prep_minion</literal> sets the behavior
   of all minions. All available parameters are:
  </para>
  <variablelist>
   <varlistentry>
    <term>default</term>
    <listitem>
     <para>
      Install updates and reboot after updating.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-update-no-reboot</term>
    <listitem>
     <para>
      Install updates without rebooting.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-reboot</term>
    <listitem>
     <para>
      Reboots without installing updates.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-no-reboot</term>
    <listitem>
     <para>
      Do not install updates or reboot.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.salt.cluster.reboot">
  <title>Halting or Rebooting Cluster</title>
  <para>
   In some cases in might be necessary to halt or reboot the whole cluster.
   We recommended to carefully check for dependencies of running services.
   The following steps provide an outline for stopping and starting the cluster:
  </para>
  <procedure>
   <step>
    <para>
     Tell the &ceph; cluster to not mark OSDs as out:
    </para>
<screen>&prompt.root;<command>ceph</command> osd set noout</screen>
   </step>
   <step>
    <para>
     Stop daemons and nodes in the following order:
    </para>
    <orderedlist>
     <listitem>
      <para>Storage clients</para>
     </listitem>
     <listitem>
      <para>Gateways, for example &ganesha; or &rgw;</para>
     </listitem>
     <listitem>
      <para>&mds;</para>
     </listitem>
     <listitem>
      <para>&osd;</para>
     </listitem>
     <listitem>
      <para>&mon;</para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>If required, perfom maintenance tasks.</para>
   </step>
   <step>
    <para>
     Start the nodes and servers in the reverse order of the shutdown process:
    </para>
    <orderedlist>
     <listitem>
      <para>&mon;</para>
     </listitem>
     <listitem>
      <para>&osd;</para>
     </listitem>
     <listitem>
      <para>&mds;</para>
     </listitem>
     <listitem>
      <para>Gateways, for example &ganesha; or &rgw;</para>
     </listitem>
     <listitem>
      <para>Storage clients</para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Remove the noout flag:
    </para>
<screen>&prompt.root;<command>ceph</command> osd unset noout</screen>
   </step>
  </procedure>
 </sect1>
</chapter>
