<?xml version="1.0"?>
<sect1 xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="en" xml:id="man_ganesha_rados_grace_ganesha_rados_grace____manipulate_the_shared_grace_management_database">
 <title>ganesha-rados-grace -- manipulate the shared grace management database</title>

 <sect2 xml:id="man_ganesha_rados_grace_synopsis">
  <title>SYNOPSIS</title>
  <para>
   ganesha-rados-grace [ --cephconf /path/to/ceph.conf ] [--ns namespace] [
   --oid obj_id ] [ --pool pool_id ] [ --userid cephuser ]
   dumpstartliftenforcemember [ nodeid ... ]
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_description">
  <title>DESCRIPTION</title>
  <para>
   This tool allows the administrator to directly manipulate the database used
   by the rados_cluster recovery backend. Cluster nodes use that database to
   indicate their current state in order to coordinate a cluster-wide grace
   period.
  </para>
  <para>
   The first argument should be a command to execute against the database. Any
   remaining arguments represent the nodeids of nodes in the cluster that
   should be acted upon.
  </para>
  <para>
   Most commands will just fail if the grace database is not present. The
   exception to this rule is the <emphasis role="strong">add</emphasis> command
   which will create the pool, database and namespace if they do not already
   exist.
  </para>
  <para>
   Note that this program does not consult ganesha.conf. If you use non-default
   values for <emphasis role="strong">ceph_conf</emphasis>,
   <emphasis role="strong">userid</emphasis>,
   <emphasis role="strong">grace_oid</emphasis>,
   <emphasis role="strong">namespace</emphasis> or
   <emphasis role="strong">pool</emphasis> in your RADOS_KV config block, then
   they will need to passed in via command-line options.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_options">
  <title>OPTIONS</title>
  <para>
   <emphasis role="strong">--cephconf</emphasis>
  </para>
  <para>
   Specify the ceph.conf configuration that should be used (default is to use
   the normal search path to find one)
  </para>
  <para>
   <emphasis role="strong">--ns</emphasis>
  </para>
  <para>
   Set the RADOS namespace to use within the pool (default is NULL)
  </para>
  <para>
   <emphasis role="strong">--oid</emphasis>
  </para>
  <para>
   Set the object id of the grace database RADOS object (default is "grace")
  </para>
  <para>
   <emphasis role="strong">--pool</emphasis>
  </para>
  <para>
   Set the RADOS poolid in which the grace database object resides (default is
   "nfs-ganesha")
  </para>
  <para>
   <emphasis role="strong">--userid</emphasis>
  </para>
  <para>
   Set the cephx user ID to use when contacting the cluster (default is NULL)
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_commands">
  <title>COMMANDS</title>
  <para>
   <emphasis role="strong">dump</emphasis>
  </para>
  <para>
   Dump the current status of the grace period database to stdout. This will
   show the current and recovery epoch serial numbers, as well as a list of
   hosts currently in the cluster and what flags they have set in their
   individual records.
  </para>
  <para>
   <emphasis role="strong">add</emphasis>
  </para>
  <para>
   Add the specified hosts to the cluster. This must be done before the given
   hosts can take part in the cluster. Attempts to modify the database by
   cluster hosts that have not yet been added will generally fail. New hosts
   are added with the enforcing flag set, as they are unable to hand out new
   state until their own grace period has been lifted.
  </para>
  <para>
   <emphasis role="strong">start</emphasis>
  </para>
  <para>
   Start a new grace period. This will begin a new grace period in the cluster
   if one is not already active and set the record for the listed cluster hosts
   as both needing a grace period and enforcing the grace period. If a grace
   period is already active, then this is equivalent to
   <emphasis role="strong">join</emphasis>.
  </para>
  <para>
   <emphasis role="strong">join</emphasis>
  </para>
  <para>
   Attempt to join an existing grace period. This works like
   <emphasis role="strong">start</emphasis>, but only if there is already an
   existing grace period in force.
  </para>
  <para>
   <emphasis role="strong">lift</emphasis>
  </para>
  <para>
   Attempt to lift the current grace period. This will clear the need grace
   flags for the listed hosts. If there are no more hosts in the cluster that
   require a grace period, then it will be fully lifted and the cluster will
   transition to normal operations.
  </para>
  <para>
   <emphasis role="strong">remove</emphasis>
  </para>
  <para>
   Remove one or more existing hosts from the cluster. This will remove the
   listed hosts from the grace database, possibly lifting the current grace
   period if there are no more hosts that need one.
  </para>
  <para>
   <emphasis role="strong">enforce</emphasis>
  </para>
  <para>
   Set the flag for the given hosts that indicates that they are currently
   enforcing the grace period; not allowing the acquisition of new state by
   clients.
  </para>
  <para>
   <emphasis role="strong">noenforce</emphasis>
  </para>
  <para>
   Clear the enforcing flag for the given hosts, meaning that those hosts are
   now allowing clients to acquire new state.
  </para>
  <para>
   <emphasis role="strong">member</emphasis>
  </para>
  <para>
   Test whether the given hosts are members of the cluster. Returns an error if
   any of the hosts are not present in the grace db omap.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_flags">
  <title>FLAGS</title>
  <para>
   When the <emphasis role="strong">dump</emphasis> command is issued,
   ganesha-rados-grace will display a list of all of the nodes in the grace
   database, and any flags they have set. The flags are as follows:
  </para>
  <para>
   <emphasis role="strong">E (Enforcing)</emphasis>
  </para>
  <para>
   The node is currently enforcing the grace period by rejecting requests from
   clients to acquire new state.
  </para>
  <para>
   <emphasis role="strong">N (Need Grace)</emphasis>
  </para>
  <para>
   The node currently requires a grace period. Generally, this means that the
   node has clients that need to perform recovery.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_nodeid_assignment">
  <title>NODEID ASSIGNMENT</title>
  <para>
   Each running ganesha daemon requires a
   <emphasis role="strong">nodeid</emphasis> string that is unique within the
   cluster. This can be any value as ganesha treats it as an opaque string. By
   default, the ganesha daemon will use the hostname of the node where it is
   running.
  </para>
  <para>
   This may not be suitable when running under certain HA clustering
   infrastructure, so it's generally recommended to manually assign nodeid
   values to the hosts in the <emphasis role="strong">RADOS_KV</emphasis>
   config block of <emphasis role="strong">ganesha.conf</emphasis>.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_ganesha_configuration">
  <title>GANESHA CONFIGURATION</title>
  <para>
   The ganesha daemon will need to be configured with the RecoveryBackend set
   to <emphasis role="strong">rados_cluster</emphasis>. If you use a
   non-default pool, namespace or oid, nodeid then those values will need to be
   set accordingly in the <emphasis role="strong">RADOS_KV</emphasis> config
   block as well.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_starting_a_new_cluster">
  <title>STARTING A NEW CLUSTER</title>
  <para>
   First, add the given cluster nodes to the grace database. Assuming that the
   nodes in our cluster will have nodeids ganesha-1 through ganesha-3:
  </para>
  <para>
   <emphasis role="strong">ganesha-rados-grace add ganesha-1 ganesha-2
   ganesha-3</emphasis>
  </para>
  <para>
   Once this is done, you can start the daemons on each host and they will
   coordinate to start and lift the grace periods as-needed.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_adding_nodes_to_a_running_cluster">
  <title>ADDING NODES TO A RUNNING CLUSTER</title>
  <para>
   After this point, new nodes can then be added to the cluster as needed using
   the <emphasis role="strong">add</emphasis> command:
  </para>
  <para>
   <emphasis role="strong">ganesha-rados-grace add ganesha-4</emphasis>
  </para>
  <para>
   After the node has been added, ganesha.nfsd can then be started. It will
   then request a new grace period as-needed.
  </para>
 </sect2>

 <sect2 xml:id="man_ganesha_rados_grace_removing_a_node_from_the_cluster">
  <title>REMOVING A NODE FROM THE CLUSTER</title>
  <para>
   To remove a node from the cluster, first unmount any clients that have that
   node mounted (possibly moving them to other servers). Then execute the
   remove command with the nodeids to be removed from the cluster. For example:
  </para>
  <para>
   <emphasis role="strong">ganesha-rados-grace remove ganesha-4</emphasis>
  </para>
  <para>
   This will remove the ganesha-4's record from the database, and possibly lift
   the current grace period if one is active and it was the last one to need
   it.
  </para>
 </sect2>
</sect1>
