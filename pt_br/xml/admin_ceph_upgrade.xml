<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Fazendo upgrade de versões anteriores</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editando</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>yes (sim)</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Este capítulo apresenta as etapas para fazer upgrade do SUSE Enterprise Storage 5.5 para a versão 6. Observe que a versão 5.5 é basicamente a versão 5 com todos os patches mais recentes aplicados.
 </para>
 <note>
  <title>Upgrade de Versões Mais Antigas Não Suportado</title>
  <para>
   O upgrade de versões do SUSE Enterprise Storage mais antigas do que a 5.5 não é suportado. Você precisa primeiro fazer upgrade para a versão mais recente do SUSE Enterprise Storage 5.5 e, em seguida, seguir as etapas neste capítulo.
  </para>
 </note>
 <sect1 xml:id="upgrade-consider-points">
  <title>Pontos de consideração antes do upgrade</title>

  <itemizedlist>
   <listitem>
    <para>
     <emphasis>Leia os detalhes da versão</emphasis>: onde você encontra mais informações sobre o que mudou desde a versão anterior do SUSE Enterprise Storage. Consulte os detalhes da versão para verificar se:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       seu hardware precisa de considerações especiais.
      </para>
     </listitem>
     <listitem>
      <para>
       qualquer pacote de software usado foi significativamente modificado.
      </para>
     </listitem>
     <listitem>
      <para>
       são necessárias precauções especiais para a instalação.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Os detalhes da versão também apresentam informações que não puderam ser incluídas a tempo no manual. Eles também incluem notas sobre problemas conhecidos.
    </para>
    <para>
     Após instalar o pacote <package>release-notes-ses</package>, encontre os detalhes da versão no diretório local <filename>/usr/share/doc/release-notes</filename> ou no site <link xlink:href="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se você fez upgrade da versão 4, verifique se o upgrade para a versão 5 foi concluído com êxito:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Verifique a existência do arquivo
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.import</screen>
      <para>
       Ele é criado pelo processo de importação durante o upgrade do SES 4 para 5. A opção <option>configuration_init: default-import</option> também está definida no arquivo
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <para>
       Se <option>configuration_init</option> ainda está definido como <option>default-import</option>, o cluster usa <filename>ceph.conf.import</filename> como arquivo de configuração, e não o <filename>ceph.conf</filename> padrão do DeepSea, que é compilado dos arquivos em
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Portanto, você precisa inspecionar se há qualquer configuração personalizada em <filename>ceph.conf.import</filename> e, possivelmente, mover a configuração para um dos arquivos em
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Em seguida, remova a linha <option>configuration_init: default-import</option> de
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <warning>
       <title>Configuração Padrão do DeepSea</title>
       <para>
        Se você <emphasis role="bold">não</emphasis> fundir a configuração do <filename>ceph.conf.import</filename> e remover a opção <option>configuration_init: default-import</option>, nenhuma configuração padrão que fizer parte do DeepSea (armazenada em <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>) será aplicada ao cluster.
       </para>
      </warning>
     </listitem>
     <listitem>
      <para>
       Verifique se o cluster usa o novo tipo de compartimento de memória “straw2”:
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep straw
</screen>
     </listitem>
     <listitem>
      <para>
       Verifique se o perfil “jewel” do Ceph foi usado:
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep profile
</screen>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Caso os clientes RBD antigos do kernel (mais antigos do que o SUSE Linux Enterprise Server 12 SP3) sejam usados, consulte o <xref linkend="rbd-old-clients-map"/>. Recomendamos fazer upgrade dos clientes RBD antigos do kernel, se possível.
    </para>
   </listitem>
   <listitem>
    <para>
     Se o openATTIC estiver localizado no Nó de Admin, ele estará disponível após o upgrade do nó. O novo Ceph Dashboard não estará disponível até você implantá-lo usando o DeepSea.
    </para>
   </listitem>
   <listitem>
    <para>
     O upgrade do cluster pode levar algum tempo, aproximadamente o tempo necessário para fazer upgrade de uma máquina multiplicado pelo número de nós do cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     Não é possível fazer upgrade de um único nó durante a execução da versão anterior do SUSE Linux Enterprise Server, mas ele precisa ser reinicializado no instalador da nova versão. Portanto, os serviços que o nó fornece estarão indisponíveis por algum tempo. Os principais serviços do cluster ainda estarão disponíveis. Por exemplo, se um MON estiver inativo durante o upgrade, ainda haverá pelo menos dois MONs ativos. Os serviços de instância única estarão indisponíveis. Por exemplo, um único iSCSI Gateway.
    </para>
   </listitem>
   <listitem>
    <para>
     Alguns tipos de daemons dependem de outros. Por exemplo, os Ceph Object Gateways dependem dos daemons Ceph MON e OSD. Recomendamos o upgrade nesta ordem:
    </para>
    <orderedlist spacing="normal">
     <listitem>
      <para>
       Nó de Admin
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitors/Ceph Managers
      </para>
     </listitem>
     <listitem>
      <para>
       Servidores de Metadados
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSDs
      </para>
     </listitem>
     <listitem>
      <para>
       Object Gateways
      </para>
     </listitem>
     <listitem>
      <para>
       iSCSI Gateways
      </para>
     </listitem>
     <listitem>
      <para>
       NFS Ganesha
      </para>
     </listitem>
     <listitem>
      <para>
       Gateways do Samba
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Se você usou o AppArmor no modo "complain" ou "enforce", precisa definir uma variável do pillar Salt antes do upgrade. Como o SUSE Linux Enterprise Server 15 SP1 está incluído com o AppArmor por padrão, o gerenciamento do AppArmor foi integrado à fase 0 do DeepSea. O comportamento padrão no SUSE Enterprise Storage 6 é remover o AppArmor e os perfis relacionados. Para manter o comportamento configurado no SUSE Enterprise Storage 5.5, verifique se uma das seguintes linhas está presente no arquivo <filename>/srv/pillar/ceph/stack/global.yml</filename> antes de iniciar o upgrade:
    </para>
<screen>
apparmor_init: default-enforce
</screen>
    <para>
     ou
    </para>
<screen>
apparmor_init: default-complain
</screen>
   </listitem>
   <listitem>
    <para>
     A partir do SUSE Enterprise Storage 6, os nomes de MDS que começam com um dígito não são mais permitidos, e os daemons MDS se recusarão a ser iniciados. Você pode verificar se seus daemons têm esses nomes executando o comando <command>ceph fs status</command> ou reiniciando um MDS e verificando a seguinte mensagem nos registros dele:
    </para>
<screen>
deprecation warning: MDS id 'mds.1mon1' is invalid and will be forbidden in
a future version.  MDS names may not start with a numeric digit.
</screen>
    <para>
     Se aparecer a mensagem acima, os nomes de MDS precisarão ser migrados antes de tentar fazer upgrade para o SUSE Enterprise Storage 6. O DeepSea inclui uma orquestração para automatizar esse tipo de migração. Os nomes de MDS que começam com um dígito receberão o prefixo “mds”.:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.mds.migrate-numerical-names
</screen>
    <tip>
     <title>Configuração Personalizada Vinculada a Nomes MDS</title>
     <para>
      Se você tem configurações vinculadas a nomes MDS e seus daemons MDS têm nomes que começam com um dígito, verifique se as configurações também se aplicam aos novos nomes (com o prefixo “mds”). Considere a seguinte seção de exemplo no arquivo <filename>/etc/ceph/ceph.conf</filename>:
     </para>
<screen>
[mds.123-my-mds] # config setting specific to MDS name with a name starting with a digit
mds cache memory limit = 1073741824
mds standby for name = 456-another-mds
</screen>
     <para>
      O orquestrator <command>ceph.mds.migrate-numerical-names</command> mudará o nome do daemon MDS “123-my-mds” para “mds.123-my-mds”. Você precisa ajustar a configuração para refletir o novo nome:
     </para>
<screen>
[mds.mds,123-my-mds] # config setting specific to MDS name with the new name
mds cache memory limit = 1073741824
mds standby for name = mds.456-another-mds
</screen>
    </tip>
    <para>
     Esse procedimento adicionará os daemons MDS com os novos nomes antes de remover os daemons MDS antigos. O número de daemons MDS será o dobro por um curto período. Os clientes poderão acessar o CephFS com uma breve pausa para failover. Portanto, planeje a migração para momentos em que você espera pouca ou nenhuma carga do CephFS.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-backup">
  <title>Fazendo backup de dados do cluster</title>

  <para>
   Embora a criação de backups da configuração e dos dados de um cluster não seja obrigatória, recomendamos enfaticamente o backup de arquivos de configuração e dados do cluster importantes. Consulte a <xref linkend="cha-deployment-backup"/> para obter mais detalhes.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-ntp">
  <title>Migrando do <systemitem class="daemon">ntpd</systemitem> para o <systemitem class="daemon">chronyd</systemitem></title>

  <para>
   O SUSE Linux Enterprise Server 15 SP1 não usa mais o <systemitem class="daemon">ntpd</systemitem> para sincronizar o horário local do host. Em vez disso, ele usa o <systemitem class="daemon">chronyd</systemitem>. Você precisa migrar o daemon de sincronização de horário em cada nó do cluster. Você pode migrar para o <systemitem>chronyd</systemitem> <emphasis role="bold">antes</emphasis> do cluster ou fazer upgrade do cluster e, <emphasis role="bold">depois disso</emphasis>, migrar para o <systemitem class="daemon">chronyd</systemitem>.
  </para>

  <procedure>
   <title>Migrar para o <systemitem class="daemon">chronyd</systemitem> <emphasis>antes</emphasis> do Upgrade do Cluster</title>
   <step>
    <para>
     Instale o pacote <package>chrony</package> :
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper install chrony</screen>
   </step>
   <step>
    <para>
     Edite o arquivo de configuração do <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> e adicione fontes de NTP da configuração atual do <systemitem class="daemon">ntpd</systemitem> ao <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>Mais Detalhes sobre a Configuração do <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Visite <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> para encontrar mais detalhes sobre como incluir fontes de horário na configuração do <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Desabilite e pare o serviço <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Inicie e habilite o serviço <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Verifique o status do chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
  </procedure>

  <procedure>
   <title>Migrar para o <systemitem class="daemon">chronyd</systemitem> <emphasis>após</emphasis> o Upgrade do Cluster</title>
   <step>
    <para>
     Durante o upgrade do cluster, adicione os seguintes repositórios de software:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Pool
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Updates
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Faça upgrade do cluster para a versão 6.
    </para>
   </step>
   <step>
    <para>
     Edite o arquivo de configuração do <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> e adicione fontes de NTP da configuração atual do <systemitem class="daemon">ntpd</systemitem> ao <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>Mais Detalhes sobre a Configuração do <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Visite <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> para encontrar mais detalhes sobre como incluir fontes de horário na configuração do <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Desabilite e pare o serviço <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Inicie e habilite o serviço <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Migre do <systemitem class="daemon">ntpd</systemitem> para o <systemitem class="daemon">chronyd</systemitem>.
    </para>
   </step>
   <step>
    <para>
     Verifique o status do chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
   <step>
    <para>
     Remova os repositórios de software legados que você adicionou para manter o <systemitem class="daemon">ntpd</systemitem> no sistema durante o processo de upgrade.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-prepare">
  <title>Corrigindo o cluster antes do upgrade</title>

  <para>
   Aplique os patches mais recentes a todos os nós do cluster antes do upgrade.
  </para>

  <sect2 xml:id="upgrade-prepare-repos">
   <title>Repositórios de software necessários</title>
   <para>
    Verifique se os repositórios necessários estão configurados em cada nó do cluster. Para listar todos os repositórios disponíveis, execute
   </para>
<screen>
<prompt>root@minion &gt; </prompt>zypper lr
</screen>
   <para>
    O SUSE Enterprise Storage 5.5 requer:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLES12-SP3-Installer-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Updates
     </para>
    </listitem>
   </itemizedlist>
   <para>
    O Gateway NFS/SMB no SLE-HA no SUSE Linux Enterprise Server 12 SP3 requer:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLE-HA12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLE-HA12-SP3-Updates
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-staging">
   <title>Sistemas de propagação em fases do repositório</title>
   <para>
    Se você estiver usando um dos sistemas de propagação em fases do repositório (SMT, RMT ou SUSE Manager), crie um novo nível de patch congelado para a versão atual e nova do SUSE Enterprise Storage.
   </para>
   <para>
    Mais informações podem ser encontradas na:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html"/>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/book_rmt.html"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/suse-manager-3/index.html"/>,
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-patch">
   <title>Corrigindo o cluster inteiro com os patches mais recentes</title>
   <procedure>
    <step>
     <para>
      Aplique os patches mais recentes do SUSE Enterprise Storage 5.5 e do SUSE Linux Enterprise Server 12 SP3 a cada nó do cluster do Ceph. Verifique se os repositórios de software corretos estão conectados a cada nó do cluster (consulte a <xref linkend="upgrade-prepare-repos"/>) e execute a fase 0 do DeepSea:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    </step>
    <step>
     <para>
      Após a conclusão da fase 0, verifique se o status de cada nó do cluster inclui “HEALTH_OK”. Se não incluir, resolva o problema antes das possíveis reinicializações nas próximas etapas.
     </para>
    </step>
    <step>
     <para>
      Execute o <command>zypper ps</command> para verificar se há processos que possam ser executados com bibliotecas ou binários desatualizados e, se houver, faça a reinicialização.
     </para>
    </step>
    <step>
     <para>
      Verifique se o kernel em execução é o mais recente disponível e, se não for, faça a reinicialização. Verifique as saídas dos seguintes comandos:
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>uname -a
<prompt>cephadm@adm &gt; </prompt>rpm -qa kernel-default
</screen>
    </step>
    <step>
     <para>
      Verifique se o pacote <package>ceph</package> é da versão 12.2.12 ou mais recente. Verifique se o pacote <package>deepsea</package> é da versão 0.8.9 ou mais recente.
     </para>
    </step>
    <step>
     <para>
      Se você já usou qualquer uma das configurações de <option>bluestore_cache</option>, elas não estão mais em vigor a partir do <package>ceph</package>
      versão 12.2.10. A nova configuração <option>bluestore_cache_autotune</option> que, por padrão, está definida como “true”, desabilita o dimensionamento manual do cache. Para ativar o comportamento antigo, você precisa definir <option>bluestore_cache_autotune=false</option>. Consulte o <xref linkend="config-auto-cache-sizing"/> para obter os detalhes.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-verify-current">
  <title>Verificando o ambiente atual</title>

  <itemizedlist>
   <listitem>
    <para>
     Se o sistema tiver problemas óbvios, corrija-os antes de iniciar o upgrade. O upgrade nunca corrige problemas existentes do sistema.
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique o desempenho do cluster. Você pode usar comandos, como <command>rados bench</command>, <command>ceph tell osd.* bench</command> ou <command>iperf3</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique o acesso aos gateways (como iSCSI Gateway ou Object Gateway) e ao Dispositivo de Blocos RADOS.
    </para>
   </listitem>
   <listitem>
    <para>
     Registre partes específicas da configuração do sistema, como configuração de rede, particionamento ou detalhes da instalação.
    </para>
   </listitem>
   <listitem>
    <para>
     Use o <command>supportconfig</command> para coletar informações importantes do sistema e grave-as fora dos nós do cluster. Mais informações podem ser encontradas em <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_admsupport_supportconfig.html"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique se há espaço livre suficiente no disco em cada nó do cluster. Use o comando <command>df -h</command> para verificar o espaço livre no disco. Quando necessário, libere espaço no disco removendo arquivos/diretórios desnecessários ou removendo instantâneos obsoletos do OS. Se não houver espaço livre suficiente no disco, não continue com o upgrade até liberar espaço suficiente.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-verify-state">
  <title>Verificando o estado do cluster</title>

  <itemizedlist>
   <listitem>
    <para>
     Use o comando <command>cluster health</command> para verificar a saúde do cluster antes de iniciar o procedimento de upgrade. Não inicie o upgrade, exceto quando cada nó do cluster relatar “HEALTH_OK”.
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique se todos os serviços estão em execução:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Master Salt e daemons do master Salt.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons do Ceph Monitor e do Ceph Manager.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons do Servidor de Metadados.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons do Ceph OSD.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons do Object Gateway.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons do iSCSI Gateway.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>

  <para>
   Os seguintes comandos apresentam os detalhes do estado do cluster e a configuração específica:
  </para>

  <variablelist>
   <varlistentry>
    <term><command>ceph -s</command></term>
    <listitem>
     <para>
      Imprime um breve resumo da saúde do cluster do Ceph, dos serviços em execução, do uso de dados e das estatísticas de E/S. Verifique se ele relata “HEALTH_OK” antes de iniciar o upgrade.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph health detail</command></term>
    <listitem>
     <para>
      Imprime os detalhes se a saúde do cluster do Ceph não estiver OK.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph versions</command></term>
    <listitem>
     <para>
      Imprime as versões dos daemons do Ceph em execução.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph df</command></term>
    <listitem>
     <para>
      Imprime o espaço total e livre do disco no cluster. Não inicie o upgrade se o espaço livre no disco do cluster for inferior a 25% do espaço total no disco.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>salt '*' cephprocesses.check results=true</command></term>
    <listitem>
     <para>
      Imprime os processos em execução do Ceph e os respectivos PIDs classificados por minions Salt.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph osd dump | grep ^flags</command></term>
    <listitem>
     <para>
      Verifique se os flags "recovery_deletes" e "purged_snapdirs” estão presentes. Se não estiverem, você poderá forçar uma depuração de todos os grupos de posicionamento executando o comando a seguir. Saiba que essa depuração forçada pode prejudicar o desempenho dos clientes Ceph.
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump pgs_brief | cut -d " " -f 1 | xargs -n1 ceph pg scrub
</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1>
  <title>Fazendo upgrade offline dos clusters CTDB</title>

  <para>
   O CTDB oferece um banco de dados em cluster usado pelos Gateways do Samba. O protocolo CTDB é muito simples e não suporta clusters de nós que se comunicam com diferentes versões de protocolo. Portanto, os nós do CTDB precisam ser colocados offline antes de realizar um upgrade.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-one-node">
  <title>Fazendo upgrade por nó: procedimento básico</title>

  <para>
   Para garantir que os principais serviços do cluster fiquem disponíveis durante o upgrade, você precisa fazer upgrade dos nós do cluster um por um, em sequência. Há duas maneiras de executar o upgrade de um nó: usando o <emphasis>DVD do instalador</emphasis> ou o <emphasis>sistema de migração de distribuição</emphasis>.
  </para>

  <para>
   Após o upgrade de cada nó, recomendamos executar o <command>rpmconfigcheck</command> para verificar se há arquivos de configuração atualizados que foram editados localmente. Se o comando retornar uma lista de nomes de arquivo com um sufixo <filename>.rpmnew</filename>, <filename>.rpmorig</filename> ou <filename>.rpmsave</filename>, compare esses arquivos com os arquivos de configuração atuais para garantir que nenhuma mudança local tenha sido perdida. Se necessário, atualize os arquivos afetados. Para obter mais informações sobre como trabalhar com arquivos <filename>.rpmnew</filename>, <filename>.rpmorig</filename> e <filename>.rpmsave</filename>, consulte <link xlink:href="https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#sec-rpm-packages-manage"/>.
  </para>

  <tip>
   <title>Pacotes Órfãos</title>
   <para>
    Após o upgrade de um nó, vários pacotes terão o estado “órfão” sem um repositório pai. Isso acontece porque os pacotes python3 relacionados não tornam os pacotes python2 obsoletos.
   </para>
   <para>
    Há mais informações sobre como listar pacotes órfãos disponíveis no site <link xlink:href="https://www.suse.com/documentation/sles-15/book_sle_admin/data/sec_zypper.html#sec_zypper_softup_orphaned"/>.
   </para>
  </tip>

  <sect2 xml:id="upgrade-one-node-manual">
   <title>Fazendo upgrade manual do nó por meio do DVD do instalador</title>
   <procedure>
    <step>
     <para>
      Reinicialize o nó usando o DVD/imagem do instalador do SUSE Linux Enterprise Server 15 SP1.
     </para>
    </step>
    <step>
     <para>
      Selecione <guimenu>Upgrade</guimenu> no menu de inicialização.
     </para>
    </step>
    <step>
     <para>
      Na tela <guimenu>Selecionar o Destino da Migração</guimenu>, verifique se “SUSE Linux Enterprise Server 15 SP1” está selecionado e ative a caixa de seleção <guimenu>Ajustar Manualmente os Repositórios para Migração</guimenu>.
     </para>
     <figure>
      <title>Selecionar o Destino da Migração</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Selecione os seguintes módulos para instalação:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SUSE Enterprise Storage 6 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Módulo Basesystem 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Módulo Desktop Applications 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Módulo Legacy 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Módulo Server Applications 15 SP1 x86_64
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Na tela <guimenu>Repositórios Usados Anteriormente</guimenu>, verifique se os repositórios corretos estão selecionados. Se o sistema não foi registrado com SCC/SMT, você precisa adicionar os repositórios manualmente.
     </para>
     <para>
      O SUSE Enterprise Storage 6 requer:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Basesystem15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE15-SP1-Installer-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Se você pretende migrar o <systemitem>ntpd</systemitem> para o <systemitem class="daemon">chronyd</systemitem> após a migração do SES (consulte a <xref linkend="upgrade-ntp"/>), inclua os seguintes repositórios:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      O Gateway NFS/SMB no SLE-HA no SUSE Linux Enterprise Server 15 SP1 requer:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Revise as <guimenu>Configurações de Instalação</guimenu> e inicie o procedimento de instalação clicando em <guimenu>Atualizar</guimenu>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-one-node-auto">
   <title>Fazendo upgrade do nó por meio do SUSE Distribution Migration System</title>
   <para>
    O <emphasis>Distribution Migration System</emphasis> (DMS) inclui um caminho de upgrade para um sistema SUSE Linux Enterprise instalado de uma versão principal para outra. O procedimento a seguir utiliza o DMS para fazer upgrade do SUSE Enterprise Storage 5.5 para a versão 6, incluindo a migração do SUSE Linux Enterprise Server 12 SP3 subjacente para o SUSE Linux Enterprise Server 15 SP1.
   </para>
   <para>
    Consulte <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/> para encontrar informações gerais e detalhadas sobre o DMS.
   </para>
   <procedure>
    <step>
     <para>
      Instale os pacotes RPM de migração. Eles ajustam o carregador de boot GRUB para acionar automaticamente o upgrade na próxima reinicialização. Instale os pacotes
      <package>SLES15-SES-Migration</package> e
      <package>suse-migration-sle15-activation</package> :
     </para>
<screen><prompt>root@minion &gt; </prompt>zypper install SLES15-SES-Migration suse-migration-sle15-activation</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        Se o nó do qual está sendo feito o upgrade <emphasis role="bold">foi</emphasis> registrado com um sistema de propagação em fases do repositório, como SCC, SMT, RMT ou SUSE Manager, crie o <filename>/etc/sle-migration-service.yml</filename> com o seguinte conteúdo:
       </para>
<screen>
use_zypper_migration: true
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
      </step>
      <step>
       <para>
        Se o nó do qual está sendo feito o upgrade <emphasis role="bold">não</emphasis> foi registrado com um sistema de propagação em fases do repositório, como SCC, SMT, RMT ou SUSE Manager, faça as seguintes mudanças:
       </para>
       <substeps>
        <step>
         <para>
          Crie o <filename>/etc/sle-migration-service.yml</filename> com o seguinte conteúdo:
         </para>
<screen>
use_zypper_migration: false
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
        </step>
        <step>
         <para>
          Desabilite ou remova os repositórios SLE 12 SP3 e SES 5 e adicione os repositórios SLE 15 SP1 e SES 6. Encontre a lista de repositórios relacionados na <xref linkend="upgrade-prepare-repos"/>.
         </para>
        </step>
       </substeps>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Reinicialize para iniciar o upgrade. Durante a execução do upgrade, você pode efetuar login no nó do qual foi feito o upgrade com <command>ssh</command> como usuário da migração utilizando a chave SSH existente do sistema host, conforme descrito em <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>. Para o SUSE Enterprise Storage, se você tiver acesso físico ou acesso direto do console à máquina, poderá efetuar login como <systemitem class="username">root</systemitem> no console do sistema usando a senha <literal>sesupgrade</literal>. O nó será reinicializado automaticamente após o upgrade.
     </para>
     <tip>
      <title>Falha no upgrade</title>
      <para>
       Se houver falha no upgrade, inspecione o <filename>/var/log/distro_migration.log</filename>. Corrija o problema, reinstale os pacotes RPM de migração e reinicialize o nó.
      </para>
     </tip>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-adm">
  <title>Fazendo upgrade do nó de admin</title>

  <itemizedlist>
   <listitem>
    <para>
     Os seguintes comandos ainda funcionarão, embora os minions Salt estejam executando versões antigas do Ceph e do Salt: <command>salt '*' test.ping</command> e <command>ceph status</command>
    </para>
   </listitem>
   <listitem>
    <para>
     Após o upgrade do Nó de Admin, o openATTIC não será mais instalado.
    </para>
   </listitem>
   <listitem>
    <para>
     Se o Nó de Admin hospedava o SMT, conclua a migração dele para o RMT (consulte <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/cha_rmt_migrate.html"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Status dos Nós do Cluster</title>
   <para>
    Após o upgrade do Nó de Admin, você poderá executar o comando <command>salt-run upgrade.status</command> para ver informações úteis sobre os nós do cluster. O comando lista as versões do Ceph e do OS de todos os nós e recomenda em que ordem fazer o upgrade de quaisquer nós que ainda executam versões antigas.
   </para>
<screen><prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
  ceph: ceph version 14.2.1-468-g994fd9e0cc (994fd9e0ccc50c2f3a55a3b7a3d4e0ba74786d50) nautilus (stable)
  os: SUSE Linux Enterprise Server 15 SP1

Nodes running these software versions:
  admin.ceph (assigned roles: master)
  mon2.ceph (assigned roles: admin, mon, mgr)

Nodes running older software versions must be upgraded in the following order:
   1: mon1.ceph (assigned roles: admin, mon, mgr)
   2: mon3.ceph (assigned roles: admin, mon, mgr)
   3: data1.ceph (assigned roles: storage)
[...]</screen>
  </tip>
 </sect1>
 <sect1 xml:id="upgrade-mons">
  <title>Fazendo upgrade dos nós do Ceph Monitor/Ceph Manager</title>

  <itemizedlist>
   <listitem>
    <para>
     Se o cluster <emphasis role="bold">não usa</emphasis> funções MDS, faça upgrade dos nós MON/MGR um por um.
    </para>
   </listitem>
   <listitem>
    <para>
     Se o cluster <emphasis role="bold">usa</emphasis> funções MDS, e as funções MON/MGR e MDS são colocalizadas, você precisa reduzir o cluster MDS e, em seguida, fazer upgrade dos nós colocalizados. Consulte a <xref linkend="upgrade-mds"/> para obter mais detalhes.
    </para>
   </listitem>
   <listitem>
    <para>
     Se o cluster <emphasis role="bold">usa</emphasis> funções MDS e elas são executadas em servidores <emphasis role="bold">dedicados</emphasis>, faça upgrade de todos os nós MON/MGR um por um, depois reduza e faça upgrade do cluster MDS. Consulte a <xref linkend="upgrade-mds"/> para obter mais detalhes.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>Upgrade do Ceph Monitor</title>
   <para>
    Em virtude de uma limitação no projeto do Ceph Monitor, depois que é feito upgrade de dois MONs para o SUSE Enterprise Storage 6 e um quorum é formado, o terceiro MON (enquanto ainda está no SUSE Enterprise Storage 5.5) não reingressará no cluster MON se ele for reiniciado por qualquer motivo, incluindo uma reinicialização de nó. Portanto, quando é feito upgrade de dois MONs, a melhor opção é fazer upgrade dos demais o quanto antes.
   </para>
  </note>

  <para>
   <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
  </para>
 </sect1>
 <sect1 xml:id="upgrade-mds">
  <title>Fazendo upgrade dos servidores de metadados</title>

  <para>
   Você precisa reduzir o cluster do Servidor de Metadados (MDS, Metadata Server). Como há recursos incompatíveis entre as versões 5.5 e 6 do SUSE Enterprise Storage, os daemons MDS mais antigos serão encerrados logo que virem um único MDS no nível do SES 6 ingressar no cluster. Portanto, é necessário reduzir o cluster MDS a um único MDS ativo (sem standbys) durante os upgrades dos nós MDS. Logo após o upgrade do segundo nó, você poderá estender o cluster MDS novamente.
  </para>

  <tip>
   <para>
    Em um cluster MDS com carga muito pesada, talvez seja necessário reduzir a carga (por exemplo, parando os clientes) para que um único MDS ativo seja capaz de processar a carga de trabalho.
   </para>
  </tip>

  <procedure>
   <step>
    <para>
     Observe o valor atual da opção <option>max_mds</option>:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs get cephfs | grep max_mds
</screen>
   </step>
   <step>
    <para>
     Reduza o cluster MDS se você tiver mais do que 1 daemon MDS ativo. Por exemplo, <option>max_mds</option> é &gt; 1. Para reduzir o cluster MDS, execute
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds 1
</screen>
    <para>
     em que <replaceable>FS_NAME</replaceable> é o nome da sua instância do CephFS (por padrão, “cephfs”).
    </para>
   </step>
   <step>
    <para>
     Encontre o nó que hospeda um dos daemons MDS de standby. Consulte a saída do comando <command>ceph fs status</command> e inicie o upgrade do cluster MDS nesse nó.
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs status
cephfs - 2 clients
======
+------+--------+--------+---------------+-------+-------+
| Rank | State  |  MDS   |    Activity   |  dns  |  inos |
+------+--------+--------+---------------+-------+-------+
|  0   | active | mon1-6 | Reqs:    0 /s |   13  |   16  |
+------+--------+--------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 2688k | 96.8G |
|   cephfs_data   |   data   |    0  | 96.8G |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
|    mon3-6   |
|    mon2-6   |
+-------------+
</screen>
    <para>
     Neste exemplo, é necessário iniciar o procedimento de upgrade no nó “mon3-6” ou “mon2-6”.
    </para>
   </step>
   <step>
    <para>
     Faça upgrade do nó com o daemon MDS de standby. Depois que o nó MDS do qual foi feito o upgrade for iniciado, os daemons MDS desatualizados serão encerrados automaticamente. Neste ponto, os clientes podem passar por um breve tempo de espera do serviço CephFS.
    </para>
    <para>
     <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Faça upgrade dos nós MDS restantes.
    </para>
   </step>
   <step>
    <para>
     Redefina <option>max_mds</option> para a configuração desejada:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds <replaceable>ACTIVE_MDS_COUNT</replaceable>
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-main-osd">
  <title>Fazendo upgrade dos Ceph OSDs</title>

  <para>
   Para cada nó de armazenamento, siga etas etapas:
  </para>

  <procedure>
   <step>
    <para>
     Identifique quais daemons OSD estão sendo executados em um nó específico:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd tree
</screen>
   </step>
   <step>
    <para>
     Defina o flag “noout” para cada daemon OSD no nó do qual está sendo feito o upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd add-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Por exemplo:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd add-noout osd.$i; done</screen>
    <para>
     Faça a verificação com:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     ou
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
      6 OSDs or CRUSH {nodes, device-classes} have {NOUP,NODOWN,NOIN,NOOUT} flags set</screen>
   </step>
   <step>
    <para>
     Crie arquivos <filename>/etc/ceph/osd/*.json</filename> para todos os OSDs existentes executando o seguinte comando no nó do qual será feito o upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan --force
</screen>
   </step>
   <step>
    <para>
     Faça upgrade do nó OSD. <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Ativar todos os OSDs encontrados no sistema:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>;ceph-volume simple activate --all
</screen>
    <tip>
     <title>Ativação das Partições de Dados Individualmente</title>
     <para>
      Para ativar partições de dados individualmente, você precisa encontrar o comando <command>ceph-volume</command> correto de cada partição para ativá-la. Substitua <replaceable>X1</replaceable> pela letra/número correto da partição:
     </para>
<screen>
 <prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/sd<replaceable>X1</replaceable>
</screen>
     <para>
      Por exemplo:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/vdb1
[...]
--&gt; OSD 8 got scanned and metadata persisted to file:
/etc/ceph/osd/8-d7bd2685-5b92-4074-8161-30d146cd0290.json
--&gt; To take over management of this scanned OSD, and disable ceph-disk
and udev, run:
--&gt;     ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
     <para>
      A última linha da saída contém o comando para ativar a partição:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
[...]
--&gt; All ceph-disk systemd units have been disabled to prevent OSDs
getting triggered by UDEV events
[...]
Running command: /bin/systemctl start ceph-osd@8
--&gt; Successfully activated OSD 8 with FSID
d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
    </tip>
   </step>
   <step>
    <para>
     Verifique se o nó OSD será iniciado apropriadamente após a reinicialização.
    </para>
   </step>
   <step>
    <para>
     Resolva a mensagem “Legacy BlueStore stats reporting detected on XX OSD(s)” (Relatório de estatísticas do BlueStore legado detectado em XX OSD(s)):
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
    <para>
     O aviso é normal ao fazer upgrade do Ceph para 14.2.2. Para desabilitá-lo, defina:
    </para>
<screen>bluestore_warn_on_legacy_statfs = false</screen>
    <para>
     A correção apopriada é executar o seguinte comando em todos os OSDs enquanto estão sendo interrompidos:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-XXX</screen>
    <para>
     Veja a seguir um script ajudante que executa o comando <command>ceph-bluestore-tool repair</command> para todos os OSDs no nó <replaceable>NODE_NAME</replaceable>:
    </para>
<screen>OSDNODE=<replaceable>OSD_NODE_NAME</replaceable>;\
 for OSD in $(ceph osd ls-tree $OSDNODE);\
 do echo "osd=" $OSD;\
 salt $OSDNODE cmd.run 'systemctl stop ceph-osd@$OSD';\
 salt $OSDNODE cmd.run 'ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-$OSD';\
 salt $OSDNODE cmd.run 'systemctl start ceph-osd@$OSD';\
 done</screen>
   </step>
   <step>
    <para>
     Cancele a definição do flag “noout” para cada daemon OSD no nó do qual foi feito o upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd rm-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Por exemplo:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd rm-noout osd.$i; done</screen>
    <para>
     Faça a verificação com:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     Nota:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
   </step>
   <step>
    <para>
     Verifique o status do cluster. Ele será semelhante à seguinte saída:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph status
cluster:
  id:     e0d53d64-6812-3dfe-8b72-fd454a6dcf12
  health: HEALTH_WARN
          3 monitors have not enabled msgr2

services:
  mon: 3 daemons, quorum mon1,mon2,mon3 (age 2h)
  mgr: mon2(active, since 22m), standbys: mon1, mon3
  osd: 30 osds: 30 up, 30 in

data:
  pools:   1 pools, 1024 pgs
  objects: 0 objects, 0 B
  usage:   31 GiB used, 566 GiB / 597 GiB avail
  pgs:     1024 active+clean
</screen>
   </step>
   <step>
    <para>
     Verifique se todos os nós OSD foram reinicializados e se os OSDs foram iniciados automaticamente após a reinicialização.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="filestore2bluestore">
  <title>Migração do OSD para BlueStore</title>

  <para>
   O OSD do BlueStore é um novo back end para os daemons OSD. Ele é a opção padrão desde o SUSE Enterprise Storage 5. Comparado com o FileStore, que armazena objetos como arquivos em um sistema de arquivos XFS, o BlueStore pode proporcionar melhor desempenho, porque armazena os objetos diretamente no dispositivo de blocos subjacente. O BlueStore também disponibiliza outros recursos, como compactação incorporada e sobregravações EC, que não estão disponíveis no FileStore.
  </para>

  <para>
   Especificamente no BlueStore, um OSD tem um dispositivo “wal” (Registro Write-Ahead) e um dispositivo “db” (banco de dados RocksDB). O banco de dados RocksDB armazena os metadados para um OSD do BlueStore. Por padrão, esses dois dispositivos residirão no mesmo dispositivo como um OSD, mas qualquer um deles pode ser inserido em uma mídia diferente, por exemplo, mais rápida.
  </para>

  <para>
   No SUSE Enterprise Storage 5, tanto o FileStore quanto o BlueStore são suportados, e os OSDs do FileStore e do BlueStore podem coexistir em um único cluster. Durante o procedimento de upgrade do SUSE Enterprise Storage, os OSDs do FileStore não são convertidos automaticamente em BlueStore. Os recursos específicos do BlueStore não estarão disponíveis nos OSDs que não foram migrados para o BlueStore.
  </para>

  <para>
   Antes da conversão em BlueStore, os OSDs precisam executar o SUSE Enterprise Storage 5. A conversão é um processo lento, pois todos os dados são regravados duas vezes. O processo de migração pode levar muito tempo para ser concluído, mas não há nenhuma interrupção do cluster, e todos os clientes podem continuar acessando o cluster durante esse período. No entanto, é comum uma redução no desempenho durante a migração. Isso é causado pela redistribuição e preenchimento de dados dos cluster.
  </para>

  <para>
   Siga o procedimento abaixo para migrar os OSDs do FileStore para o BlueStore:
  </para>

  <tip>
   <title>Desativar medidas de segurança</title>
   <para>
    Os comandos do Salt necessários para executar a migração são bloqueados por medidas de segurança. Para desativar essa medida preventiva, execute o seguinte comando:
   </para>
<screen>
 <prompt>root@master # </prompt>salt-run disengage.safety
 </screen>
   <para>
    Reconstrua os nós antes de continuar:
   </para>
<screen>
 <prompt>root@master # </prompt> salt-run rebuild.node <replaceable>TARGET</replaceable>
 </screen>
   <para>
    Você também pode reconstruir cada nó individualmente. Por exemplo:
   </para>
<screen>
<prompt>root@master # </prompt> salt-run rebuild.node data1.ceph
 </screen>
   <para>
    O <literal>rebuild.node</literal> sempre remove e recria todos os OSDs no nó.
   </para>
   <important>
    <para>
     Se um OSD não puder ser convertido, uma nova reconstrução destruirá os OSDs do BlueStore já convertidos. Em vez de uma nova reconstrução, você poderá executar:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.deploy <replaceable>TARGET</replaceable>
 </screen>
   </important>
  </tip>

  <para>
   Após a migração para o BlueStore, o total de objetos permanecerá o mesmo, e a utilização do disco será quase igual.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-appnodes-order">
  <title>Fazendo upgrade dos nós do aplicativo</title>

  <para>
   Faça upgrade dos nós do aplicativo na seguinte ordem:
  </para>

  <orderedlist>
   <listitem>
    <para>
     Object Gateways
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Se o front end dos Object Gateways for um balanceador de carga, um upgrade sequencial dos Object Gateways deverá ser possível sem interrupção.
      </para>
     </listitem>
     <listitem>
      <para>
       Confirme se os daemons do Object Gateway estão em execução após cada upgrade e faça o teste com o cliente S3/Swift.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     iSCSI Gateways
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Se os iniciadores iSCSI estiverem configurados com múltiplos caminhos, um upgrade sequencial dos iSCSI Gateways deverá ser possível sem interrupção.
      </para>
     </listitem>
     <listitem>
      <para>
       Confirme se o daemon <systemitem class="daemon">lrbd</systemitem> está em execução após cada upgrade e faça o teste com o iniciador.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     NFS Ganesha. <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
   <listitem>
    <para>
     Gateways do Samba. <emphasis role="bold">Siga o procedimento descrito na <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </orderedlist>
 </sect1>
 <sect1 xml:id="upgrade-main-policy">
  <title>Atualizando o <filename>policy.cfg</filename> e implantando o Ceph Dashboard por meio do DeepSea</title>

  <para>
   No Nó de Admin, edite o <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> e aplique as seguintes mudanças:
  </para>

  <important>
   <title>Sem Novos Serviços</title>
   <para>
    Durante o upgrade do cluster, não adicione novos serviços ao arquivo <filename>policy.cfg</filename>. Apenas mude a arquitetura do cluster após a conclusão do upgrade.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Remova <literal>role-openattic</literal>.
    </para>
   </step>
   <step>
    <para>
     Adicione <literal>role-prometheus</literal> e <literal>role-grafana</literal> ao nó com o Prometheus e o Grafana instalados (normalmente, o Nó de Admin).
    </para>
   </step>
   <step>
    <para>
     Agora, a função <literal>profile-<replaceable>NOME_PERFIL</replaceable></literal> será ignorada. Adicione a nova função correspondente: linha <literal>role-storage</literal>. Por exemplo, para o comando existente
    </para>
<screen>
profile-default/cluster/*.sls
</screen>
    <para>
     adicione
    </para>
<screen>
role-storage/cluster/*.sls
</screen>
   </step>
   <step>
    <para>
     Sincronize todos os módulos do Salt:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.sync_all</screen>
   </step>
   <step>
    <para>
     Execute as fases 1 e 2 do DeepSea para atualizar o pillar Salt:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Limpe o openATTIC:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.rescind.openattic
<prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.remove.openattic</screen>
   </step>
   <step>
    <para>
     Cancele a definição do grain “restart_igw” para impedir que a fase 0 reinicie o iSCSI Gateway, que ainda não está instalado:
    </para>
<screen>Salt mastersalt '*' grains.delkey restart_igw</screen>
   </step>
   <step>
    <para>
     Por fim, execute as fases de 0 a 4 do DeepSea:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <tip>
     <title>Erros de "subvolume ausente" durante a Fase 3</title>
     <para>
      A fase 3 do DeepSea pode falhar com um erro semelhante ao exibido a seguir:
     </para>
<screen>subvolume : ['/var/lib/ceph subvolume missing on 4510-2', \
'/var/lib/ceph subvolume missing on 4510-1', \
[...]
'See /srv/salt/ceph/subvolume/README.md']</screen>
     <para>
      Neste caso, você precisa editar o <filename role="bold">/srv/pillar/ceph/stack/global.yml</filename> e adicionar a seguinte linha:
     </para>
<screen>subvolume_init: disabled</screen>
     <para>
      Em seguida, atualize o pillar Salt e execute a fase 3 do DeepSea novamente:
     </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar
 <prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     <para>
      Após a conclusão bem-sucedida da fase 3 do DeepSea, o Ceph Dashboard será executado. Consulte o <xref linkend="ceph-dashboard"/> para obter uma visão geral detalhada dos recursos do Ceph Dashboard.
     </para>
     <para>
      Para listar os nós que executam o painel de controle, aplique o comando:
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph mgr services | grep dashboard</screen>
     <para>
      Para listar as credenciais de admin, execute:
     </para>
<screen><prompt>root@master # </prompt>salt-call grains.get dashboard_creds</screen>
    </tip>
   </step>
   <step>
    <para>
     Reinicie sequencialmente os serviços do Object Gateway para usar o servidor Web “beast” em vez do “civetweb” desatualizado:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.restart.rgw.force</screen>
   </step>
   <step>
    <para>
     Antes de continuar, recomendamos enfaticamente habilitar o módulo de telemetria do Ceph. Para obter mais informações e instruções, consulte o <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-drive-groups">
  <title>Migrando de implantações com base no perfil para DriveGroups</title>

  <para>
   No SUSE Enterprise Storage 5.5, o DeepSea ofereceu os chamados “perfis” para descrever o layout dos OSDs. A partir do SUSE Enterprise Storage 6, adotamos uma abordagem diferente denominada <emphasis>DriveGroups</emphasis> (encontre mais detalhes na <xref linkend="ds-drive-groups"/>).
  </para>

  <note>
   <para>
    A migração para a nova abordagem não é obrigatória de imediato. Operações destrutivas, como <command>salt-run osd.remove</command>, <command>salt-run osd.replace</command> ou <command>salt-run osd.purge</command>, ainda estão disponíveis. No entanto, a adição de novos OSDs exigirá que você execute uma ação.
   </para>
  </note>

  <para>
   Devido à abordagem diferente dessas implementações, não oferecemos um caminho de migração automatizado. No entanto, oferecemos uma variedade de ferramentas, executores Salt, para tornar a migração o mais simples possível.
  </para>

  <sect2>
   <title>Analisando o layout atual</title>
   <para>
    Para ver informações sobre os OSDs implantados atualmente, use o seguinte comando:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.discover
</screen>
   <para>
    Se preferir, você poderá inspecionar o conteúdo dos arquivos nos diretórios <filename>/srv/pillar/ceph/proposals/profile-*/</filename>. Eles têm uma estrutura semelhante à seguinte:
   </para>
<screen>
ceph:
  storage:
    osds:
      /dev/disk/by-id/scsi-drive_name: format: bluestore
      /dev/disk/by-id/scsi-drive_name2: format: bluestore
     </screen>
  </sect2>

  <sect2>
   <title>Criando DriveGroups que correspondem ao layout atual</title>
   <para>
    Consulte a <xref linkend="ds-drive-groups-specs"/> para obter mais detalhes sobre a especificação de DriveGroups.
   </para>
   <para>
    A diferença entre uma implantação nova e um cenário de upgrade é que as unidades que serão migradas já são “usadas”. Como
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list
</screen>
   <para>
    procura apenas discos não usados, aplique o comando
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list include_unavailable=True
</screen>
   <para>
    Ajuste os DriveGroups até corresponder à sua configuração atual. Para uma representação mais visual do que acontecerá, execute o comando a seguir. Observe que ele não terá saída se não houver discos livres:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report bypass_pillar=True
</screen>
   <para>
    Se você verificou que os DriveGroups estão configurados apropriadamente e deseja aplicar a nova abordagem, remova os arquivos do diretório <filename>/srv/pillar/ceph/proposals/profile-<replaceable>NOME_PERFIL</replaceable>/</filename>, remova as linhas <literal>profile-<replaceable>NOME_PERFIL</replaceable>/cluster/*.sls</literal> correspondentes do arquivo <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> e execute a fase 2 do DeepSea para atualizar o pillar Salt.
   </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
</screen>
   <para>
    Execute os seguintes comandos para verificar o resultado:
   </para>
<screen>
<prompt>root@master # </prompt>salt target_node pillar.get ceph:storage
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   <warning>
    <title>Configuração Incorreta dos DriveGroups</title>
    <para>
     Se os DriveGroups não estiverem configurados apropriadamente e houver discos sobressalentes na configuração, eles serão implantados da maneira que você os especificou. Recomendamos executar o comando:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   </warning>
  </sect2>

  <sect2 xml:id="upgrade-osd-deployment">
   <title>Implantando um OSD</title>
   <para>
    Para casos simples, como OSDs independentes, a migração acontecerá com o tempo. Sempre que você remover ou substituir um OSD do cluster, ele será substituído por um novo OSD baseado em LVM.
   </para>
   <tip>
    <title>Migrar para o Formato LVM</title>
    <para>
     Sempre que um único OSD "legado" precisar ser substituído em um nó, todos os OSDs que compartilham dispositivos com ele deverão ser migrados para o formato baseado em LVM.
    </para>
    <para>
     Para totalidade, considere a migração dos OSDs em todo o nó.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Configurações mais complexas</title>
   <para>
    Se você tem uma configuração mais sofisticada do que apenas OSDs independentes (por exemplo, WAL/BDs dedicados ou OSDs criptografados), a migração apenas pode acontecer quando todos os OSDs atribuídos a esse dispositivo WAL/BD são removidos. Isso ocorre porque o comando <command>ceph-volume</command> cria os Volumes Lógicos nos discos antes da implantação. Esse comportamento impede que o usuário misture implantações baseadas na partição com implantações baseadas em LV. Nesses casos, o melhor é remover manualmente todos os OSDs atribuídos a um dispositivo WAL/BD e reimplantá-los adotando a abordagem DriveGroups.
   </para>
  </sect2>
 </sect1>
</chapter>
