<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage-troubleshooting">
 <title>Solução de problemas</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sim</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Este capítulo descreve vários problemas que você pode ter ao operar um cluster do Ceph.
 </para>
 <sect1 xml:id="storage-bp-report-bug">
  <title>Relatando problemas de software</title>

  <para>
   Se você tiver algum problema durante a execução do SUSE Enterprise Storage 6 relacionado a alguns dos seus componentes, como Ceph ou Object Gateway, relate-o ao Suporte Técnico da SUSE. A forma recomendada é pelo utilitário <command>supportconfig</command>.
  </para>

  <tip>
   <para>
    Como o <command>supportconfig</command> é um software modular, verifique se o pacote <systemitem>supportutils-plugin-ses</systemitem> está instalado.
   </para>
<screen><prompt>tux &gt; </prompt>rpm -q supportutils-plugin-ses</screen>
   <para>
    Se ele estiver ausente no servidor Ceph, instale-o com
   </para>
<screen><prompt>root # </prompt>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   Embora você possa usar o <command>supportconfig</command> na linha de comando, é recomendável usar o módulo do YaST relacionado. Há mais informações a respeito do <command>supportconfig</command> em <link xlink:href="https://www.suse.com/documentation/sles-15/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-cluster-mntc-rados-striping">
  <title>Falha ao enviar objetos grandes pelo <command>rados</command> com OSD completo</title>

  <para>
   O <command>rados</command> é um utilitário de linha de comando que gerencia o armazenamento de objeto RADOS. Para obter mais informações, consulte <command>man 8 rados</command>.
  </para>

  <para>
   Se você enviar um objeto grande para um cluster do Ceph com o utilitário <command>rados</command>, como
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>rados -p mypool put myobject /file/to/send</screen>

  <para>
   ele poderá preencher todo o espaço do OSD relacionado e causar sérios problemas no desempenho do cluster.
  </para>
 </sect1>
 <sect1 xml:id="ceph-xfs-corruption">
  <title>Sistema de arquivos XFS corrompido</title>

  <para>
   Em raras circunstâncias, como bug de kernel ou hardware defeituoso/mal configurado, o sistema de arquivos adjacente (XFS) no qual um OSD armazena os dados pode ser danificado e incapaz de ser montado.
  </para>

  <para>
   Se você tem certeza de que não há nenhum problema com o hardware e o sistema está configurado apropriadamente, emita um bug no subsistema XFS do kernel do SUSE Linux Enterprise Server e marque o OSD específico como inativo:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd down <replaceable>OSD_ID</replaceable></screen>

  <warning>
   <title>Não formatar ou, de alguma forma, modificar o dispositivo danificado</title>
   <para>
    Mesmo que pareça plausível usar o <command>xfs_repair</command> para corrigir o problema no sistema de arquivos, não o utilize, pois o comando modifica o sistema de arquivos. O OSD pode ser iniciado, mas seu funcionamento talvez seja afetado.
   </para>
  </warning>

  <para>
   Agora, limpe (zap) o disco subjacente e recrie o OSD executando:
  </para>

<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm zap --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm prepare --bluestore --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-recover-toomanypgs">
  <title>Mensagem de status “Too Many PGs per OSD”</title>

  <para>
   Se você receber uma mensagem <literal>Too Many PGs per OSD</literal> após executar <command>ceph status</command>, isso significa que o valor <option>mon_pg_warn_max_per_osd</option> (por padrão, 300) foi excedido. Esse valor é comparado ao número proporcional de PGs por OSD. Isso significa que a configuração do cluster não é a ideal.
  </para>

  <para>
   O número de PGs não pode ser reduzido depois que o pool é criado. Os pools que ainda não contêm dados podem ser apagados com segurança e, em seguida, recriados com um número menor de PGs. Para os pools que já contêm dados, a única solução é adicionar OSDs ao cluster para que a proporção de PGs por OSD seja reduzida.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-stuckinactive">
  <title>Mensagem de status “<emphasis>nn</emphasis> pg stuck inactive”</title>

  <para>
   Se você receber uma mensagem de status <literal>stuck inactive</literal> após executar <command>ceph status</command>, isso significa que o Ceph não sabe onde replicar os dados armazenados para atender às regras de replicação. Isso pode ocorrer logo após a configuração inicial do Ceph e é autocorrigido. Em outros casos, isso pode exigir uma interação manual, como recuperar um OSD com defeito ou adicionar um novo OSD ao cluster. Em casos muito raros, a redução do nível de replicação pode ajudar.
  </para>

  <para>
   Se os grupos de posicionamento estiverem travados permanentemente, será necessário verificar a saída de <command>ceph osd tree</command>. A saída deve ter uma estrutura da árvore, parecida com o exemplo na <xref linkend="storage-bp-recover-osddown"/>.
  </para>

  <para>
   Se a saída de <command>ceph osd tree</command> for bem simples como no exemplo a seguir
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   Você deverá verificar se o mapa CRUSH relacionado tem uma estrutura da árvore. Se ele também for simples, ou sem hosts como no exemplo acima, isso poderá significar que a resolução de nome de host não está funcionando corretamente no cluster.
  </para>

  <para>
   Se a hierarquia estiver incorreta (por exemplo, a raiz contém hosts, mas os OSDs estão no nível superior e não foram atribuídos a hosts), você precisará mover os OSDs para o local correto na hierarquia. Isso pode ser feito usando os comandos <command>ceph osd crush move</command> e/ou <command>ceph osd crush set</command>. Para obter mais detalhes, consulte a <xref linkend="op-crush"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osdweight">
  <title>Peso do OSD é 0</title>

  <para>
   Ao ser iniciado, um peso é atribuído ao OSD. Quanto maior o peso, maior a chance de o cluster gravar dados no OSD. O peso é especificado em um Mapa CRUSH do cluster ou calculado pelo script de inicialização dos OSDs.
  </para>

  <para>
   Em alguns casos, o valor calculado do peso dos OSDs pode ser arredondado para zero. Isso significa que o OSD não está programado para armazenar dados, e não há dados gravados nele. O motivo mais comum é que o disco é muito pequeno (menor do que 15 GB) e deve ser substituído por um maior.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osddown">
  <title>OSD está inativo</title>

  <para>
   O daemon OSD está em execução ou parado/inativo. Há 3 motivos gerais para um OSD inativo:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Falha no disco rígido.
    </para>
   </listitem>
   <listitem>
    <para>
     Falha no OSD.
    </para>
   </listitem>
   <listitem>
    <para>
     Falha no servidor.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Você pode ver o status detalhado dos OSDs executando
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   A listagem de exemplo mostra que o <literal>osd.2</literal> está inativo. Em seguida, você pode verificar se o disco onde está o OSD foi montado:
  </para>

<screen><prompt>root # </prompt>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   Você pode monitorar o motivo pelo qual o OSD está inativo inspecionando o arquivo de registro <filename>/var/log/ceph/ceph-osd.2.log</filename>. Após localizar e corrigir o problema que impossibilita a execução do OSD, inicie-o com
  </para>

<screen><prompt>root # </prompt>systemctl start ceph-osd@2.service</screen>

  <para>
   Lembre-se de substituir <literal>2</literal> pelo número real do seu OSD parado.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-slowosd">
  <title>Descobrindo OSDs lentos</title>

  <para>
   Ao ajustar o desempenho do cluster, é muito importante identificar armazenamento/OSDs lentos no cluster. O motivo é que, se os dados forem gravados no disco (mais) lento, toda a operação de gravação ficará lenta, pois ela sempre espera sua conclusão em todos os discos relacionados.
  </para>

  <para>
   Não é simples localizar o gargalo no armazenamento. Será preciso examinar cada OSD para descobrir os que estão atrasando o processo de gravação. Para fazer um benchmark em um único OSD, execute:
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> osd.<replaceable>OSD_ID_NUMBER</replaceable> bench</screen>

  <para>
   Por exemplo:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   Em seguida, você precisa executar esse comando em cada OSD e comparar o valor de <literal>bytes_per_sec</literal> para descobrir os OSDs (mais) lentos.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-clockskew">
  <title>Corrigindo avisos de diferença do relógio</title>

  <para>
   As informações de horário em todos os nós do cluster devem estar sincronizadas. Se o horário de um nó não estiver totalmente sincronizado, você poderá receber avisos de diferença do relógio ao verificar o estado do cluster.
  </para>

  <para>
   A sincronização de horário é gerenciada com o NTP (consulte <link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>). Defina cada nó para sincronizar o horário com um ou mais servidores NTP, de preferência com o mesmo grupo de servidores NTP. Se a diferença de horário ainda ocorrer em um nó, siga estas etapas para corrigi-la:
  </para>

<screen><prompt>root # </prompt>systemctl stop chronyd.service
<prompt>root # </prompt>systemctl stop ceph-mon.target
<prompt>root # </prompt>systemctl start chronyd.service
<prompt>root # </prompt>systemctl start ceph-mon.target</screen>

  <para>
   Em seguida, você pode verificar a diferença de horário com o comando <command>chronyc sourcestats</command>.
  </para>

  <para>
   Os relógios dos Ceph Monitors precisam estar sincronizados com no máximo 0,05 segundo entre eles. Consulte a <xref linkend="Cluster-Time-Setting"/> para obter mais informações.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-net-issues">
  <title>Cluster de baixo desempenho causado por problemas de rede</title>

  <para>
   Há outros motivos que podem prejudicar o desempenho do cluster. Um deles pode ser problemas de rede. Nesse caso, você pode observar que o cluster está atingindo o quorum, o OSD e os nós do monitor estão offline, a transferência de dados está levando muito tempo ou há muitas tentativas de reconexão.
  </para>

  <para>
   Para verificar se o desempenho do cluster está prejudicado por problemas de rede, consulte os arquivos de registro do Ceph no diretório <filename>/var/log/ceph</filename>.
  </para>

  <para>
   Para corrigir problemas de rede no cluster, observe atentamente os seguintes pontos:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Diagnóstico básico da rede. Tente o executor das ferramentas de diagnóstico do DeepSea <literal>net.ping</literal> para efetuar ping entre os nós do cluster para ver se uma interface pode acessar outra específica e o tempo médio de resposta. Qualquer tempo de resposta específico muito mais lento do que a média também será relatado. Por exemplo:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     Tente validar toda a interface com a habilitação de JumboFrame:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     Benchmark de desempenho de rede. Tente o executor de desempenho de rede do DeepSea <literal>net.iperf</literal> para testar a largura de banda de rede do nó interno. Em determinado nó do cluster, um número de processos <command>iperf</command> (conforme o número de núcleos de CPU) são iniciados como servidores. Os nós restantes do cluster serão usados como clientes para gerar tráfego de rede. A largura de banda acumulada de todos os processos <command>iperf</command> por nó será relatada. Isso deve refletir o throughput máximo de rede atingível em todos os nós do cluster. Por exemplo:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     Verifique as configurações de firewall nos nós do cluster. Certifique-se de que elas não bloqueiem as portas/protocolos necessários à operação do Ceph. Consulte a <xref linkend="storage-bp-net-firewall"/> para obter mais informações sobre as configurações de firewall.
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique se o hardware de rede, como placas de rede, cabos ou switches, está funcionando apropriadamente.
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Rede Separada</title>
   <para>
    Para garantir uma comunicação de rede rápida e segura entre os nós do cluster, configure uma rede separada usada exclusivamente pelos nós OSD e de monitor do cluster.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="trouble-jobcache">
  <title>Pouco espaço em <filename>/var</filename></title>

  <para>
   Por padrão, o master Salt grava o retorno de cada minion para cada tarefa no <emphasis>cache de tarefas</emphasis>. Em seguida, o cache pode ser usado para pesquisar resultados de tarefas anteriores. O diretório de cache padrão é <filename>/var/cache/salt/master/jobs/</filename>.
  </para>

  <para>
   Cada retorno de tarefa de cada minion é gravado em um único arquivo. Ao longo do tempo, esse diretório pode ficar muito grande, dependendo do número de tarefas publicadas e do valor da opção <option>keep_jobs</option> no arquivo <filename>/etc/salt/master</filename>. <option>keep_jobs</option> define o número de horas (24, por padrão) para manter as informações sobre as tarefas anteriores dos minions.
  </para>

<screen>keep_jobs: 24</screen>

  <important>
   <title>Não Definir <option>keep_jobs: 0</option></title>
   <para>
    Definir <option>keep_jobs</option> como “0” faz com que a limpeza do cache de tarefas <emphasis>nunca</emphasis> seja executada, o que pode resultar em uma partição cheia.
   </para>
  </important>

  <para>
   Para desabilitar o cache de tarefas, defina <option>job_cache</option> como “Falso”:
  </para>

<screen>job_cache: False</screen>

  <tip>
   <title>Restaurando a partição cheia devido ao cache de tarefas</title>
   <para>
    Quando a partição com arquivos de cache de tarefas ficar cheia por causa da configuração incorreta de <option>keep_jobs</option>, siga estas etapas para liberar espaço no disco e melhorar as configurações do cache de tarefas:
   </para>
   <procedure>
    <step>
     <para>
      Pare o serviço master Salt:
     </para>
<screen><prompt>root@master # </prompt>systemctl stop salt-master</screen>
    </step>
    <step>
     <para>
      Mude a configuração do master Salt relacionada ao cache de tarefas editando <filename>/etc/salt/master</filename>:
     </para>
<screen>job_cache: False
keep_jobs: 1</screen>
    </step>
    <step>
     <para>
      Limpe o cache de tarefas do master Salt:
     </para>
<screen><prompt>root # </prompt>rm -rfv /var/cache/salt/master/jobs/*</screen>
    </step>
    <step>
     <para>
      Inicie o serviço master Salt:
     </para>
<screen><prompt>root@master # </prompt>systemctl start salt-master</screen>
    </step>
   </procedure>
  </tip>
 </sect1>
</chapter>
