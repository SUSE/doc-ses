<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="containerized-kubernetes.xml" version="5.0" xml:id="cha-container-kubernetes">

 <title>SUSE Enterprise Storage 6 no cluster Kubernetes do SUSE CaaS Platform 4</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/master/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editando</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>yes (sim)</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <warning>
  <title>Technology Preview</title>
  <para>
   A execução do cluster do Ceph em containers no SUSE CaaS Platform é uma versão Technology Preview. Não faça a implantação em um cluster Kubernetes de produção.
  </para>
 </warning>
 <para>
  Este capítulo descreve como implantar o SUSE Enterprise Storage 6 em containers no cluster Kubernetes do SUSE CaaS Platform 4.
 </para>
 <sect1 xml:id="kube-consider">
  <title>Considerações</title>

  <para>
   Antes de começar a implantação, considere os seguintes pontos:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Para executar o Ceph no Kubernetes, o SUSE Enterprise Storage 6 usa um projeto de upstream denominado Rook (<link xlink:href="https://rook.io/"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     Dependendo da configuração, o Rook pode consumir <emphasis>todos</emphasis> os discos não usados em todos os nós em um cluster Kubernetes.
    </para>
   </listitem>
   <listitem>
    <para>
     A configuração requer containers com privilégios.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="kube-prereq">
  <title>Pré-requisitos</title>

  <para>
   Antes de começar a implantação, você precisa ter:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Um cluster do SUSE CaaS Platform 4 em execução.
    </para>
   </listitem>
   <listitem>
    <para>
     Nós do worker do SUSE CaaS Platform 4 com um número de discos extras anexados como armazenamento para o cluster do Ceph.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="kube-rook-manifests">
  <title>Obtendo declarações sobre o Rook</title>

  <para>
   O orquestrador Rook usa arquivos de configuração no formato YAML chamados de <emphasis>declarações</emphasis>. As declarações que você precisa estão incluídas no pacote RPM
   <package>rook-k8s-yaml</package>. Para instalá-lo, execute
  </para>

<screen><prompt>root # </prompt>zypper install rook-k8s-yaml</screen>
 </sect1>
 <sect1 xml:id="kube-install">
  <title>Instalação</title>

  <para>
   O Rook-Ceph inclui dois componentes importantes: o “operador”, que é executado pelo Kubernetes e permite a criação de clusters do Ceph, e o próprio “cluster” do Ceph, que é criado e parcialmente gerenciado pelo operador.
  </para>

  <sect2 xml:id="kube-configure">
   <title>Configuração</title>
   <sect3 xml:id="kube-configure-global">
    <title>Configuração global</title>
    <para>
     As declarações usadas nesta configuração instalam todos os componentes do Rook e do Ceph no namespace “rook-ceph”. Se você precisar modificá-lo, adapte todas as referências ao namespace nas declarações do Kubernetes de acordo.
    </para>
    <para>
     Dependendo dos recursos do Rook que você pretende usar, altere a configuração “Política de Segurança do Pod” no <filename>common.yaml</filename> para limitar os requisitos de segurança do Rook. Siga os comentários no arquivo de declarações.
    </para>
   </sect3>
   <sect3 xml:id="kube-config-operator">
    <title>Configuração do operador</title>
    <para>
     O <filename>operator.yaml</filename> de declarações configura o operador do Rook. Normalmente, não é necessário mudá-lo. Encontre mais informações seguindos os comentários no arquivo de declarações.
    </para>
   </sect3>
   <sect3 xml:id="kube-config-ceph">
    <title>Configuração do cluster do Ceph</title>
    <para>
     O <filename>cluster.yaml</filename> de declarações é responsável por configurar o cluster real do Ceph que será executado no Kubernetes. Encontre a descrição detalhada de todas as opções disponíveis na documentação do Rook de upstream em <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-cluster-crd.html"/>.
    </para>
    <para>
     Por padrão, o Rook está configurado para usar todos os nós que não foram afetados por <option>node-role.kubernetes.io/master:NoSchedule</option> e seguirá as configurações de posicionamento definidas (consulte <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-cluster-crd.html#placement-configuration-settings"/>). O exemplo a seguir desabilita esse comportamento e usa apenas os nós explicitamente listados na seção de nós:
    </para>
<screen>
storage:
  useAllNodes: false
  nodes:
    - name: caasp4-worker-0
    - name: caasp4-worker-1
    - name: caasp4-worker-2
</screen>
    <note>
     <para>
      Por padrão, o Rook está configurado para usar todos os discos livres e vazios em cada nó para uso como armazenamento do Ceph.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="kube-config-docs">
    <title>Documentação</title>
    <itemizedlist>
     <listitem>
      <para>
       A documentação de upstream do Rook-Ceph em <link xlink:href="https://rook.github.io/docs/rook/master/ceph-storage.html"/> contém informações mais detalhadas sobre como configurar implantações mais avançadas. Use-a como referência para entender os conceitos básicos do Rook-Ceph antes de fazer configurações mais avançadas.
      </para>
     </listitem>
     <listitem>
      <para>
       Encontre mais detalhes sobre o produto SUSE CaaS Platform em <link xlink:href="https://www.suse.com/documentation/suse-caasp"/>.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
  </sect2>

  <sect2 xml:id="kube-config-rook-operator">
   <title>Criando o operador do Rook</title>
   <para>
    Instale os componentes comuns do Rook-Ceph, as funções CSI e o operador do Rook-Ceph executando o seguinte comando no nó master do SUSE CaaS Platform:
   </para>
<screen><prompt>root # </prompt>kubectl apply -f common.yaml -f operator.yaml</screen>
   <para>
    O <filename>common.yaml</filename> criará o namespace “rook-ceph”, as Definições de Recursos Personalizados (CRDs, Custom Resource Definitions) do Ceph (consulte <link xlink:href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"/>) para que o Kubernetes reconheça os Objetos do Ceph (por exemplo, “CephCluster”), as funções RBAC e as Políticas de Segurança do Pod (consulte <link xlink:href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/"/>), que são necessárias para permitir que o Rook gerencie os recursos específicos do cluster.
   </para>
   <tip>
    <title>Uso do <option>hostNetwork</option> e do <option>hostPorts</option></title>
    <para>
     A permissão de uso do <option>hostNetwork</option> é necessária ao usar <option>hostNetwork: true</option> na Definição de Recursos Personalizados. A permissão de uso do <option>hostPorts</option> em <literal>PodSecurityPolicy</literal> também é necessária.
    </para>
   </tip>
   <para>
    Execute <command>kubectl get pods -n rook-ceph</command> no nó master do SUSE CaaS Platform para verificar a instalação. Por exemplo:
   </para>
<screen><prompt>root # </prompt>kubectl get pods -n rook-ceph
NAME                                     READY   STATUS      RESTARTS   AGE
rook-ceph-agent-57c9j                    1/1     Running     0          22h
rook-ceph-agent-b9j4x                    1/1     Running     0          22h
rook-ceph-operator-cf6fb96-lhbj7         1/1     Running     0          22h
rook-discover-mb8gv                      1/1     Running     0          22h
rook-discover-tztz4                      1/1     Running     0          22h</screen>
  </sect2>

  <sect2 xml:id="kube-create-ceph-cluster">
   <title>Criando o cluster do Ceph</title>
   <para>
    Após módificar o <filename>cluster.yaml</filename> de acordo com as suas necessidades, você poderá criar o cluster do Ceph. Execute o seguinte comando no nó master do SUSE CaaS Platform:
   </para>
<screen><prompt>root # </prompt>kubectl apply -f cluster.yaml</screen>
   <para>
    Observe o namespace “rook-ceph” para ver o cluster do Ceph que está sendo criado. Você verá o mesmo número de Ceph Monitors que foram configurados na declaração <filename>cluster.yaml</filename> (o padrão é 3), um Ceph Manager e a mesma quantidade de Ceph OSDs que você tem de discos livres.
   </para>
   <tip>
    <title>Pods OSD Temporários</title>
    <para>
     Ao inicializar o cluster do Ceph, você verá alguns pods com o nome <literal>rook-ceph-osd-prepare-<replaceable>NODE-NAME</replaceable></literal> executados durante um tempo e, em seguida, terminados com o status “Concluído”. Como o próprio nome indica, esses pods provisionam os OSDs do Ceph. Eles não são apagados para que você possa inspecionar os registros deles após o término. Por exemplo:
    </para>
<screen><prompt>root # </prompt>kubectl get pods --namespace rook-ceph
NAME                                         READY  STATUS     RESTARTS  AGE
rook-ceph-agent-57c9j                        1/1    Running    0         22h
rook-ceph-agent-b9j4x                        1/1    Running    0         22h
rook-ceph-mgr-a-6d48564b84-k7dft             1/1    Running    0         22h
rook-ceph-mon-a-cc44b479-5qvdb               1/1    Running    0         22h
rook-ceph-mon-b-6c6565ff48-gm9wz             1/1    Running    0         22h
rook-ceph-operator-cf6fb96-lhbj7             1/1    Running    0         22h
rook-ceph-osd-0-57bf997cbd-4wspg             1/1    Running    0         22h
rook-ceph-osd-1-54cf468bf8-z8jhp             1/1    Running    0         22h
rook-ceph-osd-prepare-caasp4-worker-0-f2tmw  0/2    Completed  0         9m35s
rook-ceph-osd-prepare-caasp4-worker-1-qsfhz  0/2    Completed  0         9m33s
rook-ceph-tools-76c7d559b6-64rkw             1/1    Running    0         22h
rook-discover-mb8gv                          1/1    Running    0         22h
rook-discover-tztz4                          1/1    Running    0         22h</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="kube-using-rook">
  <title>Usando o Rook como armazenamento para carga de trabalho do Kubernetes</title>

  <para>
   O Rook permite usar três tipos diferentes de armazenamento:
  </para>

  <variablelist>
   <varlistentry>
    <term><emphasis role="bold">Armazenamento de Objetos</emphasis></term>
    <listitem>
     <para>
      O armazenamento de objetos expõe uma API S3 ao cluster de armazenamento para que os aplicativos insiram e acessem os dados. Consulte <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-object.html"/> para ver uma descrição detalhada.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Sistema Compartilhado de Arquivos</term>
    <listitem>
     <para>
      É possível montar um sistema compartilhado de arquivos com permissão de leitura/gravação de vários pods. Isso é útil para aplicativos agrupados em cluster usando um sistema compartilhado de arquivos. Consulte <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-filesystem.html"/> para ver uma descrição detalhada.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Armazenamento de Blocos</term>
    <listitem>
     <para>
      O armazenamento de blocos permite montar o armazenamento em um único pod. Consulte <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-block.html"/> para ver uma descrição detalhada.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="kube-uninstall">
  <title>Desinstalando o Rook</title>

  <para>
   Para desinstalar o Rook, siga estas etapas:
  </para>

  <procedure>
   <step>
    <para>
     Apague todos os aplicativos do Kubernetes que estão consumindo armazenamento do Rook.
    </para>
   </step>
   <step>
    <para>
     Apague todos os artefatos de objeto, arquivo e/ou armazenamento de blocos criados seguindo a <xref linkend="kube-using-rook"/>.
    </para>
   </step>
   <step>
    <para>
     Apague o cluster, o operador e os recursos relacionados do Ceph:
    </para>
<screen>
<prompt>root # </prompt>kubectl delete -f cluster.yaml
<prompt>root # </prompt>kubectl delete -f operator.yaml
<prompt>root # </prompt>kubectl delete -f common.yaml
</screen>
   </step>
   <step>
    <para>
     Apague os dados dos hosts:
    </para>
<screen><prompt>root # </prompt>rm -rf /var/lib/rook</screen>
   </step>
   <step>
    <para>
     Se necessário, limpe os discos que foram usados pelo Rook. Consulte <link xlink:href="https://rook.io/docs/rook/master/ceph-teardown.html"/> para obter mais detalhes.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
