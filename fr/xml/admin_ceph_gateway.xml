<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_gateway.xml" version="5.0" xml:id="cha.ceph.gw">

 <title>Ceph Object Gateway</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>modification</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>oui</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Ce chapitre présente des détails sur les tâches d'administration liées à Object Gateway, telles que la vérification de l'état du service, la gestion des comptes, les passerelles multisites ou l'authentification LDAP.
 </para>
 <sect1 xml:id="sec.ceph.rgw.limits">
  <title>Restrictions d'Object Gateway et règles de dénomination</title>

  <para>
   Voici la liste des limites importantes d'Object Gateway :
  </para>

  <sect2 xml:id="ogw.limits.bucket">
   <title>Limitations des compartiments</title>
   <para>
    Lors de l'approche d'Object Gateway via l'API S3, les noms de compartiment doivent être conformes au DNS et peuvent contenir le caractère tiret (« - »). Lors de l'approche d'Object Gateway via l'API Swift, vous pouvez utiliser n'importe quelle combinaison de caractères UTF-8 à l'exception du caractère « / ». Le nom d'un compartiment peut comporter jusqu'à 255 caractères. Chaque nom de compartiment doit être unique.
   </para>
   <tip>
    <title>utilisation de noms de compartiment conformes au DNS</title>
    <para>
     Bien que vous puissiez utiliser n'importe quel nom de compartiment basé sur UTF-8 dans l'API Swift, il est recommandé de nommer les compartiments conformément aux règles de dénomination S3 afin d'éviter les problèmes d'accès au même compartiment via l'API S3.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ogw.limits.object">
   <title>Limitations des objets stockés</title>
   <variablelist>
    <varlistentry>
     <term>Nombre maximal d'objets par utilisateur</term>
     <listitem>
      <para>
       Aucune restriction par défaut (limite de ~ 2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Nombre maximal d'objets par compartiment</term>
     <listitem>
      <para>
       Aucune restriction par défaut (limite de ~ 2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Taille maximale d'un objet à charger/stocker</term>
     <listitem>
      <para>
       La limite est de 5 Go par chargement. Utilisez le chargement en plusieurs parties pour les objets plus volumineux. Le nombre maximal s'élève à 10 000 pour les tranches en plusieurs parties.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ogw.limits.http">
   <title>Limitations d'en-tête HTTP</title>
   <para>
    La limitation de requête et d'en-tête HTTP dépend de l'interface Web utilisée. Par défaut, CivetWeb limite le nombre d'en-têtes HTTP à 64 et la taille de l'en-tête HTTP à 16 Ko.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw.deploy">
  <title>Déploiement de la passerelle Object Gateway</title>

  <para>
   La méthode recommandée de déploiement de la passerelle Ceph Object Gateway s'effectue via l'infrastructure DeepSea par l'ajout de la ou des lignes <literal>role-rgw [...]</literal> appropriées dans le fichier <filename>policy.cfg</filename> sur Salt Master et par l'exécution des phases DeepSea requises.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Pour inclure la passerelle Object Gateway lors du processus de déploiement de la grappe Ceph, reportez-vous au <xref linkend="ceph.install.stack"/> et au <xref linkend="policy.configuration"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Pour ajouter le rôle Object Gateway à une grappe déjà déployée, reportez-vous à la <xref linkend="salt.adding.services"/>.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="ceph.rgw.operating">
  <title>Exploitation du service Object Gateway</title>

  <para>
   Le service Object Gateway est exploité avec la commande <command>systemctl</command>. Pour utiliser le service Object Gateway, vous devez disposer des privilèges <systemitem class="username">root</systemitem>. Notez que <replaceable>gateway_host</replaceable> (hôte_passerelle) est le nom d'hôte du serveur dont vous devez utiliser l'instance Object Gateway.
  </para>

  <para>
   Les sous-commandes suivantes sont prises en charge pour le service Object Gateway :
  </para>

  <variablelist>
   <varlistentry>
    <term>systemctl status ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Imprime les informations d'état du service.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl start ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Démarre le service s'il ne fonctionne pas encore.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl restart ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Redémarre le service.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl stop ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Arrête le service actif.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl enable ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Active le service afin qu'il démarre automatiquement au démarrage.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>systemctl disable ceph-radosgw@rgw.<replaceable>gateway_host</replaceable>
    </term>
    <listitem>
     <para>
      Désactive le service afin qu'il ne démarre pas automatiquement au démarrage.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.ceph.rgw.configuration">
  <title>Paramètres de configuration</title>

  <para>
   Le comportement de la passerelle Object Gateway peut être affecté par un grand nombre d'options du fichier <filename>ceph.conf</filename>. Voici la liste des plus importantes. Pour en connaître la liste complète, reportez-vous à la section <link xlink:href="http://docs.ceph.com/docs/master/radosgw/config-ref/"/>.
  </para>

  <variablelist>
   <varlistentry>
    <term>rgw_thread_pool_size</term>
    <listitem>
     <para>
      Nombre de threads pour le serveur CivetWeb. Définissez une valeur plus élevée si vous devez servir plus de demandes. La valeur par défaut est de 100 threads.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rgw_num_rados_handles</term>
    <listitem>
     <para>
      Nombre d'identificateurs de grappe RADOS (voir <link xlink:href="http://docs.ceph.com/docs/master/rados/api/librados-intro/#step-2-configuring-a-cluster-handle"/>) pour Object Gateway. Disposer d'un nombre configurable d'identificateurs RADOS permet d'améliorer significativement les performances pour tous les types de charge de travail. En principe, chaque thread de travail Object Gateway doit maintenant choisir un identificateur RADOS pour toute sa durée de vie. La valeur par défaut est 1.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rgw_max_chunk_size</term>
    <listitem>
     <para>
      Taille maximale d'une tranche de données qui sera lue en une seule opération. L'augmentation de la valeur à 4 Mo (4194304) permet d'améliorer les performances de traitement des objets volumineux. La valeur par défaut est 128 Ko (131072).
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <sect2 xml:id="sec.ceph.rgw.configuration.notes">
   <title>Remarques supplémentaires</title>
   <variablelist>
    <varlistentry>
     <term>rgw dns name</term>
     <listitem>
      <para>
       Si le paramètre <literal>rgw dns name</literal> est ajouté au fichier <filename>ceph.conf</filename>, assurez-vous que le client S3 est configuré pour adresser les demandes au noeud d'extrémité spécifié par ce paramètre.<literal/>
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rgw.access">
  <title>Gestion des accès à la passerelle Object Gateway</title>

  <para>
   Vous pouvez communiquer avec Object Gateway en utilisant une interface compatible avec S3 ou Swift. L'interface S3 est compatible avec un vaste sous-ensemble de l'API RESTful d'Amazon S3. L'interface Swift est compatible avec un vaste sous-ensemble de l'API OpenStack Swift.
  </para>

  <para>
   Les deux interfaces nécessitent la création d'un utilisateur spécifique et l'installation du logiciel client approprié pour communiquer avec la passerelle à l'aide de la clé secrète de l'utilisateur.
  </para>

  <sect2 xml:id="accessing.ragos.gateway">
   <title>Accès à Object Gateway</title>
   <sect3>
    <title>Accès à l'interface S3</title>
    <para>
     Pour accéder à l'interface S3, un client REST est nécessaire. <command>S3cmd</command> est un client S3 de ligne de commande. Il est disponible dans <link xlink:href="https://build.opensuse.org/package/show/Cloud:Tools/s3cmd">OpenSUSE Build Service</link>. Le dépôt contient des versions de distributions SUSE Linux Enterprise et de distributions openSUSE.
    </para>
    <para>
     Si vous voulez tester votre accès à l'interface S3, vous pouvez aussi écrire un petit script Python. Le script se connecte à Object Gateway, crée un compartiment et dresse la liste de tous les compartiments. Les valeurs de <option>aws_access_key_id</option> (ID_clé_accès_AWS) et de <option>aws_secret_access_key</option> (Clé_accès_secret_AWS) sont issues des valeurs de <option>access_key</option> (clé_accès) et de <option>secret_key</option> (clé_secret) renvoyées par la commande <command>radosgw_admin</command> de la <xref linkend="adding.s3.swift.users"/>.
    </para>
    <procedure>
     <step>
      <para>
       Installez le paquetage <systemitem>python-boto</systemitem> :
      </para>
<screen>sudo zypper in python-boto</screen>
     </step>
     <step>
      <para>
       Créez un script Python appelé <filename>s3test.py</filename> avec le contenu suivant : <remark role="fixme">Provide script in RPM? Is it really necessary to create pool? This script is not necessary at all, remove it from documentation?</remark>
      </para>
<screen>import boto
import boto.s3.connection
access_key = '11BS02LGFB6AL6H1ADMW'
secret_key = 'vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY'
conn = boto.connect_s3(
aws_access_key_id = access_key,
aws_secret_access_key = secret_key,
host = '{hostname}',
is_secure=False,
calling_format = boto.s3.connection.OrdinaryCallingFormat(),
)
bucket = conn.create_bucket('my-new-bucket')
for bucket in conn.get_all_buckets():
  print "{name}\t{created}".format(
  name = bucket.name,
  created = bucket.creation_date,
  )</screen>
      <para>
       Remplacez <literal>{hostname}</literal> par le nom de l'hôte sur lequel vous avez configuré le service Object Gateway, par exemple <literal>gateway_host</literal> (hôte_passerelle).
      </para>
     </step>
     <step>
      <para>
       Exécutez le script :
      </para>
<screen>python s3test.py</screen>
      <para>
       Le script produit un résultat similaire à ceci :
      </para>
<screen>my-new-bucket 2015-07-22T15:37:42.000Z</screen>
     </step>
    </procedure>
   </sect3>
   <sect3>
    <title>Accès à l'interface Swift</title>
    <para>
     Pour accéder à Object Gateway via l'interface Swift, vous devez disposer du client de ligne de commande <command>swift</command>. La page de manuel <command>man 1 swift</command> fournit des informations complémentaires sur les options de ligne de commande du client.
    </para>
    <para>
     Le paquetage est inclus dans le module « Cloud Public » de SUSE Linux Enterprise 12 SP3. Avant d'installer le paquetage, vous devez activer le module et rafraîchir le dépôt des logiciels :
    </para>
<screen>sudo SUSEConnect -p sle-module-public-cloud/12/x86_64
sudo zypper refresh</screen>
    <para>
     Pour installer la commande <command>swift</command>, exécutez ce qui suit :
    </para>
<screen>sudo zypper in python-swiftclient</screen>
    <para>
     L'accès swift utilise la syntaxe suivante :
    </para>
<screen>swift -A http://<replaceable>IP_ADDRESS</replaceable>/auth/1.0 \
-U example_user:swift -K '<replaceable>swift_secret_key</replaceable>' list</screen>
    <para>
     Remplacez <replaceable>IP_ADDRESS</replaceable> (ADRESSE_IP) par l'adresse IP du serveur de passerelle, et <replaceable>swift_secret_key</replaceable> (clé_secret_SWIFT) par sa valeur dans la sortie de la commande <command>radosgw-admin key create</command> exécutée pour l'utilisateur <systemitem>swift</systemitem> à la <xref linkend="adding.s3.swift.users"/>.
    </para>
    <para>
     Par exemple :
    </para>
<screen>swift -A http://gateway.example.com/auth/1.0 -U example_user:swift \
-K 'r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h' list</screen>
    <para>
     La sortie est la suivante :
    </para>
<screen>my-new-bucket</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="s3.swift.accounts.managment">
   <title>Gestion des comptes S3 et Swift</title>
   <sect3 xml:id="adding.s3.swift.users">
    <title>Ajout d'utilisateurs S3 et Swift</title>
    <para>
     Vous devez créer un utilisateur, une clé d'accès et un secret pour permettre aux utilisateurs finaux d'interagir avec la passerelle. Il existe deux types d'utilisateur : <emphasis>user</emphasis> et <emphasis>subuser</emphasis>. Alors que des <emphasis>users</emphasis> sont employés pour les interactions avec l'interface S3, les <emphasis>subusers</emphasis> sont les utilisateurs de l'interface Swift. Chaque subuser est associé à un user.
    </para>
    <para>
     Il est également possible d'ajouter des utilisateurs par le biais du fichier DeepSea <filename>rgw.sls</filename>. Pour un exemple, reportez-vous à la <xref linkend="ceph.nfsganesha.customrole.rgw_multiusers"/>.
    </para>
    <para>
     Pour créer un utilisateur Swift, procédez de la façon suivante :
    </para>
    <procedure>
     <step>
      <para>
       Pour créer un utilisateur Swift (qui est un <emphasis>subuser</emphasis> suivant notre terminologie), vous devez d'abord créer le <emphasis>user</emphasis> qui lui est associé.
      </para>
<screen>sudo radosgw-admin user create --uid=<replaceable>username</replaceable> \
 --display-name="<replaceable>display-name</replaceable>" --email=<replaceable>email</replaceable></screen>
      <para>
       Par exemple :
      </para>
<screen>sudo radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
     </step>
     <step>
      <para>
       Pour créer un subuser (interface Swift) pour l'utilisateur, vous devez indiquer l'ID utilisateur (--uid= <replaceable>nom d'utilisateur</replaceable>), un ID subuser et le niveau d'accès du subuser.
      </para>
<screen>sudo radosgw-admin subuser create --uid=<replaceable>uid</replaceable> \
 --subuser=<replaceable>uid</replaceable> \
 --access=[ <replaceable>read | write | readwrite | full</replaceable> ]</screen>
      <para>
       Par exemple :
      </para>
<screen>sudo radosgw-admin subuser create --uid=example_user \
 --subuser=example_user:swift --access=full</screen>
     </step>
     <step>
      <para>
       Générez une clé secrète pour l'utilisateur.
      </para>
<screen>sudo radosgw-admin key create \
   --gen-secret \
   --subuser=example_user:swift \
   --key-type=swift</screen>
     </step>
     <step>
      <para>
       Les deux commandes afficheront des données au format JSON indiquant l'état de l'utilisateur. Notez les lignes suivantes et souvenez-vous de la valeur de <literal>secret_key</literal> (clé_secrète) :
      </para>
<screen>"swift_keys": [
   { "user": "example_user:swift",
     "secret_key": "r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h"}],</screen>
     </step>
    </procedure>
    <para/>
    <para>
     Lorsque vous accédez à Object Gateway via l'interface S3, vous devez créer un utilisateur S3 en exécutant :
    </para>
<screen>sudo radosgw-admin user create --uid=<replaceable>username</replaceable> \
 --display-name="<replaceable>display-name</replaceable>" --email=<replaceable>email</replaceable></screen>
    <para>
     Par exemple :
    </para>
<screen>sudo radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
    <para>
     La commande crée également l'accès et la clé secrète de l'utilisateur. Vérifiez le résultat des mot clés <literal>access_key</literal> (clé_accès) et <literal>secret_key</literal> (clé_secret), et leurs valeurs :
    </para>
<screen>[...]
 "keys": [
       { "user": "example_user",
         "access_key": "11BS02LGFB6AL6H1ADMW",
         "secret_key": "vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY"}],
 [...]</screen>
   </sect3>
   <sect3 xml:id="removing.s3.swift.users">
    <title>Suppression des utilisateurs S3 et Swift</title>
    <para>
     La procédure de suppression des utilisateurs est similaire pour les utilisateurs S3 et Swift. Dans le cas d'utilisateurs Swift cependant, vous devrez peut-être supprimer l'utilisateur ainsi que ses subusers.
    </para>
    <para>
     Pour supprimer un utilisateur S3 ou Swift (y compris tous ses subusers), spécifiez <option>user rm</option> et l'ID utilisateur dans la commande suivante :
    </para>
<screen>sudo radosgw-admin user rm --uid=example_user</screen>
    <para>
     Pour supprimer un subuser, spécifiez <option>subuser rm</option> et l'ID de celui-ci.
    </para>
<screen>sudo radosgw-admin subuser rm --uid=example_user:swift</screen>
    <para>
     Vous pouvez utiliser les options suivantes :
    </para>
    <variablelist>
     <varlistentry>
      <term>--purge-data</term>
      <listitem>
       <para>
        Purge toutes les données associées à l'ID utilisateur.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>--purge-keys</term>
      <listitem>
       <para>
        Purge toutes les clés associées à l'ID utilisateur.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <tip>
     <title>suppression d'un subuser</title>
     <para>
      Lorsque vous supprimez un subuser, vous supprimez également l'accès à l'interface Swift. L'utilisateur est conservé dans le système.
     </para>
    </tip>
   </sect3>
   <sect3 xml:id="changing.s3.swift.users.password">
    <title>Modification de l'accès utilisateur S3 et Swift et des clés secrètes</title>
    <para>
     Les paramètres <literal>access_key</literal> (clé_accès) et <literal>secret_key</literal> (clé_secret) identifient l'utilisateur Object Gateway lors de l'accès à la passerelle. La modification des clés utilisateur existantes revient à créer de nouvelles clés, car les anciennes clés sont écrasées.
    </para>
    <para>
     Pour les utilisateurs S3, exécutez la commande suivante :
    </para>
<screen>sudo radosgw-admin key create --uid=<replaceable>example_user</replaceable> --key-type=s3 --gen-access-key --gen-secret</screen>
    <para>
     Pour les utilisateurs Swift, exécutez la commande suivante :
    </para>
<screen>sudo radosgw-admin key create --subuser=<replaceable>example_user</replaceable>:swift --key-type=swift --gen-secret</screen>
    <variablelist>
     <varlistentry>
      <term><option>--key-type=<replaceable>type</replaceable></option>
      </term>
      <listitem>
       <para>
        Indique le type de clé. Soit <literal>swift</literal>, soit <literal>s3</literal>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-access-key</option>
      </term>
      <listitem>
       <para>
        Génère une clé d'accès aléatoire (pour l'utilisateur S3 par défaut).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-secret</option>
      </term>
      <listitem>
       <para>
        Génère une clé secrète aléatoire.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--secret=<replaceable>clé</replaceable></option>
      </term>
      <listitem>
       <para>
        Indique une clé secrète, par exemple générée manuellement.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="user.quota.managment">
    <title>Gestion des quotas utilisateur</title>
    <para>
     La passerelle Ceph Object Gateway vous permet de définir des quotas sur les utilisateurs et les compartiments appartenant aux utilisateurs. Les quotas incluent le nombre maximal d'objets dans un compartiment et la taille de stockage maximale en mégaoctets.
    </para>
    <para>
     Avant d'activer un quota utilisateur, vous devez tout d'abord définir ses paramètres :
    </para>
<screen>sudo radosgw-admin quota set --quota-scope=user --uid=<replaceable>example_user</replaceable> \
 --max-objects=1024 --max-size=1024</screen>
    <variablelist>
     <varlistentry>
      <term><option>--max-objects</option>
      </term>
      <listitem>
       <para>
        Indique le nombre maximal d'objets. Une valeur négative désactive la vérification.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--max-size</option>
      </term>
      <listitem>
       <para>
        Indique le nombre maximal d'octets. Une valeur négative désactive la vérification.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--quota-scope</option>
      </term>
      <listitem>
       <para>
        Définit l'étendue du quota. Les options sont <literal>bucket</literal> (compartiment) et <literal>user</literal> (utilisateur). Les quotas de compartiment s'appliquent aux compartiments appartenant à un utilisateur. Les quotas utilisateur s'appliquent à un utilisateur.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Une fois que vous avez défini un quota utilisateur, vous pouvez l'activer :
    </para>
<screen>sudo radosgw-admin quota enable --quota-scope=user --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Pour désactiver un quota :
    </para>
<screen>sudo radosgw-admin quota disable --quota-scope=user --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Pour dresser la liste des paramètres de quota :
    </para>
<screen>sudo radosgw-admin user info --uid=<replaceable>example_user</replaceable></screen>
    <para>
     Pour mettre à jour les statistiques de quota :
    </para>
<screen>sudo radosgw-admin user stats --uid=<replaceable>example_user</replaceable> --sync-stats</screen>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rgw.https">
  <title>Activation de HTTPS/SSL pour les passerelles Object Gateway</title>

  <para>
   Pour activer le rôle Object Gateway par défaut qui permet de communiquer en toute sécurité par le biais du protocole SSL, vous devez disposer d'un certificat émis par une autorité de certification ou créer un certificat auto-signé. Pour configurer Object Gateway avec le protocole HTTPS, vous avez le choix entre deux méthodes : une méthode simple qui utilise les paramètres par défaut et une méthode avancée qui permet d'ajuster précisément les paramètres HTTPS.
  </para>

  <sect2 xml:id="ogw.selfcert">
   <title>Création d'un certificat auto-signé</title>
   <tip>
    <para>
     Ignorez cette section si vous avez déjà un certificat valide signé par une autorité de certification.
    </para>
   </tip>
   <para>
    Par défaut, DeepSea estime que le fichier de certificat réside dans <filename>/srv/salt/ceph/rgw/cert/rgw.pem</filename> sur Salt Master. Il distribue ensuite le certificat à <filename>/etc/ceph/rgw.pem</filename> sur le minion Salt doté du rôle Object Gateway où Ceph lit le certificat.
   </para>
   <para>
    La procédure suivante décrit comment générer un certificat SSL auto-signé sur le noeud Salt Master.
   </para>
   <procedure>
    <step>
     <para>
      Ajoutez l'option <option>subjectAltName</option> à la section <literal>[v3_req]</literal> du fichier <filename>/etc/ssl/openssl.cnf</filename> pour tous les noms d'hôte auprès desquels votre passerelle Object Gateway doit être identifiée :
     </para>
<screen>
[...]
[ v3_req ]
subjectAltName = ${ENV::SAN}
[...]
</screen>
    </step>
    <step>
     <para>
      Créez la clé et le certificat à l'aide d'<command>openssl</command>. Faites précéder <command>openssl</command> avec <literal>env SAN=DNS:fqdn</literal>. Entrez toutes les données que vous devez inclure dans votre certificat. Il est recommandé d'entrer le nom de domaine complet (FQDN) comme nom commun. Avant de signer le certificat, vérifiez que « X509v3 Subject Alternative Name: » est inclus dans les extensions requises et que « X509v3 Subject Alternative Name: » est défini dans le certificat généré.
     </para>
<screen>
<prompt>root@master # </prompt>env SAN=DNS:fqdn openssl req -x509 -nodes -days 1095 \
 -newkey rsa:4096 -keyout rgw.key -out /srv/salt/ceph/rgw/cert/rgw.pem
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw.ssl.simple">
   <title>Configuration HTTPS simple</title>
   <para>
    Par défaut, l'instance Ceph résidant sur le noeud Object Gateway lit le certificat <filename>/etc/ceph/rgw.pem</filename> et utilise le port 443 pour la communication SSL sécurisée. Si vous n'avez pas besoin de modifier ces valeurs, procédez comme suit :
   </para>
   <procedure>
    <step>
     <para>
      Modifiez <filename>/srv/pillar/ceph/stack/global.yml</filename> et ajoutez la ligne suivante :
     </para>
<screen>
rgw_configurations: rgw-ssl
rgw_init: default-ssl
</screen>
    </step>
    <step>
     <para>
      Suivez les phases 2, 3 et 4 de DeepSea pour appliquer les modifications :
     </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw.ssl.advanced">
   <title>Configuration HTTPS avancée</title>
   <para>
    Si vous devez modifier les valeurs par défaut pour les paramètres SSL d'Object Gateway, procédez comme suit :
   </para>
   <procedure>
    <step>
     <para>
      Copiez la configuration SSL d'Object Gateway par défaut dans le sous-répertoire <filename>ceph.conf.d</filename> :
     </para>
<screen>
<prompt>root@master # </prompt>cp /srv/salt/ceph/configuration/files/rgw-ssl.conf \
 /srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf
</screen>
    </step>
    <step>
     <para>
      Dans le fichier <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/rgw.conf</filename>, modifiez les options par défaut, telles que le numéro de port ou le chemin du certificat SSL, afin qu'elles reflètent votre configuration.
     </para>
    </step>
    <step>
     <para>
      Exécutez les phases 3 et 4 de DeepSea pour appliquer les modifications :
     </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
</screen>
    </step>
   </procedure>
   <tip xml:id="rgw.civetweb.multiport">
    <title>liaison à plusieurs ports</title>
    <para>
     Le serveur CivetWeb peut établir une liaison à plusieurs ports. Cela est utile si vous devez accéder à une même instance Object Gateway avec des connexions SSL et non-SSL. Les numéros de ports que vous spécifiez doivent être séparés les uns des autres par le signe « + ». Voici un exemple de ligne de configuration incluant deux ports de communication :
    </para>
<screen>[client.{{ client }}]
rgw_frontends = civetweb port=80+443s ssl_certificate=/etc/ceph/rgw.pem</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rgw.sync">
  <title>Modules de synchronisation</title>

  <para>
   La fonctionnalité <emphasis>multisite</emphasis> d'Object Gateway apparue dans Jewel permet de créer plusieurs zones et de mettre en miroir les données et les métadonnées entre elles. Les <emphasis>modules de synchronisation</emphasis> sont construits au sommet de la structure multisite qui permet de transmettre des données et des métadonnées à un niveau externe différent. Un module de synchronisation permet d'effectuer un ensemble d'opérations chaque fois qu'un changement se produit dans les données (les opérations de métadonnées telles que la création d'un compartiment ou d'un utilisateur, etc. sont également considérées comme des modifications apportées aux données). Comme les modifications multisite rgw sont finalement cohérentes sur les sites distants, elles sont propagées de manière asynchrone. Cela permet de débloquer des cas d'utilisation, tels que la sauvegarde du stockage d'objets sur une grappe cloud externe ou une solution de sauvegarde personnalisée à l'aide de lecteurs de bande, l'indexation de métadonnées dans Elasticsearch, etc.
  </para>

  <sect2 xml:id="ceph.rgw.sync.zones">
   <title>Synchronisation des zones</title>
   <para>
    Une configuration de module de synchronisation est locale pour une zone en particulier. Le module de synchronisation détermine si la zone exporte des données ou ne peut consommer que des données modifiées dans une autre zone. Depuis la version « Luminous », les plug-ins pris en charge sont <literal>elasticsearch</literal>, <literal>rgw</literal> (qui est le plug-in de synchronisation par défaut des données entre les zones) et <literal>log</literal> (qui est un plug-in générique de synchronisation consignant les opérations de métadonnées entre zones distantes). Les sections suivantes s'appuient sur l'exemple d'une zone qui utilise le module de synchronisation <literal>elasticsearch</literal>. Le processus serait similaire pour la configuration de tout autre plug-in de synchronisation.
   </para>
   <note>
    <title>plug-in de synchronisation par défaut</title>
    <para>
     <literal>rgw</literal> est le plug-in de synchronisation par défaut et il n'est pas nécessaire de le configurer explicitement.
    </para>
   </note>
   <sect3 xml:id="ceph.rgw.sync.zones.req">
    <title>Exigences et hypothèses</title>
    <para>
     Supposons que vous ayez la configuration multisite simple décrite à la <xref linkend="ceph.rgw.fed"/> et composée de deux zones <literal>us-east</literal> et <literal>us-west</literal>. Maintenant, nous ajoutons une troisième zone <literal>us-east-es</literal>, qui traite uniquement les métadonnées des autres sites. Cette zone peut résider dans la même grappe Ceph ou dans une autre que <literal>us-east</literal>. Cette zone ne consommera que les métadonnées d'autres zones et les passerelles Object Gateway de cette zone ne serviront pas directement les requêtes des utilisateurs finaux.
    </para>
   </sect3>
   <sect3 xml:id="ceph.rgw.sync.zones.configure">
    <title>Configuration de modules de synchronisation</title>
    <procedure>
     <step>
      <para>
       Créez la troisième zone similaire à celles décrites dans la <xref linkend="ceph.rgw.fed"/>, par exemple :
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone create --rgw-zonegroup=us --rgw-zone=us-east-es \
--access-key={system-key} --secret={secret} --endpoints=http://rgw-es:80
      </screen>
     </step>
     <step>
      <para>
       Il est possible de configurer un module de synchronisation pour cette zone comme suit :
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --tier-type={tier-type} \
--tier-config={set of key=value pairs}
      </screen>
     </step>
     <step>
      <para>
       Par exemple, dans le module de synchronisation <literal>elasticsearch</literal> :
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --tier-type=elasticsearch \
--tier-config=endpoint=http://localhost:9200,num_shards=10,num_replicas=1
      </screen>
      <para>
       Pour les différentes options tier-config prises en charge, reportez-vous à la <xref linkend="ceph.rgw.sync.elastic"/>.
      </para>
     </step>
     <step>
      <para>
       Enfin, mettez à jour la période :
      </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
      </screen>
     </step>
     <step>
      <para>
       Démarrez ensuite radosgw dans la zone :
      </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> start ceph-radosgw@rgw.`hostname -s`
<prompt>root # </prompt><command>systemctl</command> enable ceph-radosgw@rgw.`hostname -s`
      </screen>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.rgw.sync.elastic">
   <title>Stockage des métadonnées dans Elasticsearch</title>
   <para>
    Ce module de synchronisation écrit les métadonnées d'autres zones dans Elasticsearch. À partir de la version « Luminous », voici les champs de données JSON qui sont stockés dans Elasticsearch.
   </para>
<screen>
{
  "_index" : "rgw-gold-ee5863d6",
  "_type" : "object",
  "_id" : "34137443-8592-48d9-8ca7-160255d52ade.34137.1:object1:null",
  "_score" : 1.0,
  "_source" : {
    "bucket" : "testbucket123",
    "name" : "object1",
    "instance" : "null",
    "versioned_epoch" : 0,
    "owner" : {
      "id" : "user1",
      "display_name" : "user1"
    },
    "permissions" : [
      "user1"
    ],
    "meta" : {
      "size" : 712354,
      "mtime" : "2017-05-04T12:54:16.462Z",
      "etag" : "7ac66c0f148de9519b8bd264312c4d64"
    }
  }
}
   </screen>
   <sect3 xml:id="ceph.rgw.sync.elastic.config">
    <title>Paramètres de configuration du type de niveau Elasticsearch</title>
    <variablelist>
     <varlistentry>
      <term>endpoint</term>
      <listitem>
       <para>
        Indique le noeud d'extrémité du serveur Elasticsearch auquel accéder.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_shards</term>
      <listitem>
       <para>
        <emphasis>(entier)</emphasis> Nombre de partitions avec lesquelles Elasticsearch sera configuré lors de l'initialisation de la synchronisation des données. Notez que cela ne peut pas être modifié après l'initialisation. Toute modification nécessite la reconstruction de l'index Elasticsearch et la réinitialisation du processus de synchronisation des données.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_replicas</term>
      <listitem>
       <para>
        <emphasis>(entier)</emphasis> Nombre de répliques avec lesquelles Elasticsearch sera configuré lors de l'initialisation de la synchronisation des données.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>explicit_custom_meta</term>
      <listitem>
       <para>
        <emphasis>(true | false)</emphasis> Indique si toutes les métadonnées personnalisées de l'utilisateur seront indexées ou si l'utilisateur devra configurer (au niveau compartiment) les entrées de métadonnées client à indexer. La valeur par défaut est « false ».
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>index_buckets_list</term>
      <listitem>
       <para>
        <emphasis>(liste de chaînes séparées par des virgules)</emphasis> Si elle est vide, tous les compartiments seront indexés. Dans le cas contraire, l'indexation portera uniquement sur les compartiments spécifiés ici. Il est possible de fournir des préfixes de compartiment (« foo * », par exemple) ou des suffixes de compartiment (« *bar », par exemple).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>approved_owners_list</term>
      <listitem>
       <para>
        <emphasis>(liste de chaînes séparées par des virgules)</emphasis> Si elle est vide, les compartiments de tous les propriétaires seront indexés (sous réserve d'autres restrictions) ; dans le cas contraire, l'indexation portera uniquement sur les compartiments appartenant aux propriétaires spécifiés. Il est également possible de définir des suffixes et des préfixes.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>override_index_path</term>
      <listitem>
       <para>
        <emphasis>(chaîne)</emphasis> Si elle n'est pas vide, cette chaîne sera utilisée comme chemin d'index elasticsearch. Dans le cas contraire, le chemin d'index sera fixé et généré lors de l'initialisation de la synchronisation.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph.rgw.sync.elastic.query">
    <title>Requêtes de métadonnées</title>
    <para>
     Étant donné que la grappe Elasticsearch stocke désormais les métadonnées d'objet, il est important que le noeud d'extrémité Elasticsearch ne soit pas exposé à tous les utilisateurs, mais accessible uniquement aux administrateurs de la grappe. L'exposition de requêtes de métadonnées à l'utilisateur final lui-même engendre un problème, car celui-ci doit interroger uniquement ses métadonnées et non pas celles des autres utilisateurs. Cette opération requiert que la grappe Elasticsearch authentifie les utilisateurs d'une manière similaire à RGW, ce qui pose problème.
    </para>
    <para>
     À partir de la version « Luminous » de RGW, la zone maître des métadonnées peut traiter les demandes des utilisateurs finaux. Cette approche présente l'avantage de masquer le noeud d'extrémité Elastisearch pour le public et de résoudre le problème d'authentification et d'autorisation, puisque RGW peut authentifier lui-même les requêtes de l'utilisateur final. Dans cette optique, RGW introduit une nouvelle requête dans les API de compartiment pouvant desservir les requêtes Elasticsearch. Toutes ces requêtes doivent être envoyées à la zone maître de métadonnées.
    </para>
    <variablelist>
     <varlistentry>
      <term>Obtention d'une requête Elasticsearch</term>
      <listitem>
<screen>
GET /<replaceable>BUCKET</replaceable>?query={query-expr}
       </screen>
       <para>
        Paramètres de requête :
       </para>
       <itemizedlist>
        <listitem>
         <para>
          max-keys : nombre maximal d'entrées à renvoyer
         </para>
        </listitem>
        <listitem>
         <para>
          marker : marqueur de pagination
         </para>
        </listitem>
       </itemizedlist>
<screen>
expression := [(]&lt;arg&gt; &lt;op&gt; &lt;value&gt; [)][&lt;and|or&gt; ...]
       </screen>
       <para>
        op est l'un des opérateurs suivants : &lt;, &lt;=, ==, &gt;=, &gt;
       </para>
       <para>
        Par exemple :
       </para>
<screen>
GET /?query=name==foo
       </screen>
       <para>
        Renvoie toutes les clés indexées pour lesquelles l'utilisateur dispose d'une autorisation de lecture et qui s'appellent « foo ». Dans ce cas, la sortie se compose d'une liste XML de clés similaire à la sortie des compartiments de liste S3.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Configuration des champs de métadonnées personnalisés</term>
      <listitem>
       <para>
        Définissez quelles entrées de métadonnées personnalisées doivent être indexées (sous le compartiment indiqué) et précisez le type de ces clés. Si l'indexation explicite de métadonnées personnalisées est configurée, cette opération est nécessaire pour que rgw indexe les valeurs de ces métadonnées personnalisées. Dans le cas contraire, cette opération est nécessaire lorsque les clés de métadonnées indexées ne sont pas du type chaîne.
       </para>
<screen>
POST /<replaceable>BUCKET</replaceable>?mdsearch
x-amz-meta-search: &lt;key [; type]&gt; [, ...]
       </screen>
       <para>
        Les champs de métadonnées doivent être séparés les uns des autres par des virgules ; pour forcer le type d'un champ, indiquez « ; ». Les types actuellement autorisés sont string (chaîne - par défaut), integer (entier) et date. Par exemple, si vous voulez indexer une métadonnée d'objet personnalisé x-amz-meta-year en tant que type int, x-amz-meta-date en tant que type date et x-amz-meta-title en tant que string, vous définirez le code suivant :
       </para>
<screen>
POST /mybooks?mdsearch
x-amz-meta-search: x-amz-meta-year;int, x-amz-meta-release-date;date, x-amz-meta-title;string
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Suppression de la configuration des métadonnées personnalisée</term>
      <listitem>
       <para>
        Supprimez la configuration de compartiment de métadonnées personnalisée.
       </para>
<screen>
DELETE /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Obtention de la configuration des métadonnées personnalisée</term>
      <listitem>
       <para>
        Récupérez la configuration de compartiment de métadonnées personnalisée.
       </para>
<screen>
GET /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rgw.ldap">
  <title>Authentification LDAP</title>

  <para>
   Outre l'authentification par défaut des utilisateurs locaux, Object Gateway peut également utiliser les services du serveur LDAP pour authentifier les utilisateurs.
  </para>

  <sect2 xml:id="ceph.rgw.ldap.how_works">
   <title>Mécanisme d'authentification</title>
   <para>
    Object Gateway extrait les informations d'identification LDAP de l'utilisateur à partir d'un jeton. Un filtre de recherche est défini à partir du nom d'utilisateur. La passerelle Object Gateway utilise le compte de service configuré pour rechercher une entrée correspondante dans l'annuaire. Si une entrée est trouvée, la passerelle Object Gateway tente d'établir une liaison avec le nom distinctif trouvé et le mot de passe à partir du jeton. Si les informations d'identification sont valides, la liaison réussit et Object Gateway accorde l'accès.
   </para>
   <para>
    Vous pouvez limiter les utilisateurs autorisés en définissant la base de la recherche sur une unité organisationnelle spécifique ou en spécifiant un filtre de recherche personnalisé, qui, par exemple, exige l'appartenance à un groupe spécifique, des classes d'objets personnalisées ou des attributs.
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.ldap.reqs">
   <title>Configuration requise</title>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>LDAP ou Active Directory</emphasis> : instance LDAP en cours d'exécution accessible par Object Gateway.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Compte de service</emphasis> : informations d'identification LDAP que la passerelle Object Gateway doit utiliser avec les autorisations de recherche.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Compte utilisateur</emphasis> : au moins un compte utilisateur dans l'annuaire LDAP.
     </para>
    </listitem>
   </itemizedlist>
   <important>
    <title>différenciation des utilisateurs LDAP et des utilisateurs locaux</title>
    <para>
     Vous ne devez pas utiliser les mêmes noms d'utilisateur pour les utilisateurs locaux et les utilisateurs authentifiées à l'aide de LDAP. La passerelle Object Gateway ne peut pas les distinguer et les traite comme un même utilisateur.
    </para>
   </important>
   <tip>
    <title>contrôle d'intégrité</title>
    <para>
     Vérifiez le compte de service ou la connexion LDAP à l'aide de l'utilitaire <command>ldapsearch</command>. Par exemple :
    </para>
<screen>ldapsearch -x -D "uid=ceph,ou=system,dc=example,dc=com" -W \
-H ldaps://example.com -b "ou=users,dc=example,dc=com" 'uid=*' dn</screen>
    <para>
     Veillez à utiliser les mêmes paramètres LDAP que dans le fichier de configuration Ceph pour éliminer les problèmes éventuels.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ceph.rgw.ldap.config">
   <title>Configuration de la passerelle Object Gateway en vue de l'utilisation de l'authentification LDAP</title>
   <para>
    Les paramètres suivants du fichier de configuration <filename>/etc/ceph/ceph.conf</filename> sont liés à l'authentification LDAP :
   </para>
   <variablelist>
    <varlistentry>
     <term><option>rgw_ldap_uri</option>
     </term>
     <listitem>
      <para>
       Indique le serveur LDAP à utiliser. Veillez à utiliser le paramètre <literal>ldaps://<replaceable>fqdn</replaceable>:<replaceable>port</replaceable></literal> afin d'éviter de transmettre les informations d'identification en texte brut sur une liaison non sécurisée.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_binddn</option>
     </term>
     <listitem>
      <para>
       Nom distinctif (DN) du compte de service utilisé par Object Gateway.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_secret</option>
     </term>
     <listitem>
      <para>
       Mot de passe du compte de service.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>rgw_ldap_searchdn</term>
     <listitem>
      <para>
       Indique la base dans l'arborescence des informations d'annuaire pour la recherche d'utilisateurs. Il peut s'agir de l'unité organisationnelle de vos utilisateurs ou d'une unité organisationnelle plus spécifique.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_dnattr</option>
     </term>
     <listitem>
      <para>
       Attribut utilisé dans le filtre de recherche en vue de correspondre à un nom d'utilisateur. Il s'agit le plus souvent de <literal>uid</literal> ou <literal>cn</literal> selon votre arborescence d'annuaire.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_search_filter</option>
     </term>
     <listitem>
      <para>
       Si cette information n'est pas indiquée, la passerelle Object Gateway s'appuie sur le paramètre <option>rgw_ldap_dnattr</option> pour définir automatiquement le filtre de recherche. Utilisez ce paramètre pour limiter librement la liste des utilisateurs autorisés. Reportez-vous à la <xref linkend="ceph.rgw.ldap.filter"/> pour plus d'informations.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ceph.rgw.ldap.filter">
   <title>Utilisation d'un filtre de recherche personnalisé pour limiter l'accès des utilisateurs</title>
   <para>
    Il existe deux moyens d'utiliser le paramètre <option>rgw_search_filter</option>.
   </para>
   <sect3>
    <title>Filtre partiel de restriction supplémentaire du filtre de recherche construit</title>
    <para>
     Voici un exemple de filtre partiel :
    </para>
<screen>"objectclass=inetorgperson"</screen>
    <para>
     La passerelle Object Gateway génère le filtre de recherche comme d'habitude avec le nom d'utilisateur issu du jeton et la valeur de <option>rgw_ldap_dnattr</option>. Le filtre construit est ensuite combiné au filtre partiel à partir de l'attribut <option>rgw_search_filter</option>. En fonction du nom d'utilisateur et des paramètres, le filtre de recherche final peut devenir ce qui suit :
    </para>
<screen>"(&amp;(uid=hari)(objectclass=inetorgperson))"</screen>
    <para>
     Dans ce cas, l'utilisateur « hari » ne recevra un accès que s'il se trouve dans l'annuaire LDAP, possède la classe d'objets « inetorgperson » et a fourni un mot de passe valide.
    </para>
   </sect3>
   <sect3>
    <title>Filtre complet</title>
    <para>
     Un filtre complet doit contenir un jeton <option>USERNAME</option> qui sera remplacé par le nom d'utilisateur lors de la tentative d'authentification. Le paramètre <option>rgw_ldap_dnattr</option> n'est plus utilisé dans ce cas. Par exemple, pour limiter les utilisateurs valides à un groupe spécifique, utilisez le filtre suivant :
    </para>
<screen>"(&amp;(uid=USERNAME)(memberOf=cn=ceph-users,ou=groups,dc=mycompany,dc=com))"</screen>
    <note>
     <title>Attribut <literal>memberOf</literal></title>
     <para>
      L'utilisation de l'attribut <literal>memberOf</literal> dans les recherches LDAP requiert la prise en charge côté serveur dans votre implémentation de serveur LDAP spécifique.
     </para>
    </note>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.rgw.ldap.token">
   <title>Génération d'un jeton d'accès pour l'authentification LDAP</title>
   <para>
    L'utilitaire <command>radosgw-token</command> génère le jeton d'accès basé sur le nom d'utilisateur et le mot de passe LDAP. Il génère une chaîne codée en base 64 correspondant au jeton d'accès physique. Utilisez votre client S3 favori (voir <xref linkend="accessing.ragos.gateway"/>) et spécifiez le jeton en tant que clé d'accès ainsi qu'une clé secrète vide.
   </para>
<screen><prompt>root@minion &gt; </prompt>export RGW_ACCESS_KEY_ID="<replaceable>username</replaceable>"
<prompt>root@minion &gt; </prompt>export RGW_SECRET_ACCESS_KEY="<replaceable>password</replaceable>"
<prompt>root@minion &gt; </prompt>radosgw-token --encode --ttype=ldap</screen>
   <important>
    <title>informations d'identification en texte clair</title>
    <para>
     Le jeton d'accès est une structure JSON codée en base 64 qui contient les informations d'identification LDAP en texte clair.
    </para>
   </important>
   <note>
    <title>Active Directory</title>
    <para>
     Pour Active Directory, utilisez le paramètre <option>--ttype=ad</option>.
    </para>
   </note>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw.bucket_sharding">
  <title>Partitionnement d'index de compartiment</title>

  <para>
   Object Gateway stocke les données d'index de compartiment dans une réserve d'index, par défaut <literal>.rgw.buckets.index</literal>. Si vous placez trop d'objets (plusieurs centaines de milliers) dans un même compartiment et que le quota du nombre maximal d'objets par compartiment (<option>rgw bucket default quota max objects</option>) n'est pas défini, les performances de la réserve d'index risquent de se dégrader. Le <emphasis>partitionnement d'index de compartiment</emphasis> maintient le niveau de performances et autorise un nombre élevé d'objets par compartiment.
  </para>

  <sect2 xml:id="ogw.bucket_reshard">
   <title>Repartitionnement d'index de compartiment</title>
   <para>
    Si un compartiment est devenu volumineux et que sa configuration initiale n'est plus suffisante, la réserve d'index du compartiment doit être redéfinie. Vous pouvez soit utiliser le repartitionnement d'index de compartiment en ligne automatique (voir la <xref linkend="ogw.bucket_sharding.dyn"/>) soit repartitionner l'index de compartiment hors ligne manuellement (voir la <xref linkend="ogw.bucket_sharding.re"/>).
   </para>
   <sect3 xml:id="ogw.bucket_sharding.dyn">
    <title>Repartitionnement dynamique</title>
    <para>
     Depuis la version 5 de SUSE Enterprise Storage, le repartitionnement de compartiments en ligne est pris en charge. Il vérifie si le nombre d'objets par compartiment atteint un certain seuil et augmente automatiquement le nombre de partitions utilisées par l'index de compartiment. Ce processus réduit le nombre d'entrées dans chaque partition d'index de compartiment.
    </para>
    <para>
     Le processus de détection s'exécute :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Lorsque les nouveaux objets sont ajoutés au compartiment.
      </para>
     </listitem>
     <listitem>
      <para>
       Dans un processus d'arrière-plan qui analyse périodiquement tous les compartiments. Cela est nécessaire pour traiter les compartiments existants qui ne sont pas mis à jour.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Un compartiment devant être partitionné est ajouté à la file d'attente <option>reshard_log</option> en vue de son traitement ultérieur. Les threads de repartitionnement s'exécutent en arrière-plan et effectuent un repartitionnement planifié à la fois.
    </para>
    <variablelist>
     <title>Configuration du repartitionnement dynamique</title>
     <varlistentry>
      <term><option>rgw_dynamic_resharding</option>
      </term>
      <listitem>
       <para>
        Active ou désactive le repartitionnement dynamique d'index de compartiment. Les valeurs admises sont « true » ou « false ». La valeur par défaut est « true ».
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_num_logs</option>
      </term>
      <listitem>
       <para>
        Nombre de partitions pour le journal de repartitionnement. La valeur par défaut est 16.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_bucket_lock_duration</option>
      </term>
      <listitem>
       <para>
        Durée de verrouillage sur l'objet Compartiment pendant le repartitionnement. La valeur par défaut est de 120 secondes.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_max_objs_per_shard</option>
      </term>
      <listitem>
       <para>
        Nombre maximal d'objets par partition d'index de compartiment. La valeur par défaut est de 100 000 objets.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_thread_interval</option>
      </term>
      <listitem>
       <para>
        Durée maximale entre deux exécutions du repartitionnement de threads. La valeur par défaut est de 600 secondes.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <important>
     <title>configurations multisites</title>
     <para>
      Le partitionnement dynamique n'est pas pris en charge dans un environnement multisite. Il est désactivé par défaut depuis la version 12.2.2 de Ceph, mais il est recommandé de vérifier le paramètre.
     </para>
    </important>
    <variablelist>
     <title>Commandes d'administration du processus de repartitionnement</title>
     <varlistentry>
      <term>Ajouter un compartiment à la file d'attente du repartitionnement :</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard add \
 --bucket <replaceable>BUCKET_NAME</replaceable> \
 --num-shards <replaceable>NEW_NUMBER_OF_SHARDS</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Dresser la liste de la file d'attente de repartitionnement :</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard list
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Traiter/planifier un repartitionnement de compartiment :</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard process
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Afficher l'état du repartitionnement de compartiment :</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard status --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Annuler la mise en attente du repartitionnement de compartiment :</term>
      <listitem>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin reshard cancel --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ogw.bucket_sharding.re">
    <title>Repartitionnement manuel</title>
    <para>
     Le repartitionnement dynamique mentionné à la <xref linkend="ogw.bucket_sharding.dyn"/> est pris en charge uniquement pour les configurations Object Gateway simples. Pour les configurations multisites, utilisez le repartitionnement manuel décrit dans cette section.
    </para>
    <para>
     Pour repartitionner l'index de compartiment manuellement hors ligne, utilisez la commande suivante :
    </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bucket reshard
</screen>
    <para>
     La commande <command>bucket reshard</command> effectue les opérations suivantes :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Elle crée un nouvel ensemble d'objets d'index de compartiment pour l'objet spécifié.
      </para>
     </listitem>
     <listitem>
      <para>
       Elle propage toutes les entrées d'objets de ces objets d'index.
      </para>
     </listitem>
     <listitem>
      <para>
       Elle crée une nouvelle instance de compartiment.
      </para>
     </listitem>
     <listitem>
      <para>
       Elle lie la nouvelle occurrence de compartiment au compartiment afin que toutes les nouvelles opérations d'index passent par les nouveaux index de compartiment.
      </para>
     </listitem>
     <listitem>
      <para>
       Elle copie l'ancien ID et le nouvel ID de compartiment vers la sortie standard.
      </para>
     </listitem>
    </itemizedlist>
    <procedure>
     <title>Repartitionnement de la réserve d'index de compartiment</title>
     <step>
      <para>
       Assurez-vous que toutes les opérations à effectuer dans le compartiment sont bien arrêtées.
      </para>
     </step>
     <step>
      <para>
       Sauvegardez l'index de compartiment original :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bi list \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 &gt; <replaceable>BUCKET_NAME</replaceable>.list.backup
</screen>
     </step>
     <step>
      <para>
       Repartitionnez l'index de compartiment :
      </para>
<screen>
 <prompt>root@minion &gt; </prompt>radosgw-admin reshard \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 --num-shards=<replaceable>NEW_SHARDS_NUMBER</replaceable>
</screen>
      <tip>
       <title>ancien ID de compartiment</title>
       <para>
        Dans le cadre de sa sortie, cette commande affiche également le nouvel ID et l'ancien ID du compartiment. Notez l'ancien ID de compartiment, car vous en aurez besoin pour purger les anciens objets d'index du compartiment.
       </para>
      </tip>
     </step>
     <step>
      <para>
       Vérifiez que les objets sont répertoriés correctement en comparant la liste d'index de l'ancien compartiment à celle du nouveau compartiment. Purgez ensuite les anciens objets d'index de compartiment :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin bi purge
 --bucket=<replaceable>BUCKET_NAME</replaceable>
 --bucket-id=<replaceable>OLD_BUCKET_ID</replaceable>
</screen>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw.bucket_sharding.new">
   <title>Partitionnement d'index de compartiment pour les nouveaux compartiments</title>
   <para>
    Deux options affectent le partitionnement d'index de compartiment :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Utilisez l'option <option>rgw_override_bucket_index_max_shards</option> pour les configurations simples.
     </para>
    </listitem>
    <listitem>
     <para>
      Utilisez l'option <option>bucket_index_max_shards</option> pour les configurations multisites.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Définir les options sur <literal>0</literal> désactive le partitionnement d'index de compartiment. Une valeur supérieure à <literal>0</literal> active le partitionnement d'index de compartiment et définit le nombre maximal de partitions.
   </para>
   <para>
    La formule suivante permet de calculer le nombre recommandé de partitions :
   </para>
<screen>
number_of_objects_expected_in_a_bucket / 100000
</screen>
   <para>
    Sachez que le nombre maximal de partitions est 7877.
   </para>
   <sect3>
    <title>Configurations simples</title>
    <procedure>
     <step>
      <para>
       Ouvrez le fichier de configuration Ceph et ajoutez ou modifiez l'option suivante :
      </para>
<screen>
rgw_override_bucket_index_max_shards = 12
</screen>
      <tip>
       <title>toutes les instances Object Gateway ou une seule</title>
       <para>
        Pour configurer le partitionnement d'index de compartiment pour toutes les instances Object Gateway, incluez <option>rgw_override_bucket_index_max_shards</option> dans la section <literal>[global]</literal>.
       </para>
       <para>
        Pour configurer le partitionnement d'index de compartiment pour une instance Object Gateway en particulier, incluez <option>rgw_override_bucket_index_max_shards</option> dans la section de l'instance correspondante.
       </para>
      </tip>
     </step>
     <step>
      <para>
       Redémarrez la passerelle Object Gateway. Pour plus d'informations, reportez-vous à la <xref linkend="ceph.rgw.operating"/>.
      </para>
     </step>
    </procedure>
   </sect3>
   <sect3>
    <title>Configurations multisites</title>
    <para>
     Les configurations multisites peuvent disposer d'une réserve d'index différente pour gérer le basculement. Pour configurer un nombre de partitions cohérent pour les zones d'un groupe de zones, définissez l'option <option>bucket_index_max_shards</option> dans la configuration du groupe de zones :
    </para>
    <procedure>
     <step>
      <para>
       Exportez la configuration du groupe de zones dans le fichier <filename>zonegroup.json</filename> :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin zonegroup get &gt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Modifiez le fichier <filename>zonegroup.json</filename> et définissez l'option <option>bucket_index_max_shards</option> pour chaque zone nommée.
      </para>
     </step>
     <step>
      <para>
       Réinitialisez le groupe de zones :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin zonegroup set &lt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Mettez à jour la période :
      </para>
<screen>
<prompt>root@minion &gt; </prompt>radosgw-admin period update --commit
</screen>
     </step>
    </procedure>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw.keystone">
  <title>Intégration d'OpenStack Keystone</title>

  <para>
   OpenStack Keystone est un service d'identité pour le produit OpenStack. Vous pouvez intégrer la passerelle Object Gateway à Keystone pour configurer une passerelle qui accepte un jeton d'authentification Keystone. Un utilisateur autorisé par Keystone à accéder à la passerelle est vérifié du côté de Ceph Object Gateway et créé automatiquement, si nécessaire. Object Gateway interroge Keystone périodiquement pour obtenir la liste des jetons révoqués.
  </para>

  <sect2 xml:id="ogw.keystone.ostack">
   <title>Configuration d'OpenStack</title>
   <para>
    Avant de configurer la passerelle Ceph Object Gateway, vous devez configurer OpenStack Keystone afin d'activer le service Swift et de le faire pointer vers la passerelle Ceph Object Gateway :
   </para>
   <procedure>
    <step>
     <para>
      <emphasis>Définissez le service Swift.</emphasis> Pour utiliser OpenStack en vue de la validation des utilisateurs Swift, créez d'abord le service Swift :
     </para>
<screen>
<prompt>root # </prompt>openstack service create \
 --name=swift \
 --description="Swift Service" \
 object-store
</screen>
    </step>
    <step>
     <para>
      <emphasis>Définissez les noeuds d'extrémité.</emphasis> Après avoir créé le service Swift, pointez vers la passerelle Ceph Object Gateway. Remplacez <replaceable>REGION_NAME</replaceable> par le nom du groupe de zones ou le nom de la région de la passerelle.
     </para>
<screen>
<prompt>root # </prompt>openstack endpoint create --region <replaceable>REGION_NAME</replaceable> \
 --publicurl   "http://radosgw.example.com:8080/swift/v1" \
 --adminurl    "http://radosgw.example.com:8080/swift/v1" \
 --internalurl "http://radosgw.example.com:8080/swift/v1" \
 swift
</screen>
    </step>
    <step>
     <para>
      <emphasis>Vérifiez les paramètres.</emphasis> Après avoir créé le service Swift et défini les noeuds d'extrémité, affichez ceux-ci pour vérifier que tous les paramètres sont corrects.
     </para>
<screen>
<prompt>root # </prompt>openstack endpoint show object-store
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw.keystone.ogw">
   <title>Configuration de la passerelle Ceph Object Gateway</title>
   <sect3>
    <title>Configuration des certificats SSL</title>
    <para>
     Ceph Object Gateway interroge Keystone périodiquement pour obtenir la liste des jetons révoqués. Ces requêtes sont codées et signées. Il est également possible de configurer Keystone pour fournir des jetons signés automatiquement, qui sont aussi codés et signés. Vous devez configurer la passerelle afin qu'elle puisse décoder et vérifier ces messages signés. Par conséquent, les certificats OpenSSL que Keystone utilise pour créer les requêtes doivent être convertis au format « nss db » :
    </para>
<screen>
<prompt>root # </prompt>mkdir /var/ceph/nss
<prompt>root # </prompt>openssl x509 -in /etc/keystone/ssl/certs/ca.pem \
 -pubkey | certutil -d /var/ceph/nss -A -n ca -t "TCu,Cu,Tuw"
<systemitem class="username">root</systemitem>openssl x509 -in /etc/keystone/ssl/certs/signing_cert.pem \
 -pubkey | certutil -A -d /var/ceph/nss -n signing_cert -t "P,P,P"
</screen>
    <para>
     Pour permettre à la passerelle Ceph Object Gateway d'interagir avec OpenStack Keystone, OpenStack Keystone peut également utiliser un certificat SSL auto-signé. Installez le certificat SSL de Keystone sur le noeud exécutant Ceph Object Gateway ou définissez l'option <option>rgw keystone verify ssl</option> sur « false ». Définir <option>rgw keystone verify ssl</option> sur « false » signifie que la passerelle ne tentera pas de vérifier le certificat.
    </para>
   </sect3>
   <sect3>
    <title>Configuration des options de la passerelle Object Gateway</title>
    <para>
     Vous pouvez configurer l'intégration de Keystone à l'aide des options suivantes :
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone api version</option>
      </term>
      <listitem>
       <para>
        Version de l'API Keystone. Les options valides sont 2 ou 3. La valeur par défaut est 2.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone url</option>
      </term>
      <listitem>
       <para>
        URL et numéro de port de l'API RESTful d'administration sur le serveur Keystone. Suit le modèle <replaceable>URL_SERVEUR:NUMÉRO_PORT</replaceable>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin token</option>
      </term>
      <listitem>
       <para>
        Jeton ou secret partagé qui est configuré en interne dans Keystone pour les requêtes d'administration.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted roles</option>
      </term>
      <listitem>
       <para>
        Rôles nécessaires pour répondre aux requêtes. Par défaut « Member, admin ».
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted admin roles</option>
      </term>
      <listitem>
       <para>
        Liste des rôles autorisant un utilisateur à obtenir des privilèges d'administration.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone token cache size</option>
      </term>
      <listitem>
       <para>
        Nombre maximal d'entrées dans le cache de jetons Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone revocation interval</option>
      </term>
      <listitem>
       <para>
        Nombre de secondes avant le contrôle de jetons révoqués. Par défaut, 15 * 60.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone implicit tenants</option>
      </term>
      <listitem>
       <para>
        Créez des utilisateurs dans leurs locataires du même nom. La valeur par défaut est « false ».
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw s3 auth use keystone</option>
      </term>
      <listitem>
       <para>
        Si ce paramètre est défini sur « false », Ceph Object Gateway authentifie les utilisateurs à l'aide de Keystone. La valeur par défaut est « false ».
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>nss db path</option>
      </term>
      <listitem>
       <para>
        Chemin d'accès à la base de données NSS.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Il est également possible de configurer le locataire du service Keystone, le nom d'utilisateur et le mot de passe Keystone (la version 2.0 de l'API Identity OpenStack) d'une façon similaire aux services OpenStack. De cette façon, vous pouvez éviter de définir le secret partagé <option>rgw keystone admin token</option> dans le fichier de configuration, qui doit être désactivé dans les environnements de production. Les informations d'identification du client de service doivent posséder des privilèges d'administrateur. Pour plus de détails, reportez-vous à la <link xlink:href="https://docs.openstack.org/keystone/latest/#setting-up-projects-users-and-roles">documentation officielle OpenStack Keystone</link>. Les options de configuration associées sont les suivantes :
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin user</option>
      </term>
      <listitem>
       <para>
        Nom d'utilisateur de l'administrateur Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin password</option>
      </term>
      <listitem>
       <para>
        Mot de passe de l'administrateur Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin tenant</option>
      </term>
      <listitem>
       <para>
        Locataire de l'utilisateur administrateur Keystone version 2.0.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Un utilisateur Ceph Object Gateway est assigné à un locataire Keystone. Un utilisateur Keystone possède des rôles qui lui sont assignés, sur plusieurs locataires, le cas échéant. Lorsque la passerelle Ceph Object Gateway reçoit le ticket, elle examine le locataire et les rôles utilisateur qui lui sont attribués, et elle accepte ou rejette la demande en fonction de la valeur de l'option <option>rgw keystone accepted roles</option>.
    </para>
    <tip>
     <title>assignation aux locataires OpenStack</title>
     <para>
      Les locataires Swift sont assignés à l'utilisateur Object Gateway par défaut, mais peuvent l'être également aux locataires OpenStack grâce à l'option <option>rgw keystone implicit tenants</option>. Les conteneurs utiliseront alors l'espace de noms du locataire à la place de l'espace de noms global S3 associé par défaut à Object Gateway. Il est recommandé de choisir la méthode d'assignation au stade de la planification afin d'éviter toute confusion. L'affectation ultérieure de l'option concerne uniquement les requêtes plus récentes qui sont alors assignées sous un locataire, alors que les compartiments créés précédemment continuent à résider dans un espace de noms global.
     </para>
    </tip>
    <para>
     Pour la version 3 de l'API Identity OpenStack, vous devez remplacer l'option <option>rgw keystone admin tenant</option> par :
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin domain</option>
      </term>
      <listitem>
       <para>
        Domaine de l'utilisateur administrateur Keystone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin project</option>
      </term>
      <listitem>
       <para>
        Projet de l'utilisateur administrateur Keystone.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rgw.fed">


  <title>Passerelles Object Gateway multisites</title>

  <variablelist>
   <varlistentry>
    <term>Zone</term>
    <listitem>
     <para>
      Regroupement logique d'une ou de plusieurs instances Object Gateway. Une seule zone doit être désignée comme zone maître (<emphasis>master</emphasis>) dans un groupe de zones (<emphasis>zonegroup</emphasis>), qui gère toute la création des compartiments et des utilisateurs.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Groupe de zone</term>
    <listitem>
     <para>
      Un groupe de zones (« zonegroup ») se compose de plusieurs zones. Un groupe de zones maître doit gérer les modifications de la configuration système.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Assignation de groupes de zones</term>
    <listitem>
     <para>
      Une structure de configuration qui contient l'assignation de l'ensemble du système, par exemple quel est le groupe de zones maître, quelles sont les relations entre les différents groupes de zones, et certaines options de configuration, telles que les stratégies de stockage.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Domaine Kerberos</term>
    <listitem>
     <para>
      Conteneur de groupes de zones. Cela permet de séparer les groupes de zones entre les grappes. Il est possible de créer plusieurs domaines Kerberos, ce qui facilite l'exécution de configurations complètement différentes dans la même grappe.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Période</term>
    <listitem>
     <para>
      Une période contient la structure de configuration pour l'état actuel du domaine Kerberos. Chaque période contient un ID unique et une époque. Chaque domaine Kerberos possède une période en cours associée qui contient l'état actuel de la configuration des stratégies de stockage et de groupes de zone. Tout changement de configuration pour une zone non-maître incrémentera l'époque pour la période. La définition de la zone maître sur une zone différente déclenche les modifications suivantes :
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Une nouvelle période est générée avec un nouvel ID de période et une époque de 1.
       </para>
      </listitem>
      <listitem>
       <para>
        La période actuelle du domaine Kerberos est mise à jour afin de pointer vers l'ID de période nouvellement généré.
       </para>
      </listitem>
      <listitem>
       <para>
        L'époque du domaine Kerberos est incrémentée.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Vous pouvez configurer chaque passerelle Objet Gateway pour qu'elle participe à une architecture fédérée, en travaillant dans une configuration de zone active tout en permettant les écritures dans des zones non-maîtres.
  </para>

  <sect2 xml:id="ceph.rgw.fed.term">
   <title>Terminologie</title>
   <para>
    Vous trouverez ci-dessous une description des termes spécifiques à une architecture fédérée :
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.intro">
   <title>Exemple de configuration de grappe</title>
   <para>
    Dans cet exemple, nous allons nous intéresser à la création d'un groupe de zones unique avec trois zones distinctes qui synchronisent activement leurs données. Deux zones appartiennent à la même grappe, tandis que la troisième appartient à une autre. Aucun agent de synchronisation n'est impliqué dans la mise en miroir des modifications de données entre les passerelles Objet Gateway. Cela permet d'avoir un schéma de configuration beaucoup plus simple et des configurations actives-actives. Notez que les opérations de métadonnées, telles que la création d'un utilisateur, doivent toujours passer par la zone maître. Cependant, les opérations de données, telles que la création de compartiments et d'objets, peuvent être gérées par n'importe laquelle des zones.
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.keys">
   <title>Clés système</title>
   <para>
    Lors de la configuration des zones, Object Gateway attend la création d'un utilisateur système compatible avec S3 avec ses clés d'accès et clés secrètes. Cela permet à une autre instance Object Gateway d'extraire la configuration à distance avec les clés d'accès et les clés secrètes. Pour plus d'informations sur la création d'utilisateurs S3, reportez-vous à la <xref linkend="adding.s3.swift.users"/>.
   </para>
   <tip>
    <para>
     Il est utile de générer les clés d'accès et les clés secrètes avant la création de la zone, car cela facilite la création de scripts et l'utilisation des outils de gestion de la configuration. 
    </para>
   </tip>
   <para>
    Pour les besoins de cet exemple, supposons que les clés d'accès et les clés secrètes sont définies dans les variables d'environnement :
   </para>
<screen># SYSTEM_ACCESS_KEY=1555b35654ad1656d805
# SYSTEM_SECRET_KEY=h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q==</screen>
   <para>
    Généralement, les clés d'accès sont constituées de 20 caractères alphanumériques alors que les clés secrètes sont composées de 40 caractères alphanumériques (elles peuvent également contenir des caractères +/=). Vous pouvez générer ces clés sur la ligne de commande :
   </para>
<screen># SYSTEM_ACCESS_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 20 | head -n 1)
# SYSTEM_SECRET_KEY=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 40 | head -n 1)</screen>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.naming">
   <title>Conventions de dénomination</title>
   <para>
    Cet exemple décrit le processus de configuration d'une zone maître. Prenons un groupe de zones appelé <literal>us</literal> couvrant les États-Unis, qui sera notre groupe de zones maître. Il contient deux zones définies dans le format <replaceable>groupe_zones</replaceable>-<replaceable>zone</replaceable>. Il s'agit seulement de notre convention de format : vous êtes libre de choisir le format qui vous convient. En résumé :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Groupe de zones maître : États-Unis <literal>us</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zone maître : États-Unis, région Est 1 : <literal>us-east-1</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zone secondaire : États-Unis, région Est 2 : <literal>us-east-2</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      Zone secondaire : États-Unis, région Ouest : <literal>us-west</literal>
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Il s'agit d'une partie d'un domaine Kerberos plus vaste dénommé <literal>gold</literal>. Les zones <literal>us-east-1</literal> et <literal>us-east-2</literal> appartiennent à la même grappe Ceph, <literal>us-east-1</literal> étant la zone primaire. <literal>us-west</literal> réside dans une autre grappe Ceph.
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.pools">
   <title>Réserves par défaut</title>
   <para>
    Lorsqu'elle est configurée avec les autorisations appropriées, la passerelle Object Gateway crée ses propres réserves par défaut. Les valeurs de <literal>pg_num</literal> et <literal>pgp_num</literal> proviennent du fichier de configuration <filename>ceph.conf</filename>. Les réserves liées à une zone par défaut suivent la convention <replaceable>zone-name</replaceable>.<replaceable>pool-name</replaceable> (nom_zone.nom_réserve). Par exemple, pour la zone <literal>us-east-1</literal>, il s'agira des réserves suivantes :
   </para>
<screen>.rgw.root
us-east-1.rgw.control
us-east-1.rgw.data.root
us-east-1.rgw.gc
us-east-1.rgw.log
us-east-1.rgw.intent-log
us-east-1.rgw.usage
us-east-1.rgw.users.keys
us-east-1.rgw.users.email
us-east-1.rgw.users.swift
us-east-1.rgw.users.uid
us-east-1.rgw.buckets.index
us-east-1.rgw.buckets.data
us-east-1.rgw.meta</screen>
   <para>
    Ces réserves peuvent être créées dans d'autres zones, en remplaçant <literal>us-east-1</literal> par le nom de zone approprié.
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.realm">
   <title>Création d'un domaine Kerberos</title>
   <para>
    Configurez un domaine Kerberos appelé <literal>gold</literal> et définissez-le en tant que domaine Kerberos par défaut :
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin realm create --rgw-realm=gold --default
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "epoch": 1
}</screen>
   <para>
    Notez que chaque domaine Kerberos possède un ID, ce qui offre une certaine flexibilité, par exemple si vous renommez le domaine Kerberos ultérieurement, le cas échéant. La valeur de <literal>current_period</literal> change à chaque fois que nous apportons une modification dans la zone maître. La valeur <literal>epoch</literal> est incrémentée en cas de modification de la configuration de la zone maître qui entraîne un changement de la période en cours.
   </para>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.deldefzonegrp">
   <title>Suppression du groupe de zones par défaut</title>
   <para>
    L'installation par défaut d'Object Gateway crée le groupe de zones par défaut appelé <literal>default</literal>. Supprimez ce groupe de zones par défaut, car il est à présent inutile.
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup delete --rgw-zonegroup=default</screen>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.createmasterzonegrp">
   <title>Création d'un groupe de zones maître</title>
   <para>
    Créez un groupe de zones maître appelé <literal>us</literal>. Le groupe de zones gérera l'assignation de groupe de zones et propagera les modifications au reste du système. En marquant le groupe de zones comme groupe de zones par défaut, vous autorisez explicitement les commandes ultérieures à mentionner le paramètre rgw-zonegroup.
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup create --rgw-zonegroup=us \
--endpoints=http://rgw1:80 --master --default
{
  "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "name": "us",
  "api_name": "us",
  "is_master": "true",
  "endpoints": [
      "http:\/\/rgw1:80"
  ],
  "hostnames": [],
  "hostnames_s3website": [],
  "master_zone": "",
  "zones": [],
  "placement_targets": [],
  "default_placement": "",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   <para>
    Vous pouvez également marquer un groupe de zones comme valeur par défaut avec la commande suivante :
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup default --rgw-zonegroup=us</screen>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.masterzone">
   <title>Création d'une zone maître</title>
   <para>
    À présent, créez une zone par défaut et ajoutez-la au groupe de zones par défaut. Notez que vous utiliserez cette zone pour les opérations de métadonnées, telles que la création d'utilisateur :
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 \
--endpoints=http://rgw1:80 --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "name": "us-east-1",
  "domain_root": "us-east-1/gc.rgw.data.root",
  "control_pool": "us-east-1/gc.rgw.control",
  "gc_pool": "us-east-1/gc.rgw.gc",
  "log_pool": "us-east-1/gc.rgw.log",
  "intent_log_pool": "us-east-1/gc.rgw.intent-log",
  "usage_log_pool": "us-east-1/gc.rgw.usage",
  "user_keys_pool": "us-east-1/gc.rgw.users.keys",
  "user_email_pool": "us-east-1/gc.rgw.users.email",
  "user_swift_pool": "us-east-1/gc.rgw.users.swift",
  "user_uid_pool": "us-east-1/gc.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-1/gc.rgw.buckets.index",
              "data_pool": "us-east-1/gc.rgw.buckets.data",
              "data_extra_pool": "us-east-1/gc.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-1/gc.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   <para>
    Notez que les paramètres <option>--rgw zonegroup</option> et <option>--default</option> ajoutent la zone à un groupe de zones et la définissent comme zone par défaut. Les commandes suivantes permettent également de parvenir au même résultat :
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone default --rgw-zone=us-east-1
<prompt>cephadm &gt; </prompt>radosgw-admin zonegroup add --rgw-zonegroup=us --rgw-zone=us-east-1</screen>
   <sect3 xml:id="ceph.rgw.fed.masterzone.createuser">
    <title>Création d'utilisateurs système</title>
    <para>
     Pour accéder aux réserves de zones, vous devez créer un utilisateur système. Notez que vous aurez besoin de ces clés lors de la configuration de la zone secondaire. 
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin user create --uid=zone.user \
--display-name="Zone User" --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> \
--secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable> --system</screen>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.masterzone.updateperiod">
    <title>Mise à jour de la période</title>
    <para>
     Comme vous avez modifié la configuration de la zone maître, vous devez valider les modifications pour qu'elles prennent effet dans la structure de configuration du domaine Kerberos. Initialement, la période ressemble à ceci :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period get
{
  "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "epoch": 1, "predecessor_uuid": "", "sync_status": [], "period_map":
  {
    "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "zonegroups": [], "short_zone_ids": []
  }, "master_zonegroup": "", "master_zone": "", "period_config":
  {
     "bucket_quota": {
     "enabled": false, "max_size_kb": -1, "max_objects": -1
     }, "user_quota": {
       "enabled": false, "max_size_kb": -1, "max_objects": -1
     }
  }, "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7", "realm_name": "gold", "realm_epoch": 1
}</screen>
    <para>
     Mettez à jour la période et validez les modifications :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 1,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.masterzone.startrgw">
    <title>Démarrage de la passerelle Object Gateway</title>
    <para>
     Avant de démarrer Object Gateway, vous devez mentionner les options de zone et de port Object Gateway dans le fichier de configuration. Pour plus d'informations sur Object Gateway et sa configuration, reportez-vous au <xref linkend="cha.ceph.gw"/>. La section relative à la configuration d'Object Gateway doit ressembler à ceci :
    </para>
<screen>[client.rgw.us-east-1]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-1</screen>
    <para>
     Démarrez la passerelle Object Gateway :
    </para>
<screen>sudo systemctl start ceph-radosgw@rgw.us-east-1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.secondaryzone">
   <title>Création d'une zone secondaire</title>
   <para>
    Dans la même grappe, créez et configurez la zone secondaire <literal>us-east-2</literal>. Vous pouvez exécuter toutes les commandes suivantes dans le noeud qui héberge la zone maître elle-même.
   </para>
   <para>
    Pour créer la zone secondaire, utilisez la même commande que lors de la création de la zone primaire, mais sans la suppression de l'indicateur maître :
   </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --endpoints=http://rgw2:80 \
--rgw-zone=us-east-2 --access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-east-2",
  "domain_root": "us-east-2.rgw.data.root",
  "control_pool": "us-east-2.rgw.control",
  "gc_pool": "us-east-2.rgw.gc",
  "log_pool": "us-east-2.rgw.log",
  "intent_log_pool": "us-east-2.rgw.intent-log",
  "usage_log_pool": "us-east-2.rgw.usage",
  "user_keys_pool": "us-east-2.rgw.users.keys",
  "user_email_pool": "us-east-2.rgw.users.email",
  "user_swift_pool": "us-east-2.rgw.users.swift",
  "user_uid_pool": "us-east-2.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-2.rgw.buckets.index",
              "data_pool": "us-east-2.rgw.buckets.data",
              "data_extra_pool": "us-east-2.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-2.rgw.meta",
  "realm_id": "815d74c2-80d6-4e63-8cfc-232037f7ff5c"
}</screen>
   <sect3 xml:id="ceph.rgw.fed.secondzone.updateperiod">
    <title>Mise à jour de la période</title>
    <para>
     Informez toutes les passerelles de la nouvelle modification de l'assignation système en effectuant une mise à jour de période et en appliquant les modifications :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }

              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          }

      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.secondzone.startrgw">
    <title>Démarrage de la passerelle Object Gateway</title>
    <para>
     Ajustez la configuration de la passerelle Object Gateway pour la zone secondaire, puis démarrez Object Gateway :
    </para>
<screen>[client.rgw.us-east-2]
rgw_frontends="civetweb port=80"
rgw_zone=us-east-2</screen>
<screen><prompt>cephadm &gt; </prompt>sudo systemctl start ceph-radosgw@rgw.us-east-2</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.seccluster">
   <title>Ajout d'Object Gateway à la deuxième grappe</title>
   <para>
    La deuxième grappe Ceph appartient au même groupe de zones que la grappe initiale, mais peut se trouver dans un autre lieu géographique.
   </para>
   <sect3 xml:id="ceph.rgw.fed.seccluster.realm">
    <title>Groupe de zones et domaine Kerberos par défaut</title>
    <para>
     Comme vous avez déjà créé le domaine Kerberos pour la première passerelle, extrayez-le ici pour le définir comme domaine par défaut :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin realm pull --url=http://rgw1:80 \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable>
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2
}
<prompt>cephadm &gt; </prompt>radosgw-admin realm default --rgw-realm=gold</screen>
    <para>
     Extrayez la période pour obtenir la configuration de la zone maître :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period pull --url=http://rgw1:80 \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable></screen>
    <para>
     Définissez le groupe de zones par défaut sur le groupe de zones <literal>us</literal> créé précédemment :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zonegroup default --rgw-zonegroup=us</screen>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.seccluster.seczone">
    <title>Configuration de zone secondaire</title>
    <para>
     Créez une nouvelle zone nommée <literal>us-west</literal> avec les mêmes clés système :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-west \
--access-key=<replaceable>$SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>$SYSTEM_SECRET_KEY</replaceable> \
--endpoints=http://rgw3:80 --default
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-west",
  "domain_root": "us-west.rgw.data.root",
  "control_pool": "us-west.rgw.control",
  "gc_pool": "us-west.rgw.gc",
  "log_pool": "us-west.rgw.log",
  "intent_log_pool": "us-west.rgw.intent-log",
  "usage_log_pool": "us-west.rgw.usage",
  "user_keys_pool": "us-west.rgw.users.keys",
  "user_email_pool": "us-west.rgw.users.email",
  "user_swift_pool": "us-west.rgw.users.swift",
  "user_uid_pool": "us-west.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-west.rgw.buckets.index",
              "data_pool": "us-west.rgw.buckets.data",
              "data_extra_pool": "us-west.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-west.rgw.meta",
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.seccluster.period">
    <title>Mise à jour de la période</title>
    <para>
     Pour propager les modifications de l'assignation de groupe de zones, nous mettons à jour la période, puis nous la validons :
    </para>
<screen><prompt>cephadm &gt; </prompt>radosgw-admin period update --commit --rgw-zone=us-west
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 3,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [
      "", # truncated
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "d9522067-cb7b-4129-8751-591e45815b16",
                      "name": "us-west",
                      "endpoints": [
                          "http:\/\/rgw3:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }
              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          },
          {
              "key": "d9522067-cb7b-4129-8751-591e45815b16",
              "val": 329470157
          }
      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
    <para>
     Notez que le numéro d'époque est incrémenté, ce qui indique un changement dans la configuration.
    </para>
   </sect3>
   <sect3 xml:id="ceph.rgw.fed.seccluster.rgwstart">
    <title>Démarrage de la passerelle Object Gateway</title>
    <para>
     La procédure est similaire au démarrage de la passerelle Object Gateway dans la première zone, hormis le fait que la configuration de la zone Object Gateway doit comporter le nom de la zone <literal>us-west</literal> :
    </para>
<screen>[client.rgw.us-west]
rgw_frontends="civetweb port=80"
rgw_zone=us-west</screen>
    <para>
     Démarrez la deuxième passerelle Object Gateway :
    </para>
<screen>sudo systemctl start ceph-radosgw@rgw.us-west</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.rgw.fed.failover">
   <title>Basculement et reprise après sinistre</title>
   <para>
    Si la zone maître échoue, basculez vers la zone secondaire pour la reprise après sinistre.
   </para>
   <procedure>
    <step>
     <para>
      Faites de la zone secondaire la zone maître et la zone par défaut. Par exemple :
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default
     </screen>
     <para>
      Par défaut, Ceph Object Gateway s'exécutera dans une configuration active-active. Si la grappe a été configurée pour s'exécuter dans une configuration active-passive, la zone secondaire est une zone en lecture seule. Retirez l'état --read-only pour autoriser la zone à recevoir les opérations d'écriture. Par exemple :
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default \
--read-only=False
     </screen>
    </step>
    <step>
     <para>
      Mettez à jour la période pour que les modifications prennent effet.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      Enfin, redémarrez la passerelle Ceph Object Gateway.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
   </procedure>
   <para>
    En cas de reprise de la zone maître précédente, annulez l'opération.
   </para>
   <procedure>
    <step>
     <para>
      Depuis la zone récupérée, extrayez la période de la zone maître actuelle.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period pull --url={url-to-master-zone-gateway} \
--access-key={access-key} --secret={secret}
     </screen>
    </step>
    <step>
     <para>
      Faites de la zone récupérée la zone maître et la zone par défaut.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --master --default
     </screen>
    </step>
    <step>
     <para>
      Mettez à jour la période pour que les modifications prennent effet.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      Redémarrez ensuite la passerelle Ceph Object Gateway dans la zone récupérée.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
    <step>
     <para>
      Si la zone secondaire doit être une configuration en lecture seule, mettez à jour la zone secondaire.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> zone modify --rgw-zone={zone-name} --read-only
     </screen>
    </step>
    <step>
     <para>
      Mettez à jour la période pour que les modifications prennent effet.
     </para>
<screen>
<prompt>root # </prompt><command>radosgw-admin</command> period update --commit
     </screen>
    </step>
    <step>
     <para>
      Enfin, redémarrez la passerelle Ceph Object Gateway dans la zone secondaire.
     </para>
<screen>
<prompt>root # </prompt><command>systemctl</command> restart ceph-radosgw@rgw.`hostname -s`
     </screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw.haproxy">
  <title>Équilibrage de charge des serveurs Object Gateway avec HAProxy</title>

  <para>
   Vous pouvez utiliser l'équilibreur de charge HAProxy pour distribuer toutes les requêtes sur plusieurs serveurs dorsaux Object Gateway. Reportez-vous à la page <link xlink:href="https://www.suse.com/documentation/sle-ha-12/book_sleha/data/sec_ha_lb_haproxy.html"/> pour plus d'informations sur la configuration de HAProxy.
  </para>

  <para>
   Voici une configuration simple de HAProxy pour l'équilibrage des noeuds Object Gateway à l'aide de la méthode tourniquet en tant qu'algorithme d'équilibrage :
  </para>

<screen>
<prompt>root # </prompt>cat /etc/haproxy/haproxy.cfg
[...]
frontend <replaceable>https_frontend</replaceable>
bind *:443 crt <replaceable>path-to-cert.pem</replaceable> [ciphers: ... ]
default_backend rgw

backend rgw
mode http
balance roundrobin
server rgw_server1 <replaceable>rgw-endpoint1</replaceable> weight 1 maxconn 100 check
server rgw_server2 <replaceable>rgw-endpoint2</replaceable> weight 1 maxconn 100 check
[...]
</screen>
 </sect1>
</chapter>
