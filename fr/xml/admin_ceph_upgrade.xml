<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Mise à jour à partir de versions précédentes</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>modification</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>oui</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Ce chapitre présente les étapes requises pour mettre à niveau SUSE Enterprise Storage 5.5 vers la version 6. Notez qu'en fait, la version 5.5 est une version 5 avec tous les derniers correctifs appliqués.
 </para>
 <note>
  <title>la mise à niveau à partir de versions plus anciennes n'est pas prise en charge</title>
  <para>
   La mise à niveau des versions SUSE Enterprise Storage antérieures à la version 5.5 n'est pas prise en charge. Vous devez d'abord passer à la dernière version SUSE Enterprise Storage 5.5, puis suivre les étapes de ce chapitre.
  </para>
 </note>
 <sect1 xml:id="upgrade-consider-points">
  <title>Points à prendre en compte avant la mise à niveau</title>

  <itemizedlist>
   <listitem>
    <para>
     <emphasis>Lisez les notes de version</emphasis> : elles contiennent des informations supplémentaires sur les modifications apportées depuis la version précédente de SUSE Enterprise Storage. Consultez les notes de version pour vérifier les aspects suivants :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Votre matériel doit tenir compte de certaines considérations spéciales.
      </para>
     </listitem>
     <listitem>
      <para>
       Les paquetages logiciels utilisés ont été considérablement modifiés.
      </para>
     </listitem>
     <listitem>
      <para>
       Des précautions spéciales sont nécessaires pour votre installation.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Les notes de version incluent également des informations de dernière minute qui, faute de temps, n'ont pas pu être intégrées au manuel. Elles contiennent également des notes concernant les problèmes connus.
    </para>
    <para>
     Après avoir installé le paquetage <package>release-notes-ses</package>, les notes de version sont disponibles en local dans le répertoire <filename>/usr/share/doc/release-notes</filename> ou en ligne à l'adresse <link xlink:href="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Si vous avez au préalable effectué une mise à niveau à partir de la version 4, vérifiez que la mise à niveau vers la version 5 a bien abouti :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Vérifiez l'existence du fichier suivant :
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.import</screen>
      <para>
       Il est créé par le processus d'importation (« engulf ») au cours de la mise à niveau de SES 4 vers la version 5. En outre, l'option <option>configuration_init: default-import</option> est définie dans le fichier suivant :
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <para>
       Si l'option <option>configuration_init</option> reste définie sur <option>default-import</option>, la grappe utilise <filename>ceph.conf.import</filename> comme fichier de configuration, au lieu du fichier <filename>ceph.conf</filename> par défaut de DeepSea, qui est compilé à partir des fichiers dans le répertoire suivant :
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Par conséquent, vous devez rechercher les configurations personnalisées potentielles dans <filename>ceph.conf.import</filename> et, éventuellement, les déplacer dans l'un des fichiers du répertoire suivant :
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Ensuite, supprimez la ligne <option>configuration_init: default-import</option> du fichier suivant :
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <warning>
       <title>configuration par défaut de DeepSea</title>
       <para>
        Si vous ne fusionnez <emphasis role="bold">pas</emphasis> la configuration de <filename>ceph.conf.import</filename> et supprimez l'option <option>configuration_init: default-import</option>, tous les paramètres de configuration par défaut que nous transférons en tant que partie de DeepSea (stockés dans <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>) ne seront pas appliqués à la grappe.
       </para>
      </warning>
     </listitem>
     <listitem>
      <para>
       Vérifiez si la grappe utilise le nouveau type de compartiment « straw2 » :
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep straw
</screen>
     </listitem>
     <listitem>
      <para>
       Vérifiez que le profil « jewel » Ceph est utilisé :
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep profile
</screen>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     En cas d'utilisation d'anciens clients de kernel RBD (antérieurs à SUSE Linux Enterprise Server 12 SP3), reportez-vous au <xref linkend="rbd-old-clients-map"/>. Nous vous recommandons de mettre à niveau les anciens clients de kernel RBD si possible.
    </para>
   </listitem>
   <listitem>
    <para>
     Si openATTIC est situé sur le noeud Admin, il sera indisponible après avoir mis à niveau le noeud. Le nouveau tableau de bord Ceph Dashboard ne sera disponible que lorsque vous l'aurez déployé à l'aide de DeepSea.
    </para>
   </listitem>
   <listitem>
    <para>
     La mise à niveau de la grappe peut prendre beaucoup de temps : environ le temps nécessaire pour mettre à niveau une machine multiplié par le nombre de noeuds de la grappe.
    </para>
   </listitem>
   <listitem>
    <para>
     Un noeud unique ne peut pas être mis à niveau lors de l'exécution de la version précédente de SUSE Linux Enterprise Server, mais doit être redémarré dans le programme d'installation de la nouvelle version. Par conséquent, les services que le noeud fournit ne seront pas disponibles pendant un certain temps. Les services de grappe de base restent disponibles : par exemple, si un moniteur (MON) est arrêté pendant la mise à niveau, au moins deux autres moniteurs sont actifs. Malheureusement, les services à instance unique, tels qu'une passerelle iSCSI unique, ne sont pas disponibles.
    </para>
   </listitem>
   <listitem>
    <para>
     Certains types de daemons dépendent d'autres. Par exemple, les instances Ceph Object Gateway dépendent des daemons Ceph MON et Ceph OSD. Il est recommandé de mettre à niveau les différentes instances dans l'ordre suivant :
    </para>
    <orderedlist spacing="normal">
     <listitem>
      <para>
       Noeud Admin
      </para>
     </listitem>
     <listitem>
      <para>
       Instances Ceph Monitor/Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Serveurs de métadonnées (MDS)
      </para>
     </listitem>
     <listitem>
      <para>
       Instances Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Instances Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Passerelles iSCSI
      </para>
     </listitem>
     <listitem>
      <para>
       NFS Ganesha
      </para>
     </listitem>
     <listitem>
      <para>
       Passerelles Samba
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Si vous avez utilisé AppArmor en mode « complain » ou « enforce », vous devez définir une variable d'interface Pillar de Salt avant d'effectuer la mise à niveau. Étant donné que SUSE Linux Enterprise Server 15 SP1 est fourni avec AppArmor par défaut, la gestion AppArmor a été intégrée à la phase 0 de DeepSea. Le comportement par défaut dans SUSE Enterprise Storage 6 consiste à supprimer AppArmor et les profils associés. Si vous souhaitez conserver le comportement configuré dans SUSE Enterprise Storage 5.5, vérifiez que l'une des lignes suivantes est présente dans le fichier <filename>/srv/pillar/ceph/stack/global.yml</filename> avant de commencer la mise à niveau :
    </para>
<screen>
apparmor_init: default-enforce
</screen>
    <para>
     ou
    </para>
<screen>
apparmor_init: default-complain
</screen>
   </listitem>
   <listitem>
    <para>
     À partir de SUSE Enterprise Storage 6, les noms MDS commençant par un chiffre ne sont plus autorisés de sorte que les daemons MDS refuseront de démarrer. Vous pouvez vérifier si vos daemons portent ce type de noms soit en exécutant la commande <command>ceph fs status</command>, soit en redémarrant un MDS et en consultant ses journaux à la recherche du message suivant :
    </para>
<screen>
deprecation warning: MDS id 'mds.1mon1' is invalid and will be forbidden in
a future version.  MDS names may not start with a numeric digit.
</screen>
    <para>
     Si vous repérez le message susmentionné, les noms MDS doivent être migrés avant de tenter une mise à niveau vers SUSE Enterprise Storage 6. DeepSea fournit une orchestration pour automatiser une telle migration. Le système ajoutera « mds. » au début des noms MDS commençant par un chiffre :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.mds.migrate-numerical-names
</screen>
    <tip>
     <title>configuration personnalisée liée aux noms MDS</title>
     <para>
      Si vous avez des paramètres de configuration qui sont liés aux noms MDS et que vos daemons MDS portent des noms commençant par un chiffre, vérifiez que vos paramètres de configuration s'appliquent également aux nouveaux noms (avec le préfixe « mds. » ). Voici un exemple de section dans le fichier <filename>/etc/ceph.conf</filename> :
     </para>
<screen>
[mds.123-my-mds] # config setting specific to MDS name with a name starting with a digit
mds cache memory limit = 1073741824
mds standby for name = 456-another-mds
</screen>
     <para>
      L'orchestrateur <command>ceph.mds.migrate-numerical-names</command> change le nom de daemon MDS « 123-my-mds » en « mds.123-my-mds ». Vous devez ajuster la configuration pour tenir compte du nouveau nom :
     </para>
<screen>
[mds.mds,123-my-mds] # config setting specific to MDS name with the new name
mds cache memory limit = 1073741824
mds standby for name = mds.456-another-mds
</screen>
    </tip>
    <para>
     Cela ajoutera les daemons MDS avec les nouveaux noms avant de supprimer les anciens daemons MDS. Le nombre de daemons MDS va doubler pendant une courte période. Les clients pourront accéder à CephFS moyennant une brève pause avant le basculement. Planifiez donc la migration à des moments où vous vous attendez à peu ou pas de charge de CephFS.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-backup">
  <title>Sauvegarde des données de grappe</title>

  <para>
   Bien que la création de sauvegardes de la configuration et des données d'une grappe ne soit pas obligatoire, nous recommandons vivement de sauvegarder les données de grappe et les fichiers de configuration importants. Pour plus d'informations, reportez-vous au <xref linkend="cha-deployment-backup"/>.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-ntp">
  <title>Migration de <systemitem class="daemon">ntpd</systemitem> vers <systemitem class="daemon">chronyd</systemitem></title>

  <para>
   Pour synchroniser l'heure de l'hôte local, SUSE Linux Enterprise Server 15 SP1 n'utilise plus <systemitem class="daemon">ntpd</systemitem>, mais bien <systemitem class="daemon">chronyd</systemitem>. Vous devez donc migrer le daemon de synchronisation horaire sur chaque noeud de la grappe. Vous pouvez effectuer la migration vers <systemitem>chronyd</systemitem> <emphasis role="bold">avant</emphasis> de mettre à niveau la grappe, ou mettre à niveau la grappe et réaliser la migration vers <systemitem class="daemon">chronyd</systemitem> <emphasis role="bold">ensuite</emphasis>.
  </para>

  <procedure>
   <title>Migration vers <systemitem class="daemon">chronyd</systemitem> <emphasis>avant</emphasis> la mise à niveau de la grappe</title>
   <step>
    <para>
     Installez le paquetage <package>chrony</package> :
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper install chrony</screen>
   </step>
   <step>
    <para>
     Modifiez le fichier de configuration de <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> et ajoutez les sources NTP de la configuration actuelle de <systemitem class="daemon">ntpd</systemitem> dans <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>plus de détails sur la configuration de <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Reportez-vous à la page <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> pour obtenir plus de détails sur la façon d'inclure des sources horaires dans la configuration de <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Désactivez et arrêtez le service <systemitem class="daemon">ntpd</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Démarrez et activez le service <systemitem class="daemon">chronyd</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Vérifiez le statut de chrony :
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
  </procedure>

  <procedure>
   <title>Migration vers <systemitem class="daemon">chronyd</systemitem> <emphasis>après</emphasis> la mise à niveau de la grappe</title>
   <step>
    <para>
     Lors de la mise à niveau de la grappe, ajoutez les dépôts logiciels suivants :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Pool
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Updates
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Mettez à niveau la grappe vers la version 6.
    </para>
   </step>
   <step>
    <para>
     Modifiez le fichier de configuration de <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> et ajoutez les sources NTP de la configuration actuelle de <systemitem class="daemon">ntpd</systemitem> dans <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>plus de détails sur la configuration de <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Reportez-vous à la page <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> pour obtenir plus de détails sur la façon d'inclure des sources horaires dans la configuration de <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Désactivez et arrêtez le service <systemitem class="daemon">ntpd</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Démarrez et activez le service <systemitem class="daemon">chronyd</systemitem> :
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Effectuez la migration de <systemitem class="daemon">ntpd</systemitem> vers <systemitem class="daemon">chronyd</systemitem>.
    </para>
   </step>
   <step>
    <para>
     Vérifiez le statut de chrony :
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
   <step>
    <para>
     Supprimez les dépôts logiciels hérités que vous avez ajoutés pour garder <systemitem class="daemon">ntpd</systemitem> dans le système pendant le processus de mise à niveau.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-prepare">
  <title>Application des correctifs à la grappe avant la mise à niveau</title>

  <para>
   Appliquez les derniers correctifs à tous les noeuds de la grappe avant la mise à niveau.
  </para>

  <sect2 xml:id="upgrade-prepare-repos">
   <title>Dépôts logiciels requis</title>
   <para>
    Vérifiez que les dépôts requis sont configurés sur chaque noeud de la grappe. Pour répertorier tous les dépôts disponibles, exécutez la commande suivante :
   </para>
<screen>
<prompt>root@minion &gt; </prompt>zypper lr
</screen>
   <para>
    SUSE Enterprise Storage 5.5 nécessite :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLES12-SP3-Installer-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Updates
     </para>
    </listitem>
   </itemizedlist>
   <para>
    La passerelle NFS/SMB sur SLE-HA sous SUSE Linux Enterprise Server 12 SP3 nécessite :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLE-HA12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLE-HA12-SP3-Updates
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-staging">
   <title>Systèmes de préparation de dépôt</title>
   <para>
    Si vous utilisez l'un des systèmes de préparation de dépôt (SMT, RMT ou SUSE Manager), créez un niveau de correctif figé pour la version actuelle et la nouvelle version de SUSE Enterprise Storage.
   </para>
   <para>
    Pour plus d'informations, reportez-vous aux ressources suivantes :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/book_rmt.html"/>
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/suse-manager-3/index.html"/>
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-patch">
   <title>Application des derniers correctifs à toute la grappe</title>
   <procedure>
    <step>
     <para>
      Appliquez les derniers correctifs de SUSE Enterprise Storage 5.5 et SUSE Linux Enterprise Server 12 SP3 à chaque noeud de la grappe Ceph. Vérifiez que les bons dépôts logiciels sont connectés à chaque noeud de la grappe (voir <xref linkend="upgrade-prepare-repos"/>) et exécutez la phase 0 de DeepSea :
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    </step>
    <step>
     <para>
      Une fois la phase 0 terminée, vérifiez que le statut de chaque noeud de la grappe inclut « HEALTH_OK ». Si ce n'est pas le cas, résolvez le problème avant d'éventuels redémarrages au cours des prochaines étapes.
     </para>
    </step>
    <step>
     <para>
      Exécutez <command>zypper ps</command> pour rechercher les processus susceptibles de s'exécuter avec des bibliothèques ou des fichiers binaires obsolètes, et redémarrez s'il y en a.
     </para>
    </step>
    <step>
     <para>
      Vérifiez que le kernel en cours d'exécution est le plus récent disponible et redémarrez si ce n'est pas le cas. Vérifiez les sorties des commandes suivantes :
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>uname -a
<prompt>cephadm@adm &gt; </prompt>rpm -qa kernel-default
</screen>
    </step>
    <step>
     <para>
      Vérifiez que le paquetage <package>ceph</package> présente la version 12.2.12 ou une version ultérieure. Vérifiez que le paquetage <package>deepsea</package> présente la version 0.8.9 ou une version ultérieure.
     </para>
    </step>
    <step>
     <para>
      Si vous utilisiez des paramètres <option>bluestore_cache</option>, ils ne sont plus de vigueur depuis la version 12.2.10 de <package>ceph</package>. Le nouveau paramètre <option>bluestore_cache_autotune</option>, qui est défini sur « true » par défaut, désactive la définition manuelle de la taille du cache. Pour activer l'ancien comportement, vous devez configurer <option>bluestore_cache_autotune=false</option>. Reportez-vous au <xref linkend="config-auto-cache-sizing"/> pour obtenir des informations détaillées.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-verify-current">
  <title>Vérification de l'environnement actuel</title>

  <itemizedlist>
   <listitem>
    <para>
     Si le système présente des problèmes évidents, corrigez-les avant de commencer la mise à niveau. La mise à niveau ne résout jamais les problèmes système existants.
    </para>
   </listitem>
   <listitem>
    <para>
     Vérifiez les performances de la grappe. Vous pouvez utiliser des commandes telles que <command>rados bench</command>, <command>ceph tell osd.* bench</command> ou <command>iperf3</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Vérifiez l'accès aux passerelles (telles que la passerelle iSCSI ou Object Gateway) et à RBD.
    </para>
   </listitem>
   <listitem>
    <para>
     Documentez les parties spécifiques de la configuration système, telles que les détails de la configuration réseau, du partitionnement ou de l'installation.
    </para>
   </listitem>
   <listitem>
    <para>
     Utilisez <command>supportconfig</command> pour collecter les informations système importantes et les enregistrer en dehors des noeuds de grappe. Pour plus d'informations, reportez-vous à la page <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_admsupport_supportconfig.html"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Assurez-vous que l'espace disque libre sur chaque noeud de la grappe est suffisant. Pour ce faire, utilisez la commande <command>df -h</command>. Au besoin, libérez de l'espace disque en supprimant les fichiers/répertoires inutiles ou les instantanés obsolètes du système d'exploitation. Si l'espace disque libre n'est pas suffisant, ne poursuivez pas la mise à niveau tant que vous n'en avez pas libéré suffisamment.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-verify-state">
  <title>Vérification de l'état de la grappe</title>

  <itemizedlist>
   <listitem>
    <para>
     Vérifiez la commande <command>cluster health</command> avant de commencer la procédure de mise à niveau. Ne démarrez la mise à niveau qu'une fois que chaque noeud de la grappe renvoie « HEALTH_OK ».
    </para>
   </listitem>
   <listitem>
    <para>
     Vérifier que tous les services sont en cours d'exécution :
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Salt Master et les daemons Salt Master
      </para>
     </listitem>
     <listitem>
      <para>
       Les daemons Ceph Monitor et Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Les daemons de serveur de métadonnées (MDS)
      </para>
     </listitem>
     <listitem>
      <para>
       Les daemons Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Les daemons Objet Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Les daemons de passerelle iSCSI
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>

  <para>
   Les commandes suivantes fournissent des détails sur l'état de la grappe et la configuration spécifique :
  </para>

  <variablelist>
   <varlistentry>
    <term><command>ceph -s</command></term>
    <listitem>
     <para>
      Renvoie un bref résumé de l'état de santé de la grappe Ceph, des services en cours d'exécution, de l'utilisation des données et des statistiques E/S. Vérifiez que l'état signalé est « HEALTH_OK » avant de commencer la mise à niveau.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph health detail</command></term>
    <listitem>
     <para>
      Renvoie les détails si l'état de santé de la grappe Ceph n'est pas correct.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph versions</command></term>
    <listitem>
     <para>
      Renvoie les versions des daemons Ceph en cours d'exécution.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph df</command></term>
    <listitem>
     <para>
      Renvoie la quantité d'espace disque total et d'espace disque libre sur la grappe. Ne commencez pas la mise à niveau si l'espace disque libre de la grappe est inférieur à 25 % de l'espace disque total.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>salt '*' cephprocesses.check results=true</command></term>
    <listitem>
     <para>
      Renvoie les processus Ceph en cours d'exécution et leur PID triés par minions Salt.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph osd dump | grep ^flags</command></term>
    <listitem>
     <para>
      Vérifiez la présence des drapeaux « recovery_deletes » et « purged_snapdirs ». Si ce n'est pas le cas, vous pouvez forcer un nettoyage sur tous les groupes de placement en exécutant la commande suivante. Soyez conscient que ce nettoyage forcé peut avoir un impact négatif sur les performances de vos clients Ceph.
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump pgs_brief | cut -d " " -f 1 | xargs -n1 ceph pg scrub
</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1>
  <title>Mise à niveau hors ligne des grappes CTDB</title>

  <para>
   CTDB fournit une base de données mise en grappe utilisée par les passerelles Samba. Le protocole CTDB est très simple et ne prend pas en charge les grappes de noeuds qui communiquent avec différentes versions de protocole. Par conséquent, les noeuds CTDB doivent être mis hors ligne avant d'effectuer une mise à niveau.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-one-node">
  <title>Mise à niveau par noeud - Procédure de base</title>

  <para>
   Pour garantir la disponibilité des services de grappe de base pendant la mise à niveau, vous devez mettre à niveau les noeuds de la grappe de manière séquentielle, un par un. Il existe deux façons d'effectuer la mise à niveau d'un noeud : à l'aide du <emphasis>DVD du programme d'installation</emphasis> ou en utilisant le <emphasis>système de migration de distribution</emphasis>.
  </para>

  <para>
   Après la mise à niveau de chaque noeud, nous vous recommandons d'exécuter <command>rpmconfigcheck</command> pour rechercher les éventuels fichiers de configuration mis à jour qui ont été modifiés localement. Si la commande renvoie une liste de noms de fichiers avec un suffixe <filename>.rpmnew</filename>, <filename>.rpmorig</filename> ou <filename>.rpmsave</filename>, comparez ces fichiers avec les fichiers de configuration actuels pour vérifier qu'aucun changement local n'a été perdu. Si nécessaire, mettez à jour les fichiers concernés. Pour plus d'informations sur l'utilisation des fichiers <filename>.rpmnew</filename>, <filename>.rpmorig</filename> et <filename>.rpmsave</filename>, reportez-vous à la page <link xlink:href="https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#sec-rpm-packages-manage"/>.
  </para>

  <tip>
   <title>paquetages orphelins</title>
   <para>
    Une fois qu'un noeud a été mis à niveau, un certain nombre de paquetages présentent un état « orphaned » (orphelin), sans dépôt parent. Cela est dû au fait que les paquetages associés à python3 ne rendent pas les paquetages python2 obsolètes.
   </para>
   <para>
    Pour plus d'informations sur la liste des paquetages orphelins, reportez-vous à la page <link xlink:href="https://www.suse.com/documentation/sles-15/book_sle_admin/data/sec_zypper.html#sec_zypper_softup_orphaned"/>.
   </para>
  </tip>

  <sect2 xml:id="upgrade-one-node-manual">
   <title>Mise à niveau manuelle d'un noeud à l'aide du DVD du programme d'installation</title>
   <procedure>
    <step>
     <para>
      Redémarrez le noeud à partir du DVD/de l'image du programme d'installation de SUSE Linux Enterprise Server 15 SP1.
     </para>
    </step>
    <step>
     <para>
      Sélectionnez <guimenu>Upgrade</guimenu> (Mise à niveau) dans le menu de démarrage.
     </para>
    </step>
    <step>
     <para>
      Sur l'écran <guimenu>Select the Migration Target</guimenu> (Sélectionner la cible de la migration), vérifiez que « SUSE Linux Enterprise Server 15 SP1 » est sélectionné et cochez la case <guimenu>Manually Adjust the Repositories for Migration</guimenu> (Ajuster manuellement les dépôts pour la migration).
     </para>
     <figure>
      <title>Sélection de la cible de la migration</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Sélectionnez les modules suivants pour installation :
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SUSE Enterprise Storage 6 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Basesystem Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Desktop Applications Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Legacy Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Server Applications Module 15 SP1 x86_64
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Sur l'écran <guimenu>Previously Used Repositories</guimenu> (Dépôts utilisés précédemment), vérifiez que les bons dépôts sont sélectionnés. Si le système n'est pas enregistré avec SCC/SMT, vous devez ajouter les dépôts manuellement.
     </para>
     <para>
      SUSE Enterprise Storage 6 nécessite :
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Server-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Server-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-SLES15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-SLES15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE15-SP1-Installer-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SUSE-Enterprise-Storage-6-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SUSE-Enterprise-Storage-6-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Si vous avez l'intention d'effectuer la migration de <systemitem>ntpd</systemitem> vers <systemitem class="daemon">chronyd</systemitem> après la migration de SES (voir <xref linkend="upgrade-ntp"/>), incluez les dépôts suivants :
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      La passerelle NFS/SMB sur SLE-HA sous SUSE Linux Enterprise Server 15 SP1 nécessite :
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Passez en revue les <guimenu>paramètres d'installation</guimenu> et démarrez la procédure d'installation en cliquant sur <guimenu>Update</guimenu> (Mise à jour).
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-one-node-auto">
   <title>Mise à niveau de noeud à l'aide du système de migration de distribution SUSE</title>
   <para>
    Le système de migration de distribution (<emphasis>Distribution Migration System</emphasis>, DMS) fournit un chemin de mise à niveau pour un système SUSE Linux Enterprise installé devant passer d'une version majeure à une autre. La procédure suivante utilise DMS pour mettre à niveau SUSE Enterprise Storage 5.5 vers la version 6 et effectuer également la migration sous-jacente de SUSE Linux Enterprise Server 12 SP3 vers SUSE Linux Enterprise Server 15 SP1.
   </para>
   <para>
    Reportez-vous à la page <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/> pour obtenir des informations générales et détaillées sur DMS.
   </para>
   <procedure>
    <step>
     <para>
      Installez les paquetages RPM de migration. Ils règlent le chargeur de démarrage GRUB pour déclencher automatiquement la mise à niveau lors du prochain redémarrage. Installez les paquetages
      <package>SLES15-SES-Migration</package> et
      <package>suse-migration-sle15-activation</package> :
     </para>
<screen><prompt>root@minion &gt; </prompt>zypper install SLES15-SES-Migration suse-migration-sle15-activation</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        Si le noeud mis à niveau <emphasis role="bold">est</emphasis> enregistré avec un système de préparation de dépôt tel que SCC, SMT, RMT ou SUSE Manager, créez le fichier <filename>/etc/sle-migration-service.yml</filename> avec le contenu suivant :
       </para>
<screen>
use_zypper_migration: true
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
      </step>
      <step>
       <para>
        Si le noeud mis à niveau n'est <emphasis role="bold">pas</emphasis> enregistré avec un système de préparation de dépôt tel que SCC, SMT, RMT ou SUSE Manager, effectuez les modifications suivantes :
       </para>
       <substeps>
        <step>
         <para>
          Créez le fichier <filename>/etc/sle-migration-service.yml</filename> avec le contenu suivant :
         </para>
<screen>
use_zypper_migration: false
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
        </step>
        <step>
         <para>
          Désactivez ou supprimez les dépôts SLE 12 SP3 et SES 5, puis ajoutez les dépôts SLE 15 SP1 et SES 6. Pour obtenir la liste des dépôts associés, reportez-vous à la <xref linkend="upgrade-prepare-repos"/>.
         </para>
        </step>
       </substeps>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Redémarrez pour lancer la mise à niveau. Pendant l'exécution de la mise à niveau, vous pouvez vous connecter au noeud mis à niveau via <command>ssh</command> en tant qu'utilisateur de la migration à l'aide de la clé SSH existante du système hôte comme décrit à la page <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>. Pour SUSE Enterprise Storage, si vous disposez d'un accès physique ou d'un accès console direct à la machine, vous pouvez également vous connecter en tant qu'utilisateur <systemitem class="username">root</systemitem> à la console système en utilisant le mot de passe <literal>sesupgrade</literal>. Le noeud redémarre automatiquement après la mise à niveau.
     </para>
     <tip>
      <title>échec de la mise à niveau</title>
      <para>
       Si la mise à niveau échoue, consultez le fichier journal <filename>/var/log/distro_migration.log</filename>. Résolvez le problème, réinstallez les paquetages RPM de migration et redémarrez le noeud.
      </para>
     </tip>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-adm">
  <title>Mise à niveau du noeud Admin</title>

  <itemizedlist>
   <listitem>
    <para>
     Les commandes suivantes continuent de fonctionner même si les minions Salt exécutent des anciennes versions de Ceph et Salt : <command>salt '*' test.ping</command> et <command>ceph status</command>
    </para>
   </listitem>
   <listitem>
    <para>
     Après la mise à niveau du noeud Admin, openATTIC ne sera plus installé.
    </para>
   </listitem>
   <listitem>
    <para>
     Si le noeud Admin hébergeait SMT, effectuez sa migration vers RMT (voir <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/cha_rmt_migrate.html"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>statut des noeuds de la grappe</title>
   <para>
    Une fois le noeud Admin mis à niveau, vous pouvez exécuter la commande <command>salt-run upgrade.status</command> pour afficher des informations utiles sur les noeuds de la grappe. La commande répertorie les versions Ceph et OS de tous les noeuds, et recommande l'ordre dans lequel mettre à niveau les éventuels noeuds qui exécutent encore d'anciennes versions.
   </para>
<screen><prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
  ceph: ceph version 14.2.1-468-g994fd9e0cc (994fd9e0ccc50c2f3a55a3b7a3d4e0ba74786d50) nautilus (stable)
  os: SUSE Linux Enterprise Server 15 SP1

Nodes running these software versions:
  admin.ceph (assigned roles: master)
  mon2.ceph (assigned roles: admin, mon, mgr)

Nodes running older software versions must be upgraded in the following order:
   1: mon1.ceph (assigned roles: admin, mon, mgr)
   2: mon3.ceph (assigned roles: admin, mon, mgr)
   3: data1.ceph (assigned roles: storage)
[...]</screen>
  </tip>
 </sect1>
 <sect1 xml:id="upgrade-mons">
  <title>Mise à niveau des noeuds Ceph Monitor/Ceph Manager</title>

  <itemizedlist>
   <listitem>
    <para>
     Si votre grappe <emphasis role="bold">n'utilise pas</emphasis> les rôles MDS, mettez à niveau les noeuds MON/MGR un par un.
    </para>
   </listitem>
   <listitem>
    <para>
     Si votre grappe <emphasis role="bold">utilise</emphasis> les rôles MDS et que ces derniers sont situés sur la même machine que les rôles MON/MGR, vous devez réduire la grappe MDS, puis mettre à niveau les noeuds colocalisés. Pour plus d'informations, reportez-vous à la <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Si votre grappe <emphasis role="bold">utilise</emphasis> les rôles MDS et qu'ils s'exécutent sur des serveurs <emphasis role="bold">dédiés</emphasis>, mettez à niveau tous les noeuds MON/MGR un par un, puis réduisez la grappe MDS et mettez-la à niveau. Pour plus d'informations, reportez-vous à la <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>mise à niveau de Ceph Monitor</title>
   <para>
    En raison d'une limitation dans la conception de Ceph Monitor, une fois que deux noeuds MON ont été mis à niveau vers SUSE Enterprise Storage 6 et ont formé un quorum, le troisième noeud MON (alors qu'il est encore sous SUSE Enterprise Storage 5.5) ne rejoint pas la grappe MON en cas de redémarrage pour une raison quelconque, y compris un redémarrage du noeud. Par conséquent, lorsque deux noeuds MON ont été mis à niveau, il est préférable de mettre à niveau le reste dès que possible.
   </para>
  </note>

  <para>
   <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
  </para>
 </sect1>
 <sect1 xml:id="upgrade-mds">
  <title>Mise à niveau des serveurs de métadonnées</title>

  <para>
   Vous devez réduire la grappe des serveurs de métadonnées (Metadata Server, MDS). En raison de fonctionnalités incompatibles entre les versions SUSE Enterprise Storage 5.5 et 6, les anciens daemons MDS s'arrêtent dès qu'ils détectent qu'un MDS de niveau SES 6 rejoint la grappe. Par conséquent, il est nécessaire de réduire la grappe MDS à un seul MDS actif (et aucun à l'état de veille) pour la durée des mises à niveau des noeuds MDS. Dès que le deuxième noeud est mis à niveau, vous pouvez étendre à nouveau la grappe MDS.
  </para>

  <tip>
   <para>
    Sur une grappe MDS très chargée, vous devrez peut-être réduire la charge (par exemple, en arrêtant des clients) afin qu'un seul MDS actif soit en mesure de gérer le workload.
   </para>
  </tip>

  <procedure>
   <step>
    <para>
     Notez la valeur actuelle de l'option <option>max_mds</option> :
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs get cephfs | grep max_mds
</screen>
   </step>
   <step>
    <para>
     Réduisez la grappe MDS si vous avez plus d'un daemon MDS actif, autrement dit <option>max_mds</option> est &gt; 1. Pour réduire la grappe MDS, exécutez la commande suivante :
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds 1
</screen>
    <para>
     <replaceable>FS_NAME</replaceable> est le nom de votre instance CephFS (« cephfs » par défaut).
    </para>
   </step>
   <step>
    <para>
     Recherchez le noeud hébergeant l'un des daemons MDS en veille. Consultez la sortie de la commande <command>ceph fs status</command> et démarrez la mise à niveau de la grappe MDS sur ce noeud.
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs status
cephfs - 2 clients
======
+------+--------+--------+---------------+-------+-------+
| Rank | State  |  MDS   |    Activity   |  dns  |  inos |
+------+--------+--------+---------------+-------+-------+
|  0   | active | mon1-6 | Reqs:    0 /s |   13  |   16  |
+------+--------+--------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 2688k | 96.8G |
|   cephfs_data   |   data   |    0  | 96.8G |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
|    mon3-6   |
|    mon2-6   |
+-------------+
</screen>
    <para>
     Dans cet exemple, vous devez commencer la procédure de mise à niveau sur le noeud « mon3-6 » ou « mon2-6 ».
    </para>
   </step>
   <step>
    <para>
     Mettez à niveau le noeud avec le daemon MDS en veille. Une fois que le noeud MDS mis à niveau a démarré, les daemons MDS obsolètes s'arrêtent automatiquement. À ce stade, les clients peuvent connaître une brève interruption du service CephFS.
    </para>
    <para>
     <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Mettez à niveau les noeuds MDS restants.
    </para>
   </step>
   <step>
    <para>
     Réinitialisez la valeur <option>max_mds</option> à la configuration souhaitée :
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds <replaceable>ACTIVE_MDS_COUNT</replaceable>
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-main-osd">
  <title>Mise à niveau des Ceph OSD</title>

  <para>
   Pour chaque noeud de stockage, procédez comme suit :
  </para>

  <procedure>
   <step>
    <para>
     Identifiez les daemons OSD qui s'exécutent sur un noeud particulier :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd tree
</screen>
   </step>
   <step>
    <para>
     Définissez le drapeau « noout » pour chaque daemon OSD sur le noeud en cours de mise à niveau :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd add-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Par exemple :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd add-noout osd.$i; done</screen>
    <para>
     Vérifiez avec l'une des commandes suivantes :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     ou
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
      6 OSDs or CRUSH {nodes, device-classes} have {NOUP,NODOWN,NOIN,NOOUT} flags set</screen>
   </step>
   <step>
    <para>
     Créez des fichiers <filename>/etc/ceph/osd/json</filename> pour tous les OSD existants en exécutant la commande suivante sur le noeud qui va être mis à niveau :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan --force
</screen>
   </step>
   <step>
    <para>
     Mettez à niveau le noeud OSD. <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Activez tous les OSD détectés sur le système :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>;ceph-volume simple activate --all
</screen>
    <tip>
     <title>activation individuelle de partitions de données</title>
     <para>
      Si vous souhaitez activer des partitions de données individuellement, vous devez trouver la commande <command>ceph-volume</command> appropriée pour chaque partition. Remplacez <replaceable>X1</replaceable> par la lettre/le numéro correct de la partition :
     </para>
<screen>
 <prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/sd<replaceable>X1</replaceable>
</screen>
     <para>
      Par exemple :
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/vdb1
[...]
--&gt; OSD 8 got scanned and metadata persisted to file:
/etc/ceph/osd/8-d7bd2685-5b92-4074-8161-30d146cd0290.json
--&gt; To take over management of this scanned OSD, and disable ceph-disk
and udev, run:
--&gt;     ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
     <para>
      La dernière ligne de la sortie contient la commande pour activer la partition :
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
[...]
--&gt; All ceph-disk systemd units have been disabled to prevent OSDs
getting triggered by UDEV events
[...]
Running command: /bin/systemctl start ceph-osd@8
--&gt; Successfully activated OSD 8 with FSID
d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
    </tip>
   </step>
   <step>
    <para>
     Vérifiez que le noeud OSD démarre correctement après le redémarrage.
    </para>
   </step>
   <step>
    <para>
     Traitez le message « Legacy BlueStore stats reporting detected on XX OSD(s) » (Création de rapports de statistiques BlueStore hérités sur XX OSD) :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
    <para>
     Cet avertissement est normal lors de la mise à niveau de Ceph vers la version 14.2.2. Vous pouvez le désactiver en entrant ceci :
    </para>
<screen>bluestore_warn_on_legacy_statfs = false</screen>
    <para>
     La résolution appropriée de ce problème consiste à exécuter la commande suivante sur tous les OSD pendant qu'ils sont arrêtés :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-XXX</screen>
    <para>
     Voici un script de programme auxiliaire qui exécute <command>ceph-bluestore-tool repair</command> pour tous les OSD sur le noeud <replaceable>NODE_NAME</replaceable> :
    </para>
<screen>OSDNODE=<replaceable>OSD_NODE_NAME</replaceable>;\
 for OSD in $(ceph osd ls-tree $OSDNODE);\
 do echo "osd=" $OSD;\
 salt $OSDNODE cmd.run 'systemctl stop ceph-osd@$OSD';\
 salt $OSDNODE cmd.run 'ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-$OSD';\
 salt $OSDNODE cmd.run 'systemctl start ceph-osd@$OSD';\
 done</screen>
   </step>
   <step>
    <para>
     Annulez la définition du drapeau « noout » pour chaque daemon OSD sur le noeud qui est mis à niveau :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd rm-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Par exemple :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd rm-noout osd.$i; done</screen>
    <para>
     Vérifiez avec la commande suivante :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     Remarque :
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
   </step>
   <step>
    <para>
     Vérifiez le statut de la grappe. Il ressemblera à la sortie suivante :
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph status
cluster:
  id:     e0d53d64-6812-3dfe-8b72-fd454a6dcf12
  health: HEALTH_WARN
          3 monitors have not enabled msgr2

services:
  mon: 3 daemons, quorum mon1,mon2,mon3 (age 2h)
  mgr: mon2(active, since 22m), standbys: mon1, mon3
  osd: 30 osds: 30 up, 30 in

data:
  pools:   1 pools, 1024 pgs
  objects: 0 objects, 0 B
  usage:   31 GiB used, 566 GiB / 597 GiB avail
  pgs:     1024 active+clean
</screen>
   </step>
   <step>
    <para>
     Vérifiez que tous les noeuds OSD ont été redémarrés et que les OSD ont démarré automatiquement après le redémarrage.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="filestore2bluestore">
  <title>Migration des OSD vers BlueStore</title>

  <para>
   OSD BlueStore est une nouvelle interface dorsale pour les daemons OSD. Il s'agit de l'option par défaut depuis la version 5 de SUSE Enterprise Storage. Comparé à FileStore, qui stocke des objets en tant que fichiers dans un système de fichiers XFS, BlueStore peut fournir des performances accrues, car il stocke les objets directement sur le périphérique de bloc sous-jacent. BlueStore utilise également d'autres fonctions, telles que la compression intégrée et les écrasements EC, qui ne sont pas disponibles avec FileStore.
  </para>

  <para>
   En particulier pour BlueStore, un OSD dispose d'un périphérique « wal » (Write Ahead Log) et d'un périphérique « db » (base de données RocksDB). La base de données RocksDB conserve les métadonnées pour un OSD BlueStore. Ces deux périphériques résident sur le même périphérique qu'un OSD par défaut, mais peuvent être placés sur des supports différents, plus rapides par exemple.
  </para>

  <para>
   Dans SUSE Enterprise Storage 5, FileStore et BlueStore sont tous deux pris en charge et il est possible que les OSD FileStore et BlueStore coexistent dans une seule grappe. Pendant la procédure de mise à niveau de SUSE Enterprise Storage, les OSD FileStore ne sont pas automatiquement convertis en OSD BlueStore. Sachez que les fonctions spécifiques à BlueStore ne seront pas disponibles sur les OSD qui n'ont pas été migrés vers BlueStore.
  </para>

  <para>
   Avant la conversion vers BlueStore, les OSD doivent exécuter SUSE Enterprise Storage 5. La conversion est un processus lent, car toutes les données sont réécrites deux fois. Bien que le processus de migration puisse prendre beaucoup de temps, il n'y a pas d'interruption de la grappe et tous les clients peuvent continuer à y accéder pendant cette période. Cependant, attendez-vous à des performances inférieures pendant la durée de la migration. Cela est dû au rééquilibrage et au renvoi des données de la grappe.
  </para>

  <para>
   Utilisez la procédure suivante pour migrer les OSD FileStore vers BlueStore :
  </para>

  <tip>
   <title>désactivation des mesures de sécurité</title>
   <para>
    Les commandes Salt nécessaires pour exécuter la migration sont bloquées par des mesures de sécurité. Pour désactiver ces précautions, exécutez la commande suivante :
   </para>
<screen>
 <prompt>root@master # </prompt>salt-run disengage.safety
 </screen>
   <para>
    Reconstruisez les noeuds avant de continuer :
   </para>
<screen>
 <prompt>root@master # </prompt> salt-run rebuild.node <replaceable>TARGET</replaceable>
 </screen>
   <para>
    Vous pouvez également choisir de reconstruire chaque noeud individuellement. Par exemple :
   </para>
<screen>
<prompt>root@master # </prompt> salt-run rebuild.node data1.ceph
 </screen>
   <para>
    <literal>rebuild.node</literal> supprime et recrée toujours tous les OSD sur le noeud.
   </para>
   <important>
    <para>
     Si un seul OSD ne parvient pas effectuer la conversion, une nouvelle exécution de la reconstruction détruit les OSD BlueStore déjà convertis. Au lieu de relancer la reconstruction, vous pouvez exécuter la commande suivante :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.deploy <replaceable>TARGET</replaceable>
 </screen>
   </important>
  </tip>

  <para>
   Après la migration vers BlueStore, le nombre d'objets restera le même et l'utilisation du disque sera presque la même.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-appnodes-order">
  <title>Mises à niveau des noeuds d'application</title>

  <para>
   Mettez à niveau les noeuds d'application dans l'ordre suivant :
  </para>

  <orderedlist>
   <listitem>
    <para>
     Object Gateway
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Si les passerelles Object Gateway ont devant elles un équilibreur de charge, il doit être possible de les mettre à niveau de façon progressive sans interruption de service.
      </para>
     </listitem>
     <listitem>
      <para>
       Vérifiez que les daemons Object Gateway s'exécutent après chaque mise à niveau et effectuez un test avec le client S3/Swift.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Passerelles iSCSI
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Si les initiateurs iSCSI sont configurés avec multipath, il doit être possible de mettre à niveau les passerelles iSCSI de façon progressive sans interruption de service.
      </para>
     </listitem>
     <listitem>
      <para>
       Vérifiez que le daemon <systemitem class="daemon">lrbd</systemitem> est en cours d'exécution après chaque mise à niveau et testez avec l'initiateur.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     NFS Ganesha. <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
   <listitem>
    <para>
     Passerelles Samba. <emphasis role="bold">Utilisez la procédure décrite à la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </orderedlist>
 </sect1>
 <sect1 xml:id="upgrade-main-policy">
  <title>Mise à jour de <filename>policy.cfg</filename> et déploiement de Ceph Dashboard à l'aide de DeepSea</title>

  <para>
   Sur le noeud Admin, éditez <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> et appliquez les modifications suivantes :
  </para>

  <important>
   <title>absence de nouveaux services</title>
   <para>
    Pendant la mise à niveau de la grappe, n'ajoutez pas de nouveaux services au fichier <filename>policy.cfg</filename>. Modifiez l'architecture de la grappe uniquement lorsque la mise à niveau est terminée.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Supprimez <literal>role-openattic</literal>.
    </para>
   </step>
   <step>
    <para>
     Ajoutez <literal>role-prometheus</literal> et <literal>role-grafana</literal> au noeud sur lequel Prometheus et Grafana sont installés, généralement le noeud Admin.
    </para>
   </step>
   <step>
    <para>
     Le rôle <literal>profile-<replaceable>NOM_PROFIL</replaceable></literal> est maintenant ignoré. Ajoutez le nouveau rôle correspondant, ligne <literal>role-storage</literal>. Par exemple, pour l'élément existant :
    </para>
<screen>
profile-default/cluster/*.sls
</screen>
    <para>
     Ajoutez :
    </para>
<screen>
role-storage/cluster/*.sls
</screen>
   </step>
   <step>
    <para>
     Synchronisez tous les modules Salt :
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.sync_all</screen>
   </step>
   <step>
    <para>
     Mettez à jour l'interface Pillar de Salt en exécutant les phases 1 et 2 de DeepSea :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Nettoyez openATTIC :
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.rescind.openattic
<prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.remove.openattic</screen>
   </step>
   <step>
    <para>
     Annulez la définition du grain « restart_igw » pour empêcher la phase 0 de redémarrer la passerelle iSCSI, qui n'est pas encore installée :
    </para>
<screen>Salt mastersalt '*' grains.delkey restart_igw</screen>
   </step>
   <step>
    <para>
     Enfin, exécutez les phases 0 à 4 de DeepSea :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <tip>
     <title>erreurs « subvolume missing » (sous-volume manquant) lors de la phase 3</title>
     <para>
      La phase 3 de DeepSea peut échouer avec une erreur similaire à la suivante :
     </para>
<screen>subvolume : ['/var/lib/ceph subvolume missing on 4510-2', \
'/var/lib/ceph subvolume missing on 4510-1', \
[...]
'See /srv/salt/ceph/subvolume/README.md']</screen>
     <para>
      Dans ce cas, vous devez modifier <filename role="bold">/srv/pillar/ceph/stack/global.yml</filename> et ajouter la ligne suivante :
     </para>
<screen>subvolume_init: disabled</screen>
     <para>
      Ensuite, rafraîchissez l'interface Pillar de Salt et réexécutez la phase 3 de DeepSea :
     </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar
 <prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     <para>
      Une fois la phase 3 de DeepSea réussie, Ceph Dashboard sera en cours d'exécution. Reportez-vous au <xref linkend="ceph-dashboard"/> pour un aperçu détaillé des fonctionnalités de Ceph Dashboard.
     </para>
     <para>
      Pour répertorier les noeuds exécutant le tableau de bord, exécutez la commande suivante :
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph mgr services | grep dashboard</screen>
     <para>
      Pour répertorier les informations d'identification d'administration, exécutez la commande suivante :
     </para>
<screen><prompt>root@master # </prompt>salt-call grains.get dashboard_creds</screen>
    </tip>
   </step>
   <step>
    <para>
     Redémarrez les services Object Gateway de manière séquentielle pour utiliser le serveur Web « beast » au lieu du serveur « civetweb » obsolète :
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.restart.rgw.force</screen>
   </step>
   <step>
    <para>
     Avant de continuer, nous vous recommandons fortement d'activer le module de télémétrie Ceph. Pour plus d'informations et des instructions, reportez-vous au <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-drive-groups">
  <title>Migration des déploiements basés sur le profil vers les groupes d'unités</title>

  <para>
   Dans SUSE Enterprise Storage 5.5, DeepSea proposait des « profils » pour décrire la disposition de vos OSD. À partir de SUSE Enterprise Storage 6, nous sommes passés à une approche différente, à savoir les <emphasis>Groupes d'unités</emphasis> (plus de détails à la <xref linkend="ds-drive-groups"/>).
  </para>

  <note>
   <para>
    La migration vers la nouvelle approche n'est pas immédiatement obligatoire. Des opérations destructrices, telles que <command>salt-run osd.remove</command>, <command>salt-run osd.replace</command> ou <command>salt-run osd.purge</command> sont toujours disponibles. Toutefois, l'ajout de nouveaux OSD nécessite votre intervention.
   </para>
  </note>

  <para>
   En raison de l'approche différente de ces implémentations, nous ne proposons pas de chemin de migration automatisé. Cependant, nous offrons une variété d'outils (exécuteurs Salt) pour rendre la migration aussi simple que possible.
  </para>

  <sect2>
   <title>Analyse de la disposition actuelle</title>
   <para>
    Pour afficher les informations sur les OSD actuellement déployés, utilisez la commande suivante :
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.discover
</screen>
   <para>
    Vous pouvez également inspecter le contenu des fichiers dans les répertoires <filename>/srv/pillar/ceph/proposals/profile-*/</filename>. Ils ont une structure similaire à la suivante :
   </para>
<screen>
ceph:
  storage:
    osds:
      /dev/disk/by-id/scsi-drive_name: format: bluestore
      /dev/disk/by-id/scsi-drive_name2: format: bluestore
     </screen>
  </sect2>

  <sect2>
   <title>Création de groupes d'unités correspondant à la disposition actuelle</title>
   <para>
    Reportez-vous à la <xref linkend="ds-drive-groups-specs"/> pour plus d'informations sur les groupes d'unités.
   </para>
   <para>
    La différence entre un nouveau déploiement et un scénario de mise à niveau est que les unités à migrer sont déjà « utilisées ». Étant donné que la commande
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list
</screen>
   <para>
    recherche uniquement les disques inutilisés, employez
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list include_unavailable=True
</screen>
   <para>
    Ajustez les groupes d'unités jusqu'à ce qu'ils correspondent à votre configuration actuelle. Pour une représentation plus visuelle de ce qui va se passer, utilisez la commande suivante. Notez qu'elle ne renvoie aucune sortie s'il n'y a pas de disque libre :
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report bypass_pillar=True
</screen>
   <para>
    Si vous avez vérifié que vos groupes d'unités sont correctement configurés et que vous souhaitez appliquer la nouvelle approche, supprimez les fichiers du répertoire <filename>/srv/pillar/ceph/proposals/profile-<replaceable>NOM_PROFIL</replaceable>/</filename>, supprimez les lignes correspondantes <literal>profile-<replaceable>NOM_PROFIL</replaceable>/cluster/*.sls</literal> du fichier <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>, puis exécutez la phase 2 de DeepSea pour rafraîchir l'interface Pillar de Salt.
   </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
</screen>
   <para>
    Vérifiez le résultat en exécutant les commandes suivantes :
   </para>
<screen>
<prompt>root@master # </prompt>salt target_node pillar.get ceph:storage
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   <warning>
    <title>configuration incorrecte des groupes d'unités</title>
    <para>
     Si vos groupes d'unités ne sont pas correctement configurés et que votre configuration comporte des disques de rechange, ils seront déployés de la manière dont vous les avez spécifiés. Nous recommandons d'exécuter la commande suivante :
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   </warning>
  </sect2>

  <sect2 xml:id="upgrade-osd-deployment">
   <title>Déploiement OSD</title>
   <para>
    Pour les cas simples tels que les OSD autonomes, la migration se fera au fil du temps. Chaque fois que vous supprimerez ou remplacerez un OSD de la grappe, il sera substitué par un nouvel OSD basé sur LVM.
   </para>
   <tip>
    <title>migration vers le format LVM</title>
    <para>
     Chaque fois qu'un OSD « hérité » unique doit être remplacé sur un noeud, tous les OSD qui partagent des périphériques avec lui doivent être migrés vers le format basé sur LVM.
    </para>
    <para>
     À des fins d'exhaustivité, envisagez de migrer les OSD sur l'ensemble du noeud.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Configurations plus complexes</title>
   <para>
    Si vous disposez d'une configuration plus sophistiquée que de simples OSD autonomes, par exemple des périphériques WAL/DB dédiés ou des OSD chiffrés, la migration ne peut se produire que lorsque tous les OSD affectés à cet appareil WAL/DB sont supprimés. Cela est dû à la commande <command>ceph-volume</command> qui crée des volumes logiques (Logical Volume, LV) sur les disques avant le déploiement. Cela empêche l'utilisateur de mélanger les déploiements basés sur la partition avec les déploiements basés sur LV. Dans de tels cas, il est préférable de supprimer manuellement tous les OSD qui sont assignés à un appareil WAL/DB et de les redéployer à l'aide de l'approche Groupes d'unités.
   </para>
  </sect2>
 </sect1>
</chapter>
