<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_hwrecommend.xml" version="5.0" xml:id="storage-bp-hwreq">
 <title>Hardwareanforderungen und Empfehlungen</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>Ja</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Die Hardwareanforderungen für Ceph hängen stark vom E/A-Workload ab. Die folgenden Hardwareanforderungen und Empfehlungen sollten als Ausgangspunkt für die detaillierte Planung betrachtet werden.
 </para>
 <para>
  Im Allgemeinen sind die Empfehlungen in diesem Abschnitt auf jeweils einen Prozess ausgelegt. Wenn auf dem selben Rechner mehrere Prozesse ablaufen, müssen die CPU-, RAM-, Festplatten- und Netzwerkanforderungen entsprechend erhöht werden.
 </para>
 <sect1 xml:id="multi-architecture">
  <title>Konfigurationen mit mehreren Architekturen</title>

  <para>
   SUSE Enterprise Storage unterstützt sowohl x86- als auch Arm-Architekturen. Bei der Erwägung der einzelnen Architekturen ist zu beachten, dass es bei den Cores pro OSD, der Frequenz und dem RAM keine gravierenden Unterschiede zwischen den CPU-Architekturen gibt, die sich auf die Größenfestlegung auswirken würden.
  </para>

  <para>
   Wie bei kleineren x86-Prozessoren (keine Server) bieten weniger leistungsstarke Arm-basierte Cores unter Umständen keine optimalen Arbeitsbedingungen, insbesondere wenn sie für Pools mit Löschcodierung eingesetzt werden.
  </para>
 </sect1>
 <sect1 xml:id="ses-bp-minimum-cluster">
  <title>Mindestkonfiguration für den Cluster</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Es sind mindestens vier OSD Nodes mit jeweils acht OSD-Festplatten erforderlich.
    </para>
   </listitem>
   <listitem>
    <para>
     Drei Ceph Monitor Nodes (SSD für dediziertes Betriebssystemlaufwerk erforderlich).
    </para>
   </listitem>
   <listitem>
    <para>
     iSCSI-Gateways, Object Gateways und Metadatenserver benötigen inkrementell 4 GB RAM und vier Cores.
    </para>
   </listitem>
   <listitem>
    <para>
     Für Ceph Monitors, Object Gateways und Metadatenserver Nodes ist eine redundante Bereitstellung erforderlich.
    </para>
   </listitem>
   <listitem>
    <para>
     Separater Verwaltungs-Node mit 4 GB RAM, vier Cores, 1 TB Kapazität. Dies ist in der Regel der Salt Master Node. Ceph Services und Gateways, z. B. Ceph Monitor, Ceph Manager, Metadatenserver, Ceph OSD, Object Gateway oder NFS Ganesha, werden auf dem Admin Node nicht unterstützt.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="deployment-osd-recommendation">
  <title>Objektspeicher-Nodes</title>

  <sect2 xml:id="sysreq-osd">
   <title>Mindestanforderungen</title>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      CPU-Empfehlungen:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Ein 2-GHz-CPU-Thread pro rotierendem Datenträger
       </para>
      </listitem>
      <listitem>
       <para>
        Zwei 2-GHz-CPU-Threads pro SSD
       </para>
      </listitem>
      <listitem>
       <para>
        Vier 2-GHz-CPU-Threads pro NVMe
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      Separate 10-GbE-Netzwerke (öffentlich/Client und Back-End), erforderlich 4 × 10 GbE, empfohlen 2 × 25 GbE.
     </para>
    </listitem>
    <listitem>
     <para>
      Insgesamt benötigtes RAM = Anzahl der OSDs × (1 GB + <option>osd_memory_target</option>) + 16 GB
     </para>
     <para>
      Weitere Informationen zu <option>osd_memory_target</option> finden Sie in <xref linkend="config-auto-cache-sizing"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      OSD-Datenträger in JBOD-Konfigurationen oder individuelle RAID-0-Konfigurationen.
     </para>
    </listitem>
    <listitem>
     <para>
      OSD-Journal darf sich auf der OSD-Festplatte befinden.
     </para>
    </listitem>
    <listitem>
     <para>
      OSD-Festplatten sollten exklusiv von SUSE Enterprise Storage verwendet werden.
     </para>
    </listitem>
    <listitem>
     <para>
      Dedizierte Festplatte/SSD für das Betriebssystem, vorzugsweise in einer RAID 1-Konfiguration.
     </para>
    </listitem>
    <listitem>
     <para>
      Wenn dieser OSD-Host einen Teil eines Cache Pools hostet, der für ein Cache Tiering verwendet wird, müssen Sie mindestens weitere 4 GB RAM zuordnen.
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph Monitors, Gateway und Metadata Server dürfen in Objektspeicher-Nodes vorhanden sein.
     </para>
    </listitem>
    <listitem>
     <para>
      Aus Gründen der Datenträgerleistung wird Bare Metal-Hardware für OSD Nodes empfohlen (keine virtuellen Maschinen).
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="ses-bp-mindisk">
   <title>Mindestfestplattengröße</title>
   <para>
    Zwei Arten von Festplattenspeicherplatz werden zur Ausführung auf OSD benötigt: der Speicherplatz für das Festplattenjournal (für FileStore) oder WAL/DB-Gerät (für BlueStore) sowie der primäre Speicherplatz für die gespeicherten Daten. Der Mindestwert (und Standardwert) für Journal/WAL/DB beträgt 6 GB. Der Mindestspeicherplatz für Daten beträgt 5 GB, da Partitionen, die kleiner als 5 GB sind, das Gewicht 0 zugewiesen wird.
   </para>
   <para>
    Auch wenn nun der Mindestspeicherplatz für ein OSD 11 GB beträgt, empfehlen wir mindestens 20 GB pro Festplatte, sogar für Testzwecke.
   </para>
  </sect2>

  <sect2 xml:id="rec-waldb-size">
   <title>Empfohlene Größe für das WAL- und DB-Gerät von BlueStore</title>
   <tip>
    <title>Weitere Informationen</title>
    <para>
     Weitere Informationen zu BlueStore finden Sie in <xref linkend="about-bluestore"/>.
    </para>
   </tip>
   <itemizedlist>
    <listitem>
     <para>
      Es wird empfohlen, 4 GB für das WAL-Gerät zu reservieren. Die empfohlene Größe für DB liegt bei den meisten Workloads bei 64 GB.
     </para>
    </listitem>
    <listitem>
     <para>
      Falls Sie beabsichtigen, das WAL- und DB-Gerät auf dieselbe Festplatte zu stellen, dann empfehlen wir eine einzelne Partition für beide Geräte statt eine eigene Partition pro Gerät. Dadurch kann Ceph das DB-Gerät auch für WAL-Operationen verwenden. Die Verwaltung des Festplattenspeicherplatzes ist daher effizienter, weil Ceph die DB-Partition für WAL nur dann verwendet, wenn es unbedingt erforderlich ist. Ein weiterer Vorteil besteht darin, dass eine volle Auslastung der WAL-Partition sehr unwahrscheinlich ist und kein Speicherplatz verschwendet wird, da er gegebenenfalls auch für DB-Operationen verwendet werden kann.
     </para>
     <para>
      Um das DB-Gerät für WAL freizugeben, geben Sie <emphasis>nicht</emphasis> das WAL-Gerät an, sondern nur das DB-Gerät.
     </para>
     <para>
      Weitere Informationen zum Festlegen eines OSD-Layouts finden Sie in <xref linkend="ds-drive-groups"/>.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="ses-bp-share-ssd-journal">
   <title>Verwenden von SSD für OSD-Journale</title>
   <para>
    Solid-State- oder Festkörperlaufwerke (SSD) haben keine beweglichen Teile. Dadurch wird die Zeit für den zufälligen Zugriff und die Leselatenz reduziert und der Datendurchsatz beschleunigt. Da der Preis pro 1 MB für SSDs erheblich höher ist als der Preis für sich drehende Festplatten, eignen sich SSDs nur für kleinere Speicher.
   </para>
   <para>
    Die Leistung von OSDs wird möglicherweise erheblich verbessert, wenn Sie deren Journal auf einem SSD speichern und die Objektdaten auf einer separaten Festplatte.
   </para>
   <tip>
    <title>Gemeinsame Nutzung eines SSD für mehrere Journale</title>
    <para>
     Da Journaldaten relativ wenig Speicherplatz belegen, können Sie mehrere Journalverzeichnisse auf einer einzigen SSD-Festplatte einhängen. Bedenken Sie dabei jedoch, dass sich mit jedem freigegebenen Journal die Leistung der SSD-Festplatte verschlechtert. Wir empfehlen, maximal sechs Journale pro SSD-Festplatte zu speichern und zwölf pro NVMe-Festplatte.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="maximum-count-of-disks-osd">
   <title>Maximale empfohlene Anzahl von Festplatten</title>
   <para>
    Jeder Server kann so viele Festplatten enthalten wie für ihn zulässig sind. Bei der Planung der Anzahl von Festplatten pro Server gibt es einiges zu bedenken:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <emphasis>Netzwerk-Bandbreite.</emphasis> Je mehr Festplatten ein Server enthält, desto mehr Daten müssen für die Schreiboperationen der Festplatte über die Netzwerkkarte(n) übertragen werden.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Arbeitsspeicher.</emphasis> RAM ab 2 GB wird für den BlueStore-Cache herangezogen. Mit dem Standardwert von 4 GB für <option>osd_memory_target</option> erhält das System eine angemessene Cache-Anfangsgröße für rotierende Datenträger. Bei SSD oder NVME sollten Sie die Cache-Größe und die RAM-Zuordnung pro OSD erhöhen, damit die höchstmögliche Leistung erzielt wird.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Fehlertoleranz.</emphasis> Wenn der Server komplett ausfällt, verliert der Cluster temporär so viele OSDs wie er Festplatten hat. Darüberhinaus müssen Sie alle Daten des ausgefallenen Servers auf die anderen Nodes im Cluster kopieren, damit die Reproduktionsregeln weiterhin ausgeführt werden.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="sysreq-mon">
  <title>Monitor Nodes</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Mindestens drei Ceph Monitor Nodes sind erforderlich. Die Anzahl der Monitors sollte immer ungerade sein (1+2n).
    </para>
   </listitem>
   <listitem>
    <para>
     4 GB RAM.
    </para>
   </listitem>
   <listitem>
    <para>
     Prozessor mit vier logischen Cores.
    </para>
   </listitem>
   <listitem>
    <para>
     Ein SSD oder ein anderer ausreichend schneller Speichertyp ist für Monitors sehr zu empfehlen, insbesondere für den Pfad <filename>/var/lib/ceph</filename> in jedem Monitor Node, da das Quorum bei hohen Festplattenlatenzen möglicherweise instabil ist. Zwei Festplatten in der RAID 1-Konfiguration werden aus Redundanzgründen empfohlen. Es wird empfohlen, dass separate Festplatten oder mindestens separate Festplattenpartitionen für die Überwachungsprozesse zur Verfügung stehen, um den verfügbaren Festplattenspeicherplatz des Monitors vor Ereignissen wie schleichender Protokolldateiausweitung zu schützen.
    </para>
   </listitem>
   <listitem>
    <para>
     Pro Node darf nur ein Überwachungsprozess vorhanden sein.
    </para>
   </listitem>
   <listitem>
    <para>
     Die Kombination von OSD, Monitor oder Object Gateway Nodes wird nur unterstützt, wenn ausreichend Hardwareressourcen verfügbar sind. Dies bedeutet, dass die Anforderungen für alle Services aufsummiert werden müssen.
    </para>
   </listitem>
   <listitem>
    <para>
     Zwei Netzwerkschnittstellen verbunden mit mehreren Schaltern.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sysreq-rgw">
  <title>Object Gateway Nodes</title>

  <para>
   Object Gateway Nodes sollten sechs bis acht CPU Cores und 32 GB RAM haben (64 GB empfohlen). Wenn sich noch andere Prozesse auf demselben Rechner befinden, müssen deren Anforderungen aufsummiert werden.
  </para>
 </sect1>
 <sect1 xml:id="sysreq-mds">
  <title>Metadata Server Nodes</title>

  <para>
   Die richtige Größe der Metadata Server Nodes hängt vom spezifischen Anwendungsfall ab. Generell gilt, je mehr offene Dateien der Metadata Server verarbeiten muss, desto mehr CPU und RAM benötigt er. Nachfolgend finden Sie die Mindestanforderungen an die 
  </para>

  <itemizedlist>
   <listitem>
    <para>
     3 GB RAM für jeden Metadatenserver-Daemon.
    </para>
   </listitem>
   <listitem>
    <para>
     Gebundene Netzwerkschnittstelle.
    </para>
   </listitem>
   <listitem>
    <para>
     2,5 GHz CPU mit mindestens 2 Cores.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sysreq-smaster">
  <title>Salt Master</title>

  <para>
   Mindestens 4 GB RAM und ein CPU mit vier Cores sind erforderlich. Dies umfasst die Ausführung des Ceph Dashboards auf dem Admin Node. Für große Cluster mit Hunderten von Nodes werden 6 GB RAM vorgeschlagen.
  </para>
 </sect1>
 <sect1 xml:id="sysreq-iscsi">
  <title>iSCSI Nodes</title>

  <para>
   iSCSI Nodes sollten sechs bis acht CPU-Cores und 16 GB RAM haben.
  </para>
 </sect1>
 <sect1 xml:id="ceph-install-ceph-deploy-network">
  <title>Netzwerkempfehlungen</title>

  <para>
   Die Netzwerkumgebung, in der Sie Ceph ausführen möchten, sollte idealerweise eine gebundene Gruppe von mindestens zwei Netzwerkschnittstellen sein, die logisch aufgeteilt ist in einen öffentlichen Teil und einen verbürgten internen Teil über VLANs. Der empfohlene Bindungsmodus ist 802.3ad, falls möglich, um maximale Bandbreite und Stabilität zur Verfügung zu stellen.
  </para>

  <para>
   Das öffentliche VLAN dient dazu, den Service für Kunden bereitzustellen. Der interne Teil sorgt für die authentifizierte Ceph Netzwerkkommunikation. Der Hauptgrund dafür besteht darin, dass die Nachrichten zum Konfigurieren geheimer Schlüssel möglicherweise öffentlich übertragen werden und daher eine Schwachstelle darstellen, denn Ceph bietet Authentifizierung und Schutz vor Angriffen erst, nachdem diese geheimen Schlüssel hinzugefügt wurden.
  </para>

  <tip>
   <title>Über DHCP konfigurierte Nodes</title>
   <para>
    Wenn Ihre Speicher-Nodes über DHCP konfiguriert werden, reichen die standardmäßigen Zeitüberschreitungen möglicherweise nicht für eine korrekte Konfiguration des Netzwerks aus, bevor die Ceph Daemons starten. In diesem Fall starten die Ceph MONs und OSDs nicht korrekt (die Ausführung von <command>systemctl status ceph\*</command> führt zu „unable to bind“-Fehlern). Wir empfehlen, die Zeitüberschreitung des DHCP-Clients in jedem Node in Ihrem Speicher-Cluster auf mindestens 30 Sekunden zu erhöhen. Dies wird erreicht durch Ändern der folgenden Einstellungen in jedem Node:
   </para>
   <para>
    Legen Sie in <filename>/etc/sysconfig/network/dhcp</filename> Folgendes fest:
   </para>
<screen>DHCLIENT_WAIT_AT_BOOT="30"</screen>
   <para>
    Legen Sie in <filename>/etc/sysconfig/network/config</filename> Folgendes fest:
   </para>
<screen>WAIT_FOR_INTERFACES="60"</screen>
  </tip>

  <sect2 xml:id="storage-bp-net-private">
   <title>Hinzufügen eines privaten Netzwerks zu einem aktiven Cluster</title>
   <para>
    Wenn Sie bei der Ceph-Bereitstellung kein Cluster-Netzwerk angeben, dann wird eine einzelne öffentliche Netzwerkumgebung angenommen. Auch wenn Ceph in einem öffentlichen Netzwerk gut funktioniert, wird seine Leistung und Sicherheit durch Festlegen eines zweiten privaten Cluster-Netzwerks erhöht. Zur Unterstützung von zwei Netzwerken muss jeder Ceph Node über mindestens zwei Netzwerkkarten verfügen.
   </para>
   <para>
    Sie müssen auf jeden Ceph Node die folgenden Änderungen anwenden. Bei einem kleinen Cluster ist dies relativ schnell erledigt, doch bei einem Cluster mit Hunderten oder Tausenden Nodes kann dieser Vorgang sehr zeitaufwändig sein.
   </para>
   <procedure>
    <step>
     <para>
      Halten Sie die auf Ceph bezogenen Services in jedem Cluster Node an.
     </para>
     <para>
      Fügen Sie eine Zeile zu <filename>/etc/ceph/ceph.conf</filename> hinzu, um das Cluster-Netzwerk zu definieren. Beispiel:
     </para>
<screen>cluster network = 10.0.0.0/24</screen>
     <para>
      Wenn Sie eigens statische IP-Adressen zuweisen oder die <option>cluster network</option>-Einstellungen außer Kraft setzen müssen, können Sie dies mit der optionalen Einstellung <option>cluster addr</option> erledigen.
     </para>
    </step>
    <step>
     <para>
      Überprüfen Sie, ob das private Cluster-Netzwerk auf Betriebssystemebene wie erwartet funktioniert.
     </para>
    </step>
    <step>
     <para>
      Starten Sie die auf Ceph bezogenen Services in jedem Cluster Node.
     </para>
<screen><prompt>root # </prompt>systemctl start ceph.target</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="storage-bp-net-subnets">
   <title>Monitor Nodes in verschiedenen Teilnetzen</title>
   <para>
    Wenn sich die Monitor Nodes in mehreren Teilnetzen befinden, beispielsweise in verschiedenen Räumen und durch verschiedene Schalter gesteuert, dann müssen Sie die Datei <filename>ceph.conf</filename> entsprechend anpassen. Wenn beispielsweise die Nodes die IP-Adressen 192.168.123.12, 1.2.3.4 und 242.12.33.12 aufweisen, fügen Sie die folgenden Zeilen zum Abschnitt <literal>global</literal> hinzu:
   </para>
<screen>[global]
[...]
mon host = 192.168.123.12, 1.2.3.4, 242.12.33.12
mon initial members = MON1, MON2, MON3
[...]</screen>
   <para>
    Müssen Sie eine öffentliche Adresse oder ein öffentliches Netzwerk pro Monitor angeben, dann müssen Sie außerdem einen Abschnitt <literal>[mon.<replaceable>X</replaceable>]</literal> für jeden Monitor hinzufügen:
   </para>
<screen>[mon.MON1]
public network = 192.168.123.0/24

[mon.MON2]
public network = 1.2.3.0/24

[mon.MON3]
public network = 242.12.33.12/0</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="sysreq-naming">
  <title>Benennungseinschränkungen</title>

  <para>
   Ceph unterstützt nicht generell Nicht-ASCII-Zeichen in Konfigurationsdateien, Pool-Namen, Benutzernamen und so weiter. Wir empfehlen, beim Konfigurieren eines Ceph Clusters in allen Ceph-Objekt- bzw. Konfigurationsnamen nur einfache alphanumerische Zeichen (A-Z, a-z, 0-9) und wenige Satzzeichen  ('.', '-', '_') zu verwenden.
  </para>
 </sect1>
 <sect1 xml:id="ses-bp-diskshare">
  <title>Ein einziger Server für OSD und Monitor</title>

  <para>
   Obwohl es technisch möglich ist, Ceph OSDs und Monitors in Testumgebungen auf demselben Server auszuführen, empfehlen wir dringend, einen separaten Server für jeden Monitor Node in der Produktionsumgebung einzurichten. Der hauptsächliche Grund dafür ist die Leistung. Je mehr OSDs der Cluster enthält, desto mehr E/A-Operationen müssen die Monitor Nodes durchführen. Wenn ein Server von einem Monitor Node und OSD(s) gemeinsam genutzt wird, stellen die E/A-Operationen des OSD eine Beschränkung für den Monitor Node dar.
  </para>

  <para>
   Es ist weiterhin zu überlegen, ob Festplatten von einem OSD, einem Monitor Node und dem Betriebssystem auf dem Server gemeinsam genutzt werden sollen. Die Antwort ist einfach: wenn möglich, stellen Sie eine separate Festplatte für den OSD bereit und einen separaten Server für einen Monitor Node.
  </para>

  <para>
   Obwohl Ceph verzeichnisbasierte OSDs unterstützt, sollte für einen OSD immer eine eigene Festplatte vorhanden sein und nicht die des Betriebssystems dafür genutzt werden.
  </para>

  <tip>
   <para>
    Wenn es <emphasis>wirklich</emphasis> erforderlich ist, OSD und Monitor Node auf demselben Server auszuführen, führen Sie den Monitor auf einer separaten Festplatte aus. Hängen Sie dazu die Festplatte im Verzeichnis <filename>/var/lib/ceph/mon</filename> ein, um die Leistung etwas zu verbessern.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="ses-bp-production-cluster">
  <title>Empfohlene Konfiguration für Produktions-Cluster</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Sieben Objektspeicher-Nodes
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Die einzelnen Nodes dürfen nicht mehr als ca. 15 % des Gesamtspeichers ausmachen
      </para>
     </listitem>
     <listitem>
      <para>
       10 GB Ethernet (vier physische Netzwerke gebunden an mehrere Schalter)
      </para>
     </listitem>
     <listitem>
      <para>
       Mindestens 56 OSDs pro Speicher-Cluster
      </para>
     </listitem>
     <listitem>
      <para>
       RAID 1-Betriebssystemfestplatte für jeden OSD-Speicher-Node
      </para>
     </listitem>
     <listitem>
      <para>
       SSDs für Journal im Verhältnis 6:1 von SSD-Journal zu OSD
      </para>
     </listitem>
     <listitem>
      <para>
       1,5 GB RAM pro TB der OSD-Basiskapazität für jeden Objektspeicher-Node
      </para>
     </listitem>
     <listitem>
      <para>
       2 GHz pro OSD für jeden Objektspeicher-Node
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Dedizierte physische Infrastruktur-Nodes
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Drei Ceph Monitor Nodes: 4 GB RAM, 4-Core-Prozessor, RAID 1-SSDs als Festplatte
      </para>
     </listitem>
     <listitem>
      <para>
       Ein SES-Verwaltungs-Node: 4 GB RAM, 4-Core-Prozessor, RAID 1-SSDs als Festplatte
      </para>
     </listitem>
     <listitem>
      <para>
       Redundante physische Bereitstellung von Gateway oder Metadata Server Nodes:
      </para>
      <itemizedlist>
       <listitem>
        <para>
         Object Gateway Nodes: 32 GB RAM, 8-Core-Prozessor, RAID 1-SSDs als Festplatte
        </para>
       </listitem>
       <listitem>
        <para>
         iSCSI Gateway Nodes: 16 GB RAM, 4-Core-Prozessor, RAID 1-SSDs als Festplatte
        </para>
       </listitem>
       <listitem>
        <para>
         Metadata Server Nodes (einer aktiv, einer unmittelbar betriebsbereit im Standby-Modus): 32 GB RAM, 8-Core-Prozessor, RAID 1-SSDs als Festplatte
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="req-ses-other">
  <title>SUSE Enterprise Storage 6 und andere SUSE-Produkte</title>

  <para>
   Dieser Abschnitt enthält wichtige Informationen zur Integration von SUSE Enterprise Storage 6 in andere SUSE-Produkte.
  </para>

  <sect2 xml:id="req-ses-suma">
   <title>SUSE Manager</title>
   <para>
    SUSE Manager und SUSE Enterprise Storage sind nicht integriert. Daher kann SUSE Manager aktuell keinen SUSE Enterprise Storage Cluster verwalten.
   </para>
  </sect2>
 </sect1>
</chapter>
