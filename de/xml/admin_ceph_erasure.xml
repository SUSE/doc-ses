<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_erasure.xml" version="5.0" xml:id="cha-ceph-erasure">
 <title>Erasure Coded Pools</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>Bearbeiten</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>Ja</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Ceph bietet eine Alternative zur normalen Reproduktion von Daten in Pools, die als <emphasis>Erasure</emphasis> oder <emphasis>Erasure Coded</emphasis> Pool bezeichnet wird. Erasure Pools bieten nicht alle Funktionen der <emphasis>reproduzierten</emphasis> Pools (sie können beispielsweise keine Metadaten für RBD-Pools speichern), belegen jedoch weniger Basisspeicherplatz. Ein standardmäßiger Erasure Pool, in dem 1 TB Daten gespeichert werden können, erfordert 1,5 TB Basisspeicherplatz für einen einzelnen Festplattenausfall. Im Vergleich dazu benötigt ein reproduzierter Pool einen Basisspeicherplatz von 2 TB für denselben Zweck.
 </para>
 <para>
  Hintergrundinformationen zu dem Begriff Erasure Code finden Sie unter <link xlink:href="https://en.wikipedia.org/wiki/Erasure_code"/>.
 </para>
 <note>
  <para>
   Wenn Sie mit FileStore arbeiten, haben Sie erst Zugriff auf Erasure Coded Pools über die RBD-Schnittstelle, wenn Sie eine Cache-Schicht konfigurieren. Weitere Informationen finden Sie in <xref linkend="ceph-tier-erasure"/> oder im standardmäßigen BlueStore (siehe <xref linkend="about-bluestore"/>).
  </para>
 </note>
 <sect1 xml:id="ec-prerequisite">
  <title>Voraussetzungen für Pools mit Löschcodierung</title>

  <para>
   Zur Nutzung von Erasure Coding muss Folgendes ausgeführt werden:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Definieren Sie eine Löschregel in der CRUSH-Zuordnung.
    </para>
   </listitem>
   <listitem>
    <para>
     Definieren Sie ein Löschcode-Profil, in dem der zu verwendende Codierungsalgorithmus angegeben ist.
    </para>
   </listitem>
   <listitem>
    <para>
     Erstellen Sie einen Pool mit der obigen Regel und dem Profil.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Denken Sie daran, dass das Profil und die Details im Profil nicht mehr geändert werden können, sobald der Pool erstellt wurde und Daten in den Pool aufgenommen wurden.
  </para>

  <para>
   Stellen Sie sicher, dass die CRUSH-Regeln für <emphasis>Erasure Pools</emphasis> <literal>indep</literal> für <literal>step</literal> verwenden. Weitere Informationen finden Sie in <xref linkend="datamgm-rules-step-mode"/>.
  </para>
 </sect1>
 <sect1 xml:id="cha-ceph-erasure-default-profile">
  <title>Erstellen eines Erasure Coded Pools für Testzwecke</title>

  <para>
   Der einfachste Erasure Coded Pool entspricht RAID5 und benötigt mindestens drei Hosts. Dieser Vorgang beschreibt die Erstellung eines Pools für Testzwecke.
  </para>

  <procedure>
   <step>
    <para>
     Mit dem Kommando <command>ceph osd pool create</command> wird ein Pool vom Typ <emphasis>erasure</emphasis> erstellt. Die Zahl <literal>12</literal> steht für die Anzahl der Placement Groups. Mit den Standardparametern kann der Pool den Ausfall eines OSD verarbeiten.
    </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool create ecpool 12 12 erasure
pool 'ecpool' created</screen>
   </step>
   <step>
    <para>
     Die Zeichenkette <literal>ABCDEFGHI</literal> wird in ein Objekt namens <literal>NYAN</literal> geschrieben.
    </para>
<screen><prompt>cephadm@adm &gt; </prompt>echo ABCDEFGHI | rados --pool ecpool put NYAN -</screen>
   </step>
   <step>
    <para>
     Für Testzwecke können die OSDs nun deaktiviert werden, zum Beispiel durch Trennen vom Netzwerk.
    </para>
   </step>
   <step>
    <para>
     Auf den Inhalt der Datei wird mit dem Kommando <command>rados</command> zugegriffen, um zu testen, ob der Pool den Ausfall von Geräten verarbeiten kann.
    </para>
<screen><prompt>cephadm@adm &gt; </prompt>rados --pool ecpool get NYAN -
ABCDEFGHI</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="cha-ceph-erasure-erasure-profiles">
  <title>Erasure Code Profile</title>

  <para>
   Wird das Kommando <command>ceph osd pool create</command> zum Erstellen eines <emphasis>erasure pool</emphasis> aufgerufen, dann wird das Standardprofil verwendet, es sei denn ein anderes Profil wird angegeben. Profile definieren die Redundanz von Daten. Dies erfolgt durch Festlegen von zwei Parametern, die willkürlich als <literal>k</literal> und <literal>m</literal> bezeichnet werden. k und m definieren, in wie viele <literal>Datenblöcke</literal> eine bestimmte Datenmenge aufgeteilt und wie viele Codierungs-Datenblöcke erstellt werden. Redundante Datenblöcke werden dann auf verschiedenen OSDs gespeichert.
  </para>

  <para>
   Für Erasure Pool-Profile erforderliche Definitionen:
  </para>

  <variablelist>
   <varlistentry>
    <term>chunk</term>
    <listitem>
     <para>
      Wenn die Verschlüsselungsfunktion aufgerufen wird, gibt sie Datenblöcke der selben Größe zurück: Datenblöcke, die verkettet werden können, um das ursprüngliche Objekt zu rekonstruieren sowie Codierungs-Datenblöcke, mit denen ein verlorener Datenblock neu aufgebaut werden kann.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>k</term>
    <listitem>
     <para>
      Die Anzahl der Datenblöcke, d. h. die Anzahl der Blöcke, in die das ursprüngliche Objekt aufgeteilt wurde. Bei einem Wert von beispielsweise <literal>k=2</literal> wird ein Objekt von 10 KB in <literal>k</literal> Objekte zu je 5 KB aufgeteilt. Der Standardwert für <literal>min_size</literal> für Pools mit Löschcodierung lautet <literal>k + 1</literal>. Es wird jedoch empfohlen, <literal>min_size</literal> auf einen Wert von mindestens <literal>k + 2</literal> festzulegen, damit keine Schreib- und Datenverluste eintreten.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>m</term>
    <listitem>
     <para>
      Die Anzahl der Codierungs-Datenblöcke, d. h. die Anzahl der zusätzlichen Blöcke, die durch die Verschlüsselungsfunktionen berechnet werden. Bei 2 Codierungs-Datenblöcken können 2 OSDs ausfallen, ohne dass Daten verloren gehen.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>crush-failure-domain</term>
    <listitem>
     <para>
      Definiert, an welche Geräte die Datenblöcke verteilt werden. Ein Bucket-Typ muss als Wert festgelegt werden. Alle Bucket-Typen finden Sie in <xref linkend="datamgm-buckets"/>. Wenn die Fehlerdomäne <literal>rack</literal> lautet, werden die Datenblöcke in verschiedenen Racks gespeichert, um die Stabilität im Fall von Rack-Fehlern zu erhöhen. Denken Sie daran, das hierfür k+m Racks erforderlich sind.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Mit dem in <xref linkend="cha-ceph-erasure-default-profile"/> verwendeten standardmäßigen Löschcode-Profil verlieren Sie keine Cluster-Daten, wenn ein einzelnes OSD oder ein einzelner Host ausfällt. Daher benötigt es zum Speichern von 1 TB Daten weitere 0,5 TB Basisspeicherplatz. Für 1 TB Daten sind daher 1,5 TB Basisspeicherplatz erforderlich (k=2, m=1). Dies entspricht einer allgemeinen RAID5-Konfiguration. Zum Vergleich: Ein reproduzierter Pool benötigt 2 TB Basisspeicherplatz zum Speichern von 1 TB Daten.
  </para>

  <para>
   Die Einstellungen des Standardprofils werden angezeigt mit:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd erasure-code-profile get default
directory=.libs
k=2
m=1
plugin=jerasure
crush-failure-domain=host
technique=reed_sol_van</screen>

  <para>
   Es ist wichtig, das richtige Profil zu wählen, weil es nach Erstellung des Pools nicht mehr geändert werden kann. Ein neuer Pool mit einem anderen Profil muss erstellt und alle Objekte müssen vom vorigen Pool in den neuen Pool verschoben werden (siehe <xref linkend="pools-migration"/>).
  </para>

  <para>
   Die wichtigsten Parameter des Profils sind <literal>k</literal>, <literal>m</literal> und <literal>crush-failure-domain</literal>, weil sie den Speicher-Overhead und die Datenhaltbarkeit definieren. Wenn beispielsweise die gewünschte Architektur den Verlust von zwei Racks mit einem Speicher-Overhead von 66 % kompensieren muss, kann das folgende Profil definiert werden. Dies gilt jedoch nur für eine CRUSH-Zuordnung mit Buckets vom Typ „rack“:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd erasure-code-profile set <replaceable>myprofile</replaceable> \
   k=3 \
   m=2 \
   crush-failure-domain=rack</screen>

  <para>
   Das Beispiel in <xref linkend="cha-ceph-erasure-default-profile"/> kann mit diesem neuen Profil wiederholt werden:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd pool create ecpool 12 12 erasure <replaceable>myprofile</replaceable>
<prompt>cephadm@adm &gt; </prompt>echo ABCDEFGHI | rados --pool ecpool put NYAN -
<prompt>cephadm@adm &gt; </prompt>rados --pool ecpool get NYAN -
ABCDEFGHI</screen>

  <para>
   Das NYAN-Objekt wird in drei Datenblöcke aufgeteilt (<literal>k=3</literal>) und zwei weitere Datenblöcke werden erstellt (<literal>m=2</literal>). Der Wert von <literal>m</literal> definiert, wie viele OSDs gleichzeitig ausfallen können, ohne dass Daten verloren gehen. Mit <literal>crush-failure-domain=rack</literal> wird ein CRUSH-Regelsatz erstellt, der sicherstellt, dass keine zwei Datenblöcke im selben Rack gespeichert werden.
  </para>

  <informalfigure>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_erasure_obj.png" width="80%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_erasure_obj.png" width="60%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </informalfigure>

  <sect2 xml:id="ec-create">
   <title>Erstellen eines neuen Löschcode-Profils</title>
   <para>
    Mit folgendem Kommando erstellen Sie ein neues Löschcode-Profil:
   </para>
<screen>
<prompt>root # </prompt>ceph osd erasure-code-profile set <replaceable>NAME</replaceable> \
 directory=<replaceable>DIRECTORY</replaceable> \
 plugin=<replaceable>PLUGIN</replaceable> \
 stripe_unit=<replaceable>STRIPE_UNIT</replaceable> \
 <replaceable>KEY</replaceable>=<replaceable>VALUE</replaceable> ... \
 --force
</screen>
   <variablelist>
    <varlistentry>
     <term>VERZEICHNIS</term>
     <listitem>
      <para>
       Optional. Legen Sie den Namen des Verzeichnisses fest, aus dem das Löschcode-Plugin geladen werden soll. Der Standardwert lautet <filename>/usr/lib/ceph/erasure-code</filename>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>PLUGIN</term>
     <listitem>
      <para>
       Optional. Mit dem Löschcode-Plugin können Sie Kodierungsblöcke berechnen und fehlende Blöcke wiederherstellen. Verfügbare Plugins: „jerasure“, „isa“, „lrc“ und „shes“. Der Standardwert lautet „jerasure“.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>STRIPE_UNIT</term>
     <listitem>
      <para>
       Optional. Datenmenge in einem Datenblock pro Stripe. Bei einem Profil mit 2 Datenblöcken und dem Wert „stripe_unit=4K“ wird beispielsweise der Bereich 0–4K in Block 0 abgelegt, 4K–8K in Block 1 und 8K–12K wieder in Block 0. Dieser Wert muss ein Vielfaches von 4K sein, damit die bestmögliche Leistung erzielt wird. Der Standardwert wird beim Erstellen eines Pools aus der Monitor-Konfigurationsoption <option>osd_pool_erasure_code_stripe_unit</option> abgerufen. Der Wert für „stripe_width“ eines Pools mit diesem Profil entspricht der Anzahl der Datenblöcke, multipliziert mit diesem Wert für „stripe_unit“.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>KEY=VALUE</term>
     <listitem>
      <para>
       Schlüssel-/Wertepaare von Optionen für das ausgewählte Löschcode-Plugin.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>--force</term>
     <listitem>
      <para>
       Optional. Überschreibt ein vorhandenes Profil mit demselben Namen und ermöglicht die Einstellung eines nicht durch 4K teilbaren Werts für „stripe_unit“.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ec-rm">
   <title>Entfernen eines Löschcode-Profils</title>
   <para>
    Mit folgendem Kommando entfernen Sie das unter <replaceable>NAME</replaceable> angegebene Löschcode-Profil:
   </para>
<screen>
<prompt>root # </prompt>ceph osd erasure-code-profile rm <replaceable>NAME</replaceable>
</screen>
   <important>
    <para>
     Wenn ein Pool auf das Profil verweist, kann das Profil nicht gelöscht werden.
    </para>
   </important>
  </sect2>

  <sect2 xml:id="ec-get">
   <title>Abrufen der Details eines Löschcode-Profils</title>
   <para>
    Mit folgendem Kommando rufen Sie Details für das unter <replaceable>NAME</replaceable> angegebene Löschcode-Profil ab:
   </para>
<screen>
<prompt>root # </prompt>ceph osd erasure-code-profile get <replaceable>NAME</replaceable>
</screen>
  </sect2>

  <sect2 xml:id="ec-ls">
   <title>Auflisten von Löschcode-Profilen</title>
   <para>
    Mit folgendem Kommando rufen Sie eine Liste der Namen aller Löschcode-Profile ab:
   </para>
<screen>
<prompt>root # </prompt>ceph osd erasure-code-profile ls
</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="ec-rbd">
  <title>Erasure Coded Pools mit RADOS Block Device</title>

  <para>
   Setzen Sie ein entsprechendes Tag, wenn Sie einen EC Pool als RBD-Pool kennzeichnen möchten:
  </para>

<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd pool application enable rbd <replaceable>ec_pool_name</replaceable>
</screen>

  <para>
   RBD kann Image-<emphasis>Daten</emphasis> in EC Pools speichern. Der Image Header und die Metadaten müssen jedoch weiterhin in einem reproduzierten Pool gespeichert werden. Nehmen wir an, Sie verfügen zu diesem Zweck über einen Pool namens „rbd“:
  </para>

<screen>
<prompt>cephadm@adm &gt; </prompt>rbd create rbd/<replaceable>image_name</replaceable> --size 1T --data-pool <replaceable>ec_pool_name</replaceable>
</screen>

  <para>
   Sie können das Image normalerweise wie jedes andere Image verwenden, außer dass alle Daten im Pool <replaceable>ec_pool_name</replaceable> gespeichert werden statt im „rbd“-Pool.
  </para>
 </sect1>
</chapter>
