<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Upgrade von vorigen Versionen</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>Bearbeiten</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>Ja</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  In diesem Kapitel finden Sie die Schritte zum Aufrüsten von SUSE Enterprise Storage 5.5 auf Version 6. Version 5.5 entspricht im Grunde der Version 5, auf die alle aktuellen Patches angewendet wurden.
 </para>
 <note>
  <title>Keine Unterstützung für das Upgrade älterer Versionen</title>
  <para>
   Das Upgrade von SUSE Enterprise Storage-Versionen vor 5.5 wird nicht unterstützt. Sie müssen zunächst auf die aktuelle Version von SUSE Enterprise Storage 5.5 aufrüsten und dann die Schritte in diesem Kapitel ausführen.
  </para>
 </note>
 <sect1 xml:id="upgrade-consider-points">
  <title>Vor dem Upgrade zu beachtende Punkte</title>

  <itemizedlist>
   <listitem>
    <para>
     <emphasis>In den Versionshinweisen</emphasis> finden Sie zusätzliche Informationen zu den Änderungen, die seit der vorigen Version von SUSE Enterprise Storage vorgenommen wurden. Informieren Sie sich in den Versionshinweisen über Folgendes:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Sind bei der Hardware besondere Überlegungen zu beachten?
      </para>
     </listitem>
     <listitem>
      <para>
       Wurden erhebliche Änderungen an den verwendeten Software-Paketen vorgenommen?
      </para>
     </listitem>
     <listitem>
      <para>
       Gelten besondere Vorsichtsmaßnahmen für die vorliegende Installation?
      </para>
     </listitem>
    </itemizedlist>
    <para>
     In den Versionshinweisen finden Sie auch Informationen, die erst nach der Fertigstellung des Handbuchs bekannt wurden. Auch bekannte Probleme werden beschrieben.
    </para>
    <para>
     Nach Installation des Pakets <package>release-notes-ses</package>finden Sie die Versionshinweise lokal im Verzeichnis <filename>/usr/share/doc/release-notes</filename> oder online unter <link xlink:href="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Falls Sie zuvor Version 4 aufgerüstet haben, prüfen Sie, ob das Upgrade auf Version 5 erfolgreich abgeschlossen wurde:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Prüfen Sie, ob folgende Datei vorhanden ist:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.import</screen>
      <para>
       Die Datei wird beim Importprozess während des Upgrades von SES 4 auf 5 erstellt. Außerdem wird die Option <option>configuration_init: default-import</option> in folgender Datei festgelegt:
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <para>
       Wenn <option>configuration_init</option> noch auf <option>default-import</option> eingestellt ist, greift der Cluster auf <filename>ceph.conf.import</filename> als Konfigurationsdatei zurück, nicht auf die Standarddatei <filename>ceph.conf</filename> von DeepSea, die aus Dateien in folgendem Verzeichnis kompiliert wird:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Sie müssen daher <filename>ceph.conf.import</filename> auf benutzerdefinierte Konfigurationen prüfen und diese Konfigurationen ggf. in eine der Dateien in folgendem Verzeichnis verschieben:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Entfernen Sie anschließend die Zeile <option>configuration_init: default-import</option> aus
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <warning>
       <title>Standardmäßige DeepSea-Konfiguration</title>
       <para>
        Wenn Sie <emphasis role="bold">nicht</emphasis> die Konfiguration aus <filename>ceph.conf.import</filename> zusammenführen und die Option <option>configuration_init: default-import</option> entfernen, werden alle standardmäßigen Konfigurationseinstellungen von DeepSea (in <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> gespeichert) nicht auf den Cluster angewendet.
       </para>
      </warning>
     </listitem>
     <listitem>
      <para>
       Prüfen Sie, ob der Cluster den neuen Bucket-Typ „straw2“ nutzt:
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep straw
</screen>
     </listitem>
     <listitem>
      <para>
       Prüfen Sie, ob das Ceph Profil „jewel“ verwendet wird:
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep profile
</screen>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Werden ältere RBD-Kernel-Clients (vor SUSE Linux Enterprise Server 12 SP3) verwendet, beachten Sie <xref linkend="rbd-old-clients-map"/>. Es wird empfohlen, ältere RBD-Kernel-Clients nach Möglichkeit aufzurüsten.
    </para>
   </listitem>
   <listitem>
    <para>
     Wenn sich openATTIC auf dem Admin Node befindet, ist es nach dem Aufrüsten des Knotens nicht mehr verfügbar. Das neue Ceph Dashboard ist dann verfügbar, wenn Sie es mit DeepSea implementiert haben.
    </para>
   </listitem>
   <listitem>
    <para>
     Das Cluster-Upgrade kann lange dauern, nämlich in etwa so lange, wie es dauert, ein Upgrade eines Computers multipliziert mit der Anzahl der Cluster Nodes durchzuführen.
    </para>
   </listitem>
   <listitem>
    <para>
     Ein einzelner Knoten kann nicht aufgerüstet werden, wenn darauf noch die vorherige SUSE Linux Enterprise Server-Version ausgeführt wird, sondern muss mit dem Installationsprogramm der neuen Version neu gestartet werden. Die Services, die dieser Knoten anbietet, stehen daher eine gewisse Zeit lang nicht zur Verfügung. Die wesentlichen Cluster-Services sind weiterhin verfügbar – ist beispielsweise ein MON während des Upgrades inaktiv, gibt es dennoch mindestens zwei aktive MONs. Services, für die nur eine einzelne Instanz vorliegt, z. B. ein einzelnes iSCSI-Gateway, stehen leider nicht zur Verfügung.
    </para>
   </listitem>
   <listitem>
    <para>
     Bestimmte Arten von Daemons hängen von anderen ab. Beispielsweise hängen Object Gateways von Ceph MON und Ceph OSD Daemons ab. Wir empfehlen für das Upgrade die folgende Reihenfolge:
    </para>
    <orderedlist spacing="normal">
     <listitem>
      <para>
       Admin Node
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitors/Ceph Managers
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSDs
      </para>
     </listitem>
     <listitem>
      <para>
       Object Gateways
      </para>
     </listitem>
     <listitem>
      <para>
       iSCSI Gateways
      </para>
     </listitem>
     <listitem>
      <para>
       NFS Ganesha
      </para>
     </listitem>
     <listitem>
      <para>
       Samba Gateways
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Wenn Sie AppArmor im Modus „complain“ oder „enforce“ ausgeführt hatten, müssen Sie vor dem Upgrade eine Salt-Pillar-Variable festlegen. SUSE Linux Enterprise Server 15 SP1 umfasst standardmäßig AppArmor, weshalb die AppArmor-Verwaltung in die DeepSea-Phase 0 integriert wurde. Laut dem Standardverhalten in SUSE Enterprise Storage 6 werden AppArmor und die zugehörigen Profile entfernt. Soll das in SUSE Enterprise Storage 5.5 konfigurierte Verhalten beibehalten werden, prüfen Sie, ob die Datei <filename>/srv/pillar/ceph/stack/global.yml</filename> eine der folgenden Zeilen enthält, bevor Sie das Upgrade starten:
    </para>
<screen>
apparmor_init: default-enforce
</screen>
    <para>
     oder
    </para>
<screen>
apparmor_init: default-complain
</screen>
   </listitem>
   <listitem>
    <para>
     Ab SUSE Enterprise Storage 6 sind MDS-Namen, die mit einer Ziffer beginnen, nicht mehr zulässig und MDS-Daemons werden nicht gestartet. Sie können prüfen, ob Ihre Daemons solche Namen aufweisen. Führen Sie hierzu entweder das Kommando <command>ceph fs status</command> aus oder starten Sie einen MDS neu und prüfen Sie, ob dessen Protokolle die folgende Meldung enthalten:
    </para>
<screen>
deprecation warning: MDS id 'mds.1mon1' is invalid and will be forbidden in
a future version.  MDS names may not start with a numeric digit.
</screen>
    <para>
     Wird die obige Meldung angezeigt, müssen die MDS-Namen migriert werden, bevor Sie auf SUSE Enterprise Storage 6 aufrüsten können. DeepSea umfasst eine Orchestrierung, mit der diese Migration automatisiert wird. Den MDS-Namen, die mit einer Ziffer beginnen, wird „mds“ vorangestellt.:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.mds.migrate-numerical-names
</screen>
    <tip>
     <title>Benutzerdefinierte Konfiguration mit Bindung an MDS-Namen</title>
     <para>
      Wenn bestimmte Konfigurationseinstellungen an MDS-Namen gebunden sind und die Namen Ihrer MDS-Daemons mit einer Ziffer beginnen, prüfen Sie, ob Ihre Konfigurationseinstellungen auch für die neuen Namen angewendet werden (mit dem Präfix „mds“). Betrachten Sie den folgenden Beispielabschnitt in der Datei <filename>/etc/ceph/ceph.conf</filename>:
     </para>
<screen>
[mds.123-my-mds] # config setting specific to MDS name with a name starting with a digit
mds cache memory limit = 1073741824
mds standby for name = 456-another-mds
</screen>
     <para>
      Der Orchestrator <command>ceph.mds.migrate-numerical-names</command> ersetzt den MDS-Daemon-Namen „123-my-mds“ durch „mds.123-my-mds“. Sie müssen die Konfiguration gemäß dem neuen Namen anpassen:
     </para>
<screen>
[mds.mds,123-my-mds] # config setting specific to MDS name with the new name
mds cache memory limit = 1073741824
mds standby for name = mds.456-another-mds
</screen>
    </tip>
    <para>
     Damit werden MDS-Daemons mit den neuen Namen eingefügt, bevor die bisherigen MDS-Daemons entfernt werden. Die Anzahl der MDS-Daemons verdoppelt sich für kurze Zeit. Die Clients können erst nach einer kurzen Pause für das Failover auf CephFS zugreifen. Planen Sie die Migration daher für einen Zeitraum, in dem Sie nur eine geringe oder gar keine CephFS-Auslastung erwarten.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-backup">
  <title>Sichern von Clusterdaten</title>

  <para>
   Die Sicherung der Konfiguration und Daten eines Clusters ist nicht obligatorisch. Es wird jedoch dringend empfohlen, wichtige Konfigurationsdateien und Clusterdaten zu sichern. Weitere Informationen finden Sie in <xref linkend="cha-deployment-backup"/>.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-ntp">
  <title>Migration von <systemitem class="daemon">ntpd</systemitem> zu <systemitem class="daemon">chronyd</systemitem></title>

  <para>
   SUSE Linux Enterprise Server 15 SP1 synchronisiert die Uhrzeit des lokalen Hosts nicht mehr über <systemitem class="daemon">ntpd</systemitem>. Stattdessen wird <systemitem class="daemon">chronyd</systemitem> verwendet. Sie müssen den Zeitsynchronisierungs-Daemon auf jedem Cluster Node migrieren. Sie können wahlweise <emphasis role="bold">vor</emphasis> dem Cluster-Upgrade zu <systemitem>chronyd</systemitem> migrieren oder zunächst den Cluster aufrüsten und die Migration zu <systemitem class="daemon">chronyd</systemitem>
   <emphasis role="bold">danach durchführen</emphasis>.
  </para>

  <procedure>
   <title>Migration zu <systemitem class="daemon">chronyd</systemitem> <emphasis>vor</emphasis> dem Cluster-Upgrade</title>
   <step>
    <para>
     Installieren Sie das Paket <package>chrony</package> :
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper install chrony</screen>
   </step>
   <step>
    <para>
     Bearbeiten Sie die <systemitem class="daemon">chronyd</systemitem>-Konfigurationsdatei <filename>/etc/chrony.conf</filename> und fügen Sie NTP-Quellen aus der aktuellen <systemitem class="daemon">ntpd</systemitem>-Konfiguration in <filename>/etc/ntp.conf</filename> ein.
    </para>
    <tip>
     <title>Weitere Informationen zur <systemitem class="daemon">chronyd</systemitem>-Konfiguration</title>
     <para>
      In <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> finden Sie weitere Anweisungen, wie Sie Zeitquellen in die <systemitem class="daemon">chronyd</systemitem>-Konfiguration einfügen.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Deaktivieren und stoppen Sie den <systemitem class="daemon">ntpd</systemitem>-Service:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Starten und aktivieren Sie den <systemitem class="daemon">chronyd</systemitem>-Service:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Überprüfen Sie den Status von „chrony“:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
  </procedure>

  <procedure>
   <title>Migration zu <systemitem class="daemon">chronyd</systemitem> <emphasis>nach</emphasis> dem Cluster-Upgrade</title>
   <step>
    <para>
     Fügen Sie während des Cluster-Upgrades die folgenden Software-Repositorys ein:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Pool
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Updates
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Rüsten Sie den Cluster auf Version 6 auf.
    </para>
   </step>
   <step>
    <para>
     Bearbeiten Sie die <systemitem class="daemon">chronyd</systemitem>-Konfigurationsdatei <filename>/etc/chrony.conf</filename> und fügen Sie NTP-Quellen aus der aktuellen <systemitem class="daemon">ntpd</systemitem>-Konfiguration in <filename>/etc/ntp.conf</filename> ein.
    </para>
    <tip>
     <title>Weitere Informationen zur <systemitem class="daemon">chronyd</systemitem>-Konfiguration</title>
     <para>
      In <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> finden Sie weitere Anweisungen, wie Sie Zeitquellen in die <systemitem class="daemon">chronyd</systemitem>-Konfiguration einfügen.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Deaktivieren und stoppen Sie den <systemitem class="daemon">ntpd</systemitem>-Service:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Starten und aktivieren Sie den <systemitem class="daemon">chronyd</systemitem>-Service:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Migrieren Sie von <systemitem class="daemon">ntpd</systemitem> zu <systemitem class="daemon">chronyd</systemitem>.
    </para>
   </step>
   <step>
    <para>
     Überprüfen Sie den Status von „chrony“:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
   <step>
    <para>
     Entfernen Sie die eingefügten Legacy-Software-Repositorys, mit denen <systemitem class="daemon">ntpd</systemitem> während des Upgrade-Prozesses im System beibehalten wurde.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-prepare">
  <title>Patchen des Clusters vor dem Upgrade</title>

  <para>
   Wenden Sie die aktuellen Patches vor dem Upgrade auf alle Cluster Nodes an.
  </para>

  <sect2 xml:id="upgrade-prepare-repos">
   <title>Erforderliche Software-Repositorys</title>
   <para>
    Prüfen Sie, ob die erforderlichen Repositorys auf den einzelnen Knoten konfiguriert sind. Mit folgendem Kommando rufen Sie eine Liste aller verfügbaren Repositorys ab:
   </para>
<screen>
<prompt>root@minion &gt; </prompt>zypper lr
</screen>
   <para>
    Für SUSE Enterprise Storage 5.5 erforderlich:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLES12-SP3-Installer-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Updates
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Für NFS/SMB Gateway auf SLE-HA unter SUSE Linux Enterprise Server 12 SP3 erforderlich:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLE-HA12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLE-HA12-SP3-Updates
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-staging">
   <title>Repository-Staging-Systeme</title>
   <para>
    Wenn Sie mit einem Repository-Staging-System arbeiten (SMT, RMT oder SUSE Manager), erstellen Sie eine neue, eingefrorene Patchstufe für die aktuelle und die neue SUSE Enterprise Storage-Version.
   </para>
   <para>
    Weitere Informationen finden Sie in:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html"/>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/book_rmt.html"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/suse-manager-3/index.html"/>,
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-patch">
   <title>Patchen des gesamten Clusters mit den aktuellen Patches</title>
   <procedure>
    <step>
     <para>
      Wenden Sie die aktuellen Patches für SUSE Enterprise Storage 5.5 und SUSE Linux Enterprise Server 12 SP3 auf jeden Ceph Cluster Node an. Prüfen Sie, ob die richtigen Software-Repositorys mit den einzelnen Cluster Nodes verbunden sind (siehe <xref linkend="upgrade-prepare-repos"/>) und führen Sie die DeepSea-Phase 0 aus:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    </step>
    <step>
     <para>
      Prüfen Sie nach Abschluss der Phase 0, ob der Status der einzelnen Cluster „HEALTH_OK“ umfasst. Falls nicht, beheben Sie das Problem, bevor Sie etwaige Neustarts in nachfolgenden Schritten vornehmen.
     </para>
    </step>
    <step>
     <para>
      Prüfen Sie mit <command>zypper ps</command>, ob Prozesse vorliegen, die mit veralteten Bibliotheken oder Binärdateien ausgeführt werden, und starten Sie die betreffenden Prozesse neu.
     </para>
    </step>
    <step>
     <para>
      Prüfen Sie, ob der ausgeführte Kernel die aktuell verfügbare Version aufweist, und starten Sie ihn neu, wenn dies nicht der Fall ist. Prüfen Sie die Ausgabe der folgenden Kommandos:
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>uname -a
<prompt>cephadm@adm &gt; </prompt>rpm -qa kernel-default
</screen>
    </step>
    <step>
     <para>
      Prüfen Sie, ob das Paket <package>ceph</package> in Version 12.2.12 (oder höher) vorliegt. Prüfen Sie, ob das Paket <package>deepsea</package> in Version 0.8.9 (oder höher) vorliegt.
     </para>
    </step>
    <step>
     <para>
      Wenn Sie bislang mit Einstellungen für <option>bluestore_cache</option> gearbeitet haben, sind diese Einstellungen ab <package>ceph</package>
      Version 12.2.10 nicht mehr in Kraft. Die neue Einstellung <option>bluestore_cache_autotune</option>, die standardmäßig auf „true“ eingestellt ist, deaktiviert die manuelle Festlegung der Cache-Größe. Soll das bisherige Verhalten wieder aktiviert werden, legen Sie <option>bluestore_cache_autotune=false</option> fest. Weitere Informationen finden Sie unter <xref linkend="config-auto-cache-sizing"/>.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-verify-current">
  <title>Überprüfen der aktuellen Umgebung</title>

  <itemizedlist>
   <listitem>
    <para>
     Wenn offensichtliche Probleme im System vorliegen, beheben Sie sie, bevor Sie das Upgrade starten. Allein durch das Upgrade werden bestehende Systemprobleme unter keinen Umständen behoben.
    </para>
   </listitem>
   <listitem>
    <para>
     Prüfen Sie die Cluster-Leistung. Wählen Sie hierzu unter Kommandos wie <command>rados bench</command>, <command>ceph tell osd.* bench</command> oder <command>iperf3</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Prüfen Sie den Zugriff auf Gateways (z. B. iSCSI-Gateway oder Object Gateway) und auf RADOS Block Device.
    </para>
   </listitem>
   <listitem>
    <para>
     Dokumentspezifische Teile der Systemeinrichtung, z. B. Details zur Netzwerkeinrichtung, Partitionierung oder Installation.
    </para>
   </listitem>
   <listitem>
    <para>
     Stellen Sie wichtige Systeminformationen mit <command>supportconfig</command> zusammen und speichern Sie sie außerhalb der Cluster Nodes. Weitere Informationen finden Sie in <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_admsupport_supportconfig.html"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Prüfen Sie, ob ausreichend freier Speicherplatz auf jedem Cluster Node bereitsteht. Prüfen Sie den freien Speicherplatz mit <command>df -h</command>. Bei Bedarf geben Sie Speicherplatz frei: Entfernen Sie nicht mehr benötigte Dateien/Verzeichnisse oder veraltete OS-Snapshots. Falls der Speicherplatz nicht ausreicht, setzen Sie das Upgrade erst dann fort, wenn Sie genügend Speicherplatz freigegeben haben.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-verify-state">
  <title>Prüfen des Cluster-Status</title>

  <itemizedlist>
   <listitem>
    <para>
     Führen Sie das Kommando <command>cluster health</command> aus, bevor Sie den Upgrade-Vorgang starten. Starten Sie das Upgrade erst dann, wenn jeder Cluster Node „HEALTH_OK“ meldet.
    </para>
   </listitem>
   <listitem>
    <para>
     Prüfen Sie, ob alle Services ausgeführt werden:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Salt Master und Salt Master Daemons.
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor und Ceph Manager Daemons.
      </para>
     </listitem>
     <listitem>
      <para>
       Metadatenserver Daemons.
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD Daemons.
      </para>
     </listitem>
     <listitem>
      <para>
       Object Gateway-Daemons.
      </para>
     </listitem>
     <listitem>
      <para>
       iSCSI-Gateway-Daemons.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>

  <para>
   Die folgenden Kommandos geben Details zum Cluster-Status und zur jeweiligen Konfiguration zurück:
  </para>

  <variablelist>
   <varlistentry>
    <term><command>ceph -s</command></term>
    <listitem>
     <para>
      Gibt eine kurze Zusammenfassung des Ceph Cluster-Zustands, der ausgeführten Services, der Datenauslastung und der E/A-Statistik zurück. Prüfen Sie, ob die Meldung „HEALTH_OK“ vorliegt, bevor Sie das Upgrade starten.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph health detail</command></term>
    <listitem>
     <para>
      Gibt Details zurück, wenn der Ceph Cluster-Zustand nicht in Ordnung ist.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph versions</command></term>
    <listitem>
     <para>
      Gibt die Versionen der ausgeführten Ceph Daemons zurück.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph df</command></term>
    <listitem>
     <para>
      Gibt den gesamten und den freien Speicherplatz auf dem Cluster zurück. Starten Sie das Upgrade nur dann, wenn der freie Speicherplatz im Cluster bei mindestens 25 % des gesamten Speicherplatzes liegt.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>salt '*' cephprocesses.check results=true</command></term>
    <listitem>
     <para>
      Gibt die ausgeführten Ceph-Prozesse und ihre PIDs zurück, sortiert nach den Salt Minions.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph osd dump | grep ^flags</command></term>
    <listitem>
     <para>
      Prüfen Sie, ob die Flaggen „recovery_deletes“ und „purged_snapdirs“ vorhanden sind. Falls nicht, können Sie mit folgendem Kommando ein Scrubbing für alle Platzierungsgruppen erzwingen: Beachten Sie, dass dieses erzwungene Scrubbing die Leistung Ihrer Ceph Clients unter Umständen negativ beeinflusst.
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump pgs_brief | cut -d " " -f 1 | xargs -n1 ceph pg scrub
</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1>
  <title>Offline-Upgrade von CTDB-Clustern</title>

  <para>
   CTDB umfasst eine geclusterte Datenbank, die von Samba Gateways herangezogen wird. Das CTDB-Protokoll ist sehr einfach und unterstützt keine Cluster mit Knoten, die mit anderen Protokollversionen kommunizieren. CTDB-Knoten müssen daher vor einem Upgrade offline geschaltet werden.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-one-node">
  <title>Upgrade Knoten für Knoten – Grundverfahren</title>

  <para>
   Damit die wesentlichen Cluster-Services auch während des Upgrades verfügbar sind, müssen Sie die Cluster Nodes einzeln nacheinander aufrüsten. Für das Upgrade eines Knotens stehen zwei Möglichkeiten zur Auswahl: entweder mit der <emphasis>Installationsprogramm-DVD</emphasis> oder mit dem <emphasis>Distribution Migration System</emphasis>.
  </para>

  <para>
   Nach dem Aufrüsten der einzelnen Knoten wird empfohlen, mit <command>rpmconfigcheck</command> nach aktualisierten Konfigurationsdateien zu suchen, die lokal bearbeitet wurden. Wenn das Kommando eine Liste von Dateinamen mit dem Suffix <filename>.rpmnew</filename>, <filename>.rpmorig</filename> oder <filename>.rpmsave</filename> zurückgibt, vergleichen Sie diese Dateien mit den aktuellen Konfigurationsdateien, damit gewährleistet ist, dass keine lokalen Änderungen verloren gehen. Aktualisieren Sie ggf. die betroffenen Dateien. Weitere Informationen zur Verwendung von <filename>.rpmnew</filename>-, <filename>.rpmorig</filename>- und <filename>.rpmsave</filename>-Dateien finden Sie in <link xlink:href="https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#sec-rpm-packages-manage"/>.
  </para>

  <tip>
   <title>Bezuglose Pakete</title>
   <para>
    Nach dem Aufrüsten eines Knotens sind einige Pakete „bezuglos“, besitzen also kein übergeordnetes Repository mehr. Dieser Fall tritt ein, da python2-Pakete nicht automatisch veraltet sind, wenn python3-spezifische Pakete vorliegen.
   </para>
   <para>
    Weitere Informationen zum Abrufen bezugloser Pakete finden Sie in <link xlink:href="https://www.suse.com/documentation/sles-15/book_sle_admin/data/sec_zypper.html#sec_zypper_softup_orphaned"/>.
   </para>
  </tip>

  <sect2 xml:id="upgrade-one-node-manual">
   <title>Manuelles Knoten-Upgrade mit der Installationsprogramms-DVD</title>
   <procedure>
    <step>
     <para>
      Starten Sie den Knoten von der Installationsprogramm-DVD/dem Image mit Linux Enterprise Server 15 SP1 neu.
     </para>
    </step>
    <step>
     <para>
      Wählen Sie im Boot-Menü die Option <guimenu>Upgrade</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Prüfen Sie im Bildschirm <guimenu>Select the Migration Target</guimenu> (Migrationsziel auswählen), ob „SUSE Linux Enterprise Server 15 SP1“ ausgewählt ist, und aktivieren Sie das Kontrollkästchen <guimenu>Manually Adjust the Repositories for Migration</guimenu> (Repositorys für Migration manuell anpassen).
     </para>
     <figure>
      <title>Auswahl des Migrationsziels</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Wählen Sie die folgenden Module zur Installation aus:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SUSE Enterprise Storage 6 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Basesystem Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Desktop Applications Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Legacy Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Server Applications Module 15 SP1 x86_64
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Prüfen Sie im Bildschirm <guimenu>Previously Used Repositories</guimenu> (Bisher verwendete Repositorys), ob die richtigen Repositorys 
ausgewählt sind. Falls das System nicht bei SCC/SMT registriert ist, müssen Sie die Repositorys manuell einfügen.
     </para>
     <para>
      Für SUSE Enterprise Storage 6 erforderlich:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Basesystem15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE15-SP1-Installer-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Wenn <systemitem>ntpd</systemitem> nach der SES-Migration zu <systemitem class="daemon">chronyd</systemitem> migriert werden soll (siehe <xref linkend="upgrade-ntp"/>), fügen Sie die folgenden Repositorys ein:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Für NFS/SMB Gateway auf SLE-HA unter SUSE Linux Enterprise Server 15 SP1 erforderlich:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Prüfen Sie die <guimenu>Installation Settings</guimenu> (Installationseinstellungen) und starten Sie den Installationsvorgang mit <guimenu>Update</guimenu> (Aktualisieren).
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-one-node-auto">
   <title>Knoten-Upgrade mit dem SUSE Distribution Migration System</title>
   <para>
    Das <emphasis>Distribution Migration System</emphasis> (DMS) bietet einen Pfad für das Upgrade eines installierten SUSE Linux Enterprise-Systems von einer Hauptversion auf eine andere Hauptversion. Im nachfolgenden Verfahren wird SUSE Enterprise Storage 5.5 mit DMS auf Version 6 aufgerüstet, wobei auch die zugrunde liegende Migration von SUSE Linux Enterprise Server 12 SP3 auf SUSE Linux Enterprise Server 15 SP1 durchgeführt wird.
   </para>
   <para>
    Allgemeine und ausführliche Informationen zu DMS finden Sie in <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>.
   </para>
   <procedure>
    <step>
     <para>
      Installieren Sie die RPM-Pakete für die Migration. Damit wird der GRUB-Bootloader so angepasst, dass das Upgrade beim nächsten Neustart automatisch ausgelöst wird. Installieren Sie das Paket
      <package>SLES15-SES-Migration</package> und
      <package>suse-migration-sle15-activation</package> :
     </para>
<screen><prompt>root@minion &gt; </prompt>zypper install SLES15-SES-Migration suse-migration-sle15-activation</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        Ist der aufzurüstende Knoten bei einem Repository-Staging-System wie SCC, SMT, RMT oder SUSE Manager <emphasis role="bold">registriert</emphasis>, erstellen Sie <filename>/etc/sle-migration-service.yml</filename> mit folgendem Inhalt:
       </para>
<screen>
use_zypper_migration: true
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
      </step>
      <step>
       <para>
        Ist der aufzurüstende Knoten <emphasis role="bold">nicht</emphasis> bei einem Repository-Staging-System wie SCC, SMT, RMT oder SUSE Manager registriert, nehmen Sie die folgenden Änderungen vor:
       </para>
       <substeps>
        <step>
         <para>
          Erstellen Sie <filename>/etc/sle-migration-service.yml</filename> mit folgendem Inhalt:
         </para>
<screen>
use_zypper_migration: false
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
        </step>
        <step>
         <para>
          Deaktivieren oder entfernen Sie die Repositorys für SLE 12 SP3 und SES 5 und fügen Sie die Repositorys für SLE 15 SP1 und SES 6 ein. Eine Liste der zugehörigen Repositorys finden Sie in <xref linkend="upgrade-prepare-repos"/>.
         </para>
        </step>
       </substeps>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Führen Sie einen Neustart durch, sodass das Upgrade gestartet wird. Während des laufenden Upgrades können Sie sich vom Hostsystem aus über <command>ssh</command> mit dem vorhandenen SSH-Schlüssel als Migrationsbenutzer anmelden (siehe <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>). Wenn Sie bei SUSE Enterprise Storage den physischen Zugriff oder den direkten Konsolenzugriff auf den Computer besitzen, können Sie sich auch an der Systemkonsole als <systemitem class="username">root</systemitem> mit dem Passwort <literal>sesupgrade</literal> anmelden. Der Knoten wird nach dem Upgrade automatisch neu gestartet.
     </para>
     <tip>
      <title>Upgrade-Fehler</title>
      <para>
       Wenn das Upgrade fehlschlägt, prüfen Sie <filename>/var/log/distro_migration.log</filename>. Beheben Sie das Problem, installieren Sie die RPM-Pakete für die Migration erneut und starten Sie den Knoten neu.
      </para>
     </tip>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-adm">
  <title>Upgrade des Admin Node</title>

  <itemizedlist>
   <listitem>
    <para>
     Die folgenden Kommandos sind weiterhin funktionsfähig, auch wenn auf den Salt Minions veraltete Versionen von Ceph und Salt ausgeführt werden: <command>salt '*' test.ping</command> und <command>ceph status</command>
    </para>
   </listitem>
   <listitem>
    <para>
     Nach dem Upgrade des Admin Node ist openATTIC nicht mehr installiert.
    </para>
   </listitem>
   <listitem>
    <para>
     Wenn SMT auf dem Admin Node gehostet wurde, führen Sie dessen Migration zu RMT durch (siehe <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/cha_rmt_migrate.html"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>Status der Cluster Nodes</title>
   <para>
    Nach dem Upgrade des Admin Node können Sie mit dem Kommando <command>salt-run upgrade.status</command> nützliche Informationen zu den Cluster Nodes abrufen. Mit diesem Kommando werden die Ceph- und OS-Versionen aller Knoten aufgelistet und Sie erhalten eine Empfehlung für die Reihenfolge, in der die Knoten aufgerüstet werden sollten, auf denen noch ältere Versionen ausgeführt werden.
   </para>
<screen><prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
  ceph: ceph version 14.2.1-468-g994fd9e0cc (994fd9e0ccc50c2f3a55a3b7a3d4e0ba74786d50) nautilus (stable)
  os: SUSE Linux Enterprise Server 15 SP1

Nodes running these software versions:
  admin.ceph (assigned roles: master)
  mon2.ceph (assigned roles: admin, mon, mgr)

Nodes running older software versions must be upgraded in the following order:
   1: mon1.ceph (assigned roles: admin, mon, mgr)
   2: mon3.ceph (assigned roles: admin, mon, mgr)
   3: data1.ceph (assigned roles: storage)
[...]</screen>
  </tip>
 </sect1>
 <sect1 xml:id="upgrade-mons">
  <title>Upgrade von Ceph Monitor/Ceph Manager Nodes</title>

  <itemizedlist>
   <listitem>
    <para>
     Wenn Ihr Cluster <emphasis role="bold">keine</emphasis> MDS-Rollen nutzt, rüsten Sie die MON/MGR Nodes einzeln nacheinander auf.
    </para>
   </listitem>
   <listitem>
    <para>
     Wenn der Cluster MDS-Rollen <emphasis role="bold">nutzt</emphasis> und sich die MON/MGR- und MDS-Rollen auf demselben Rechner befinden, müssen Sie den MDS Cluster verkleinern und dann die auf demselben Rechner befindlichen Knoten aufrüsten. Weitere Informationen finden Sie in <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Wenn Ihr Cluster MDS-Rollen <emphasis role="bold">nutzt</emphasis> und diese Rollen auf <emphasis role="bold">dedizierten</emphasis> Servern ausgeführt werden, rüsten Sie alle MON/MGR Nodes einzeln nacheinander auf; verkleinern Sie dann den MDS Cluster und rüsten Sie ihn auf. Weitere Informationen finden Sie in <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>Upgrade von Ceph Monitor</title>
   <para>
    Aufgrund einer Einschränkung im Ceph Monitor-Design gilt Folgendes: Sobald zwei MONs auf SUSE Enterprise Storage 6 aufgerüstet wurden und ein Quorum gebildet haben, wird der dritte MON (auf dem weiterhin SUSE Enterprise Storage 5.5 ausgeführt wird) nicht wieder in den MON-Cluster aufgenommen, wenn er neu gestartet wurde (z. B. nach dem Neustart eines Knotens). Wenn zwei MONs aufgerüstet wurden, sollten die restlichen MONs daher so rasch wie möglich ebenfalls aufrüstet werden.
   </para>
  </note>

  <para>
   <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
  </para>
 </sect1>
 <sect1 xml:id="upgrade-mds">
  <title>Upgrade von Metadatenservern</title>

  <para>
   Sie müssen den Metadatenserver (MDS)-Cluster verkleinern. Aufgrund einer Inkompatibilität bestimmter Funktionen in den SUSE Enterprise Storage-Versionen 5.5 und 6 werden die älteren MDS-Daemons heruntergefahren, sobald ein einzelner MDS mit SES 6 in den Cluster eingefügt wird. Für die Dauer des Upgrades der MDS Nodes muss der MDS-Cluster daher auf einen einzelnen aktiven MDS (ohne Standbys) verkleinert werden. Sobald der zweite Knoten aufgerüstet wurde, können Sie den MDS-Cluster wieder erweitern.
  </para>

  <tip>
   <para>
    Auf einem stark ausgelasteten MDS-Cluster müssen Sie die Auslastung ggf. vermindern (z. B. Clients anhalten), sodass ein einzelner MDS den gesamten Workload tragen kann.
   </para>
  </tip>

  <procedure>
   <step>
    <para>
     Beachten Sie den aktuellen Wert der Option <option>max_mds</option>:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs get cephfs | grep max_mds
</screen>
   </step>
   <step>
    <para>
     Verkleinern Sie den MDS-Cluster, wenn mehrere aktive MDS-Daemons vorliegen, also wenn <option>max_mds</option> &gt; 1 ist. Mit folgendem Kommando verkleinern Sie den MDS-Cluster:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds 1
</screen>
    <para>
     <replaceable>FS_NAME</replaceable> bezeichnet hierbei den Namen der CephFS-Instanz (standardmäßig „cephfs“).
    </para>
   </step>
   <step>
    <para>
     Ermitteln Sie den Knoten, auf dem einer der Standby-MDS-Daemons ausgeführt wird. Betrachten Sie die Ausgabe des Kommandos <command>ceph fs status</command> und starten Sie das Upgrade des MDS-Clusters auf diesem Knoten.
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs status
cephfs - 2 clients
======
+------+--------+--------+---------------+-------+-------+
| Rank | State  |  MDS   |    Activity   |  dns  |  inos |
+------+--------+--------+---------------+-------+-------+
|  0   | active | mon1-6 | Reqs:    0 /s |   13  |   16  |
+------+--------+--------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 2688k | 96.8G |
|   cephfs_data   |   data   |    0  | 96.8G |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
|    mon3-6   |
|    mon2-6   |
+-------------+
</screen>
    <para>
     In diesem Beispiel müssen Sie den Upgrade-Vorgang entweder auf dem Knoten „mon3-6“ oder auf dem Knoten „mon2-6“ starten.
    </para>
   </step>
   <step>
    <para>
     Rüsten Sie den Knoten mit dem Standby-MDS-Daemon auf. Sobald der aufgerüstete MDS-Knoten startet, werden die veralteten MDS-Daemons automatisch heruntergefahren. Zu diesem Zeitpunkt kann der CephFS-Service für die Clients kurzzeitig ausfallen.
    </para>
    <para>
     <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Rüsten Sie die verbleibenden MDS-Knoten auf.
    </para>
   </step>
   <step>
    <para>
     Setzen Sie <option>max_mds</option> auf die gewünschte Konfiguration zurück:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds <replaceable>ACTIVE_MDS_COUNT</replaceable>
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-main-osd">
  <title>Upgrade von Ceph OSDs</title>

  <para>
   Führen Sie die folgenden Schritte auf jedem Speicher-Node aus:
  </para>

  <procedure>
   <step>
    <para>
     Ermitteln Sie die OSD-Daemons, die auf einem bestimmten Knoten ausgeführt werden:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd tree
</screen>
   </step>
   <step>
    <para>
     Legen Sie die Flagge „noout“ für jeden OSD Daemon auf dem aufzurüstenden Knoten fest:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd add-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd add-noout osd.$i; done</screen>
    <para>
     Prüfen Sie mit:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     oder
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
      6 OSDs or CRUSH {nodes, device-classes} have {NOUP,NODOWN,NOIN,NOOUT} flags set</screen>
   </step>
   <step>
    <para>
     Erstellen Sie <filename>/etc/ceph/osd/*.json</filename>-Dateien für alle vorhandenen OSDs. Führen Sie hierzu das folgende Kommando auf dem aufzurüstenden Knoten aus:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan --force
</screen>
   </step>
   <step>
    <para>
     Rüsten Sie den OSD Node auf. <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Aktivieren Sie alle im System aufgefundenen OSDs:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>;ceph-volume simple activate --all
</screen>
    <tip>
     <title>Aktivieren einzelner Datenpartitionen</title>
     <para>
      Sollen die Datenpartitionen einzeln aktiviert werden, müssen Sie das entsprechende Kommando <command>ceph-volume</command> für die jeweilige Partitionen ermitteln. Ersetzen Sie <replaceable>X1</replaceable> durch den richtigen Buchstaben/die richtige Zahl der Partition:
     </para>
<screen>
 <prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/sd<replaceable>X1</replaceable>
</screen>
     <para>
      Beispiel:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/vdb1
[...]
--&gt; OSD 8 got scanned and metadata persisted to file:
/etc/ceph/osd/8-d7bd2685-5b92-4074-8161-30d146cd0290.json
--&gt; To take over management of this scanned OSD, and disable ceph-disk
and udev, run:
--&gt;     ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
     <para>
      Die letzte Zeile der Ausgabe enthält das Kommando, mit dem Sie die Partition aktivieren:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
[...]
--&gt; All ceph-disk systemd units have been disabled to prevent OSDs
getting triggered by UDEV events
[...]
Running command: /bin/systemctl start ceph-osd@8
--&gt; Successfully activated OSD 8 with FSID
d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
    </tip>
   </step>
   <step>
    <para>
     Prüfen Sie, ob der OSD Node nach dem Neustart ordnungsgemäß gestartet wird.
    </para>
   </step>
   <step>
    <para>
     Reagieren Sie auf die Meldung „Legacy BlueStore stats reporting detected on XX OSD(s)“ (Gemeldete Legacy-BlueStore-Statistik auf XX OSD(s) erkannt):
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
    <para>
     Diese Warnmeldung ist beim Upgrade von Ceph auf Version 14.2.2 normal. Mit folgender Einstellung können Sie sie deaktivieren:
    </para>
<screen>bluestore_warn_on_legacy_statfs = false</screen>
    <para>
     Zur Problembehebung führen Sie das folgende Kommando auf allen OSDs aus, während sie gestoppt sind:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-XXX</screen>
    <para>
     Das folgende Helper-Skript führt <command>ceph-bluestore-tool repair</command> für alle OSDs auf dem Knoten <replaceable>NODE_NAME</replaceable> aus:
    </para>
<screen>OSDNODE=<replaceable>OSD_NODE_NAME</replaceable>;\
 for OSD in $(ceph osd ls-tree $OSDNODE);\
 do echo "osd=" $OSD;\
 salt $OSDNODE cmd.run 'systemctl stop ceph-osd@$OSD';\
 salt $OSDNODE cmd.run 'ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-$OSD';\
 salt $OSDNODE cmd.run 'systemctl start ceph-osd@$OSD';\
 done</screen>
   </step>
   <step>
    <para>
     Heben Sie die Flagge „noout“ für jeden OSD Daemon auf dem aufzurüstenden Knoten auf:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd rm-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd rm-noout osd.$i; done</screen>
    <para>
     Prüfen Sie mit:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     Hinweis:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
   </step>
   <step>
    <para>
     Prüfen Sie den Cluster-Status. Die Ausgabe ähnelt der folgenden:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph status
cluster:
  id:     e0d53d64-6812-3dfe-8b72-fd454a6dcf12
  health: HEALTH_WARN
          3 monitors have not enabled msgr2

services:
  mon: 3 daemons, quorum mon1,mon2,mon3 (age 2h)
  mgr: mon2(active, since 22m), standbys: mon1, mon3
  osd: 30 osds: 30 up, 30 in

data:
  pools:   1 pools, 1024 pgs
  objects: 0 objects, 0 B
  usage:   31 GiB used, 566 GiB / 597 GiB avail
  pgs:     1024 active+clean
</screen>
   </step>
   <step>
    <para>
     Prüfen Sie, ob alle OSD Nodes neu gestartet und ob die OSDs nach dem Neustart automatisch gestartet wurden.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="filestore2bluestore">
  <title>OSD-Migration zu BlueStore</title>

  <para>
   OSD BlueStore ist ein neues Back-End für die OSD Daemons. Ab SUSE Enterprise Storage 5 ist dies die Standardoption. Verglichen mit FileStore, das Objekte als Dateien in einem XFS-Dateisystem speichert, kann BlueStore eine höhere Leistung bereitstellen, weil es Objekte direkt auf dem zugrundeliegenden Blockgerät speichert. BlueStore ermöglicht außerdem weitere Funktionen, wie integrierte Komprimierung und EC-Überschreibungen, die bei FileStore nicht zur Verfügung stehen.
  </para>

  <para>
   Für BlueStore spezifisch umfasst ein OSD ein „wal“ (Write Ahead-Protokoll)-Gerät und ein „db“ (RocksDB-Datenbank)-Gerät. Die RocksDB-Datenbank enthält die Metadaten für einen BlueStore OSD. Diese beiden Geräte befinden sich standardmäßig auf demselben Gerät wie ein OSD, doch jedes der beiden kann auf andere (z. B. schnellere) Medien platziert werden.
  </para>

  <para>
   In SUSE Enterprise Storage 5 werden sowohl FileStore als auch BlueStore unterstützt und FileStore und BlueStore OSDs können gemeinsam in einem einzelnen Cluster vorhanden sein. Während des Upgrade-Vorgangs für SUSE Enterprise Storage werden FileStore OSDs nicht automatisch zu BlueStore konvertiert. Beachten Sie, dass die BlueStore-spezifischen Funktionen nicht auf OSDs verfügbar sind, die nicht zu BlueStore migriert wurden.
  </para>

  <para>
   Vor der Konvertierung zu BlueStore müssen die OSDs SUSE Enterprise Storage 5 ausführen. Der Konvertierungsvorgang ist langsam, weil alle Daten zweimal umgeschrieben werden. Obwohl der Migrationsvorgang möglicherweise lange dauert, fällt der Cluster nicht aus und alle Clients können währenddessen weiterhin auf den Cluster zugreifen. Rechnen Sie für die Dauer der Migration jedoch mit einer geringeren Leistung. Der Grund dafür besteht in einem Ausgleich und Abgleich der Cluster-Daten.
  </para>

  <para>
   Gehen Sie bei der Migration von FileStore OSDs zu BlueStore folgendermaßen vor:
  </para>

  <tip>
   <title>Sicherheitsmaßnahmen ausschalten</title>
   <para>
    Salt-Kommandos, die zur Ausführung der Migration erforderlich sind, werden durch Sicherheitsmaßnahmen blockiert. Führen Sie folgendes Kommando aus, um diese Vorsichtsmaßnahmen auszuschalten:
   </para>
<screen>
 <prompt>root@master # </prompt>salt-run disengage.safety
 </screen>
   <para>
    Bauen Sie die Knoten vor dem Fortsetzen des Vorgangs neu auf:
   </para>
<screen>
 <prompt>root@master # </prompt> salt-run rebuild.node <replaceable>TARGET</replaceable>
 </screen>
   <para>
    Sie können die Knoten auch einzeln neu aufbauen. Beispiel:
   </para>
<screen>
<prompt>root@master # </prompt> salt-run rebuild.node data1.ceph
 </screen>
   <para>
    Mit <literal>rebuild.node</literal> werden stets alle OSDs im Knoten entfernt und neu erstellt.
   </para>
   <important>
    <para>
     Wenn ein OSD nicht konvertiert werden kann, zerstört die erneute Ausführung des Aufbaus die bereits konvertierten BlueStore OSDs. Anstatt den Aufbau neu auszuführen, können Sie Folgendes ausführen:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.deploy <replaceable>TARGET</replaceable>
 </screen>
   </important>
  </tip>

  <para>
   Nach der Migration zu BlueStore bleibt die Anzahl der Objekte gleich und die Datenträgerauslastung ist nahezu dieselbe.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-appnodes-order">
  <title>Upgrade von Anwendungsknoten</title>

  <para>
   Rüsten Sie die Anwendungsknoten in der folgenden Reihenfolge auf:
  </para>

  <orderedlist>
   <listitem>
    <para>
     Object Gateways
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Wenn sich ein Lastausgleich vor Object Gateways befindet, sollte ein Upgrade der Object Gateways bei laufendem Betrieb ohne Ausfall möglich sein.
      </para>
     </listitem>
     <listitem>
      <para>
       Prüfen Sie nach jedem Upgrade, ob die Object Gateway-Daemons ausgeführt werden, und testen Sie mit einem S3/Swift-Client.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     iSCSI Gateways
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Wenn iSCSI Initiatoren mit Multipath konfiguriert sind, sollte ein Upgrade der iSCSI-Gateways bei laufendem Betrieb ohne Ausfall möglich sein.
      </para>
     </listitem>
     <listitem>
      <para>
       Prüfen Sie nach jedem Upgrade, ob der <systemitem class="daemon">lrbd</systemitem>-Daemon ausgeführt wird, und testen Sie mit einem Initiator.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     NFS Ganesha. <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
   <listitem>
    <para>
     Samba Gateways. <emphasis role="bold">Befolgen Sie die Anweisungen in <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </orderedlist>
 </sect1>
 <sect1 xml:id="upgrade-main-policy">
  <title>Aktualisieren von <filename>policy.cfg</filename> und Deploy Ceph Dashboard mit DeepSea</title>

  <para>
   Bearbeiten Sie <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> auf dem Admin Node und wenden Sie die folgenden Änderungen an:
  </para>

  <important>
   <title>Keine neuen Services</title>
   <para>
    Nehmen Sie während des Cluster-Upgrades keine neuen Services in die Datei <filename>policy.cfg</filename> auf. Ändern Sie die Cluster-Architektur erst dann, wenn das Upgrade abgeschlossen ist.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Entfernen Sie <literal>role-openattic</literal>.
    </para>
   </step>
   <step>
    <para>
     Fügen Sie <literal>role-prometheus</literal> und <literal>role-grafana</literal> in den Knoten ein, auf dem Prometheus und Grafana installiert waren (in der Regel der Admin Node).
    </para>
   </step>
   <step>
    <para>
     Die Rolle <literal>profile-<replaceable>PROFILE_NAME</replaceable></literal> wird nunmehr ignoriert. Fügen Sie die neue Rolle in der Zeile <literal>role-storage</literal> ein. Für die vorhandene Rolle
    </para>
<screen>
profile-default/cluster/*.sls
</screen>
    <para>
     fügen Sie beispielsweise Folgendes ein:
    </para>
<screen>
role-storage/cluster/*.sls
</screen>
   </step>
   <step>
    <para>
     Synchronisieren Sie alle Salt-Module:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.sync_all</screen>
   </step>
   <step>
    <para>
     Aktualisieren Sie den Salt-Pillar mit DeepSea-Phase 1 und Phase 2:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Bereinigen Sie openATTIC:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.rescind.openattic
<prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.remove.openattic</screen>
   </step>
   <step>
    <para>
     Heben Sie das Grain „restart_igw“ auf, sodass Phase 0 nicht das iSCSI-Gateway neu startet, das bislang noch nicht installiert wurde:
    </para>
<screen>Salt mastersalt '*' grains.delkey restart_igw</screen>
   </step>
   <step>
    <para>
     Führen Sie abschließend die DeepSea-Phasen 0–4 aus:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <tip>
     <title>Fehler „subvolume missing“ (Subvolume fehlt) in Phase 3</title>
     <para>
      Unter Umständen schlägt die DeepSea-Phase 3 mit diesem Fehler fehl:
     </para>
<screen>subvolume : ['/var/lib/ceph subvolume missing on 4510-2', \
'/var/lib/ceph subvolume missing on 4510-1', \
[...]
'See /srv/salt/ceph/subvolume/README.md']</screen>
     <para>
      In diesem Fall müssen Sie <filename role="bold">/srv/pillar/ceph/stack/global.yml</filename> bearbeiten und die folgende Zeile einfügen:
     </para>
<screen>subvolume_init: disabled</screen>
     <para>
      Aktualisieren Sie dann den Salt-Pillar und führen Sie die DeepSea-Phase 3 erneut aus:
     </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar
 <prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     <para>
      Sobald die DeepSea-Phase 3 erfolgreich beendet wurde, wird das Ceph Dashboard ausgeführt. Eine ausführliche Übersicht der Ceph Dashboard-Funktionen finden Sie in <xref linkend="ceph-dashboard"/>.
     </para>
     <para>
      Mit folgendem Kommando rufen Sie eine Liste der Knoten ab, auf denen das Dashboard ausgeführt wird:
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph mgr services | grep dashboard</screen>
     <para>
      Mit folgendem Kommando rufen Sie eine Liste der Admin-Berechtigungsnachweise ab:
     </para>
<screen><prompt>root@master # </prompt>salt-call grains.get dashboard_creds</screen>
    </tip>
   </step>
   <step>
    <para>
     Starten Sie die Object Gateway-Services einzeln nacheinander, sodass sie den „beast“-Webserver anstelle des veralteten „civetweb“ nutzen:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.restart.rgw.force</screen>
   </step>
   <step>
    <para>
     Bevor Sie den Vorgang fortsetzen, wird dringend empfohlen, das Ceph-Telemetriemodul zu aktivieren. Weitere Informationen und Anweisungen finden Sie in <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-drive-groups">
  <title>Migration von profilbasierten Implementierungen zu DriveGroups</title>

  <para>
   In SUSE Enterprise Storage 5.5 wurde das Layout Ihrer OSDs mit sogenannten „Profilen“ in DeepSea beschrieben. Mit SUSE Enterprise Storage 6 wurde auf eine andere Vorgehensweise umgestellt, auf die sogenannten <emphasis>DriveGroups</emphasis> (weitere Informationen siehe <xref linkend="ds-drive-groups"/>).
  </para>

  <note>
   <para>
    Die Migration auf die neue Vorgehensweise ist nicht sofort obligatorisch. Destruktive Operationen wie <command>salt-run osd.remove</command>, <command>salt-run osd.replace</command> oder <command>salt-run osd.purge</command> sind nach wie vor verfügbar. Sollen neue OSDs eingefügt werden, ist jedoch Ihre Mithilfe gefordert.
   </para>
  </note>

  <para>
   Angesichts der unterschiedlichen Vorgehensweise dieser Implementierungen bieten wir keinen automatisierten Migrationspfad an. Wir bieten jedoch verschiedene Werkzeuge (Salt-Ausführungsprogramme) an, die die Migration so weit wie möglich erleichtern sollen.
  </para>

  <sect2>
   <title>Analysieren des aktuellen Layouts</title>
   <para>
    Mit folgendem Kommando rufen Sie Informationen zu den derzeit implementierten OSDs ab:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.discover
</screen>
   <para>
    Alternativ können Sie den Inhalt der Dateien in den Verzeichnissen <filename>/srv/pillar/ceph/proposals/profile-*/</filename> prüfen. Ihre Struktur sieht in etwa wie folgt aus:
   </para>
<screen>
ceph:
  storage:
    osds:
      /dev/disk/by-id/scsi-drive_name: format: bluestore
      /dev/disk/by-id/scsi-drive_name2: format: bluestore
     </screen>
  </sect2>

  <sect2>
   <title>Erstellen von passenden DriveGroups für das aktuelle Layout</title>
   <para>
    Weitere detaillierte Informationen zur DriveGroups-Spezifikation finden Sie in <xref linkend="ds-drive-groups-specs"/>.
   </para>
   <para>
    Der Unterschied zwischen einer frischen Implementierung und einem Upgrade-Szenario liegt darin, dass die zu migrierenden Laufwerke bereits „genutzt“ werden. Da
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list
</screen>
   <para>
    nur nach nicht genutzten Datenträgern sucht, verwenden Sie
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list include_unavailable=True
</screen>
   <para>
    Passen Sie die DriveGroups gemäß Ihrer aktuellen Einrichtung an. Mit folgendem Kommando erhalten Sie eine eher bildliche Darstellung der Abläufe. Beachten Sie, dass dieses Kommando nichts zurückgibt, wenn keine freien Datenträger vorliegen:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report bypass_pillar=True
</screen>
   <para>
    Wenn Sie die ordnungsgemäße Konfiguration Ihrer DriveGroups geprüft haben und nun die neue Vorgehensweise anwenden möchten, entfernen Sie die Dateien aus dem Verzeichnis <filename>/srv/pillar/ceph/proposals/profile-<replaceable>PROFILE_NAME</replaceable>/</filename>, entfernen Sie die entsprechenden Zeilen für <literal>profile-<replaceable>PROFILE_NAME</replaceable>/cluster/*.sls</literal> aus der Datei <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> und führen Sie die DeepSea-Phase 2 aus, sodass der Salt-Pillar aktualisiert wird.
   </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
</screen>
   <para>
    Prüfen Sie das Ergebnis mit folgenden Kommandos:
   </para>
<screen>
<prompt>root@master # </prompt>salt target_node pillar.get ceph:storage
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   <warning>
    <title>Fehlerhafte DriveGroups-Konfiguration</title>
    <para>
     Wenn Ihre DriveGroups nicht ordnungsgemäß konfiguriert sind und Ihre Einrichtung Ersatz-Datenträger umfasst, werden diese Datenträger so implementiert, wie Sie dies angegeben haben. Wir empfehlen, Folgendes auszuführen:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   </warning>
  </sect2>

  <sect2 xml:id="upgrade-osd-deployment">
   <title>OSD-Implementierung</title>
   <para>
    In einfachen Fällen wie Stand-Alone-OSDs erfolgt die Migration im Lauf der Zeit. Immer wenn Sie einen OSD im Cluster entfernen oder ersetzen, wird er durch einen neuen, LVM-basierten OSD ersetzt.
   </para>
   <tip>
    <title>Migration zum LVM-Format</title>
    <para>
     Immer wenn ein einzelner „Legacy“-OSD in einem Knoten ersetzt werden muss, müssen auch alle OSDs, die bestimmte Geräte gemeinsam mit diesem OSD nutzen, zum LVM-basierten Format migriert werden.
    </para>
    <para>
     Aus Gründen der Vollständigkeit sollten Sie die OSDs im gesamten Knoten migrieren.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Komplexere Einrichtungen</title>
   <para>
    Bei einer differenzierteren Einrichtung, die über Stand-Alone-OSDs hinausgeht (z. B. dedizierte WAL/DBs oder verschlüsselte OSDs), kann die Migration nur dann durchgeführt werden, wenn alle dem betreffenden WAL/DB-Gerät zugeordneten OSDs entfernt wurden. Dies ergibt sich aus dem Kommando <command>ceph-volume</command>, mit dem logische Volumes auf Datenträgern vor der Implementierung erstellt werden. So wird verhindert, dass der Benutzer partitionsbasierte Implementierungen mit LV-basierten Implementierungen vermischt. In diesen Fällen ist es am besten, alle einem WAL/DB-Gerät zugeordneten OSDs manuell zu entfernen und mit dem DriveGroups-Verfahren neu zu implementieren.
   </para>
  </sect2>
 </sect1>
</chapter>
