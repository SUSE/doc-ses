<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_rbd.xml" version="5.0" xml:id="ceph.rbd">
 <title>RADOS Block Device</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>Ja</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Ein Block ist eine Folge von Byte, beispielsweise ein 512-Byte-Datenblock. Blockbasierte Speicherschnittstellen werden am häufigsten zum Speichern von Daten auf rotierenden Medien wie Festplatten, CDs, Disketten verwendet. Angesichts der Omnipräsenz von Blockgeräteschnittstellen ist ein virtuelles Blockgerät für ein Massenspeichersystem wie Ceph hervorragend zur Interaktion geeignet.
 </para>
 <para>
  Ceph-Blockgeräte lassen die gemeinsame Nutzung physischer Ressourcen zu und ihre Größe kann geändert werden. Sie speichern Daten auf mehreren OSDs in einem Ceph Cluster verteilt. Ceph-Blockgeräte nutzen die RADOS-Funktionen wie Snapshotting, Reproduktion und Konsistenz. Ceph's RADOS Block Devices (RBD) interagieren mit OSDs über Kernel-Module oder die <systemitem>librbd</systemitem>-Bibliothek.
 </para>
 <figure>
  <title>RADOS-Protokoll</title>
  <mediaobject>
   <imageobject role="fo">
    <imagedata fileref="ceph_rbd_schema.png" width="70%" format="PNG"/>
   </imageobject>
   <imageobject role="html">
    <imagedata fileref="ceph_rbd_schema.png" width="70%" format="PNG"/>
   </imageobject>
  </mediaobject>
 </figure>
 <para>
  Die Blockgeräte von Ceph sind sehr leistungsfähig und unbegrenzt auf Kernel-Module skalierbar. Sie unterstützen Virtualisierungslösungen wie QEMU oder Cloud-basierte Rechnersysteme wie OpenStack, die auf <systemitem class="library">libvirt</systemitem> basieren. Sie können Object Gateway, CephFS und RADOS Block Devices gleichzeitig am selben Cluster ausführen.
 </para>
 <sect1 xml:id="ceph.rbd.commands">
  <title>Kommandos für Blockgeräte</title>

  <para>
   Mit dem Kommando <command>rbd</command> werden Blockgeräte-Images erstellt, aufgelistet, intern geprüft und entfernt. Sie können es beispielsweise auch zum Klonen von Images, zum Erstellen von Snapshots, für ein Rollback eines Image zu einem Snapshot oder zum Anzeigen eines Snapshots verwenden.
  </para>

  <tip>
   <title>Zugriff auf einen Cluster</title>
   <para>
    Für RADOS Block Device-Kommandos benötigen Sie Zugriff auf einen aktiven Ceph Cluster.
   </para>
  </tip>

  <sect2 xml:id="ceph.rbd.cmds.create">
   <title>Erstellen eines Blockgeräte-Image</title>
   <para>
    Bevor Sie ein Blockgerät zu einem Node hinzufügen, müssen Sie zunächst ein Image dafür im Cluster erstellen. Führen Sie zum Erstellen eines Blockgeräte-Image folgendes Kommando aus:
   </para>
<screen><prompt>root # </prompt>rbd create --size <replaceable>megabytes</replaceable> <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
   <para>
    Führen Sie folgendes Kommando aus, wenn Sie beispielsweise ein 1 GB Image namens "bar" erstellen möchten, in dem Informationen in einem Pool namens "swimmingpool" gespeichert werden:
   </para>
<screen><prompt>root # </prompt>rbd create --size 1024 swimmingpool/bar</screen>
   <tip>
    <title>Standard-Pool</title>
    <para>
     Wenn Sie beim Erstellen eines Image keinen Pool angeben, wird es im Standard-Pool "rbd" gespeichert.
    </para>
   </tip>
   <note>
    <title>Zunächst den Pool erstellen</title>
    <para>
     Sie müssen zunächst einen Pool erstellen, bevor Sie diesen als Ursprung angeben können. Weitere Einzelheiten finden Sie in <xref linkend="ceph.pools"/>.
    </para>
   </note>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.create-ec">
   <title>Erstellen eines Blockgeräte-Image in einem Erasure Coded Pool</title>
   <para>
    Ab SUSE Enterprise Storage 5 ist es möglich, Daten eines Blockgeräte-Image in Erasure Coded Pools zu speichern. Nur der Datenteil ("data") eines RBD-Image kann in einem Erasure Coded Pool gespeichert werden. Darüber hinaus muss im Erasure Coded Pool die Flagge "overwrite" auf <emphasis>true</emphasis> festgelegt sein. Es ist nur möglich, diese Flagge auf <emphasis>true</emphasis> festzulegen, wenn alle OSDs BlueStore verwenden.
   </para>
   <para>
    Ein Erasure Coded Pool kann keine Image-Metadaten enthalten. Die Metadaten können entweder im Standard-Pool "rbd" gespeichert werden oder im Pool, den der Benutzer explizit mit dem Parameter <parameter>--pool=</parameter> im Kommando <command>rbd create</command> angibt.
   </para>
   <note>
    <title>BlueStore erforderlich</title>
    <para>
     Alle Nodes benötigen BlueStore, um Erasure Coded Pools für Blockgeräte-Images zu verwenden.
    </para>
   </note>
   <para>
    Führen Sie zum Erstellen eines RBD-Image in einem Erasure Coded Pool die folgenden Schritte aus:
   </para>
<screen><prompt>root # </prompt><command>ceph</command> osd pool create <replaceable>POOL_NAME</replaceable> 12 12 erasure
<prompt>root # </prompt><command>ceph</command> osd pool set <replaceable>POOL_NAME</replaceable> allow_ec_overwrites true

# Metadata will reside in pool "rbd", and data in pool "<replaceable>POOL_NAME</replaceable>"
<prompt>root # </prompt><command>rbd</command> create <replaceable>IMAGE_NAME</replaceable> --size=1G --data-pool <replaceable>POOL_NAME</replaceable>

#Metadata will reside in pool "<replaceable>OTHER_POOL</replaceable>", and data in pool "<replaceable>POOL_NAME</replaceable>"
<prompt>root # </prompt><command>rbd</command> create <replaceable>IMAGE_NAME</replaceable> --size=1G --data-pool <replaceable>POOL_NAME</replaceable> --pool=<replaceable>OTHER_POOL</replaceable></screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.list">
   <title>Auflisten von Blockgeräte-Images</title>
   <para>
    Führen Sie folgendes Kommando aus, um Blockgeräte im "rbd"-Pool aufzulisten ("rbd" ist der Name des Standard-Pools):
   </para>
<screen><prompt>root # </prompt>rbd ls</screen>
   <para>
    Führen Sie folgendes Kommando aus, um Blockgeräte in einem Pool namens "swimmingpool" aufzulisten:
   </para>
<screen><prompt>root # </prompt>rbd ls swimmingpool</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.info">
   <title>Abrufen von Image-Informationen</title>
   <para>
    Führen Sie folgendes Kommando aus, um Informationen von einem Image "bar" in einem Pool namens "swimmingpool" abzurufen:
   </para>
<screen><prompt>root # </prompt>rbd info swimmingpool/bar</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.resize">
   <title>Ändern der Größe eines Blockgeräte-Image</title>
   <para>
    RADOS Block Device-Images werden schlank bereitgestellt, was bedeutet, dass Sie erst physischen Speicherplatz belegen, wenn Sie damit beginnen, Daten darin zu speichern. Ihre Kapazität ist jedoch auf den Wert beschränkt, den Sie mit der Option <option>--size</option> festlegen. Führen Sie folgendes Kommando aus, wenn Sie die maximale Größe des Image erhöhen (oder verringern) möchten:
   </para>
<screen><prompt>root # </prompt>rbd resize --size 2048 foo # to increase
rbd resize --size 2048 foo --allow-shrink # to decrease</screen>
  </sect2>

  <sect2 xml:id="ceph.rbd.cmds.rm">
   <title>Entfernen eines Blockgeräte-Image</title>
   <para>
    Führen Sie zum Entfernen eines Blockgeräts, das einem Image "bar" in einem Pool namens "swimmingpool" entspricht, folgendes Kommando aus:
   </para>
<screen><prompt>root # </prompt>rbd rm swimmingpool/bar</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="storage.bp.integration.mount_rbd">
  <title>Einhängen und Aushängen von RBD-Images</title>

  <para>
   Nach Erstellung eines RADOS Block Device können Sie es formatieren, es für den Dateiaustausch einhängen und danach wieder aushängen.
  </para>

  <procedure>
   <step>
    <para>
     Stellen Sie sicher, dass Ihr Ceph Cluster einen Pool mit dem Festplatten-Image enthält, das eingehängt werden soll. Nehmen wir an, der Name des Pools lautet <literal>mypool</literal> und das Image ist <literal>myimage</literal>.
    </para>
<screen>rbd list mypool</screen>
   </step>
   <step>
    <para>
     Ordnen Sie das Image einem neuen Blockgerät zu.
    </para>
<screen><prompt>root # </prompt>rbd map --pool mypool myimage</screen>
    <tip>
     <title>Benutzername und -authentifizierung</title>
     <para>
      Geben Sie einen Benutzernamen mit <option>--id <replaceable>user-name</replaceable></option> an. Wenn Sie die <systemitem>cephx</systemitem>-Authentifizierung nutzen, müssen Sie außerdem ein Geheimnis angeben. Es kann von einem Schlüsselbund stammen oder aus einer Datei, die das Geheimnis enthält:
     </para>
<screen><prompt>root # </prompt>rbd map --pool rbd myimage --id admin --keyring /path/to/keyring</screen>
     <para>
      oder
     </para>
<screen><prompt>root # </prompt>rbd map --pool rbd myimage --id admin --keyfile /path/to/file</screen>
    </tip>
   </step>
   <step>
    <para>
     Listen Sie alle zugeordneten Geräte auf:
    </para>
<screen><prompt>root # </prompt>rbd showmapped
 id pool   image   snap device
 0  mypool myimage -    /dev/rbd0</screen>
    <para>
     Das Gerät, mit dem wir arbeiten möchten, heißt <filename>/dev/rbd0</filename>.
    </para>
   </step>
   <step>
    <para>
     Erstellen Sie am Gerät namens <filename>/dev/rbd0</filename> ein XFS-Dateisystem.
    </para>
<screen><prompt>root # </prompt>mkfs.xfs /dev/rbd0
 log stripe unit (4194304 bytes) is too large (maximum is 256KiB)
 log stripe unit adjusted to 32KiB
 meta-data=/dev/rbd0              isize=256    agcount=9, agsize=261120 blks
          =                       sectsz=512   attr=2, projid32bit=1
          =                       crc=0        finobt=0
 data     =                       bsize=4096   blocks=2097152, imaxpct=25
          =                       sunit=1024   swidth=1024 blks
 naming   =version 2              bsize=4096   ascii-ci=0 ftype=0
 log      =internal log           bsize=4096   blocks=2560, version=2
          =                       sectsz=512   sunit=8 blks, lazy-count=1
 realtime =none                   extsz=4096   blocks=0, rtextents=0</screen>
   </step>
   <step>
    <para>
     Hängen Sie das Gerät ein und prüfen Sie, ob es korrekt eingehängt wurde. Ersetzen Sie <filename>/mnt</filename> durch Ihren Einhängepunkt.
    </para>
<screen><prompt>root # </prompt>mount /dev/rbd0 /mnt
<prompt>root # </prompt>mount | grep rbd0
/dev/rbd0 on /mnt type xfs (rw,relatime,attr2,inode64,sunit=8192,...</screen>
    <para>
     Nun können Sie Daten auf das und vom Gerät verschieben als wäre es ein lokales Verzeichnis.
    </para>
    <tip>
     <title>Vergrößern des RBD-Geräts</title>
     <para>
      Wenn sich herausstellt, dass die Größe des RBD-Geräts nicht mehr ausreicht, lässt es sich leicht vergrößern.
     </para>
     <orderedlist spacing="normal">
      <listitem>
       <para>
        Vergrößern Sie das RBD-Image, beispielsweise auf 10 GB
       </para>
<screen><prompt>root # </prompt>rbd resize --size 10000 mypool/myimage
 Resizing image: 100% complete...done.</screen>
      </listitem>
      <listitem>
       <para>
        Erweitern Sie das Dateisystem, bis es die neue Größe des Geräts ausfüllt.
       </para>
<screen><prompt>root # </prompt>xfs_growfs /mnt
 [...]
 data blocks changed from 2097152 to 2560000</screen>
      </listitem>
     </orderedlist>
    </tip>
   </step>
   <step>
    <para>
     Wenn Sie Ihre Arbeit an dem Gerät beenden, können Sie es aushängen.
    </para>
<screen><prompt>root # </prompt>unmount /mnt</screen>
   </step>
  </procedure>

  <tip>
   <title>Manuelles Einhängen und Aushängen</title>
   <para>
    Da die manuelle Zuordnung und das Einhängen von RBD-Images nach dem Start sowie das Aushängen und Aufheben der Zuordnung vor dem Herunterfahren sehr mühsam sein kann, wird ein Skript <command>rbdmap</command> und eine <systemitem class="daemon">systemd</systemitem>-Einheit zur Verfügung gestellt. Weitere Informationen finden Sie in <xref linkend="ceph.rbd.rbdmap"/>.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="cha.ceph.snapshots.rbd">
  <title>Blockgeräte-Snapshots</title>

  <para>
   Ein RBD-Image ist eine Snapshot eines RADOS Block Device-Image. Mit Snapshots behalten Sie den Verlauf des Zustands eines Image bei: Ceph unterstützt auch ein Snapshot Layering zum schnellen und einfachen Klonen von VM-Images. Ceph unterstützt Blockgeräte-Snapshots mit dem Kommando <command>rbd</command> sowie viele übergeordnete Schnittstellen wie QEMU, <systemitem>libvirt</systemitem>, OpenStack und CloudStack.
  </para>

  <note>
   <para>
    Stoppen Sie Eingabe- und Ausgabeoperationen, bevor Sie einen Snapshot von einem Image erstellen. Wenn das Image ein Dateisystem enthält, muss sich das Dateisystem <emphasis>vor</emphasis> dem Erstellen eines Snapshots in einem konsistenten Zustand befinden.
   </para>
  </note>

  <sect2>
   <title>Hinweise zu Cephx</title>
   <para>
    Wenn <systemitem>cephx</systemitem> aktiviert ist (weitere Informationen finden Sie unter <link xlink:href="http://ceph.com/docs/master/rados/configuration/auth-config-ref/"/>), dann müssen Sie einen Benutzernamen oder eine ID und einen Pfad zum Schlüsselbund mit dem entsprechenden Schlüssel für den Benutzer angeben. Weitere detaillierte Informationen finden Sie unter <link xlink:href="http://ceph.com/docs/master/rados/operations/user-management/">Benutzerverwaltung</link>. Es ist auch möglich, die Umgebungsvariable <systemitem>CEPH_ARGS</systemitem> hinzuzufügen, um die erneute Eingabe der folgenden Parameter zu verhindern.
   </para>
<screen><prompt>root # </prompt>rbd --id <replaceable>user-ID</replaceable> --keyring=/path/to/secret <replaceable>commands</replaceable>
<prompt>root # </prompt>rbd --name <replaceable>username</replaceable> --keyring=/path/to/secret <replaceable>commands</replaceable></screen>
   <para>
    Beispiel:
   </para>
<screen><prompt>root # </prompt>rbd --id admin --keyring=/etc/ceph/ceph.keyring <replaceable>commands</replaceable>
<prompt>root # </prompt>rbd --name client.admin --keyring=/etc/ceph/ceph.keyring <replaceable>commands</replaceable></screen>
   <tip>
    <para>
     Fügen Sie den Benutzer und das Geheimnis zur Umgebungsvariable <systemitem>CEPH_ARGS</systemitem> hinzu, damit Sie diese Informationen nicht jedes Mal neu eingeben müssen.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Allgemeine Informationen zu Snapshots</title>
   <para>
    Das folgende Verfahren zeigt, wie Snapshots mit dem Kommando <command>rbd</command> in der Kommandozeile erstellt, aufgelistet und entfernt werden.
   </para>
   <sect3>
    <title>Erstellen von Snapshots</title>
    <para>
     Geben Sie zum Erstellen eines Snapshots mit <command>rbd</command> die Option <option>snap create</option>, den Pool-Namen und den Image-Namen an.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap create --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap create <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool rbd snap create --snap snapshot1 image1
<prompt>root # </prompt>rbd snap create rbd/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>Auflisten von Snapshots</title>
    <para>
     Geben Sie zum Auflisten von Snapshots eines Image den Pool-Namen und den Image-Namen an.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap ls <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap ls <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool rbd snap ls image1
<prompt>root # </prompt>rbd snap ls rbd/image1</screen>
   </sect3>
   <sect3>
    <title>Snapshot Rollbacks</title>
    <para>
     Geben Sie zur Durchführung eines Rollbacks zu einem Snapshot mit <command>rbd</command> die Option <option>snap rollback</option>, den Pool-Namen, den Image-Namen und den Namen des Snapshots an.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap rollback --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap rollback <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap rollback --snap snapshot1 image1
<prompt>root # </prompt>rbd snap rollback pool1/image1@snapshot1</screen>
    <note>
     <para>
      Bei einem Rollback eines Image zu einem Snapshot wird die aktuelle Version des Image mit den Daten aus einem Snapshot überschrieben. Ein Rollback dauert umso länger je größer das Image ist. Einen Snapshot zu <emphasis>klonen ist schneller</emphasis> als ein <emphasis>Rollback</emphasis> eines Image zu einem Snapshot durchzuführen und ist die bevorzugte Methode, wenn zu einem früheren Zustand zurückgekehrt werden soll.
     </para>
    </note>
   </sect3>
   <sect3>
    <title>Löschen eines Snapshots</title>
    <para>
     Geben Sie zum Löschen eines Snapshots mit <command>rbd</command> die Option <option>snap rm</option>, den Pool-Namen, den Image-Namen und den Benutzernamen an.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap rm --snap <replaceable>snap-name</replaceable> <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap rm <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snap-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap rm --snap snapshot1 image1
<prompt>root # </prompt>rbd snap rm pool1/image1@snapshot1</screen>
    <note>
     <para>
      Ceph OSDs löschen Daten asynchron. Daher wird beim Löschen eines Snapshots nicht sofort Festplattenspeicherplatz frei.
     </para>
    </note>
   </sect3>
   <sect3>
    <title>Entfernen aller Snapshots</title>
    <para>
     Geben Sie zum Entfernen aller Snapshots für eine Image mit <command>rbd</command> die Option <option>snap purge</option> und den Image-Namen an.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap purge <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd snap purge <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap purge image1
<prompt>root # </prompt>rbd snap purge pool1/image1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph.snapshoti.layering">
   <title>Layering</title>
   <para>
    Ceph unterstützt die Möglichkeit zur Erstellung vieler COW (copy-on-write)-Klone eines Blockgeräte-Snapshots. Durch ein Snapshot Layering können Ceph-Blockgeräte-Clients Images sehr schnell erstellen. Beispielsweise könnten Sie ein Blockgeräte-Image mit einem darauf geschriebenen Linux VM und danach einen Snapshot von diesem Image erstellen, dann den Snapshot schützen und beliebig viele COW-Klone erstellen. Ein Snapshot ist schreibgeschützt. Daher vereinfacht ein Snapshot die Semantik und ermöglicht es, Klone schnell zu erstellen.
   </para>
   <note>
    <para>
     Die im folgenden Kommandozeilenbeispiel genannten Elemente "parent" (übergeordnet) und "child" (untergeordnet) beziehen sich auf einen Ceph-Blockgeräte-Snapshot (parent) und das entsprechende Image, das vom Snapshot geklont wurde (child).
    </para>
   </note>
   <para>
    Jedes geklonte Image (child) speichert einen Verweis auf das übergeordnete Image (parent), wodurch das geklonte Image den übergeordneten Snapshot (parent) öffnen und lesen kann.
   </para>
   <para>
    Ein COW-Klon eines Snapshots verhält sich exakt genauso wie jedes andere Ceph-Blockgeräte-Image. Geklonte Images können gelesen, geschrieben und geklont werden und ihre Größe lässt sich ändern. Geklonte Images haben keine besonderen Einschränkungen. Der COW-Klon eines Snapshots verweist jedoch auf den Snapshot. Daher <emphasis>müssen</emphasis> Sie den Snapshot schützen, bevor Sie ihn klonen.
   </para>
   <note>
    <para>
     Ceph unterstützt nur das Klonen von <emphasis>Format 2</emphasis>-Images (was bedeutet, dass Sie mit <command>rbd create --image-format 2</command> erstellt wurden).
    </para>
   </note>
   <sect3>
    <title>Erste Schritte mit Layering</title>
    <para>
     Ceph-Blockgeräte-Layering ist ein einfacher Prozess. Sie benötigen ein Image. Sie müssen einen Snapshot vom Image erstellen. Sie müssen den Snapshot schützen. Nach Ausführung dieser Schritte beginnen Sie mit dem Klonen des Snapshots.
    </para>
    <para>
     Das geklonte Image verweist auf den übergeordneten Snapshot und enthält Pool-ID, Image-ID und Snapshot-ID. Durch die enthaltene Pool-ID können Snapshots von einem Pool zu Images in einem anderen Pool geklont werden.
    </para>
    <itemizedlist mark="bullet" spacing="normal">
     <listitem>
      <para>
       <emphasis>Image-Vorlage</emphasis>: Bei einem üblichen Anwendungsfall für Blockgeräte-Layering wird ein Master Image erstellt und ein Snapshot, der als Vorlage für Klone dient. Beispielsweise erstellt ein Benutzer ein Image für eine Linux-Distribution (zum Beispiel SUSE Linux Enterprise Server) und dann einen Snapshot dafür. Der Benutzer aktualisiert möglicherweise das Image regelmäßig und erstellt einen neuen Snapshot (zum Beispiel <command>zypper ref &amp;&amp; zypper patch</command> gefolgt von <command>rbd snap create</command>). So wie sich das Image weiterentwickelt, kann der Benutzer beliebige einzelne Snapshots klonen.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>Erweiterte Vorlage</emphasis>: Bei einem anspruchsvolleren Anwendungsfall wird ein Vorlagen-Image erweitert, das mehr Informationen als eine Basis-Image enthält. Beispielsweise könnte ein Benutzer ein Image (eine VM-Vorlage) klonen und weitere Software installieren (beispielsweise eine Datenbank, ein Content Management-System oder ein Analysesystem) und dann einen Snapshot des erweiterten Image erstellen, das genauso wie das Basis-Image aktualisiert wird.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>Vorlagen-Pool</emphasis>: Eine Methode des Blockgeräte-Layerings ist die Erstellung eines Pools, der Master-Images enthält, die als Vorlagen fungieren, sowie Snapshots dieser Vorlagen. Sie könnten dann Nur-Lesen-Berechtigungen an Benutzer verteilen. Die Benutzer haben dadurch die Möglichkeit, die Snapshots zu klonen, dürfen jedoch nicht im Pool schreiben oder Vorgänge ausführen.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis>Image-Migration/Wiederherstellung</emphasis>: Eine Methode des Blockgeräte-Layerings ist die Migration oder Wiederherstellung von Daten von einem Pool in einen anderen Pool.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3>
    <title>Schützen von Snapshots</title>
    <para>
     Klone greifen auf die übergeordneten Snapshots zu. Alle Klone würden zerstört werden, wenn ein Benutzer versehentlich den übergeordneten Snapshot löscht. Sie müssen den Snapshot schützen, bevor Sie ihn klonen, um Datenverlust zu verhindern.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap protect \
 --image <replaceable>image-name</replaceable> --snap <replaceable>snapshot-name</replaceable>
<prompt>root # </prompt>rbd snap protect <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap protect --image image1 --snap snapshot1
<prompt>root # </prompt>rbd snap protect pool1/image1@snapshot1</screen>
    <note>
     <para>
      Geschützte Snapshots können nicht gelöscht werden.
     </para>
    </note>
   </sect3>
   <sect3>
    <title>Klonen von Snapshots</title>
    <para>
     Zum Klonen eines Snapshots müssen Sie den übergeordneten Pool, das Image, den Snapshot, den untergeordneten Pool und den Image-Namen angeben. Der Snapshot muss vor dem Klonen geschützt werden.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> --image <replaceable>parent-image</replaceable> \
 --snap <replaceable>snap-name</replaceable> --dest-pool <replaceable>pool-name</replaceable> \
 --dest <replaceable>child-image</replaceable>
<prompt>root # </prompt>rbd clone <replaceable>pool-name</replaceable>/<replaceable>parent-image</replaceable>@<replaceable>snap-name</replaceable> \
<replaceable>pool-name</replaceable>/<replaceable>child-image-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd clone pool1/image1@snapshot1 pool1/image2</screen>
    <note>
     <para>
      Ein Snapshot kann von einem Pool zu einem Image in einem anderen Pool geklont werden. Sie könnten beispielsweise schreibgeschützte Images und Snapshots als Vorlagen in einem Pool beibehalten und beschreibbare Klone in einem anderen Pool.
     </para>
    </note>
   </sect3>
   <sect3>
    <title>Aufheben des Schutzes von Snapshots</title>
    <para>
     Vor dem Löschen eines Snapshots muss zunächst dessen Schutz aufgehoben werden. Außerdem dürfen Sie <emphasis>keine</emphasis> Snapshots löschen, die Verweise von Klonen enthalten. Sie müssen jeden Klon eines Snapshots vereinfachen, bevor Sie den Snapshot löschen.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> snap unprotect --image <replaceable>image-name</replaceable> \
 --snap <replaceable>snapshot-name</replaceable>
<prompt>root # </prompt>rbd snap unprotect <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 snap unprotect --image image1 --snap snapshot1
<prompt>root # </prompt>rbd snap unprotect pool1/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>Auflisten der untergeordneten Klone von Snapshots</title>
    <para>
     Führen Sie zum Auflisten der untergeordneten Klone eines Snapshots folgendes Kommando aus:
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> children --image <replaceable>image-name</replaceable> --snap <replaceable>snap-name</replaceable>
<prompt>root # </prompt>rbd children <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable>@<replaceable>snapshot-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 children --image image1 --snap snapshot1
<prompt>root # </prompt>rbd children pool1/image1@snapshot1</screen>
   </sect3>
   <sect3>
    <title>Vereinfachen eines geklonten Image</title>
    <para>
     Geklonte Images behalten einen Verweis auf den übergeordneten Snapshot bei. Wenn Sie den Verweis vom untergeordneten Klon zum übergeordneten Snapshot entfernen, wird das Image tatsächlich "vereinfacht", indem die Informationen vom Snapshot zum Klon kopiert werden. Die Vereinfachung eines Klons dauert umso länger je größer der Snapshot ist. Zum Löschen eines Snapshots müssen Sie zunächst die untergeordneten Images vereinfachen.
    </para>
<screen><prompt>root # </prompt>rbd --pool <replaceable>pool-name</replaceable> flatten --image <replaceable>image-name</replaceable>
<prompt>root # </prompt>rbd flatten <replaceable>pool-name</replaceable>/<replaceable>image-name</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --pool pool1 flatten --image image1
<prompt>root # </prompt>rbd flatten pool1/image1</screen>
    <note>
     <para>
      Da ein vereinfachtes Image alle Informationen des Snapshots enthält, belegt ein vereinfachtes Image mehr Speicherplatz als ein Layering-Klon.
     </para>
    </note>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.rbd.rbdmap">
  <title>rbdmap: Zuordnen von RBD-Geräten beim Booten</title>

  <para>
   <command>rbdmap</command> ist ein Shell-Skript, das die Vorgänge <command>rbd map</command> und <command>rbd unmap</command> an einem oder mehreren RADOS Block Device-Images automatisiert. Obwohl Sie das Skript jederzeit manuell ausführen können, ist es üblich, es automatisch zuzuordnen und die RBD-Images beim Booten einzuhängen (und sie beim Herunterfahren auszuhängen und die Zuordnung aufzuheben). Dieser Vorgang wird vom Init-System ausgelöst. Zu diesem Zweck ist eine Datei für die <systemitem class="daemon">systemd</systemitem>-Einheit (<filename>rbdmap.service</filename>) im Paket <systemitem>ceph-common</systemitem> enthalten.
  </para>

  <para>
   Das Skript nimmt ein einzelnes Argument, entweder <option>map</option> oder <option>unmap</option>. In beiden Fällen analysiert das Skript eine Konfigurationsdatei. Die Standardeinstellung <filename>/etc/ceph/rbdmap</filename> kann mit der Umgebungsvariable <literal>RBDMAPFILE</literal> überschrieben werden. Jede Zeile der Konfigurationsdatei entspricht einem RBD-Image, das zugeordnet oder dessen Zuordnung aufgehoben werden soll.
  </para>

  <para>
   Die Konfigurationsdatei hat das folgende Format:
  </para>

<screen>image_specification rbd_options</screen>

  <variablelist>
   <varlistentry>
    <term>image_specification</term>
    <listitem>
     <para>
      Pfad zu einem Image in einem Pool. Geben Sie diesen als <replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable> an. Wenn Sie <replaceable>pool_name</replaceable> weglassen, wird der Standardwert "rbd" angenommen.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>rbd_options</term>
    <listitem>
     <para>
      Eine optionale Liste der Parameter, die an das zugrundeliegende Kommando <command>rbd map</command> weitergegeben werden sollen. Diese Parameter und ihre Werte sollten als durch Komma getrennte Zeichenkette angegeben werden, wie zum Beispiel:
     </para>
<screen>PARAM1=VAL1,PARAM2=VAL2,...</screen>
     <para>
      Im Beispiel führt das Skript <command>rbdmap</command> folgendes Kommando aus:
     </para>
<screen>rbd map <replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable> --PARAM1 VAL1 --PARAM2 VAL2</screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Wenn das Skript als <command>rbdmap map</command> ausgeführt wird, analysiert es die Konfigurationsdatei und versucht, für jedes angegebenen RBD-Image zunächst das Image zuzuordnen (mit dem Kommando <command>the rbd map</command>) und dann das Image einzuhängen.
  </para>

  <para>
   Wenn es als <command>rbdmap unmap</command> ausgeführt wird, werden die in der Konfigurationsdatei aufgelisteten Images ausgehängt und ihre Zuordnungen werden aufgehoben.
  </para>

  <para>
   <command>rbdmap unmap-all</command> versucht, alle aktuell zugeordneten RBD-Images auszuhängen und danach deren Zuordnungen aufzuheben, unabhängig davon, ob sie in der Konfigurationsdatei aufgelistet sind.
  </para>

  <para>
   Bei erfolgreicher Ausführung ordnet der Vorgang "rbd map" das Image einem /dev/rbdX-Gerät zu. Zu diesem Zeitpunkt wird eine udev-Regel ausgelöst, um einen symbolischen Link zu einem Geräteanzeigenamen <filename>/dev/rbd/<replaceable>pool_name</replaceable>/<replaceable>image_name</replaceable></filename> zu erstellen, der auf das reale zugeordnete Gerät zeigt.
  </para>

  <para>
   Damit das Einhängen und Aushängen erfolgreich ausgeführt wird, muss der Anzeigename des Geräts einen entsprechenden Eintrag in <filename>/etc/fstab</filename> haben. Geben Sie beim Schreiben von <filename>/etc/fstab</filename>-Einträgen für RBD-Images die Einhängeoption "noauto" (oder "nofail") an. Dadurch wird verhindert, dass das Init-System das Gerät zu früh einhängt, also noch bevor das betreffende Gerät überhaupt vorhanden ist, weil <filename>rbdmap.service</filename> normalerweise ziemlich spät in der Boot-Sequenz ausgelöst wird.
  </para>

  <para>
   Eine vollständige Liste der <command>rbd</command>-Optionen finden Sie  auf der <command>rbd</command>-Handbuchseite (<command>man 8 rbd</command>).
  </para>

  <para>
   Beispiele zur Anwendung von <command>rbdmap</command> finden Sie auf der <command>rbdmap</command>-Handbuchseite (<command>man 8 rbdmap</command>).
  </para>
 </sect1>
 <sect1 xml:id="ceph.rbd.mirror">
  <title>Spiegeln des RADOS Block Device</title>

  <para>
   RBD-Images können asynchron zwischen zwei Ceph Clustern gespiegelt werden. Dazu wird die Funktion des RBD-Journaling-Image verwendet, um die absturzkonsistente Reproduktion zwischen Clustern sicherzustellen. Die Spiegelung wird pro Pool in Peer-Clustern konfiguriert. Sie kann so konfiguriert werden, dass alle Images in einem Pool oder nur eine bestimmte Teilmenge der Images automatisch gespiegelt werden. Die Spiegelung wird mit dem <command>rbd</command>-Kommando ausgeführt. Der <systemitem>rbd-mirror</systemitem> Daemon ist dafür zuständig, Image-Updates aus dem Remote-Peer-Cluster zu entnehmen und diese auf das Image im lokalen Cluster anzuwenden.
  </para>

  <important>
   <title>rbd-mirror Daemon</title>
   <para>
    Für die RBD-Spiegelung benötigen Sie zwei Ceph Cluster. Auf jedem von beiden muss der <systemitem>rbd-mirror</systemitem> Daemon ausgeführt werden.
   </para>
  </important>

  <sect2 xml:id="rbd.mirror.daemon">
   <title>rbd-mirror Daemon</title>
   <para>
    Die beiden <systemitem>rbd-mirror</systemitem> Daemons sind dafür zuständig, Image-Protokolle am Remote-Peer-Cluster zu beobachten und die Protokollereignisse im Vergleich zum lokalen Cluster wiederzugeben. Die Journaling-Funktion für RBD-Images zeichnet alle Änderungen am Image in der Reihenfolge auf wie sie vorgenommen werden. Dadurch wird sichergestellt, dass ein absturzkonsistenter Spiegel des Remote-Image lokal verfügbar ist.
   </para>
   <para>
    Der <systemitem>rbd-mirror</systemitem> Daemon ist im Paket <systemitem>rbd-mirror</systemitem> enthalten. Installieren, aktivieren und starten Sie ihn in einem der Cluster Nodes:
   </para>
<screen><prompt>root@minion &gt; </prompt>zypper install rbd-mirror
<prompt>root@minion &gt; </prompt>systemctl enable ceph-rbd-mirror@<replaceable>server_name</replaceable>.service
<prompt>root@minion &gt; </prompt>systemctl start ceph-rbd-mirror@<replaceable>server_name</replaceable>.service</screen>
   <important>
    <para>
     Jeder <systemitem>rbd-mirror</systemitem> Daemon muss gleichzeitig eine Verbindung zu beiden Clustern herstellen können.
    </para>
   </important>
  </sect2>

  <sect2 xml:id="ceph.rbd.mirror.poolconfig">
   <title>Pool-Konfiguration</title>
   <para>
    Die folgenden Verfahren zeigen, wie einfache Verwaltungsaufgaben zum Konfigurieren der Spiegelung mit dem <command>rbd</command>-Kommando ausgeführt werden. Die Spiegelung wird pro Pool in den Ceph Clustern konfiguriert.
   </para>
   <para>
    Sie müssen die Schritte zur Pool-Konfiguration an beiden Peer Clustern ausführen. Bei diesen Verfahren wird der Einfachheit halber angenommen, dass von einem einzelnen Host aus auf zwei Cluster ("local" und "remote") zugegriffen werden kann.
   </para>
   <para>
    Weitere detaillierte Informationen zum Herstellen einer Verbindung zu verschiedenen Ceph Clustern finden Sie auf der <command>rbd</command>-Handbuchseite (<command>man 8 rbd</command>).
   </para>
   <tip>
    <title>Mehrere Cluster</title>
    <para>
     Der Cluster-Name in den folgenden Beispielen entspricht einer Ceph-Konfigurationsdatei des selben Namens <filename>/etc/ceph/remote.conf</filename>. In der Dokumentation zu <link xlink:href="http://docs.ceph.com/docs/master/rados/configuration/ceph-conf/#running-multiple-clusters">ceph-conf</link> finden Sie weitere Informationen zur Konfiguration mehrerer Cluster.
    </para>
   </tip>
   <sect3>
    <title>Aktivieren der Spiegelung</title>
    <para>
     Geben Sie zum Aktivieren der Spiegelung in einem Pool das Unterkommando <command>mirror pool enable</command>, den Pool-Namen und den Spiegelungsmodus an. Der Spiegelungsmodus kann entweder "pool" oder "image" lauten:
    </para>
    <variablelist>
     <varlistentry>
      <term>pool</term>
      <listitem>
       <para>
        Alle Images im Pool mit aktivierter Journaling-Funktion werden gespiegelt.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>image</term>
      <listitem>
       <para>
        Die Spiegelung muss auf jedem Image explizit aktiviert werden. Weitere Informationen finden Sie in <xref linkend="rbd.mirror.enable_image_mirroring"/>.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Beispiel:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool enable image-pool pool
<prompt>root # </prompt>rbd --cluster remote mirror pool enable image-pool pool</screen>
   </sect3>
   <sect3>
    <title>Deaktivieren der Spiegelung</title>
    <para>
     Geben Sie zum Deaktivieren der Spiegelung in einem Pool das Unterkommando <command>mirror pool disable</command> und den Pool-Namen an. Wenn die Spiegelung auf diese Weise in einem Pool deaktiviert wird, dann wird sie auch in anderen Images (im Pool) deaktiviert, für die eine Spiegelung explizit aktiviert wurde.
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool disable image-pool
<prompt>root # </prompt>rbd --cluster remote mirror pool disable image-pool</screen>
   </sect3>
   <sect3>
    <title>Hinzufügen des Cluster Peers</title>
    <para>
     Damit der <systemitem>rbd-mirror</systemitem> Daemon seinen Peer Cluster ermitteln kann, muss der Peer im Pool registriert sein. Geben Sie zum Hinzufügen des Peer Clusters für die Spiegelung das Unterkommando <command>mirror pool peer add</command>, den Pool-Namen und eine Cluster-Spezifikation an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool peer add image-pool client.remote@remote
<prompt>root # </prompt>rbd --cluster remote mirror pool peer add image-pool client.local@local</screen>
   </sect3>
   <sect3>
    <title>Entfernen des Cluster Peers</title>
    <para>
     Geben Sie zum Entfernen eines Peer Clusters für die Spiegelung das Unterkommando <command>mirror pool peer remove</command>, den Pool-Namen und die Peer-UUID (verfügbar über das Kommando <command>rbd mirror pool info</command>) an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool peer remove image-pool \
 55672766-c02b-4729-8567-f13a66893445
<prompt>root # </prompt>rbd --cluster remote mirror pool peer remove image-pool \
 60c0e299-b38f-4234-91f6-eed0a367be08</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="rbd.mirror.imageconfig">
   <title>Image-Konfiguration</title>
   <para>
    Im Gegensatz zur Pool-Konfiguration muss die Image-Konfiguration nur für einen einzigen für die Spiegelung vorgesehenen Peer Ceph Cluster durchgeführt werden.
   </para>
   <para>
    Gespiegelte RBD-Images werden entweder als <emphasis>primär</emphasis> oder <emphasis>nicht primär</emphasis> ausgewiesen. Dies ist eine Eigenschaft des Image und nicht des Pools. Als nicht primär ausgewiesene Images können nicht bearbeitet werden.
   </para>
   <para>
    Images werden automatisch zu primären Images hochgestuft, wenn die Spiegelung zuvor für ein Image aktiviert wird (entweder implizit mit dem Pool-Spiegelungsmodus "pool" und durch Aktivieren der Journaling-Funktion für das Image oder explizit (Informationen hierzu finden Sie in <xref linkend="rbd.mirror.enable_image_mirroring"/>) mit dem <command>rbd</command>-Kommando).
   </para>
   <sect3>
    <title>Aktivieren des Supports für Image Journaling</title>
    <para>
     Bei der RBD-Spiegelung wird immer die RBD Journaling-Funktion verwendet, um sicherzustellen, dass das reproduzierte Image immer absturzkonsistent bleibt. Die Journaling-Funktion muss aktiviert werden, bevor ein Image zu einem Peer Cluster gespiegelt werden kann. Die Funktion kann bei der Image-Erstellung aktiviert werden, indem die Option <option>--image-feature exclusive-lock,journaling</option> für das <command>rbd</command>-Kommando angegeben wird.
    </para>
    <para>
     Alternativ kann die Journaling-Funktion für bereits vorhandene RBD-Images dynamisch aktiviert werden. Geben Sie zum Aktivieren des Journaling den Unterbefehl <command>feature enable</command>, den Pool-Namen, den Image-Namen und den Namen der Funktion an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local feature enable image-pool/image-1 journaling</screen>
    <note>
     <title>Abhängigkeit der Option</title>
     <para>
      Die Funktion <option>journaling</option> hängt von der Funktion <option>exclusive-lock</option> ab. Wenn die Funktion <option>exclusive-lock</option> nicht bereits aktiviert ist, müssen Sie diese vor Aktivierung der Funktion <option>journaling</option> aktivieren.
     </para>
    </note>
    <tip>
     <title>Journaling an allen neuen Images</title>
     <para>
      Zum standardmäßigen Aktivieren des Journaling an allen neuen Images fügen Sie die folgende Zeile zur Ihrer Ceph-Konfigurationsdatei hinzu:
     </para>
<screen>rbd default features = 125</screen>
    </tip>
   </sect3>
   <sect3 xml:id="rbd.mirror.enable_image_mirroring">
    <title>Aktivieren der Image-Spiegelung</title>
    <para>
     Wenn eine Spiegelung für den Pool eines Image im Modus "image" konfiguriert ist, muss die Spiegelung für jedes Image im Pool explizit aktiviert werden. Geben Sie zum Aktivieren der Spiegelung für ein bestimmtes Image das Unterkommando <command>mirror image enable</command> zusammen mit dem Pool- und Image-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image enable image-pool/image-1</screen>
   </sect3>
   <sect3>
    <title>Deaktivieren der Image-Spiegelung</title>
    <para>
     Geben Sie zum Deaktivieren der Spiegelung für ein bestimmtes Image das Unterkommando <command>mirror image disable</command> zusammen mit dem Pool- und Image-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image disable image-pool/image-1</screen>
   </sect3>
   <sect3>
    <title>Hochstufen und Herabstufen eines Image</title>
    <para>
     In einem Failover-Szenario, in dem die primäre Bezeichnung zum Image im Peer Cluster verschoben werden muss, müssen Sie den Zugriff auf das primäre Image stoppen, das aktuelle primäre Image herabstufen, das neue primäre Image hochstufen und den Zugriff auf das Image am alternativen Cluster wieder aufnehmen.
    </para>
    <para>
     Geben Sie zum Herabstufen eines bestimmten Image zu "nicht primär" das Unterkommando <command>mirror image demote</command> zusammen mit dem Pool- und Image-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror image demote image-pool/image-1</screen>
    <para>
     Geben Sie zum Herabstufen aller primären Images in einem Pool zu "nicht primär" das Unterkommando <command>mirror pool demote</command> zusammen mit dem Pool-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool demote image-pool</screen>
    <para>
     Geben Sie zum Hochstufen eines bestimmten Image zu "primär" das Unterkommando <command>mirror image promote</command> zusammen mit dem Pool- und Image-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster remote mirror image promote image-pool/image-1</screen>
    <para>
     Geben Sie zum Hochstufen aller primären Images in einem Pool zu "primär" das Unterkommando <command>mirror pool promote</command> zusammen mit dem Pool-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd --cluster local mirror pool promote image-pool</screen>
    <tip>
     <title>Aufteilen der E/A-Last</title>
     <para>
      Da der Status "primär" oder "nicht primär" pro Image gilt, ist es möglich, die E/A-Last auf zwei Cluster aufzuteilen und dort ein Failover oder Failback durchzuführen.
     </para>
    </tip>
    <note>
     <title>Erzwungene Hochstufung</title>
     <para>
      Die Hochstufung wird mit der Option <option>--force</option> erzwungen. Die erzwungene Hochstufung ist erforderlich, wenn die Herabstufung nicht auf den Peer Cluster übertragen werden kann (beispielsweise im Fall eines Cluster-Fehlers oder Kommunikationsausfalls). Dies führt zu einem Split Brain-Szenario zwischen den beiden Peers und das Image wird nicht mehr synchronisiert bis ein Unterkommando <command>resync</command> ausgestellt wird.
     </para>
    </note>
   </sect3>
   <sect3>
    <title>Erzwingen der erneuten Synchronisierung eines Image</title>
    <para>
     Wenn der <systemitem>rbd-mirror</systemitem>-Daemon ein Split Brain-Szenario erkennt, versucht er erst wieder, das betreffende Image zu spiegeln, wenn das Problem behoben ist. Um die Spiegelung für ein Image wieder aufzunehmen, müssen Sie zunächst das Image, das als veraltet ermittelt wurde, herabstufen und dann eine erneute Synchronisierung mit dem primären Image anfordern. Geben Sie zum Anfordern einer erneuten Synchronisierung des Image das Unterkommando <command>mirror image resync</command> zusammen mit dem Pool- und Image-Namen an:
    </para>
<screen><prompt>root # </prompt>rbd mirror image resync image-pool/image-1</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="rbd.mirror.status">
   <title>Spiegelstatus</title>
   <para>
    Der Reproduktionsstatus des Peer Clusters wird für jedes primäre gespiegelte Image gespeichert. Dieser Status wird mit den Unterkommandos <command>mirror image status</command> und <command>mirror pool status</command> abgerufen:
   </para>
   <para>
    Geben Sie zum Anfordern des Spiegel-Image-Status das Unterkommando <command>mirror image status</command> zusammen mit dem Pool- und Image-Namen an:
   </para>
<screen><prompt>root # </prompt>rbd mirror image status image-pool/image-1</screen>
   <para>
    Geben Sie zum Anfordern einer Übersicht zum Spiegel-Pool-Status das Unterkommando <command>mirror pool status</command> zusammen mit dem Pool-Namen an:
   </para>
<screen><prompt>root # </prompt>rbd mirror pool status image-pool</screen>
   <tip>
    <title/>
    <para>
     Durch Hinzufügen der Option <option>--verbose</option> zum Unterkommando <command>mirror pool status</command> werden zusätzlich Statusdetails für jedes Spiegel-Image im Pool ausgegeben.
    </para>
   </tip>
  </sect2>
 </sect1>
</chapter>
