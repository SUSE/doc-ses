<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Actualización desde versiones anteriores</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>editar</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>sí</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  En este capítulo se presentan los pasos necesarios para actualizar SUSE Enterprise Storage 5.5 a la versión 6. Tenga en cuenta que la versión 5.5 es básicamente la 5 con todos los parches más recientes aplicados.
 </para>
 <note>
  <title>actualización desde versiones anteriores no admitidas</title>
  <para>
   No se admite la actualización desde versiones de SUSE Enterprise Storage anteriores a la 5.5. En primer lugar, debe actualizar a la versión más reciente de SUSE Enterprise Storage 5.5 y, a continuación, siga los pasos de este capítulo.
  </para>
 </note>
 <sect1 xml:id="upgrade-consider-points">
  <title>Puntos que se deben tener en cuenta antes de la actualización</title>

  <itemizedlist>
   <listitem>
    <para>
     <emphasis>Lea las notas de la versión.</emphasis> En ellas encontrará información adicional sobre los cambios realizados desde la versión previa de SUSE Enterprise Storage. Consulte las notas de versión para comprobar lo siguiente:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       si el hardware necesita consideraciones especiales,
      </para>
     </listitem>
     <listitem>
      <para>
       si los paquetes de software usados han cambiado de forma significativa,
      </para>
     </listitem>
     <listitem>
      <para>
       si es necesario tomar precauciones especiales para la instalación.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Las notas de la versión también proporcionan información que no pudo publicarse en el manual a tiempo y notas acerca de problemas conocidos.
    </para>
    <para>
     Después de instalar el paquete <package>release-notes-ses</package>, encontrará las notas de la versión en el directorio <filename>/usr/share/doc/release-notes</filename> o en línea en <link xlink:href="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     En caso de que haya actualizado previamente desde la versión 4, compruebe que la actualización a la versión 5 se haya completado correctamente:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Compruebe que el archivo exista:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.import</screen>
      <para>
       Es creado por el proceso de importación durante la actualización de SES 4 a SES 5. Además, la opción <option>configuration_init: default-import</option> se define en el archivo
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <para>
       Si <option>configuration_init</option> todavía está definido como <option>default-import</option>, el clúster está utilizando <filename>ceph.conf.import</filename> como su archivo de configuración y no el archivo <filename>ceph.conf</filename> por defecto de DeepSea que se compila a partir de los archivos de:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Por lo tanto, debe inspeccionar si hay alguna configuración personalizada en <filename>ceph.conf.import</filename> y, posiblemente, trasladar la configuración a uno de los archivos de:
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       A continuación, elimine la línea <option>configuration_init: default‑import</option> de:
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <warning>
       <title>configuración por defecto de DeepSea</title>
       <para>
        Si <emphasis role="bold">no</emphasis> combina la configuración de <filename>ceph.conf.import</filename> y elimina la opción <option>configuration_init: default‑import</option>, no se aplicará al clúster ningún valor de configuración por defecto que hayamos enviado como parte de DeepSea (almacenado en <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>).
       </para>
      </warning>
     </listitem>
     <listitem>
      <para>
       Compruebe si el clúster utiliza el nuevo tipo de depósito "straw2":
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep straw
</screen>
     </listitem>
     <listitem>
      <para>
       Compruebe que se utiliza el perfil de Ceph "jewel":
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep profile
</screen>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     En caso de que se utilicen clientes de kernel del RBD antiguos (anteriores a SUSE Linux Enterprise Server 12 SP3), consulte <xref linkend="rbd-old-clients-map"/>. Se recomienda actualizar los clientes del kernel del RBD antiguo, si es posible.
    </para>
   </listitem>
   <listitem>
    <para>
     Si openATTIC se encuentra en el nodo de administración, no estará disponible después de actualizar el nodo. La nueva Ceph Dashboard no estará disponible hasta que la distribuya mediante DeepSea.
    </para>
   </listitem>
   <listitem>
    <para>
     La actualización del clúster puede tardar mucho tiempo, aproximadamente el que se tarda en actualizar un equipo multiplicado por el número de nodos del clúster.
    </para>
   </listitem>
   <listitem>
    <para>
     No es posible actualizar un solo nodo mientras se ejecuta la versión anterior de SUSE Linux Enterprise Server: debe reiniciarse en el programa de instalación de la nueva versión. Por lo tanto, los servicios que proporciona el nodo no estarán disponibles durante un tiempo. Los servicios de clúster principales seguirán estando disponibles; por ejemplo, si una instancia de MON está inactiva durante la actualización, seguirá habiendo al menos dos activas. Desafortunadamente, los servicios de una sola instancia, como una única pasarela iSCSI Gateway, no estarán disponibles.
    </para>
   </listitem>
   <listitem>
    <para>
     Algunos tipos de daemons dependen de otros. Por ejemplo, los daemons de Object Gateway dependen de los daemons de Ceph MON y OSD. Se recomienda actualizar en este orden:
    </para>
    <orderedlist spacing="normal">
     <listitem>
      <para>
       Nodo de administración
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor/Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Servidores de metadatos
      </para>
     </listitem>
     <listitem>
      <para>
       Daemons Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Pasarelas Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Pasarelas iSCSI Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       NFS Ganesha
      </para>
     </listitem>
     <listitem>
      <para>
       Pasarelas Samba Gateway
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Si ha usado AppArmor en el modo "complain" o "enforce", debe establecer una variable de pilar de Salt antes de actualizar. Dado que SUSE Linux Enterprise Server 15 SP1 se suministra con AppArmor por defecto, la gestión de AppArmor se ha integrado en la fase 0 de DeepSea. El comportamiento por defecto en SUSE Enterprise Storage 6 es eliminar AppArmor y los perfiles relacionados. Si desea conservar el comportamiento configurado en SUSE Enterprise Storage 5.5, compruebe que haya una de las siguientes líneas presente en el archivo <filename>/srv/pillar/ceph/stack/global.yml</filename> antes de iniciar la actualización:
    </para>
<screen>
apparmor_init: default-enforce
</screen>
    <para>
     O bien
    </para>
<screen>
apparmor_init: default-complain
</screen>
   </listitem>
   <listitem>
    <para>
     Desde SUSE Enterprise Storage 6, los nombres del MDS que comienzan con un dígito ya no se permiten y los daemons del MDS no se iniciarán. Puede comprobar si los daemons tienen este tipo de nombre ejecutando el comando <command>ceph fs status</command> o reiniciando un MDS y buscando en sus registros el siguiente mensaje:
    </para>
<screen>
deprecation warning: MDS id 'mds.1mon1' is invalid and will be forbidden in
a future version.  MDS names may not start with a numeric digit.
</screen>
    <para>
     Si ve el mensaje anterior, los nombres del MDS deben migrarse antes de intentar actualizar a SUSE Enterprise Storage 6. DeepSea proporciona orquestación para automatizar dicha migración. A los nombres del MDS que comiencen con un dígito se les añadirá "mds." al principio:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.mds.migrate-numerical-names
</screen>
    <tip>
     <title>configuración personalizada vinculada a nombres del MDS</title>
     <para>
      Si tiene valores de configuración vinculados a nombres del MDS y los daemons del MDS tienen nombres que comienzan con un dígito, verifique que los valores de configuración también se aplique a los nuevos nombres (con el prefijo "mds." ). Observe la siguiente sección de ejemplo del archivo <filename>/etc/ceph/ceph.conf</filename>:
     </para>
<screen>
[mds.123-my-mds] # config setting specific to MDS name with a name starting with a digit
mds cache memory limit = 1073741824
mds standby for name = 456-another-mds
</screen>
     <para>
      El orquestador <command>ceph.mds.migrate-numerical-names</command> cambiará el nombre del daemon del MDS "123-my-mds" a "mds.123-my-mds". Es necesario ajustar la configuración para reflejar el nuevo nombre:
     </para>
<screen>
[mds.mds,123-my-mds] # config setting specific to MDS name with the new name
mds cache memory limit = 1073741824
mds standby for name = mds.456-another-mds
</screen>
    </tip>
    <para>
     Esto añadirá daemons del MDS con los nuevos nombres antes de eliminar los antiguos. El número de daemons del MDS se duplicará durante un breve periodo de tiempo. Los clientes podrán acceder a CephFS tras una breve pausa para el failover. Por lo tanto, planifique la migración en horas en las que espere poca o ninguna carga de CephFS.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-backup">
  <title>Copia de seguridad de los datos del clúster</title>

  <para>
   Aunque la creación de copias de seguridad de la configuración y los datos de un clúster no es obligatoria, se recomienda encarecidamente realizarla. Consulte <xref linkend="cha-deployment-backup"/> para obtener más información.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-ntp">
  <title>Migración de <systemitem class="daemon">ntpd</systemitem> a <systemitem class="daemon">chronyd</systemitem></title>

  <para>
   SUSE Linux Enterprise Server 15 SP1 ya no utiliza <systemitem class="daemon">ntpd</systemitem> para sincronizar la hora del host local. En su lugar, se utiliza <systemitem class="daemon">chronyd</systemitem>. Debe migrar el daemon de sincronización de hora en cada nodo del clúster. Puede migrar a <systemitem>chronyd</systemitem> <emphasis role="bold">antes</emphasis> que el clúster o actualizar el clúster y migrar a <systemitem class="daemon">chronyd</systemitem> <emphasis role="bold">después.</emphasis>
  </para>

  <procedure>
   <title>Migración a <systemitem class="daemon">chronyd</systemitem> <emphasis>antes</emphasis> de la actualización del clúster</title>
   <step>
    <para>
     Instale el paquete <package>chrony:</package> 
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper install chrony</screen>
   </step>
   <step>
    <para>
     Edite el archivo de configuración <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> y añada orígenes NTP desde la configuración <systemitem class="daemon">ntpd</systemitem> actual en <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>más detalles sobre la configuración de <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      En <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> encontrará más detalles sobre cómo incluir las fuentes de hora en la configuración de <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Inhabilite y detenga el servicio <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Inicie y habilite el servicio <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Verifique el estado de chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
  </procedure>

  <procedure>
   <title>Migración a <systemitem class="daemon">chronyd</systemitem> <emphasis>después</emphasis> de la actualización del clúster</title>
   <step>
    <para>
     Durante la actualización del clúster, añada los siguientes repositorios de software:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Pool
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Updates
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Actualice el clúster a la versión 6.
    </para>
   </step>
   <step>
    <para>
     Edite el archivo de configuración <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> y añada orígenes NTP desde la configuración <systemitem class="daemon">ntpd</systemitem> actual en <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>más detalles sobre la configuración de <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      En <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> encontrará más detalles sobre cómo incluir las fuentes de hora en la configuración de <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Inhabilite y detenga el servicio <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Inicie y habilite el servicio <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Migre de <systemitem class="daemon">ntpd</systemitem> a <systemitem class="daemon">chronyd</systemitem>.
    </para>
   </step>
   <step>
    <para>
     Verifique el estado de chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
   <step>
    <para>
     Elimine los repositorios de software heredados que agregó para mantener <systemitem class="daemon">ntpd</systemitem> en el sistema durante el proceso de actualización.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-prepare">
  <title>Aplicación de parches al clúster antes de la actualización</title>

  <para>
   Aplique los parches más recientes a todos los nodos del clúster antes de la actualización.
  </para>

  <sect2 xml:id="upgrade-prepare-repos">
   <title>Repositorios de software requeridos</title>
   <para>
    Compruebe que los repositorios necesarios están configurados en todos los nodos del clúster. Para mostrar todos los repositorios disponibles, ejecute:
   </para>
<screen>
<prompt>root@minion &gt; </prompt>zypper lr
</screen>
   <para>
    SUSE Enterprise Storage 5.5 requiere:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLES12-SP3-Installer-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Updates
     </para>
    </listitem>
   </itemizedlist>
   <para>
    NFS/SMB Gateway en SLE-HA en SUSE Linux Enterprise Server 12 SP3 requiere lo siguiente:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLE-HA12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLE-HA12-SP3-Updates
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-staging">
   <title>Sistemas de fases de repositorio</title>
   <para>
    Si utiliza un sistemas de fases de repositorio (SMT, RMT o SUSE Manager), cree un nuevo nivel de parche inmovilizado para la versión actual y la versión nueva de SUSE Enterprise Storage.
   </para>
   <para>
    Encontrará más información en:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html"/>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/book_rmt.html"/>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/suse-manager-3/index.html"/>.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-patch">
   <title>Aplicación de los parches más recientes a todo el clúster</title>
   <procedure>
    <step>
     <para>
      Aplique los parches más recientes de SUSE Enterprise Storage 5.5 y SUSE Linux Enterprise Server 12 SP3 a todos los nodos del clúster de Ceph. Verifique que se han conectado los repositorios de software correctos a cada nodo del clúster (consulte la <xref linkend="upgrade-prepare-repos"/>) y ejecute la fase 0 de DeepSea:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    </step>
    <step>
     <para>
      Después de completar la fase 0, verifique que el estado de cada nodo del clúster incluya "HEALTH_OK". Si no es así, resuelva el problema antes de que se produzcan los posibles reinicios en los pasos siguientes.
     </para>
    </step>
    <step>
     <para>
      Ejecute <command>zypper ps</command> para comprobar si hay procesos que podría ejecutar con bibliotecas o archivos binarios obsoletos y reinicie si los hay.
     </para>
    </step>
    <step>
     <para>
      Verifique que el kernel en ejecución es el último disponible y reinicie si no lo es. Compruebe el resultado de los siguientes comandos:
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>uname -a
<prompt>cephadm@adm &gt; </prompt>rpm -qa kernel-default
</screen>
    </step>
    <step>
     <para>
      Verifique que el paquete <package>ceph</package> es de la versión 12.2.12 o posterior. Verifique que el paquete <package>deepsea</package> es de la versión 0.8.9 o posterior.
     </para>
    </step>
    <step>
     <para>
      Si anteriormente usó cualquier valor de <option>bluestore_cache</option>, tenga en cuenta que no están en vigor desde la versión 12.2.10 de <package>Ceph.</package>
      El nuevo ajuste <option>bluestore_cache_autotune</option>, que se define por defecto como "true", inhabilita el cambio de tamaño manual del caché. Para activar el comportamiento anterior, debe definir <option>bluestore_cache_autotune=false</option>. Consulte <xref linkend="config-auto-cache-sizing"/> para obtener más detalles.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-verify-current">
  <title>Verificación del entorno actual</title>

  <itemizedlist>
   <listitem>
    <para>
     Si el sistema tiene problemas evidentes, soluciónelos antes de iniciar la actualización. La actualización nunca soluciona los problemas existentes del sistema.
    </para>
   </listitem>
   <listitem>
    <para>
     Compruebe el rendimiento del clúster. Puede utilizar comandos como <command>rados bench</command>, <command>ceph tell osd.* bench</command> o <command>iperf3</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Compruebe el acceso a las pasarelas (como iSCSI Gateway o Object Gateway) y al dispositivos de bloques RADOS.
    </para>
   </listitem>
   <listitem>
    <para>
     Tome documentación sobre las partes específicas de la configuración del sistema, como la configuración de red, la partición o los detalles de la instalación.
    </para>
   </listitem>
   <listitem>
    <para>
     Utilice <command>supportconfig</command> para recopilar información importante del sistema y guardarla fuera de los nodos del clúster. Encontrará más información en <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_admsupport_supportconfig.html"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Asegúrese de que haya suficiente espacio libre en disco en cada nodo del clúster. Compruebe el espacio libre en disco con <command>df -h</command>. Cuando sea necesario, libere espacio en disco eliminando archivos o directorios innecesarios o eliminando instantáneas obsoletas del sistema operativo. Si no hay suficiente espacio libre en disco, no continúe con la actualización hasta que haya liberado suficiente.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-verify-state">
  <title>Comprobación del estado del clúster</title>

  <itemizedlist>
   <listitem>
    <para>
     Compruebe el comando <command>cluster health</command> antes de iniciar el procedimiento de actualización. No inicie la actualización a menos que todos los nodos del clúster notifiquen el estado "HEALTH_OK".
    </para>
   </listitem>
   <listitem>
    <para>
     Verifique que todos los servicios se estén ejecutando:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       El master de Salt y los daemons del master de Salt.
      </para>
     </listitem>
     <listitem>
      <para>
       Los daemons de Ceph Monitor y Ceph Manager.
      </para>
     </listitem>
     <listitem>
      <para>
       Los daemons del servidor de metadatos.
      </para>
     </listitem>
     <listitem>
      <para>
       Los daemons de Ceph OSD.
      </para>
     </listitem>
     <listitem>
      <para>
       Los daemons de Object Gateway.
      </para>
     </listitem>
     <listitem>
      <para>
       Los daemons de iSCSI Gateway.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>

  <para>
   Los comandos siguientes proporcionan detalles sobre el estado del clúster y la configuración específica:
  </para>

  <variablelist>
   <varlistentry>
    <term><command>ceph -s</command></term>
    <listitem>
     <para>
      Muestra un breve resumen del estado del clúster de Ceph, los servicios en ejecución, el uso de datos y las estadísticas de E/S. Verifique que notifica el estado "HEALTH_OK" antes de iniciar la actualización.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph health detail</command></term>
    <listitem>
     <para>
      Muestra detalles si el estado del clúster de Ceph no es correcto.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph versions</command></term>
    <listitem>
     <para>
      Muestra las versiones de los daemons de Ceph en ejecución.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph df</command></term>
    <listitem>
     <para>
      Muestra el espacio en disco total y libre del clúster. No inicie la actualización si el espacio libre en disco del clúster es inferior al 25 % del espacio total en disco.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>salt '*' cephprocesses.check results=true</command></term>
    <listitem>
     <para>
      Muestra los procesos de Ceph y en ejecución sus PID ordenados por minion de Salt.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph osd dump | grep ^flags</command></term>
    <listitem>
     <para>
      Verifique que los indicadores "recovery_deletes" y "purged_snapdirs" estén presentes. Si no es así, puede aplicar un borrado seguro de todos los grupos de colocación ejecutando el comando siguiente. Tenga en cuenta que este borrado seguro impuesto posiblemente afecte de forma negativa al rendimiento de los clientes de Ceph.
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump pgs_brief | cut -d " " -f 1 | xargs -n1 ceph pg scrub
</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1>
  <title>Actualización sin conexión de los clústeres CTDB</title>

  <para>
   CTDB proporciona una base de datos en clúster que se utiliza en las pasarelas Samba Gateway. El protocolo CTDB es muy sencillo y no admite clústeres de nodos que se comuniquen con versiones distintas del protocolo. Por lo tanto, los nodos CTDB deben desconectarse antes de realizar una actualización.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-one-node">
  <title>Actualización por nodo: procedimiento básico</title>

  <para>
   Para asegurarse de que los servicios principales del clúster están disponibles durante la actualización, debe actualizar los nodos del clúster secuencialmente uno por uno. Hay dos formas de realizar la actualización de un nodo: mediante el <emphasis>DVD del instalador</emphasis> o mediante el <emphasis>sistema de migración de distribución</emphasis>.
  </para>

  <para>
   Después de actualizar cada nodo, se recomienda ejecutar <command>rpmconfigcheck</command> para comprobar si hay archivos de configuración actualizados que se hayan editado localmente. Si el comando devuelve una lista de nombres de archivo con el sufijo<filename>.rpmnew</filename>, <filename>.rpmorig</filename> o <filename>.rpmsave</filename>, compare estos archivos con los archivos de configuración actuales para asegurarse de que no se ha perdido ningún cambio local. Si fuera necesario, actualice los archivos afectados. Para obtener más información sobre cómo trabajar con archivos <filename>.rpmnew</filename>, <filename>.rpmorig</filename> y <filename>.rpmsave</filename>, consulte <link xlink:href="https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#sec-rpm-packages-manage"/>.
  </para>

  <tip>
   <title>paquetes huérfanos</title>
   <para>
    Después de actualizar un nodo, varios paquetes estarán en estado "huérfano" sin un repositorio padre. Esto sucede porque los paquetes relacionados con python3 no hacen que los paquetes python2 queden obsoletos.
   </para>
   <para>
    Encontrará más información sobre cómo mostrar los paquetes huérfanos en <link xlink:href="https://www.suse.com/documentation/sles-15/book_sle_admin/data/sec_zypper.html#sec_zypper_softup_orphaned"/>.
   </para>
  </tip>

  <sect2 xml:id="upgrade-one-node-manual">
   <title>Actualización manual de nodo mediante el DVD del instalador</title>
   <procedure>
    <step>
     <para>
      Reinicie el nodo desde el DVD o la imagen del instalador de SUSE Linux Enterprise Server 15 SP1.
     </para>
    </step>
    <step>
     <para>
      Seleccione <guimenu>Actualizar</guimenu> en el menú de arranque.
     </para>
    </step>
    <step>
     <para>
      En la pantalla <guimenu>Seleccionar el destino de migración</guimenu>, verifique que "SUSE Linux Enterprise Server 15 SP1" esté seleccionado y marque la casilla <guimenu>Ajustar manualmente los repositorios para la migración</guimenu>.
     </para>
     <figure>
      <title>Seleccionar el destino de migración</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Seleccione los siguientes módulos para instalarlos:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SUSE Enterprise Storage 6 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Basesystem Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Desktop Applications Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Legacy Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Server Applications Module 15 SP1 x86_64
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      En la pantalla <guimenu>Repositorios usados anteriormente</guimenu>, verifique que estén seleccionados los repositorios correctos. Si el sistema no está registrado con SCC/SMT, debe añadir los repositorios manualmente.
     </para>
     <para>
      SUSE Enterprise Storage 6 requiere:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Basesystem15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE15-SP1-Installer-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Si tiene previsto migrar <systemitem class="daemon">ntpd</systemitem> a <systemitem>chronyd</systemitem> después de la migración de SES (consulte la <xref linkend="upgrade-ntp"/>), incluya los siguientes repositorios:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      NFS/SMB Gateway en SLE-HA en SUSE Linux Enterprise Server 15 SP1 requiere lo siguiente:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Revise los <guimenu>valores de instalación</guimenu> e inicie el procedimiento de instalación haciendo clic en <guimenu>Actualizar</guimenu>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-one-node-auto">
   <title>Actualización de nodos con el sistema de migración de distribución de SUSE</title>
   <para>
    El <emphasis>sistema de migración de distribución</emphasis> (DMS, por su siglas en inglés) proporciona una vía de actualización de una versión principal a otra para los sistemas SUSE Linux Enterprise instalados. El siguiente procedimiento utiliza el DMS para actualizar SUSE Enterprise Storage 5.5 a la versión 6, incluida la migración subyacente de SUSE Linux Enterprise Server 12 SP3 a SUSE Linux Enterprise Server 15 SP1.
   </para>
   <para>
    Consulte en <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/> la información general y detallada sobre el DMS.
   </para>
   <procedure>
    <step>
     <para>
      Instale los paquetes RPM de migración. Sirven para ajustar el cargador de arranque GRUB a fin de activar automáticamente la actualización en el siguiente reinicio. Instale los paquetes
      <package>SLES15-SES-Migration</package> y
      <package>suse-migration-sle15-activation</package> :
     </para>
<screen><prompt>root@minion &gt; </prompt>zypper install SLES15-SES-Migration suse-migration-sle15-activation</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        Si el nodo que se está actualizando <emphasis role="bold">está</emphasis> registrado con un sistema de fases de repositorio como SCC, SMT, RMT o SUSE Manager, cree <filename>/etc/sle-migration-service.yml</filename> con el siguiente contenido:
       </para>
<screen>
use_zypper_migration: true
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
      </step>
      <step>
       <para>
        Si el nodo que se está actualizando <emphasis role="bold">no</emphasis> está registrado con un sistema de fases de repositorio como SCC, SMT, RMT o SUSE Manager, realice los siguientes cambios:
       </para>
       <substeps>
        <step>
         <para>
          Cree <filename>/etc/sle-migration-service.yml</filename> con el siguiente contenido:
         </para>
<screen>
use_zypper_migration: false
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
        </step>
        <step>
         <para>
          Inhabilite o elimine los repositorios SLE 12 SP3 y SES 5 y añada los repositorios SLE 15 SP1 y SES6. Encontrará la lista de repositorios relacionados en la <xref linkend="upgrade-prepare-repos"/>.
         </para>
        </step>
       </substeps>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Reinicie para iniciar la actualización. Mientras se ejecuta la actualización, puede entrar a la sesión en el nodo actualizado a través de <command>ssh</command> como usuario de migración utilizando la clave SSH existente del sistema host como se describe en <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>. Para SUSE Enterprise Storage, si tiene acceso físico o acceso directo de consola al equipo, también puede entrar a la sesión como usuario <systemitem class="username">root</systemitem> en la consola del sistema con la contraseña <literal>sesupgrade</literal>. El nodo se reiniciará automáticamente después de la actualización.
     </para>
     <tip>
      <title>fallo de actualización</title>
      <para>
       Si se produce un error en la actualización, inspeccione el registro <filename>/var/log/distro_migration.log</filename>. Solucione el problema, vuelva a instalar los paquetes RPM de migración y reinicie el nodo.
      </para>
     </tip>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-adm">
  <title>Actualización del nodo de administración</title>

  <itemizedlist>
   <listitem>
    <para>
     Los siguientes comandos seguirán funcionando, aunque los minions de Salt estén ejecutando versiones antiguas de Ceph y Salt: <command>salt '*' test.ping</command> y <command>ceph status</command>
    </para>
   </listitem>
   <listitem>
    <para>
     Después de actualizar el nodo de administración, openATTIC ya no se instalará.
    </para>
   </listitem>
   <listitem>
    <para>
     Si el nodo de administración alojaba SMT, complete su migración a RMT (consulte <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/cha_rmt_migrate.html"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>estado de los nodos de clúster</title>
   <para>
    Después de actualizar el nodo de administración, puede ejecutar el comando <command>salt-run upgrade.status</command> para obtener información útil sobre los nodos del clúster. El comando muestra las versiones de Ceph y del OS de todos los nodos y recomienda el orden en el que se deberán actualizar los nodos que todavía ejecuten versiones antiguas.
   </para>
<screen><prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
  ceph: ceph version 14.2.1-468-g994fd9e0cc (994fd9e0ccc50c2f3a55a3b7a3d4e0ba74786d50) nautilus (stable)
  os: SUSE Linux Enterprise Server 15 SP1

Nodes running these software versions:
  admin.ceph (assigned roles: master)
  mon2.ceph (assigned roles: admin, mon, mgr)

Nodes running older software versions must be upgraded in the following order:
   1: mon1.ceph (assigned roles: admin, mon, mgr)
   2: mon3.ceph (assigned roles: admin, mon, mgr)
   3: data1.ceph (assigned roles: storage)
[...]</screen>
  </tip>
 </sect1>
 <sect1 xml:id="upgrade-mons">
  <title>Actualización de nodos de Ceph Monitor/Ceph Manager</title>

  <itemizedlist>
   <listitem>
    <para>
     Si el clúster <emphasis role="bold">no</emphasis> utiliza funciones del MDS, actualice los nodos MON/MGR uno por uno.
    </para>
   </listitem>
   <listitem>
    <para>
     Si el clúster <emphasis role="bold">utiliza</emphasis> funciones del MDS y las funciones MON/MGR y MDS se recolocan de forma automática, debe reducir el tamaño del clúster del MDS y, a continuación, actualizar los nodos recolocados. Consulte la <xref linkend="upgrade-mds"/> para obtener más información.
    </para>
   </listitem>
   <listitem>
    <para>
     Si el clúster <emphasis role="bold">utiliza</emphasis> funciones del MDS y se ejecutan en servidores <emphasis role="bold">dedicados</emphasis>, actualice todos los nodos MON/MGR uno por uno, reduzca el tamaño del clúster del MDS y actualícelo. Consulte la <xref linkend="upgrade-mds"/> para obtener más información.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>actualización de Ceph Monitor</title>
   <para>
    Debido a una limitación en el diseño de Ceph Monitor, una vez que se han actualizado dos MON a SUSE Enterprise Storage 6 y se ha formado un quórum, el tercer MON (mientras sigue en SUSE Enterprise Storage 5.5) no se reincorporará al clúster de MON si se reinicia por cualquier motivo, incluso si se reinicia el nodo. Por lo tanto, si se han actualizado dos MON, es mejor actualizar el resto tan pronto como sea posible.
   </para>
  </note>

  <para>
   <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
  </para>
 </sect1>
 <sect1 xml:id="upgrade-mds">
  <title>Actualización de servidores de metadatos</title>

  <para>
   Debe reducir el tamaño del clúster del servidor de metadatos (MDS). Dado que hay características incompatibles entre las versiones 5.5 y 6 de SUSE Enterprise Storage, los daemons del MDS anteriores se apagarán tan pronto como vean a un solo MDS de nivel SES 6 unirse al clúster. Por lo tanto, es necesario reducir el tamaño del clúster del MDS a un solo MDS activo (y sin esperas) durante todo el proceso de actualización de los nodos del MDS. Tan pronto como se actualice el segundo nodo, podrá ampliar de nuevo el clúster del MDS.
  </para>

  <tip>
   <para>
    En un clúster del MDS con carga muy elevada, es posible que deba reducir la carga (por ejemplo, deteniendo clientes) para que un único MDS activo pueda controlarla.
   </para>
  </tip>

  <procedure>
   <step>
    <para>
     Anote el valor actual de la opción <option>max_mds</option>:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs get cephfs | grep max_mds
</screen>
   </step>
   <step>
    <para>
     Reduzca el tamaño del clúster del MDS si tiene más de 1 daemon del MDS activo, es decir, si <option>max_mds</option> es &gt; 1. Para reducir el tamaño del clúster del MDS, ejecute:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds 1
</screen>
    <para>
     donde <replaceable>FS_NAME</replaceable> es el nombre de la instancia de CephFS ("cephfs" por defecto).
    </para>
   </step>
   <step>
    <para>
     Busque el nodo donde se aloja uno de los daemons del MDS en espera. Consulte el resultado del comando <command>ceph fs status</command> e inicie la actualización del clúster del MDS en este nodo.
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs status
cephfs - 2 clients
======
+------+--------+--------+---------------+-------+-------+
| Rank | State  |  MDS   |    Activity   |  dns  |  inos |
+------+--------+--------+---------------+-------+-------+
|  0   | active | mon1-6 | Reqs:    0 /s |   13  |   16  |
+------+--------+--------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 2688k | 96.8G |
|   cephfs_data   |   data   |    0  | 96.8G |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
|    mon3-6   |
|    mon2-6   |
+-------------+
</screen>
    <para>
     En este ejemplo, necesita iniciar el procedimiento de actualización en el nodo "mon3-6" o en el "mon2-6".
    </para>
   </step>
   <step>
    <para>
     Actualice el nodo con el daemon en espera del MDS. Después de que se inicie el nodo actualizado del MDS, los daemons obsoletos del MDS se apagarán automáticamente. En este momento, los clientes pueden experimentar un breve tiempo de inactividad del servicio CephFS.
    </para>
    <para>
     <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Actualice los nodos restantes del MDS.
    </para>
   </step>
   <step>
    <para>
     Restablezca la configuración deseada en <option>max_mds</option>:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds <replaceable>ACTIVE_MDS_COUNT</replaceable>
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-main-osd">
  <title>Actualización de los OSD Ceph</title>

  <para>
   Siga estos pasos para cada nodo de almacenamiento:
  </para>

  <procedure>
   <step>
    <para>
     Identifique qué daemons del OSD se ejecutan en un nodo determinado:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd tree
</screen>
   </step>
   <step>
    <para>
     Establezca el indicador "noout" para cada daemon del OSD del nodo que se está actualizando:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd add-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Por ejemplo:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd add-noout osd.$i; done</screen>
    <para>
     Verifíquelo con:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     O bien
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
      6 OSDs or CRUSH {nodes, device-classes} have {NOUP,NODOWN,NOIN,NOOUT} flags set</screen>
   </step>
   <step>
    <para>
     Cree archivos <filename>/etc/ceph/osd/*.json</filename> para todos los OSD existentes ejecutando el siguiente comando en el nodo que se va a actualizar:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan --force
</screen>
   </step>
   <step>
    <para>
     Actualice el nodo del OSD. <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Active todos los OSD que se encuentran en el sistema:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>;ceph-volume simple activate --all
</screen>
    <tip>
     <title>activación individual de particiones de datos</title>
     <para>
      Si desea activar las particiones de datos individualmente, debe encontrar el comando <command>ceph-volume</command> correcto de cada partición para activarla. Sustituya <replaceable>X1</replaceable> por la letra o número correcto de la partición:
     </para>
<screen>
 <prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/sd<replaceable>X1</replaceable>
</screen>
     <para>
      Por ejemplo:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/vdb1
[...]
--&gt; OSD 8 got scanned and metadata persisted to file:
/etc/ceph/osd/8-d7bd2685-5b92-4074-8161-30d146cd0290.json
--&gt; To take over management of this scanned OSD, and disable ceph-disk
and udev, run:
--&gt;     ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
     <para>
      La última línea del resultado contiene el comando para activar la partición:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
[...]
--&gt; All ceph-disk systemd units have been disabled to prevent OSDs
getting triggered by UDEV events
[...]
Running command: /bin/systemctl start ceph-osd@8
--&gt; Successfully activated OSD 8 with FSID
d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
    </tip>
   </step>
   <step>
    <para>
     Verifique que el nodo del OSD se inicia correctamente después del reinicio.
    </para>
   </step>
   <step>
    <para>
     Fíjese en el mensaje "Legacy BlueStore stats reporting detected on XX OSD(s)" (Se han detectado informes de estadísticas de BlueStore heredados en XX OSD):
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
    <para>
     La advertencia es normal al actualizar Ceph a la versión 14.2.2. Puede desactivarla configurando lo siguiente:
    </para>
<screen>bluestore_warn_on_legacy_statfs = false</screen>
    <para>
     La solución adecuada es ejecutar el siguiente comando en todos los OSD mientras están detenidos:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-XXX</screen>
    <para>
     A continuación se muestra un guion auxiliar que ejecuta <command>ceph-bluestore-tool repair</command> para todos los OSD del nodo <replaceable>NODE_NAME</replaceable>:
    </para>
<screen>OSDNODE=<replaceable>OSD_NODE_NAME</replaceable>;\
 for OSD in $(ceph osd ls-tree $OSDNODE);\
 do echo "osd=" $OSD;\
 salt $OSDNODE cmd.run 'systemctl stop ceph-osd@$OSD';\
 salt $OSDNODE cmd.run 'ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-$OSD';\
 salt $OSDNODE cmd.run 'systemctl start ceph-osd@$OSD';\
 done</screen>
   </step>
   <step>
    <para>
     Desactive el indicador "noout" en cada daemon del OSD del nodo que se actualiza:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd rm-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Por ejemplo:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd rm-noout osd.$i; done</screen>
    <para>
     Verifíquelo con:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     Nota:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
   </step>
   <step>
    <para>
     verifique el estado del clúster. Mostrará un aspecto similar al siguiente:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph status
cluster:
  id:     e0d53d64-6812-3dfe-8b72-fd454a6dcf12
  health: HEALTH_WARN
          3 monitors have not enabled msgr2

services:
  mon: 3 daemons, quorum mon1,mon2,mon3 (age 2h)
  mgr: mon2(active, since 22m), standbys: mon1, mon3
  osd: 30 osds: 30 up, 30 in

data:
  pools:   1 pools, 1024 pgs
  objects: 0 objects, 0 B
  usage:   31 GiB used, 566 GiB / 597 GiB avail
  pgs:     1024 active+clean
</screen>
   </step>
   <step>
    <para>
     Compruebe que todos los nodos del OSD se han reiniciado y que los OSD se han iniciado automáticamente después del reinicio.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="filestore2bluestore">
  <title>Migración de OSDs a BlueStore</title>

  <para>
   OSD BlueStore es un nuevo back-end para los daemons del OSD. Es la opción por defecto desde SUSE Enterprise Storage 5. En comparación con FileStore, que almacena los objetos como archivos en un sistema de archivos XFS, BlueStore puede ofrecer un mayor rendimiento debido a que almacena los objetos directamente en el dispositivo de bloques subyacente. BlueStore también permite otras funciones, como la compresión integrada y la sobrescritura de codificación de borrado, que no están disponibles con FileStore.
  </para>

  <para>
   Específicamente para BlueStore, un OSD dispone de un dispositivo "wal" (Write Ahead Log, registro de escritura predictiva) y un dispositivo "db" (base de datos RocksDB). La base de datos RocksDB almacena los metadatos de un OSD BlueStore. Estos dos dispositivos se encuentran por defecto en el mismo dispositivo que un OSD, pero cualquiera de ellos se puede colocar en otro lugar, por ejemplo en un medio más rápido.
  </para>

  <para>
   En SUSE Enterprise Storage 5, se admite tanto FileStore como BlueStore y es posible que ambos sistemas coexistan en un mismo clúster. Durante el procedimiento de actualización de SUSE Enterprise Storage, los OSD de FileStore no se convierten automáticamente a BlueStore. Tenga en cuenta que las funciones específicas de BlueStore no estarán disponibles en los OSD que no se hayan migrado a BlueStore.
  </para>

  <para>
   Antes de convertirlos a BlueStore, los OSD deben disponer ya de SUSE Enterprise Storage en ejecución. La conversión es un proceso lento, ya que todos los datos se reescriben dos veces. Aunque el proceso de migración puede tardar mucho tiempo en completarse, no hay ninguna interrupción del clúster y todos los clientes pueden seguir accediendo a él durante ese período. No obstante, el rendimiento será inferior durante la migración. Esto es debido al reequilibrio de la carga y la reposición de datos del clúster.
  </para>

  <para>
   Utilice el procedimiento siguiente para migrar los OSD de FileStore a BlueStore:
  </para>

  <tip>
   <title>desactivación de las medidas de seguridad</title>
   <para>
    Los comandos de Salt necesarios para ejecutar la migración se bloquean por motivos de seguridad. Para desactivar estas medidas de seguridad, ejecute el siguiente comando:
   </para>
<screen>
 <prompt>root@master # </prompt>salt-run disengage.safety
 </screen>
   <para>
    Reconstruya los nodos antes de continuar:
   </para>
<screen>
 <prompt>root@master # </prompt> salt-run rebuild.node <replaceable>TARGET</replaceable>
 </screen>
   <para>
    También puede reconstruir cada nodo individualmente. Por ejemplo:
   </para>
<screen>
<prompt>root@master # </prompt> salt-run rebuild.node data1.ceph
 </screen>
   <para>
    El comando <literal>rebuild.node</literal> siempre elimina y vuelve a crear todos los OSD del nodo.
   </para>
   <important>
    <para>
     Si un OSD no se puede convertir, al volver a ejecutar la reconstrucción se destruyen los BlueStore OSD ya convertidos. En lugar de volver a ejecutar la reconstrucción, puede ejecutar:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.deploy <replaceable>TARGET</replaceable>
 </screen>
   </important>
  </tip>

  <para>
   Después de la migración a BlueStore, el recuento de objetos seguirá siendo el mismo y el uso de disco será prácticamente igual.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-appnodes-order">
  <title>Actualización de nodos de aplicación</title>

  <para>
   Actualice los nodos de aplicación en el siguiente orden:
  </para>

  <orderedlist>
   <listitem>
    <para>
     Pasarelas Object Gateway
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Si las pasarelas Object Gateway están respaldadas por un equilibrador de carga, debería de ser posible realizar una actualización gradual de las pasarelas sin interrupciones.
      </para>
     </listitem>
     <listitem>
      <para>
       Compruebe que los daemons de Object Gateway se están ejecutando después de cada actualización y pruebe con el cliente S3/Swift.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Pasarelas iSCSI Gateway
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Si los iniciadores iSCSI están configurados con múltiples rutas, debería de ser posible realizar una actualización gradual de las pasarelas iSCSI Gateway sin que haya interrupciones.
      </para>
     </listitem>
     <listitem>
      <para>
       Compruebe que el daemon <systemitem class="daemon">lrbd</systemitem> se está ejecutando después de cada actualización y pruebe con el iniciador.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     NFS Ganesha. <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
   <listitem>
    <para>
     Pasarelas Samba Gateway. <emphasis role="bold">Utilice el procedimiento descrito en la <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </orderedlist>
 </sect1>
 <sect1 xml:id="upgrade-main-policy">
  <title>Actualización de <filename>policy.cfg</filename> y distribución de Ceph Dashboard con DeepSea</title>

  <para>
   En el nodo de administración, edite <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> y aplique los siguientes cambios:
  </para>

  <important>
   <title>sin nuevos servicios</title>
   <para>
    Durante la actualización del clúster, no añada nuevos servicios al archivo <filename>policy.cfg</filename>. Cambie la arquitectura del clúster solo después de completar la actualización.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Elimine <literal>role-openattic</literal>.
    </para>
   </step>
   <step>
    <para>
     Añada <literal>role-prometheus</literal> y <literal>role-grafana</literal> al nodo que tenía instalados Prometheus y Grafana; normalmente se trata del nodo de administración.
    </para>
   </step>
   <step>
    <para>
     Ahora se ignora la función <literal>profile‑<replaceable/>NOMBRE_PERFIL</literal>. Añada la nueva función correspondiente en la línea <literal>role-storage</literal>. Por ejemplo, para
    </para>
<screen>
profile-default/cluster/*.sls
</screen>
    <para>
     añada
    </para>
<screen>
role-storage/cluster/*.sls
</screen>
   </step>
   <step>
    <para>
     Sincronice todos los módulos de Salt:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.sync_all</screen>
   </step>
   <step>
    <para>
     Actualice el pilar de Salt ejecutando las fases 1 y 2 de DeepSea:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Limpie openATTIC:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.rescind.openattic
<prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.remove.openattic</screen>
   </step>
   <step>
    <para>
     Desactive el grain "restart_igw" para evitar que la fase 0 reinicie iSCSI Gateway, que aún no se ha instalado:
    </para>
<screen>Salt mastersalt '*' grains.delkey restart_igw</screen>
   </step>
   <step>
    <para>
     Por último, ejecute las fases 0 a 4 de DeepSea:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <tip>
     <title>errores de "falta un subvolumen" durante la fase 3</title>
     <para>
      La fase 3 de DeepSea puede fallar con un error similar al siguiente:
     </para>
<screen>subvolume : ['/var/lib/ceph subvolume missing on 4510-2', \
'/var/lib/ceph subvolume missing on 4510-1', \
[...]
'See /srv/salt/ceph/subvolume/README.md']</screen>
     <para>
      En tal caso, debe editar <filename role="bold">/srv/pillar/ceph/stack/global.yml</filename> y añadir la siguiente línea:
     </para>
<screen>subvolume_init: disabled</screen>
     <para>
      A continuación, actualice el pilar de Salt y vuelva a ejecutar la fase 3 de DeepSea:
     </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar
 <prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     <para>
      Después de que DeepSea haya completado correctamente la fase 3, la Ceph Dashboard se estará ejecutando. Consulte <xref linkend="ceph-dashboard"/> para obtener una descripción detallada de las funciones de Ceph Dashboard.
     </para>
     <para>
      Para mostrar los nodos en los que se ejecuta la consola, ejecute:
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph mgr services | grep dashboard</screen>
     <para>
      Para mostrar las credenciales de administrador, ejecute:
     </para>
<screen><prompt>root@master # </prompt>salt-call grains.get dashboard_creds</screen>
    </tip>
   </step>
   <step>
    <para>
     Reinicie secuencialmente los servicios de Object Gateway para utilizar el servidor Web "beast" en lugar del servidor "civetweb" obsoleto:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.restart.rgw.force</screen>
   </step>
   <step>
    <para>
     Antes de continuar, se recomienda habilitar el módulo de telemetría de Ceph. Para obtener más información, consulte <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-drive-groups">
  <title>Migración de distribuciones basadas en perfiles a DriveGroups</title>

  <para>
   En SUSE Enterprise Storage 5.5, DeepSea ofrecía los llamados "perfiles" para describir el diseño de los OSD. A partir de SUSE Enterprise Storage 6, hemos pasado a un enfoque diferente denominado <emphasis>DriveGroups</emphasis> (encontrará más detalles en la <xref linkend="ds-drive-groups"/>).
  </para>

  <note>
   <para>
    La migración al nuevo enfoque no es obligatoria de inmediato. Las operaciones destructivas como <command>salt‑run osd.remove</command>, <command>salt‑run osd.replace</command> o <command>salt‑run osd.purge </command> siguen estando disponibles. Sin embargo, para añadir nuevos OSD se requerirá su intervención.
   </para>
  </note>

  <para>
   Debido al diferente enfoque de estas implementaciones, no se ofrece una vía de migración automatizada. Sin embargo, se ofrecen varias herramientas (runners de Salt) para que la migración sea lo más sencilla posible.
  </para>

  <sect2>
   <title>Análisis del diseño actual</title>
   <para>
    Para ver información sobre los OSD distribuidos actualmente, utilice el siguiente comando:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.discover
</screen>
   <para>
    Como alternativa, puede inspeccionar el contenido de los archivos en los directorios <filename>/srv/pillar/ceph/proposals/profile-*/</filename>. Tienen una estructura similar a la siguiente:
   </para>
<screen>
ceph:
  storage:
    osds:
      /dev/disk/by-id/scsi-drive_name: format: bluestore
      /dev/disk/by-id/scsi-drive_name2: format: bluestore
     </screen>
  </sect2>

  <sect2>
   <title>Creación de DriveGroups que coincidan con el diseño actual</title>
   <para>
    Consulte la <xref linkend="ds-drive-groups-specs"/> para obtener más información sobre la especificación DriveGroups.
   </para>
   <para>
    La diferencia entre una distribución nueva y una actualización es que las unidades que se van a migrar ya están "utilizadas". Dado que
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list
</screen>
   <para>
    solo busca discos no utilizados, use:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list include_unavailable=True
</screen>
   <para>
    Ajuste DriveGroups hasta que coincida con la configuración actual. Para obtener una representación más visual de lo que sucederá, utilice el siguiente comando. Tenga en cuenta que no habrá resultado alguno si no hay discos libres:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report bypass_pillar=True
</screen>
   <para>
    Si ha verificado que DriveGroups está configurado correctamente y desea aplicar el nuevo enfoque, elimine los archivos del directorio <filename>/srv/pillar/ceph/proposals/profile-<replaceable>NOMBRE_PERFIL</replaceable>/</filename>, elimine las líneas <literal>profile‑<replaceable>NOMBRE_PERFIL</replaceable>/cluster/*.sls</literal> correspondientes del archivo  del archivo <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> y ejecute la fase 2 de DeepSea para actualizar el pilar de Salt.
   </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
</screen>
   <para>
    Verifique el resultado ejecutando los siguientes comandos:
   </para>
<screen>
<prompt>root@master # </prompt>salt target_node pillar.get ceph:storage
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   <warning>
    <title>configuración incorrecta de DriveGroups</title>
    <para>
     Si DriveGroups no está configurado correctamente y hay discos de repuesto en la configuración, se distribuirán de la forma en que los especificó. Se recomienda ejecutar lo siguiente:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   </warning>
  </sect2>

  <sect2 xml:id="upgrade-osd-deployment">
   <title>Distribución de OSD</title>
   <para>
    En los casos sencillos, como con un OSD independiente, la migración se realizará progresivamente. Cada vez que elimine o sustituya un OSD del clúster, se sustituirá por un nuevo basado en LVM.
   </para>
   <tip>
    <title>migración al formato LVM</title>
    <para>
     Cada vez que un único OSD "heredado" necesita reemplazarse en un nodo, todos los OSD que comparten dispositivos con él deberán migrarse al formato basado en LVM.
    </para>
    <para>
     Para no dejarse ninguno, lo mejor es migrar los OSD de todo el nodo.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Configuraciones más complejas</title>
   <para>
    Si tiene una configuración más sofisticada (no solo OSD independientes), por ejemplo, WAL/DB dedicados o OSD cifrados, la migración solo puede producirse cuando se hayan eliminado todos los OSD asignados a ese dispositivo WAL/DB. Esto se debe al comando <command>ceph-volume</command>, que crea volúmenes lógicos en los discos antes de la distribución. Se evita así que el usuario mezcle distribuciones basadas en particiones con distribuciones basadas en volúmenes lógicos. En tales casos, es mejor eliminar manualmente todos los OSD asignados a un dispositivo WAL/DB y volver a distribuirlos mediante el enfoque DriveGroups.
   </para>
  </sect2>
 </sect1>
</chapter>
