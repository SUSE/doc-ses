<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_admin_ha.xml" version="5.0" xml:id="cha.admin_ha">
 <title>Configuración de alta disponibilidad del nodo de administración de Ceph</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>sí</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  El <emphasis>nodo de administración de Ceph</emphasis> es un nodo de clúster de Ceph donde se ejecuta el servicio del master de Salt. El nodo de administración es un punto central del clúster de Ceph porque gestiona el resto de los nodos del clúster consultando y dando instrucciones a los servicios minion de Salt. Normalmente también incluye otros servicios; por ejemplo, la interfaz de usuario Web openATTIC con la consola <emphasis>Grafana</emphasis> respaldada por el kit de herramientas de supervisión <emphasis>Prometheus</emphasis>.
 </para>
 <para>
  En caso de que el nodo de administración de Ceph falle, lo habitual es que deba proporcionar un nuevo hardware que funcione para el nodo y que tenga que restaurar la pila de configuración del clúster completa a partir de una copia de seguridad reciente. Este método lleva bastante tiempo y provoca interrupciones del clúster.
 </para>
 <para>
  Para evitar tiempos de inactividad del clúster de Ceph debido a fallos en el nodo de administración, se recomienda usar el clúster de alta disponibilidad (HA) para el nodo de administración de Ceph.
 </para>
 <sect1 xml:id="admin_ha.architecture">
  <title>Esquema del clúster de alta disponibilidad para el nodo de administración de Ceph</title>

  <para>
   La idea de un clúster de alta disponibilidad consiste en que, en caso de fallo del nodo del clúster, el otro nodo se haga cargo automáticamente de su función, incluido el nodo de administración de Ceph virtualizado. De este modo, los otros nodos del clúster de Ceph no notan que el nodo de administración de Ceph ha fallado.
  </para>

  <para>
   La solución de alta disponibilidad mínima para el nodo de administración de Ceph requiere el siguiente hardware:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Dos servidores instalados desde cero donde se pueda ejecutar SUSE Linux Enterprise con la extensión de alta disponibilidad y donde se pueda virtualizar el nodo de administración de Ceph.
    </para>
   </listitem>
   <listitem>
    <para>
     Dos o más vías de comunicación de red redundantes; por ejemplo, mediante vínculos de dispositivos de red.
    </para>
   </listitem>
   <listitem>
    <para>
     Almacenamiento compartido para alojar las imágenes de disco de la máquina virtual del nodo de administración de Ceph. Debe ser posible acceder al almacenamiento compartido desde ambos servidores. Puede ser, por ejemplo, una exportación NFS, un recurso compartido Samba o el destino iSCSI.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Encontrará más información sobre los requisitos del clúster en <link xlink:href="https://www.suse.com/documentation/sle-ha-12/install-quick/data/install-quick.html#sec_ha_inst_quick_req"/>.
  </para>

  <figure>
   <title>Clúster de alta disponibilidad de 2 nodos para el nodo de administración de Ceph</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_admin_ha1.png" width="60%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_admin_ha1.png" width="60%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
 <sect1 xml:id="admin_ha.cluster">
  <title>Vinculación del clúster de alta disponibilidad con nodo de administración de Ceph</title>

  <para>
   El procedimiento siguiente resume los pasos más importantes a la hora de crear el clúster de alta disponibilidad para la virtualización del nodo de administración de Ceph. Para obtener más detalles, consulte los enlaces indicados.
  </para>

  <procedure>
   <step>
    <para>
     Configure un clúster de alta disponibilidad básico de 2 nodos con almacenamiento compartido, como se describe en <link xlink:href="https://www.suse.com/documentation/sle-ha-12/install-quick/data/install-quick.html"/>.
    </para>
   </step>
   <step>
    <para>
     En ambos nodos del clúster, instale todos los paquetes necesarios para ejecutar el hipervisor KVM y el kit de herramientas <systemitem class="library">libvirt</systemitem>, como se describe en <link xlink:href="https://www.suse.com/documentation/sles-12/book_virt/data/sec_vt_installation_kvm.html"/>.
    </para>
   </step>
   <step>
    <para>
     En el primer nodo del clúster, cree una máquina virtual KVM nueva mediante <systemitem class="library">libvirt</systemitem>, como se describe en <link xlink:href="https://www.suse.com/documentation/sles-12/book_virt/data/sec_libvirt_inst_vmm.html"/>. Utilice el almacenamiento compartido preconfigurado para almacenar las imágenes de disco de la máquina virtual.
    </para>
   </step>
   <step>
    <para>
     Después de que se haya completado la configuración de la máquina virtual, exporte su configuración a un archivo XML en el almacenamiento compartido. Utilice la siguiente sintaxis:
    </para>
<screen>
<prompt>root # </prompt>virsh dumpxml <replaceable>VM_NAME</replaceable> &gt; /path/to/shared/vm_name.xml
</screen>
   </step>
   <step>
    <para>
     Cree un recurso para la máquina virtual del nodo de administración de Ceph. Consulte <link xlink:href="https://www.suse.com/documentation/sle-ha-12/book_sleha/data/cha_conf_hawk2.html"/> para obtener información general sobre cómo crear recursos de alta disponibilidad. Encontrará información detallada sobre cómo crear un recurso para una máquina virtual KVM en <link xlink:href="http://www.linux-ha.org/wiki/VirtualDomain_%28resource_agent%29"/>.
    </para>
   </step>
   <step>
    <para>
     En la máquina virtual invitada que acaba de crear, distribuya el nodo de administración de Ceph, incluidos los servicios adicionales que necesite allí. Siga los pasos relevantes de la <xref linkend="ceph.install.stack"/>. Al mismo tiempo, distribuya los demás nodos del clúster de Ceph en los servidores del clúster que no sean de alta disponibilidad.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
