<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage-troubleshooting">
 <title>Solución de problemas</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sí</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  En este capítulo se describen varios de los problemas que pueden aparecer cuando se trabaja en un clúster de Ceph.
 </para>
 <sect1 xml:id="storage-bp-report-bug">
  <title>Notificación de problemas de software</title>

  <para>
   Si encuentra un problema al ejecutar SUSE Enterprise Storage 6 relacionado con alguno de sus componentes, como Ceph u Object Gateway, informe al servicio de asistencia técnica de SUSE. La forma recomendada de hacerlo es mediante la utilidad <command>supportconfig</command>.
  </para>

  <tip>
   <para>
    Dado que <command>supportconfig</command> es un software modular, asegúrese de que el paquete <systemitem>supportutils-plugin-ses</systemitem> está instalado.
   </para>
<screen><prompt>tux &gt; </prompt>rpm -q supportutils-plugin-ses</screen>
   <para>
    Si no está en el servidor de Ceph, instálelo con:
   </para>
<screen><prompt>root # </prompt>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   Aunque puede utilizar <command>supportconfig</command> en la línea de comandos, se recomienda utilizar el módulo de YaST relacionado. Encontrará más información sobre <command>supportconfig</command> en <link xlink:href="https://www.suse.com/documentation/sles-15/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-cluster-mntc-rados-striping">
  <title>El envío de objetos de gran tamaño con <command>rados</command> falla con OSD lleno</title>

  <para>
   <command>rados</command> es una utilidad de línea de comandos para gestionar el almacenamiento de objetos RADOS. Para obtener más información, consulte la página <command>man 8 rados</command>.
  </para>

  <para>
   Si envía un objeto de gran tamaño a un clúster de Ceph con la utilidad <command>rados</command>, por ejemplo,
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>rados -p mypool put myobject /file/to/send</screen>

  <para>
   puede llenar todo el espacio dedicado al OSD y causar problemas graves en el rendimiento del clúster.
  </para>
 </sect1>
 <sect1 xml:id="ceph-xfs-corruption">
  <title>Sistema de archivos XFS dañado</title>

  <para>
   En algunas raras circunstancias, como si se producen errores del kernel o si hay hardware dañado o mal configurado, el sistema de archivos subyacente (XFS) en el que el OSD almacena los datos puede estar dañado o ser imposible de montar.
  </para>

  <para>
   Si está seguro de que no hay ningún problema con el hardware y de que el sistema está configurado correctamente, emita un informe de error para el subsistema XFS del kernel de SUSE Linux Enterprise Server y marque el OSD concreto como inactivo:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd down <replaceable>OSD_ID</replaceable></screen>

  <warning>
   <title>no formatee ni modifique de ninguna otra forma el dispositivo dañado</title>
   <para>
    Aunque utilizar <command>xfs_repair</command> para corregir el problema del sistema de archivos pueda parecer una opción razonable, no la utilice, ya que el comando modifica el sistema de archivos. El OSD podría iniciarse, pero podría afectar a su correcto funcionamiento.
   </para>
  </warning>

  <para>
   Borre la tabla de particiones del disco subyacente y vuelva a crear el OSD ejecutando:
  </para>

<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm zap --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm prepare --bluestore --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-recover-toomanypgs">
  <title>Mensaje de estado "Too Many PGs per OSD" (Hay demasiados grupos de colocación por OSD)</title>

  <para>
   Si recibe el mensaje <literal>Too Many PGs per OSD</literal> (Hay demasiados grupos de colocación por OSD) después de ejecutar <command>ceph status</command>, significa que el valor <option>mon_pg_warn_max_per_osd</option> (300 por defecto) se ha superado. Este valor se compara con la proporción entre el número de grupos de colocación por OSD. Esto significa que la configuración del clúster no es óptima.
  </para>

  <para>
   El número de grupos de colocación no se puede reducir después de crear el repositorio. Los repositorios que aún no contienen ningún dato se pueden suprimir con seguridad y volver a crearse con un número inferior de grupos de colocación. Si los repositorios ya contienen datos, la única solución es añadir nuevos OSD al clúster para que la proporción de grupos de colocación por OSD se reduzca.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-stuckinactive">
  <title>Mensaje de estado "<emphasis>nn</emphasis> pg stuck inactive" (grupo de colocación nn atascado inactivo)</title>

  <para>
   Si recibe un mensaje de estado de tipo <literal>stuck inactive</literal> (grupo de colocación atascado inactivo) después de ejecutar <command>ceph status</command>, significa que Ceph no sabe dónde replicar los datos almacenados para cumplir las reglas de réplica. Puede producirse poco después de la configuración inicial de Ceph y se corrige automáticamente. En otros casos, puede hacer falta intervención manual; por ejemplo, habrá que reparar un OSD dañado o añadir un OSD nuevo al clúster. En muy raras ocasiones, reducir el nivel de réplica podría ser de utilidad.
  </para>

  <para>
   Si los grupos de colocación se atascan perpetuamente, debe comprobar el resultado de <command>ceph osd tree</command>. El resultado debe tener una estructura de árbol similar a la del ejemplo de la <xref linkend="storage-bp-recover-osddown"/>.
  </para>

  <para>
   Si el resultado de <command>ceph osd tree</command> es plano, como en el ejemplo siguiente:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   debe comprobar que el mapa de CRUSH relacionado tenga una estructura de árbol. Si también es plano, o si no tiene ningún host como en el ejemplo anterior, puede significar que la resolución del nombre de host no funcione correctamente en el clúster.
  </para>

  <para>
   Si la jerarquía no es correcta, por ejemplo, la raíz contiene hosts pero los OSD están en el nivel superior y no están asignados a hosts, debe mover los OSD a la ubicación correcta en la jerarquía. Esto puede realizarse mediante los comandos <command>ceph osd crush move</command> o <command>ceph osd crush set</command>. Para obtener más información, consulte la <xref linkend="op-crush"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osdweight">
  <title>El peso del OSD es 0</title>

  <para>
   Cuando se inicia el OSD, se le asigna un peso. Cuanto mayor sea el peso, mayor será la posibilidad de que el clúster escriba datos en el OSD. El peso se especifica en un mapa de CRUSH o se calcula mediante el guión de inicio de los OSD.
  </para>

  <para>
   En algunos casos, el valor calculado para el peso de los OSD puede redondearse a cero. Eso significa que el OSD no está programado para almacenar datos y, por lo tanto, no se escriben datos en él. Esto suele deberse a que el disco es demasiado pequeño (inferior a 15 GB) y debe sustituirse por uno mayor.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osddown">
  <title>El OSD está apagado</title>

  <para>
   El daemon OSD está en ejecución o detenido/apagado. Hay 3 razones por las qué un OSD puede estar apagado:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Un fallo del disco duro.
    </para>
   </listitem>
   <listitem>
    <para>
     El OSD se ha detenido por fallo.
    </para>
   </listitem>
   <listitem>
    <para>
     El servidor se ha detenido por fallo.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Puede ver el estado detallado del OSD ejecutando:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   El ejemplo muestra que <literal>osd.2</literal> está apagado. Puede comprobar si el disco donde está ubicado el OSD está montado:
  </para>

<screen><prompt>root # </prompt>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   Para averiguar el motivo por el que el OSD está apagado, inspeccione su archivo de registro <filename>/var/log/ceph/ceph-osd.2.log</filename>. Cuando encuentre y solucione el motivo por el que el OSD no se está ejecutando, inícielo con:
  </para>

<screen><prompt>root # </prompt>systemctl start ceph-osd@2.service</screen>

  <para>
   No olvide sustituir <literal>2</literal> por el número real del OSD que se ha detenido.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-slowosd">
  <title>Búsqueda de OSD lentos</title>

  <para>
   Al ajustar el rendimiento del clúster, es muy importante identificar los OSD o los sistemas de almacenamiento lentos. La razón es que si los datos se escriben en el disco más lento, la operación de escritura se ralentiza por completo, ya que siempre se espera hasta que la operación termina en todos los discos relacionados.
  </para>

  <para>
   Localizar los cuellos de botella de almacenamiento no es sencillo. Tendrá que examinar cada OSD para averiguar cuáles son los que ralentizan el proceso de escritura. Para llevar a cabo una evaluación comparativa de un único OSD, ejecute:
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> osd.<replaceable>OSD_ID_NUMBER</replaceable> bench</screen>

  <para>
   Por ejemplo:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   A continuación, debe ejecutar este comando en cada OSD y comparar el valor <literal>bytes_per_sec</literal> para comprobar cuáles son los OSD más lentos.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-clockskew">
  <title>Solución de advertencias de diferencias del reloj</title>

  <para>
   La información de hora de todos los nodos del clúster debe estar sincronizada. Si la hora de un nodo no está perfectamente sincronizada, se generarán advertencias de diferencias del reloj cuando se compruebe el estado del clúster.
  </para>

  <para>
   La sincronización de hora se gestiona con NTP (consulte <link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>). Defina que cada nodo sincronice la hora con uno o varios servidores NTP; preferentemente en el mismo grupo de servidores NTP. Si aún se produce alguna diferencia de hora en un nodo, siga estos pasos para solucionarlo:
  </para>

<screen><prompt>root # </prompt>systemctl stop chronyd.service
<prompt>root # </prompt>systemctl stop ceph-mon.target
<prompt>root # </prompt>systemctl start chronyd.service
<prompt>root # </prompt>systemctl start ceph-mon.target</screen>

  <para>
   A continuación, puede comprobar la diferencia horaria con <command>chronyc sourcestats</command>.
  </para>

  <para>
   Los monitores de Ceph deben tener sus relojes sincronizados con una diferencia máxima de 0,05 segundos entre sí. Consulte la <xref linkend="Cluster-Time-Setting"/> para obtener más información.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-net-issues">
  <title>Rendimiento deficiente del clúster debido a problemas de la red</title>

  <para>
   Existen diversas razones por las que el rendimiento del clúster puede ser deficiente. Una de ellas pueden ser los problemas de red. En tal caso, puede observar que el clúster alcanza un quórum, los nodos de OSD y de monitor se desconectan, las transferencias de datos tardan mucho tiempo o que se producen muchos intentos de volver a conectar.
  </para>

  <para>
   Para comprobar si el rendimiento del clúster está afectado por problemas de red, revise los archivos de registro de Ceph del directorio <filename>/var/log/ceph</filename>.
  </para>

  <para>
   Para solucionar problemas de red en el clúster, céntrese en los siguientes puntos:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Diagnóstico básico de red. Con el runner de herramientas de diagnóstico de DeepSea, <literal>net.ping</literal>, realice un ping entre los nodos del clúster para comprobar si la interfaz individual puede contactar con una interfaz específica y el tiempo de respuesta medio. También se indicará cualquier tiempo de respuesta específico mucho más lento que la media. Por ejemplo:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     Intente validar todas las interfaces con JumboFrame. Para ello, habilite:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     Evaluación comparativa del rendimiento de la red. Con el runner de rendimiento de red de DeepSea, <literal>net.iperf</literal>, pruebe el ancho de banda de red del nodo interno. En un nodo de clúster determinado, un número de procesos <command>iperf</command> (según el número de núcleos de CPU) se inician como servidores. Los demás nodos del clúster se utilizan como clientes para generar el tráfico de red. Se indica el ancho de banda acumulado de todos los procesos <command>iperf</command> por nodo. Esto debe reflejar el rendimiento de red máximo que se puede conseguir en todos los nodos del clúster. Por ejemplo:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     Compruebe los valores del cortafuegos en los nodos del clúster. Asegúrese de que no bloquea los protocolos o puertos necesarios para el funcionamiento de Ceph. Consulte la <xref linkend="storage-bp-net-firewall"/> para obtener más información sobre los valores del cortafuegos.
    </para>
   </listitem>
   <listitem>
    <para>
     Compruebe que el hardware de red, como las tarjetas de red, los cables o los conmutadores, funciona correctamente.
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>red independiente</title>
   <para>
    Para garantizar una comunicación de red rápida y segura entre los nodos del clúster, configure una red independiente que usarán exclusivamente los nodos de OSD y monitor del clúster.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="trouble-jobcache">
  <title>El directorio <filename>/var</filename> se queda sin espacio</title>

  <para>
   Por defecto, el master de Salt guarda el resultado de todas las tareas de los minions en su <emphasis>caché de tareas</emphasis>. Ese caché se utilizará más adelante para buscar resultados de las tareas anteriores. El directorio de caché es por defecto <filename>/var/cache/salt/master/jobs/</filename>.
  </para>

  <para>
   Todos los resultados de tareas de todos los minions se guardan en un único archivo. Con el tiempo, ese directorio puede crecer desmesuradamente, según el número de tareas publicadas y el valor de la opción <option>keep_jobs</option> del archivo <filename>/etc/valor salt/master</filename>. <option>keep_jobs</option> define el número de horas (24 por defecto) que se debe conservar la información acerca de las tareas de minions pasadas.
  </para>

<screen>keep_jobs: 24</screen>

  <important>
   <title>no defina el valor <option>keep_jobs: 0</option></title>
   <para>
    Si define <option>keep_jobs</option> en "0", el limpiador de caché de tareas no se ejecutará <emphasis>nunca</emphasis>; lo que probablemente dé como resultado que la partición se llene.
   </para>
  </important>

  <para>
   Si desea inhabilitar el caché de tareas, defina en <option>job_cache</option> el valor "False":
  </para>

<screen>job_cache: False</screen>

  <tip>
   <title>restauración de una partición llena por el caché de tareas</title>
   <para>
    Cuando la partición con el caché de tareas se llena porque se ha definido incorrectamente el valor <option>keep_jobs</option>, siga estos pasos para liberar espacio de disco y mejorar la configuración del caché de tareas:
   </para>
   <procedure>
    <step>
     <para>
      Detenga el servicio de master de Salt:
     </para>
<screen><prompt>root@master # </prompt>systemctl stop salt-master</screen>
    </step>
    <step>
     <para>
      Cambie la configuración del master de Salt relacionada con el caché de tareas mediante <filename>/etc/salt/master</filename>:
     </para>
<screen>job_cache: False
keep_jobs: 1</screen>
    </step>
    <step>
     <para>
      Borre el caché de tareas del master de Salt:
     </para>
<screen><prompt>root # </prompt>rm -rfv /var/cache/salt/master/jobs/*</screen>
    </step>
    <step>
     <para>
      Inicie el servicio de master de Salt:
     </para>
<screen><prompt>root@master # </prompt>systemctl start salt-master</screen>
    </step>
   </procedure>
  </tip>
 </sect1>
</chapter>
