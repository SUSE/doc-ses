<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="containerized-kubernetes.xml" version="5.0" xml:id="cha-container-kubernetes">

 <title>Cluster Kubernetes SUSE Enterprise Storage 6 sopra SUSE CaaS Platform 4</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>modifica</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>sì</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <warning>
  <title>tecnologia in anteprima</title>
  <para>
   L'esecuzione del cluster Ceph in container su SUSE CaaS Platform è un'anteprima. Non effettuare la distribuzione su un cluster Kubernetes di produzione.
  </para>
 </warning>
 <para>
  Questo capitolo descrive come distribuire i cluster Kubernetes SUSE Enterprise Storage 6 sopra SUSE CaaS Platform 4 in container.
 </para>
 <sect1 xml:id="kube-consider">
  <title>Considerazioni</title>

  <para>
   Prima di avviare la distribuzione, leggere le considerazioni seguenti:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Per eseguire Ceph in Kubernetes, SUSE Enterprise Storage 6 utilizza un progetto upstream denominato Rook (<link xlink:href="https://rook.io/"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     A seconda della configurazione, Rook può consumare <emphasis>tutti</emphasis> i dischi inutilizzati su tutti i nodi in un cluster Kubernetes.
    </para>
   </listitem>
   <listitem>
    <para>
     La configurazione richiede container con privilegi.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="kube-prereq">
  <title>Prerequisiti</title>

  <para>
   Prima di avviare la distribuzione, occorre disporre di:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Un cluster SUSE CaaS Platform 4 in esecuzione.
    </para>
   </listitem>
   <listitem>
    <para>
     Nodi di lavoro SUSE CaaS Platform 4 con alcuni dischi aggiuntivi collegati come storage per il cluster Ceph.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="kube-rook-manifests">
  <title>Ottenimento dei manifesti di Rook</title>

  <para>
   L'unità di coordinamento di Rook utilizza i file di configurazione nel formato YAML, denominati <emphasis>manifesti</emphasis>. I manifesti necessari sono inclusi nel pacchetto RPM
   <package>rook-k8s-yaml</package>. Installarlo eseguendo
  </para>

<screen><prompt>root # </prompt>zypper install rook-k8s-yaml</screen>
 </sect1>
 <sect1 xml:id="kube-install">
  <title>Installazione</title>

  <para>
   Rook-Ceph include due componenti principali: l'"operatore", eseguito da Kubernetes e che consente la creazione dei cluster Ceph, e lo stesso "cluster" Ceph, creato e parzialmente gestito dall'operatore.
  </para>

  <sect2 xml:id="kube-configure">
   <title>Configurazione</title>
   <sect3 xml:id="kube-configure-global">
    <title>Configurazione globale</title>
    <para>
     I manifesti utilizzati in questa configurazione installano tutti i componenti di Rook e Ceph nello spazio dei nomi "rook-ceph". Se è necessario apportare modifiche, utilizzare di conseguenza tutti i riferimenti allo spazio dei nomi nei manifesti Kubernetes.
    </para>
    <para>
     A seconda delle funzioni di Rook che si intende utilizzare, modificare la configurazione "Pod Security Policy" in <filename>common.yaml</filename> per limitare i requisiti di sicurezza di Rook. Seguire i commenti nel file manifesto.
    </para>
   </sect3>
   <sect3 xml:id="kube-config-operator">
    <title>Configurazione dell'operatore</title>
    <para>
     Il manifesto <filename>operator.yaml</filename> consente di configurare l'operatore Rook. Questo valore non deve essere generalmente modificato. Seguire i commenti nel file manifesto per ulteriori informazioni.
    </para>
   </sect3>
   <sect3 xml:id="kube-config-ceph">
    <title>Configurazione del cluster Ceph</title>
    <para>
     Il manifesto <filename>cluster.yaml</filename> è responsabile della configurazione del cluster Ceph effettivo che verrà eseguito in Kubernetes. Nella documentazione upstream di Rook all'indirizzo <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-cluster-crd.html"/> è possibile trovare la descrizione dettagliata di tutte le opzioni disponibili.
    </para>
    <para>
     Per default, Rook è configurato sull'utilizzo di tutti i nodi non corrotti con <option>node-role.kubernetes.io/master:NoSchedule</option> e seguirà le impostazioni di posizionamento configurate (consultare la pagina all'indirizzo <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-cluster-crd.html#placement-configuration-settings"/>). Nell'esempio seguente, tale comportamento viene disabilitato e vengono utilizzati soltanto i nodi elencati esplicitamente nella sezione corrispondente:
    </para>
<screen>
storage:
  useAllNodes: false
  nodes:
    - name: caasp4-worker-0
    - name: caasp4-worker-1
    - name: caasp4-worker-2
</screen>
    <note>
     <para>
      Per default, Rook utilizza come storage Ceph tutti i dischi vuoti e liberi presenti in ogni nodo.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="kube-config-docs">
    <title>Documentazione</title>
    <itemizedlist>
     <listitem>
      <para>
       La documentazione upstream di Rook-Ceph all'indirizzo <link xlink:href="https://rook.github.io/docs/rook/master/ceph-storage.html"/> contiene altri dettagli sulla configurazione di distribuzioni più avanzate. Utilizzarla come riferimento per conoscere le nozioni di base su Rook-Ceph prima di applicare configurazioni più avanzate.
      </para>
     </listitem>
     <listitem>
      <para>
       All'indirizzo <link xlink:href="https://www.suse.com/documentation/suse-caasp"/> sono disponibili ulteriori dettagli su SUSE CaaS Platform.
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
  </sect2>

  <sect2 xml:id="kube-config-rook-operator">
   <title>Creazione dell'operatore Rook</title>
   <para>
    Installare i componenti comuni di Rook-Ceph, i ruoli CSI e l'operatore Rook-Ceph eseguendo il comando seguente sul nodo master di SUSE CaaS Platform:
   </para>
<screen><prompt>root # </prompt>kubectl apply -f common.yaml -f operator.yaml</screen>
   <para>
    <filename>common.yaml</filename> creerà lo spazio dei nomi "rook-ceph", le Custom Resource Definitions (CRD) di Ceph (consultare la pagina all'indirizzo <link xlink:href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"/>) per segnalare a Kubernetes gli oggetti Ceph (ad esempio, "CephCluster") e i ruoli RBAC e le policy di sicurezza dei pod (consultare la pagina all'indirizzo <link xlink:href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/"/>) necessarie per consentire a Rook di gestire le risorse specifiche del cluster.
   </para>
   <tip>
    <title>utilizzo di <option>hostNetwork</option> e <option>hostPorts</option></title>
    <para>
     È obbligatorio consentire l'utilizzo di <option>hostNetwork</option> se si utilizza <option>hostNetwork: true</option> nella Cluster Resource Definition. È obbligatorio consentire anche l'utilizzo di <option>hostPorts</option> in <literal>PodSecurityPolicy</literal>.
    </para>
   </tip>
   <para>
    Verificare l'installazione eseguendo <command>kubectl get pods -n rook-ceph</command> sul nodo master di SUSE CaaS Platform, ad esempio:
   </para>
<screen><prompt>root # </prompt>kubectl get pods -n rook-ceph
NAME                                     READY   STATUS      RESTARTS   AGE
rook-ceph-agent-57c9j                    1/1     Running     0          22h
rook-ceph-agent-b9j4x                    1/1     Running     0          22h
rook-ceph-operator-cf6fb96-lhbj7         1/1     Running     0          22h
rook-discover-mb8gv                      1/1     Running     0          22h
rook-discover-tztz4                      1/1     Running     0          22h</screen>
  </sect2>

  <sect2 xml:id="kube-create-ceph-cluster">
   <title>Creazione del cluster Ceph</title>
   <para>
    Dopo aver modificato <filename>cluster.yaml</filename> in base alle esigenze, è possibile creare il cluster Ceph. Eseguire il comando seguente sul nodo master di SUSE CaaS Platform:
   </para>
<screen><prompt>root # </prompt>kubectl apply -f cluster.yaml</screen>
   <para>
    Esaminare lo spazio dei nodi "rook-ceph" per osservare la creazione del cluster Ceph. Verranno visualizzati tanti Ceph Monitor quanti ne sono stati configurati nel manifesto <filename>cluster.yaml</filename> (il valore di default è 3), un Ceph Manager e tanti Ceph OSD quanti sono i dischi liberi.
   </para>
   <tip>
    <title>pod OSD temporanei</title>
    <para>
     Durante il bootstrap del cluster Ceph, alcuni pod denominati <literal>rook-ceph-osd-prepare-<replaceable>NODE-NAME</replaceable></literal> saranno in esecuzione per alcuni istanti per poi terminare con lo stato "Completed". Come indicato dal nome, tali pod effettuano il provisioning dei Ceph OSD. Poiché non vengono eliminati, sarà possibile esaminarne i log in seguito all'interruzione. Ad esempio:
    </para>
<screen><prompt>root # </prompt>kubectl get pods --namespace rook-ceph
NAME                                         READY  STATUS     RESTARTS  AGE
rook-ceph-agent-57c9j                        1/1    Running    0         22h
rook-ceph-agent-b9j4x                        1/1    Running    0         22h
rook-ceph-mgr-a-6d48564b84-k7dft             1/1    Running    0         22h
rook-ceph-mon-a-cc44b479-5qvdb               1/1    Running    0         22h
rook-ceph-mon-b-6c6565ff48-gm9wz             1/1    Running    0         22h
rook-ceph-operator-cf6fb96-lhbj7             1/1    Running    0         22h
rook-ceph-osd-0-57bf997cbd-4wspg             1/1    Running    0         22h
rook-ceph-osd-1-54cf468bf8-z8jhp             1/1    Running    0         22h
rook-ceph-osd-prepare-caasp4-worker-0-f2tmw  0/2    Completed  0         9m35s
rook-ceph-osd-prepare-caasp4-worker-1-qsfhz  0/2    Completed  0         9m33s
rook-ceph-tools-76c7d559b6-64rkw             1/1    Running    0         22h
rook-discover-mb8gv                          1/1    Running    0         22h
rook-discover-tztz4                          1/1    Running    0         22h</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="kube-using-rook">
  <title>Utilizzo di Rook come storage per i workload di Kubernetes</title>

  <para>
   Rook consente di utilizzare tre tipi diversi di storage:
  </para>

  <variablelist>
   <varlistentry>
    <term><emphasis role="bold">Storage oggetto</emphasis></term>
    <listitem>
     <para>
      Lo storage oggetto espone un'API S3 sul cluster di memorizzazione per consentire alle applicazioni di inserire e ottenere dati. Per la descrizione dettagliata, consultare la pagina all'indirizzo <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-object.html"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>File system condiviso</term>
    <listitem>
     <para>
      Un file system condiviso può essere montato con l'autorizzazione di lettura/scrittura da più pod. È utile per le applicazioni gestite in cluster tramite un file system condiviso. Per la descrizione dettagliata, consultare la pagina all'indirizzo <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-filesystem.html"/>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Storage di blocco</term>
    <listitem>
     <para>
      Lo storage di blocco consente di montare lo storage su un singolo pod. Per la descrizione dettagliata, consultare la pagina all'indirizzo <link xlink:href="https://rook.io/docs/rook/v1.0/ceph-block.html"/>.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="kube-uninstall">
  <title>Disinstallazione di Rook</title>

  <para>
   Per disinstallare Rook, seguire la procedura indicata di seguito:
  </para>

  <procedure>
   <step>
    <para>
     Eliminare le applicazioni Kubernetes che utilizzano lo storage di Rook.
    </para>
   </step>
   <step>
    <para>
     Eliminare tutti gli elementi di oggetto, file e/o storage di blocco creati seguendo <xref linkend="kube-using-rook"/>.
    </para>
   </step>
   <step>
    <para>
     Eliminare il cluster, l'operatore e le risorse correlate a Ceph:
    </para>
<screen>
<prompt>root # </prompt>kubectl delete -f cluster.yaml
<prompt>root # </prompt>kubectl delete -f operator.yaml
<prompt>root # </prompt>kubectl delete -f common.yaml
</screen>
   </step>
   <step>
    <para>
     Eliminare i dati sugli host:
    </para>
<screen><prompt>root # </prompt>rm -rf /var/lib/rook</screen>
   </step>
   <step>
    <para>
     Se necessario, cancellare i dischi utilizzati da Rook. Per ulteriori dettagli, consultare la pagina all'indirizzo <link xlink:href="https://rook.io/docs/rook/master/ceph-teardown.html"/>.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
