<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage-troubleshooting">
 <title>Soluzione dei problemi</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sì</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  In questo capitolo sono descritti i vari problemi che è possibile riscontrare durante il funzionamento di un cluster Ceph.
 </para>
 <sect1 xml:id="storage-bp-report-bug">
  <title>Segnalazione di problemi correlati al software</title>

  <para>
   Se si riscontrano problemi durante l'esecuzione di SUSE Enterprise Storage 6 correlati ad alcuni dei suoi componenti, come Ceph o Object Gateway, segnalarli al supporto tecnico SUSE. L'utility consigliata per questa operazione è <command>supportconfig</command>.
  </para>

  <tip>
   <para>
    Poiché <command>supportconfig</command> è un software modulare, assicurarsi che sia installato il pacchetto <systemitem>supportutils-plugin-ses</systemitem>.
   </para>
<screen><prompt>tux &gt; </prompt>rpm -q supportutils-plugin-ses</screen>
   <para>
    Qualora mancasse sul server Ceph, installarlo con
   </para>
<screen><prompt>root # </prompt>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   Sebbene sia possibile utilizzare <command>supportconfig</command> sulla riga di comando, si consiglia di utilizzare il modulo YaST correlato. Ulteriori informazioni su <command>supportconfig</command> sono disponibili in <link xlink:href="https://www.suse.com/documentation/sles-15/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/> (in lingua inglese).
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-cluster-mntc-rados-striping">
  <title>L'invio di oggetti di grandi dimensioni con <command>rados</command> ha esito negativo con un OSD pieno</title>

  <para>
   <command>rados</command> è un'utility da riga di comando che consente di gestire la memorizzazione di oggetti RADOS. Per ulteriori informazioni, vedere <command>man 8 rados</command>.
  </para>

  <para>
   Se si invia un oggetto di grandi dimensioni a un cluster Ceph con l'utility <command>rados</command>, come
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>rados -p mypool put myobject /file/to/send</screen>

  <para>
   è possibile che si riempia lo spazio OSD correlato compromettendo seriamente le prestazioni del cluster.
  </para>
 </sect1>
 <sect1 xml:id="ceph-xfs-corruption">
  <title>File system XFS corrotto</title>

  <para>
   In rare circostanze come bug del kernel o hardware danneggiato/mal configurato, il file system sottostante (XFS) in cui un OSD memorizza i rispettivi dati potrebbe essere danneggiato o impossibile da montare.
  </para>

  <para>
   Se si è certi del buon funzionamento dell'hardware e il sistema è configurato correttamente, segnalare un bug a fronte del sottosistema XFS del kernel di SUSE Linux Enterprise Server e contrassegnare l'OSD in questione come inattivo:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd down <replaceable>OSD_ID</replaceable></screen>

  <warning>
   <title>non formattare, né modificare il dispositivo danneggiato</title>
   <para>
    Sebbene l'utilizzo di <command>xfs_repair</command> per correggere il problema nel file system possa sembrare una soluzione ragionevole, evitare di farlo in quanto con questo comando il file system viene modificato. È possibile avviare l'OSD ma il suo funzionamento potrebbe essere influenzato.
   </para>
  </warning>

  <para>
   Adesso, cancellare il disco sottostante e ricreare l'OSD eseguendo:
  </para>

<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm zap --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
<prompt>cephadm@osd &gt; </prompt>ceph-volume lvm prepare --bluestore --data /dev/<replaceable>OSD_DISK_DEVICE</replaceable>
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-recover-toomanypgs">
  <title>Messaggio di stato "Too Many PGs per OSD" (Troppi gruppi di posizionamento per OSD)</title>

  <para>
   Se si riceve il messaggio <literal>Too Many PGs per OSD (Troppi gruppi di posizionamento per OSD)</literal> dopo aver eseguito <command>ceph status</command>, significa che il valore di <option>mon_pg_warn_max_per_osd</option> (300 per default) è stato superato. Tale valore viene paragonato al rapporto del numero di gruppi di posizionamento per OSD. Vale a dire che la configurazione del cluster non è ottimale.
  </para>

  <para>
   Una volta creato il pool, è impossibile ridurre il numero dei gruppi di posizionamento. È possibile eliminare tranquillamente i pool che ancora non contengono dati e ricrearli con un numero inferiore di gruppi di posizionamento. Laddove i pool contengono già dati, l'unica soluzione consiste nell'aggiungere OSD al cluster in modo che il rapporto dei gruppi di posizionamento per OSD scenda.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-stuckinactive">
  <title>Messaggio di stato "<emphasis>nn</emphasis> pg stuck inactive" (nn gruppi di posizionamento bloccati inattivi)</title>

  <para>
   Se si riceve il messaggio di stato <literal>stuck inactive (bloccato inattivo)</literal> dopo aver eseguito <command>ceph status</command>, significa che Ceph non sa dove replicare i dati memorizzati per soddisfare le regole di replica. Questo problema può verificarsi subito dopo l'installazione iniziale di Ceph e viene corretto automaticamente. In altri casi, potrebbe essere necessaria un'iterazione manuale, come la riattivazione di un OSD interrotto o l'aggiunta di un nuovo OSD al cluster. In casi molto rari, potrebbe essere utile ridurre il livello di replica.
  </para>

  <para>
   Se i gruppi di posizionamento sono bloccati per sempre, è necessario verificare l'output di <command>ceph osd tree</command>. L'output deve presentare una struttura ad albero, simile all'esempio nella <xref linkend="storage-bp-recover-osddown"/>.
  </para>

  <para>
   Se l'output di <command>ceph osd tree</command> è non gerarchico come nell'esempio seguente
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   Verificare che la mappa CRUSH correlata presenti una struttura ad albero. Se anch'essa è non gerarchica, o è priva di host come nell'esempio riportato sopra, può significare che la risoluzione del nome host non funzioni correttamente nel cluster.
  </para>

  <para>
   Se la gerarchia è errata, ad esempio la radice contiene host ma gli OSD sono nel livello superiore e non sono assegnati automaticamente agli host, sarà necessario spostare gli OSD alla posizione corretta nella gerarchia. È possibile effettuare tale operazione utilizzando i comandi <command>ceph osd crush move</command> e/o <command>ceph osd crush set</command>. Per informazioni più dettagliate, vedere <xref linkend="op-crush"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osdweight">
  <title>Il peso dell'OSD è 0</title>

  <para>
   All'avvio dell'OSD, a questo viene assegnato un peso. Più elevato è il peso, maggiori sono le possibilità che il cluster scriva dati nell'OSD. Il peso viene specificato in una mappa CRUSH del cluster o viene calcolato dallo script di avvio degli OSD.
  </para>

  <para>
   In alcuni casi, il valore calcolato per il peso degli OSD può essere arrotondato a zero. Vale a dire che l'OSD non è pianificato per la memorizzazione dei dati e in esso non viene scritto alcun dato. Solitamente il motivo è dovuto alle dimensioni troppo piccole del disco (meno di 15 GB) che deve essere sostituito con uno più grande.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osddown">
  <title>OSD inattivo</title>

  <para>
   Il daemon dell'OSD è in esecuzione o interrotto/inattivo. Se un OSD è inattivo, i motivi generali possono essere tre:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Errore del disco rigido.
    </para>
   </listitem>
   <listitem>
    <para>
     Crash dell'OSD.
    </para>
   </listitem>
   <listitem>
    <para>
     Crash del server.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   È possibile visualizzare lo stato dettagliato degli OSD eseguendo
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   Nell'elenco dell'esempio <literal>osd.2</literal> risulta inattivo. Quindi si può verificare se il disco in cui risiede l'OSD è montato:
  </para>

<screen><prompt>root # </prompt>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   È possibile controllare il motivo per cui l'OSD è inattivo esaminando il rispettivo file di log <filename>/var/log/ceph/ceph-osd.2.log</filename>. Una volta rilevato e corretto il motivo per cui l'OSD non è in esecuzione, avviarlo con
  </para>

<screen><prompt>root # </prompt>systemctl start ceph-osd@2.service</screen>

  <para>
   Non dimenticare di sostituire <literal>2</literal> con il numero effettivo dell'OSD che è stato interrotto.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-slowosd">
  <title>Rilevamento di OSD lenti</title>

  <para>
   Quando si ottimizzano le prestazioni del cluster, è molto importante identificare lo spazio di memorizzazione/gli OSD lenti all'interno del cluster. Il motivo di tale rallentamento è che se i dati vengono scritti nel disco (più) lento, l'operazione di scrittura completa rallenta poiché attende sempre che venga completata su tutti i dischi correlati.
  </para>

  <para>
   Può essere utile individuare il collo di bottiglia nello spazio di memorizzazione. È necessario esaminare ogni singolo OSD per trovare quelli che rallentano il processo di scrittura. Per effettuare un benchmark su un singolo OSD, eseguire:
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> osd.<replaceable>OSD_ID_NUMBER</replaceable> bench</screen>

  <para>
   Ad esempio:
  </para>

<screen><prompt>cephadm@adm &gt; </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   Quindi, è necessario eseguire questo comando su ciascun OSD e confrontare il valore <literal>bytes_per_sec</literal> per ottenere gli OSD (più) lenti.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-clockskew">
  <title>Correzione degli avvisi di sfasamento di orario</title>

  <para>
   Le informazioni relative all'orario devono essere sincronizzate su tutti i nodi del cluster. Se l'orario di un nodo non è completamente sincronizzato, è possibile ricevere avvisi sullo sfasamento di orario quando si verifica lo stato del cluster.
  </para>

  <para>
   La sincronizzazione dell'orario viene gestita con NTP (vedere <link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>). Impostare ciascun nodo per sincronizzarne l'orario con uno o più server NTP, preferibilmente sullo stesso gruppo di server NTP. Se lo sfasamento di orario persiste su un nodo, seguire la procedura indicata di seguito per correggerlo:
  </para>

<screen><prompt>root # </prompt>systemctl stop chronyd.service
<prompt>root # </prompt>systemctl stop ceph-mon.target
<prompt>root # </prompt>systemctl start chronyd.service
<prompt>root # </prompt>systemctl start ceph-mon.target</screen>

  <para>
   È quindi possibile verificare la differenza di fuso orario con <command>chronyc sourcestats</command>.
  </para>

  <para>
   Gli orologi dei Ceph monitor devono essere sincronizzati con un margine di 0,05 secondi tra loro. Per ulteriori informazioni consultare <xref linkend="Cluster-Time-Setting"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-net-issues">
  <title>Prestazioni del cluster scarse a causa di problemi di rete</title>

  <para>
   Le prestazioni del cluster possono risultare scadenti a causa di vari motivi. Tra questi i problemi di rete. In tal caso, è possibile notare il raggiungimento del quorum da parte del cluster, nodi OSD e di monitoraggio offline, trasferimenti dei dati prolungati o numerosi tentativi di riconnessione.
  </para>

  <para>
   Per verificare se le prestazioni del cluster vengono danneggiate da problemi di rete, esaminare i file di log Ceph nella directory <filename>/var/log/ceph</filename>.
  </para>

  <para>
   Per correggere problemi di rete sul cluster, focalizzarsi sui seguenti punti:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Diagnostica della rete di base. Provare lo strumento di esecuzione degli strumenti di diagnostica DeepSea <literal>net.ping</literal> per effettuare il ping tra i nodi del cluster per verificare che l'interfaccia individuale sia in grado di raggiungere un'interfaccia specifica e il tempo di risposta medio. Verrà inoltre segnalato qualsiasi tempo di risposta specifico molto più lento di quello medio. Ad esempio:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     Provare a convalidare tutta l'interfaccia con l'abilitazione per frame jumbo:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     Benchmark delle prestazioni di rete. Provare lo strumento di esecuzione delle prestazioni di rete DeepSea <literal>net.iperf</literal> per testare la larghezza di banda della rete del nodo interno. In un determinato nodo del cluster, vengono avviati come server alcuni processi <command>iperf</command> (in base al numero di core CPU). I nodi del cluster rimanenti verranno utilizzati come client per generare traffico di rete. Viene segnalata la larghezza di banda accumulata di tutti i processi <command>iperf</command> per nodo. Ciò deve riflettere la velocità massima raggiungibile della rete effettiva su tutti i nodi del cluster. Ad esempio:
    </para>
<screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     Verificare le impostazioni firewall sui nodi del cluster. Assicurarsi che non blocchino le porte/i protocolli richiesti per il funzionamento di Ceph. Per ulteriori informazioni sulle impostazioni firewall, vedere <xref linkend="storage-bp-net-firewall"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Verificare che l'hardware di rete, come le schede di rete, i cavi o i commutatori, funzioni correttamente.
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>rete separata</title>
   <para>
    Per garantire una comunicazione di rete veloce e sicura tra i nodi del cluster, configurare una rete separata utilizzata esclusivamente dai nodi OSD e di monitoraggio del cluster.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="trouble-jobcache">
  <title>Spazio quasi esaurito di <filename>/var</filename></title>

  <para>
   Per default, il Salt master salva ogni restituzione dei minion per ciascun lavoro nella rispettiva <emphasis>cache dei lavori</emphasis>. È quindi possibile utilizzare la cache in un momento successivo per ricercare i risultati dei lavori precedenti. Il percorso predefinito della directory della cache è <filename>/var/cache/salt/master/jobs/</filename>.
  </para>

  <para>
   Ciascun lavoro restituito da ogni minion viene salvato in un singolo file. Nel tempo questa directory può raggiungere dimensioni molto grandi, a seconda del numero di lavori pubblicati e del valore dell'opzione <option>keep_jobs</option> nel file <filename>/etc/salt/master</filename>. L'opzione <option>keep_jobs</option> consente di definire il numero di ore (24 per default) per le quali conservare le informazioni sui lavori dei minion precedenti.
  </para>

<screen>keep_jobs: 24</screen>

  <important>
   <title>non impostare <option>keep_jobs: 0</option></title>
   <para>
    Se si imposta <option>keep_jobs</option> su "0", la pulizia della cache dei lavori non verrà eseguita <emphasis>mai</emphasis>, con il possibile risultato di una partizione piena.
   </para>
  </important>

  <para>
   Se si desidera disabilitare la cache dei lavori, impostare <option>job_cache</option> su "False":
  </para>

<screen>job_cache: False</screen>

  <tip>
   <title>ripristino della partizione piena a causa della cache dei lavori</title>
   <para>
    Quando la partizione con i file di cache dei lavori si riempie a causa dell'impostazione <option>keep_jobs</option> errata, seguire la procedura indicata di seguito per liberare spazio su disco e migliorare le impostazioni della cache dei lavori:
   </para>
   <procedure>
    <step>
     <para>
      Interrompere il servizio Salt master:
     </para>
<screen><prompt>root@master # </prompt>systemctl stop salt-master</screen>
    </step>
    <step>
     <para>
      Modificare la configurazione di Salt correlata alla cache dei lavori modificando <filename>/etc/salt/master</filename>:
     </para>
<screen>job_cache: False
keep_jobs: 1</screen>
    </step>
    <step>
     <para>
      Svuotare la cache dei lavori Salt master:
     </para>
<screen><prompt>root # </prompt>rm -rfv /var/cache/salt/master/jobs/*</screen>
    </step>
    <step>
     <para>
      Avviare il servizio Salt master:
     </para>
<screen><prompt>root@master # </prompt>systemctl start salt-master</screen>
    </step>
   </procedure>
  </tip>
 </sect1>
</chapter>
