<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_admin_ha.xml" version="5.0" xml:id="cha-admin-ha">
 <title>Configurazione nodo admin HA</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:translation>sì</dm:translation>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Il <emphasis>nodo admin </emphasis> è un nodo del cluster Ceph dove è in esecuzione il servizio Salt master. Il nodo admin è un punto centrale del cluster Ceph perché gestisce i nodi residui del cluster tramite interrogazione e istruendo i relativi servizi Salt minion. Comprende in genere anche altri servizi, ad esempio l'interfaccia utente Web di Ceph Dashboard con il dashboard <emphasis>Grafana</emphasis> supportato dal kit di strumenti di monitoraggio <emphasis>Prometheus</emphasis>.
 </para>
 <para>
  In caso di errore del nodo admin, occorre di solito fornire un nuovo hardware funzionante per il nodo e ripristinare lo stack di configurazione cluster completo da un backup recente. Tale metodo richiede tempo e determina l'indisponibilità del cluster.
 </para>
 <para>
  Per evitare il tempo di fermo delle prestazioni del cluster Ceph provocati dall'errore del nodo admin, si consiglia di utilizzare il cluster ad elevata disponibilità (High Availability, HA) per il nodo admin Ceph.
 </para>
 <sect1 xml:id="admin-ha-architecture">
  <title>Profilo del cluster HA per il nodo admin </title>

  <para>
   Il concetto di un cluster HA prevede che in caso di errore di un nodo del cluster, l'altro nodo subentri automaticamente nel ruolo, compreso il nodo admin virtualizzato. In questo modo, gli altri nodi del cluster Ceph non avvertono l'errore del nodo admin Ceph.
  </para>

  <para>
   La soluzione HA minima per il nodo admin richiede il seguente hardware:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Due server bare metal in grado di eseguire SUSE Linux Enterprise con l'estensione High Availability e virtualizzare il nodo admin.
    </para>
   </listitem>
   <listitem>
    <para>
     Due o più percorsi di comunicazione di rete ridondanti, ad esempio tramite Network Device Bonding.
    </para>
   </listitem>
   <listitem>
    <para>
     Storage condiviso per ospitare le immagini dei dischi della macchina virtuale del nodo admin. Lo storage condiviso deve essere accessibile da entrambi i server. Può essere ad esempio un'esportazione NFS, una condivisione Samba o una destinazione iSCSI.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Ulteriori dettagli sui requisiti del cluster sono disponibili all'indirizzo <link xlink:href="https://www.suse.com/documentation/sle-ha-15/book_sleha_quickstarts/data/sec_ha_inst_quick_req.html"/>.
  </para>

  <figure>
   <title>Cluster HA a 2 nodi per il nodo admin </title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_admin_ha1.png" width="60%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_admin_ha1.png" width="60%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>
 </sect1>
 <sect1 xml:id="admin-ha-cluster">
  <title>Costruzione del cluster HA con il nodo admin</title>

  <para>
   La procedura seguente riepiloga i passaggi più importanti di costruzione del cluster HA per virtualizzare il nodo admin. Per i dettagli, consultare i collegamenti indicati.
  </para>

  <procedure>
   <step>
    <para>
     Configurare un cluster HA di base a 2 nodi con storage condiviso come descritto in <link xlink:href="https://www.suse.com/documentation/sle-ha-15/book_sleha_quickstarts/data/art_sleha_install_quick.html"/>.
    </para>
   </step>
   <step>
    <para>
     Su entrambi i nodi cluster, installare tutti i pacchetti richiesti per eseguire l'ipervisore KVM e il toolkit <systemitem class="library">libvirt</systemitem> come descritto in <link xlink:href="https://www.suse.com/documentation/sles-15/book_virt/data/sec_vt_installation_kvm.html"/>.
    </para>
   </step>
   <step>
    <para>
     Sul primo nodo del cluster, creare una nuova macchina virtuale (VM) KVM utilizzando <systemitem class="library">libvirt</systemitem> come descritto in <link xlink:href="https://www.suse.com/documentation/sles-15/book_virt/data/sec_libvirt_inst_vmm.html"/>. Utilizzare lo storage condiviso preconfigurato per memorizzare le immagini del disco della VM.
    </para>
   </step>
   <step>
    <para>
     Al termine della configurazione della VM, esportarne la configurazione su un file XML sullo storage condiviso. Usare la seguente sintassi:
    </para>
<screen>
<prompt>root # </prompt>virsh dumpxml <replaceable>VM_NAME</replaceable> &gt; /path/to/shared/vm_name.xml
</screen>
   </step>
   <step>
    <para>
     Creare una risorsa per la VM del nodo admin. Per informazioni generali sulla creazione di risorse HA, consultare <link xlink:href="https://www.suse.com/documentation/sle-ha-15/book_sleha_guide/data/cha_conf_hawk2.html"/>. All'indirizzo <link xlink:href="http://www.linux-ha.org/wiki/VirtualDomain_%28resource_agent%29"/> sono disponibili informazioni dettagliate sulla creazione di risorse per una macchina virtuale KVM.
    </para>
   </step>
   <step>
    <para>
     Sul guest VM appena creato, distribuire il nodo admin compresi i servizi aggiuntivi necessari. Seguire la procedura pertinente indicata nella <xref linkend="ceph-install-stack"/>. Contemporaneamente, distribuire i restanti nodi del cluster Ceph sui server del cluster non HA.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
