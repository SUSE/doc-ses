<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_saltcluster.xml" version="5.0" xml:id="storage.salt.cluster">
 <title>Amministrazione di Salt Cluster</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>sì</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  Dopo aver distribuito il cluster Ceph, occasionalmente potrà essere necessario apportare alcune modifiche. Tra queste sono incluse l'aggiunta o la rimozione di nuovi nodi, dischi o servizi. In questo capitolo è descritto come compiere tali task amministrativi.
 </para>
 <sect1 xml:id="salt.adding.nodes">
  <title>Aggiunta di nuovi nodi cluster</title>

  <para>
   La procedura per aggiungere nuovi nodi al cluster è pressoché identica alla distribuzione dei nodi cluster iniziale descritta in <xref linkend="ceph.install.saltstack"/>:
  </para>

  <procedure>
   <step>
    <para>
     Installare SUSE Linux Enterprise Server 12 SP3 sul nuovo nodo, configurarne le impostazioni di rete in modo che il nome host del Salt master venga risolto correttamente e installare il pacchetto <systemitem>salt-minion</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper in salt-minion</screen>
    <para>
     Se il nome host del Salt master è diverso da <literal>salt</literal>, modificare <filename>/etc/salt/minion</filename> e aggiungere quanto segue:
    </para>
<screen>master: <replaceable>DNS_name_of_your_salt_master</replaceable></screen>
    <para>
     Se sono state apportate modifiche ai file di configurazione di cui sopra, riavviare il servizio <systemitem>salt.minion</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl restart salt-minion.service</screen>
   </step>
   <step>
    <para>
     Accettare tutte le chiavi salt sul Salt master:
    </para>
<screen><prompt>root@master # </prompt>salt-key --accept-all</screen>
   </step>
   <step>
    <para>
     Verificare che anche la destinazione di <filename>/srv/pillar/ceph/deepsea_minions.sls</filename> sia il nuovo Salt minion. Per ulteriori dettagli, fare riferimento a <xref linkend="ds.minion.targeting.name"/> di <xref linkend="ds.depl.stages"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire la fase di preparazione. Moduli e grain (piccoli elementi di dati) vengono sincronizzati in modo che il nuovo minion possa fornire tutte le informazioni che DeepSea si aspetta:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
   </step>
   <step>
    <para>
     Eseguire la fase di rilevazione. Verranno scritte nuove voci di file nella directory <filename>/srv/pillar/ceph/proposals</filename> in cui è possibile modificare i file .yml pertinenti:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     Se lo si desidera, modificare <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> se l'host appena aggiunto non corrisponde allo schema di denominazione esistente. Per ulteriori informazioni, fare riferimento a <xref linkend="policy.configuration"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire la fase di configurazione. Viene letto tutto ciò che risiede in <filename>/srv/pillar/ceph</filename> e Pillar viene aggiornato di conseguenza:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
    <para>
     Pillar memorizza i dati cui è possibile accedere con il seguente comando:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>target</replaceable> pillar.items</screen>
   </step>
   <step>
    <para>
     Le fasi di configurazione e distribuzione includono i nodi aggiunti di recente:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt.adding.services">
  <title>Aggiunta di nuovi ruoli ai nodi</title>

  <para>
   È possibile distribuire tutti i tipi di ruoli supportati con DeepSea. Vedere <xref linkend="policy.role.assignment"/> per ulteriori informazioni sui tipi di ruoli supportati ed esempi della rispettiva corrispondenza.
  </para>

  <tip>
   <title>ruoli e fasi obbligatori e opzionali</title>
   <para>
    In genere si consiglia di eseguire tutte le fasi di distribuzione comprese tra 0 e 5 quando si aggiunte aggiunge un nuovo ruolo a un nodo cluster. Per risparmiare tempo, è possibile ignorare le fasi 3 o 4, a seconda del tipo di ruolo che si intende distribuire. Mentre i ruoli OSD e MON includono servizi di base e sono richiesti da Ceph, altri ruoli, come Object Gateway, sono opzionali. Le fasi di distribuzione DeepSea sono gerarchiche: mentre nella fase 3 vengono distribuiti servizi di base, nella fase 4 vengono distribuiti quelli opzionali.
   </para>
   <para>
    Pertanto, è necessario eseguire la fase 3 quando si distribuiscono ruoli di base, come MON su un nodo OSD esistente, ed è possibile ignorare la fase 4.
   </para>
   <para>
    In modo analogo, è possibile ignorare la fase 3 quando si distribuiscono servizi opzionali come Object Gateway, ma in tal caso è necessario eseguire la fase 4.
   </para>
  </tip>

  <para>
   Per aggiungere un nuovo servizio a un nodo esistente, seguire la procedura indicata di seguito:
  </para>

  <procedure>
   <step>
    <para>
     Adattare <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> in modo che corrisponda all'host esistente con il nuovo ruolo. Per ulteriori informazioni, fare riferimento a <xref linkend="policy.configuration"/>. Ad esempio, se è necessario eseguire un Object Gateway su un nodo MON, la riga è simile a:
    </para>
<screen>role-rgw/xx/x/example.mon-1.sls</screen>
   </step>
   <step>
    <para>
     Eseguire la fase 2 per aggiornare Pillar:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Eseguire la fase 3 per distribuire i servizi di base o la fase 4 per eseguire quelli opzionali. È anche possibile eseguire entrambe le fasi.
    </para>
   </step>
  </procedure>

  <tip>
   <para>
    Tenere presente che quando si aggiunge un OSD al cluster esistente, successivamente questo ne eseguirà il ribilanciamento per un periodo di tempo. Per ridurre al minimo i periodi di ribilanciamento, si consiglia di aggiungere contemporaneamente tutti gli OSD previsti.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="salt.node.removing">
  <title>Rimozione e reinstallazione dei nodi del cluster</title>

  <para>
   Per rimuovere un ruolo da un cluster, modificare <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> e rimuovere le righe di corrispondenti. Eseguire quindi le fasi 2 e 5 come descritto in <xref linkend="ceph.install.stack"/>.
  </para>

  <note>
   <title>rimozione degli ODS dal cluster</title>
   <para>
    Qualora fosse necessario rimuovere un determinato nodo OSD dal cluster, assicurarsi che questo disponga di uno spazio libero su disco maggiore rispetto al disco che si intende rimuovere. Tenere presente che la rimozione di un OSD comporta il ribilanciamento dell'intero cluster.
   </para>
  </note>

  <para>
   Quando si rimuove un ruolo da un minion, l'obiettivo è annullare tutte le modifiche correlate a tale ruolo. Per la maggior parte dei ruoli, il task è semplice, ma potrebbero verificarsi problemi con le dipendenze del pacchetto. Se un pacchetto è disinstallato, le dipendenze non lo sono.
  </para>

  <para>
   Gli OSD rimossi figurano come unità vuote. I task correlati sovrascrivono la parte iniziale dei file system e rimuovono le partizioni di backup oltre a cancellare le tabelle delle partizioni.
  </para>

  <note>
   <title>conservazione delle partizioni create mediante altri metodi</title>
   <para>
    È possibile che le unità disco configurate precedentemente mediante altri metodi, come <command>ceph-deploy</command>, contengano comunque partizioni che non verranno distrutte automaticamente da DeepSea. L'amministratore deve recuperare tali unità.
   </para>
  </note>

  <example xml:id="ex.ds.rmnode">
   <title>Rimozione di un Salt minion dal cluster</title>
   <para>
    Se si assegna un nome ai minion di memorizzazione, ad esempio, "data1.ceph", "data2.ceph" ... "data6.ceph" e le righe correlate nel file <filename>policy.cfg</filename> sono simili a quanto segue:
   </para>
<screen>[...]
# Hardware Profile
profile-default/cluster/data*.sls
profile-default/stack/default/ceph/minions/data*.yml
[...]</screen>
   <para>
    Per rimuovere il Salt minion "data2.ceph", modificare le righe come indicato di seguito:
   </para>
<screen>
[...]
# Hardware Profile
profile-default/cluster/data[1,3-6]*.sls
profile-default/stack/default/ceph/minions/data[1,3-6]*.yml
[...]</screen>
   <para>
    Quindi, eseguire le fasi 2 e 5:
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5</screen>
  </example>

  <example xml:id="ex.ds.mignode">
   <title>Migrazione dei nodi</title>
   <para>
    Presupporre la seguente situazione: durante la nuova installazione del cluster, l'amministratore ha allocato uno dei nodi di memorizzazione come Object Gateway autonomo durante l'attesa dell'arrivo dell'hardware del gateway. Adesso l'hardware permanente è disponibile per il gateway e finalmente è possibile assegnare il ruolo desiderato al nodo di memorizzazione di backup e rimuovere il ruolo gateway.
   </para>
   <para>
    Dopo aver eseguito le fasi 0 e 1 (vedere <xref linkend="ds.depl.stages"/>) per il nuovo hardware, il nuovo gateway viene denominato <literal>rgw1</literal>. Se per il nodo <literal>data8</literal> è necessario che venga rimosso il ruolo Object Gateway, che venga aggiunto il ruolo di memorizzazione e <filename>policy.cfg</filename> presenta il seguente aspetto:
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-7]*.sls
profile-default/stack/default/ceph/minions/data[1-7]*.sls

# Roles
role-rgw/cluster/data8*.sls</screen>
   <para>
    Modificarlo in:
   </para>
<screen># Hardware Profile
profile-default/cluster/data[1-8]*.sls
profile-default/stack/default/ceph/minions/data[1-8]*.sls

# Roles
role-rgw/cluster/rgw1*.sls</screen>
   <para>
    Eseguire le fasi da 2 a 5. Nella fase 3 verrà aggiunto <literal>data8</literal> come nodo di memorizzazione. Per un breve periodo, <literal>data8</literal> avrà entrambi i ruoli. Nella fase 4 verrà aggiunto il ruolo Object Gateway a <literal>rgw1</literal> e nella fase 5 verrà rimosso il ruolo Object Gateway da <literal>data8</literal>.
   </para>
  </example>
 </sect1>
 <sect1 xml:id="ds.mon">
  <title>Ridistribuzione dei nodi di monitoraggio</title>

  <para>
   Quando uno o più nodi di monitoraggio vengono meno e non rispondono, è necessario rimuoverli dal cluster e possibilmente aggiungerli nuovamente.
  </para>

  <important>
   <title>il numero minimo di nodi di monitoraggio è tre</title>
   <para>
    Il numero di nodi di monitoraggio non deve essere inferiore a tre. Se un nodo di monitoraggio viene meno e di conseguenza nel cluster ne rimangono solo uno o due, è necessario assegnare temporaneamente il ruolo di monitoraggio agli altri nodi cluster prima di ridistribuire i nodi di monitoraggio con errore. Dopo la distribuzione dei nodi di monitoraggio con errore, è possibile disinstallare temporaneamente ruoli di monitoraggio.
   </para>
   <para>
    Per ulteriori informazioni sull'aggiunta di nuovi nodi/ruoli al cluster Ceph, vedere <xref linkend="salt.adding.nodes"/> e <xref linkend="salt.adding.services"/>.
   </para>
   <para>
    Per ulteriori informazioni sulla rimozione dei nodi cluster, fare riferimento a <xref linkend="salt.node.removing"/>.
   </para>
  </important>

  <para>
   Un nodo Ceph ha due gradi di errore di base:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     L'host Salt minion è interrotto fisicamente o a livello di sistema operativo e non risponde alla chiamata <command>salt '<replaceable>minion_name</replaceable>' test.ping</command>. In tal caso è necessario ridistribuire completamente il server seguendo le istruzioni pertinenti incluse in <xref linkend="ceph.install.stack"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     I servizi correlati al monitoraggio vengono meno e il recupero è impossibile, ma l'host risponde alla chiamata <command>salt '<replaceable>minion_name</replaceable>' test.ping</command>. In tal caso, seguire la procedura indicata di seguito:
    </para>
   </listitem>
  </itemizedlist>

  <procedure>
   <step>
    <para>
     Modificare <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> sul Salt master e rimuovere o aggiornare le righe che corrispondono ai nodi di monitoraggio con errore in modo che questi puntino ai nodi di monitoraggio in funzione.
    </para>
   </step>
   <step>
    <para>
     Eseguire le fasi da 2 a 5 di DeepSea per applicare le modifiche:
    </para>
<screen>
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.4
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.5
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt.node.add-disk">
  <title>Aggiunta di un OSD a un nodo</title>

  <para>
   Per aggiungere un disco a un nodo OSD esistente, verificare che sul disco siano state rimosse e cancellate tutte le partizioni. Per ulteriori dettagli, fare riferimento a <xref linkend="deploy.wiping.disk"/> in <xref linkend="ceph.install.stack"/>. Una volta che il disco è vuoto, aggiungerlo al file YAML del nodo. Il percorso del file è <filename>/srv/pillar/ceph/proposals/profile-default/stack/default/ceph/minions/<replaceable>node_name</replaceable>.yml</filename>. Dopo aver salvato il file, eseguire le fasi 2 e 3 di DeepSea:
  </para>

<screen><prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>

  <tip>
   <title>profili aggiornati automaticamente</title>
   <para>
    Invece di modificare manualmente il file YAML, DeepSea può creare nuovi profili. Per consentire a DeepSea di creare nuovi profili, è necessario spostare quelli esistenti:
   </para>
<screen><prompt>root@master # </prompt><command>old</command> /srv/pillar/ceph/proposals/profile-default/
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.1
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.2
<prompt>root@master # </prompt><command>deepsea</command> stage run ceph.stage.3</screen>
  </tip>
 </sect1>
 <sect1 xml:id="salt.removing.osd">
  <title>Rimozione di un OSD</title>

  <para>
   È possibile rimuovere un Ceph OSD dal cluster eseguendo il seguente comando:
  </para>

<screen><prompt>root@master # </prompt><command>salt-run</command> disengage.safety
<prompt>root@master # </prompt><command>salt-run</command> remove.osd <replaceable>OSD_ID</replaceable></screen>

  <para>
   <replaceable>OSD_ID</replaceable> deve essere un numero dell'OSD senza il termine <literal>osd</literal>. Ad esempio, da <literal>osd.3</literal> utilizzare solo la cifra <literal>3</literal>.
  </para>

  <tip>
   <title>rimozione di più ODS</title>
   <para>
    Non è possibile in alcun modo rimuovere più OSD contemporaneamente con il comando <command>salt-run remove.osd</command>. Per automatizzare la rimozione di più OSD, è possibile utilizzare il ciclo seguente (5, 21, 33, 19 sono numeri ID degli OSD da rimuovere):
   </para>
<screen>
for i in 5 21 33 19
do
 echo $i
 salt-run disengage.safety
 salt-run remove.osd $i
done
</screen>
  </tip>

  <sect2 xml:id="osd.forced.removal">
   <title>Rimozione forzata degli OSD interrotti</title>
   <para>
    In alcuni casi la rimozione di un OSD si conclude con un errore non grave (vedere <xref linkend="salt.removing.osd"/>). Ciò può verificarsi se, ad esempio, l'OSD o la rispettiva cache vengono interrotti, a causa di operazioni I/O in sospeso, o quando è impossibile smontare il disco OSD. In tal caso, è necessario forzare la rimozione dell'OSD:
   </para>
<screen><prompt>root@master # </prompt><replaceable>target</replaceable> osd.remove <replaceable>OSD_ID</replaceable> force=True</screen>
   <para>
    Con questo comando si rimuovono le partizioni dei dati e le partizioni del journal o WAL/DB.
   </para>
   <para>
    Per identificare possibili dispositivi journal/WAL/DB orfani, seguire la procedura indicata di seguito:
   </para>
   <procedure>
    <step>
     <para>
      Selezionare il dispositivo che potrebbe contenere partizioni orfane e salvare l'elenco delle partizioni in un file:
     </para>
<screen>
<prompt>root@minion &gt; </prompt>ls /dev/sdd?* &gt; /tmp/partitions
</screen>
    </step>
    <step>
     <para>
      Eseguire <command>readlink</command> a fronte di tutti i dispositivi block.wal, block.db e journal, quindi confrontare l'output con l'elenco delle partizioni salvato precedentemente:
     </para>
<screen>
<prompt>root@minion &gt; </prompt>readlink -f /var/lib/ceph/osd/ceph-*/{block.wal,block.db,journal} \
 | sort | comm -23 /tmp/partitions -
</screen>
     <para>
      L'output è l'elenco delle partizioni che <emphasis>non</emphasis> vengono utilizzate da Ceph.
     </para>
    </step>
    <step>
     <para>
      Rimuovere le partizioni orfane che non appartengono a Ceph con il comando (ad esempio <command>fdisk</command>, <command>parted</command> o <command>sgdisk</command>).
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="ds.osd.recover">
  <title>Recupero di un nodo OSD reinstallato</title>

  <para>
   Se il sistema operativo si interrompe ed è impossibile recuperarlo su uno dei nodi OSD nodes, seguire la procedura indicata di seguito per recuperarlo e ridistribuirne il ruolo OSD con dati del cluster invariati:
  </para>

  <procedure>
   <step>
    <para>
     Reinstallare il sistema operativo sul nodo.
    </para>
   </step>
   <step>
    <para>
     Installare i pacchetti <package>salt-minion</package> sul nodo OSD, eliminare la chiave del Salt minion precedente sul Salt master e registrare la nuova chiave del Salt minion con il Salt master. Per ulteriori informazioni sulla distribuzione del Salt minion, vedere <xref linkend="ceph.install.stack"/>.
    </para>
   </step>
   <step>
    <para>
     Eseguire le seguenti parti invece dell'intera fase 0:
    </para>
<screen>
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.sync
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.packages.common
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.mines
<prompt>root@master # </prompt>salt '<replaceable>osd_node</replaceable>' state.apply ceph.updates
</screen>
   </step>
   <step>
    <para>
     Eseguire le fasi da 1 a 5 di DeepSea:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.5
</screen>
   </step>
   <step>
    <para>
     Eseguire la fase 0 di DeepSea:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
</screen>
   </step>
   <step>
    <para>
     Riavviare il nodo OSD pertinente. Tutti i dischi OSD verranno rilevati e riutilizzati.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="salt.automated.installation">
  <title>Installazione automatizzata tramite Salt</title>

  <para>
   È possibile automatizzare l'installazione mediante l'uso di Salt Reactor. Per gli ambienti virtuali o di hardware coerenti, questa configurazione consentirà di creare un cluster Ceph con il comportamento specificato.
  </para>

  <warning>
   <para>
    Salt non è in grado di effettuare verifiche della dipendenza in base agli eventi del reattore. Vi è il rischio effettivo di sovraccarico del Salt master o che questo non risponda più.
   </para>
  </warning>

  <para>
   Per l'installazione automatizzata è richiesto quanto segue:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Un file <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> creato in modo appropriato.
    </para>
   </listitem>
   <listitem>
    <para>
     La preparazione di configurazione personalizzata posizionata nella directory <filename>/srv/pillar/ceph/stack</filename>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Nella configurazione del reattore di default verranno eseguite solo le fasi 0 e 1. In tal modo è possibile testare il reattore senza dover attendere il completamento delle fasi successive.
  </para>

  <para>
   All'avvio del primo salt-minion avrà inizio la fase 0. Un blocco impedisce più istanze. Quando tutti i minion completano la fase 0, avrà inizio la fase 1.
  </para>

  <para>
   Se l'operazione viene eseguita correttamente, modificare l'ultima riga nel file <filename>/etc/salt/master.d/reactor.conf</filename>:
  </para>

<screen>- /srv/salt/ceph/reactor/discovery.sls</screen>

  <para>
   come segue
  </para>

<screen>- /srv/salt/ceph/reactor/all_stages.sls</screen>
 </sect1>
 <sect1 xml:id="deepsea.rolling_updates">
  <title>Aggiornamento dei nodi cluster</title>

  <para>
   È una buona idea applicare regolarmente aggiornamenti in sequenza ai nodi cluster. Per applicare gli aggiornamenti, eseguire la fase 0:
  </para>

<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>

  <para>
   Se DeepSea rileva un cluster Ceph in esecuzione, vengono applicati gli aggiornamenti e i nodi vengono avviati in sequenza. DeepSea segue il consiglio ufficiale di Ceph secondo il quale è opportuno aggiornare prima i monitoraggi, successivamente gli OSD e infine i servizi aggiuntivi, come MDS, Object Gateway, iSCSI Gateway o NFS Ganesha. DeepSea interrompe il processo di aggiornamento se rileva un problema nel cluster. Un trigger può essere:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Ceph segnala "HEALTH_ERR" per più di 300 secondi.
    </para>
   </listitem>
   <listitem>
    <para>
     Dopo un aggiornamento i Salt minion vengono interrogati per verificare se i servizi loro assegnati sono ancora attivi e in esecuzione. L'aggiornamento ha esito negativo se i servizi sono inattivi per più di 900 secondi.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Queste disposizioni assicurano il funzionamento del cluster Ceph nonostante aggiornamenti corrotti o con errore.
  </para>

  <para>
   La fase 0 di DeepSea aggiorna il sistema tramite <command>zypper update</command> e lo riavvia se il kernel viene aggiornato. Se si desidera eliminare l'eventualità di un riavvio forzato di tutti i potenziali nodi, assicurarsi che sia installato e in esecuzione l'ultimo kernel, prima di iniziare la fase 0 di DeepSea.
  </para>

  <tip>
   <title><command>zypper patch</command></title>
   <para>
    Se si preferisce aggiornare il sistema utilizzando il comando <command>zypper patch</command>, modificare <filename>/srv/pillar/ceph/stack/global.yml</filename> e aggiungere la riga seguente:
   </para>
<screen>update_method_init: zypper-patch</screen>
  </tip>

  <para>
   È possibile modificare il comportamento di avvio di default della fase 0 di DeepSea aggiungendo le righe seguenti a <filename>/srv/pillar/ceph/stack/global.yml</filename>:
  </para>

<screen>stage_prep_master: default-update-no-reboot
stage_prep_minion: default-update-no-reboot</screen>

  <para>
   Con <literal>stage_prep_master</literal> si imposta il comportamento della fase 0 del Salt master e con <literal>stage_prep_minion</literal> quello di tutti i minion. Tutti i parametri disponibili sono:
  </para>

  <variablelist>
   <varlistentry>
    <term>default</term>
    <listitem>
     <para>
      Installa gli aggiornamenti e successivamente esegue il riavvio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-update-no-reboot</term>
    <listitem>
     <para>
      Installa gli aggiornamenti senza il riavvio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-reboot</term>
    <listitem>
     <para>
      Riavvia senza installare gli aggiornamenti.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>default-no-update-no-reboot</term>
    <listitem>
     <para>
      Non installa gli aggiornamenti né il riavvio.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="sec.salt.cluster.reboot">
  <title>Interruzione o riavvio del cluster</title>

  <para>
   In alcuni casi può essere necessario interrompere o riavviare l'intero cluster. Si consiglia di verificare attentamente le dipendenze dei servizi in esecuzione. Nei passaggi successivi è descritto come interrompere e avviare il cluster:
  </para>

  <procedure>
   <step>
    <para>
     Indicare al cluster Ceph di impostare il flag noout:
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd set noout</screen>
   </step>
   <step>
    <para>
     Interrompere daemon e nodi nel seguente ordine:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Client di memorizzazione
      </para>
     </listitem>
     <listitem>
      <para>
       Gateway, ad esempio NFS Ganesha o Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Se necessario, eseguire task di manutenzione.
    </para>
   </step>
   <step>
    <para>
     Avviare nodi e server in ordine inverso rispetto al processo di spegnimento:
    </para>
    <orderedlist>
     <listitem>
      <para>
       Ceph Monitor
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Gateway, ad esempio NFS Ganesha o Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       Client di memorizzazione
      </para>
     </listitem>
    </orderedlist>
   </step>
   <step>
    <para>
     Rimuovere il flag noout:
    </para>
<screen><prompt>root # </prompt><command>ceph</command> osd unset noout</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="ds.custom.cephconf">
  <title>File <filename>ceph.conf</filename> personalizzato</title>

  <para>
   Se è necessario inserire impostazioni personalizzate nel file <filename>ceph.conf</filename>, è possibile farlo modificando i file di configurazione nella directory <filename>/srv/salt/ceph/configuration/files/ceph.conf.d</filename>:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     global.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mon.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mgr.conf
    </para>
   </listitem>
   <listitem>
    <para>
     mds.conf
    </para>
   </listitem>
   <listitem>
    <para>
     osd.conf
    </para>
   </listitem>
   <listitem>
    <para>
     client.conf
    </para>
   </listitem>
   <listitem>
    <para>
     rgw.conf
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title><filename>rgw.conf</filename> univoco</title>
   <para>
    Object Gateway offre molta flessibilità ed è univoco rispetto alle altre sezioni di <filename>ceph.conf</filename>. Tutti gli altri componenti Ceph presentano intestazioni statiche, come <literal>[mon]</literal> o <literal>[osd]</literal>. Object Gateway ha intestazioni univoche, come <literal>[client.rgw.rgw1]</literal>. Vale a dire che per il file <filename>rgw.conf</filename> è necessaria una voce intestazione. Per un esempio, vedere <filename>/srv/salt/ceph/configuration/files/rgw.conf</filename>.
   </para>
  </note>

  <important>
   <title>esecuzione della fase 3</title>
   <para>
    Dopo aver apportato modifiche personalizzate ai file di configurazione di cui sopra, eseguire la fase 3 per applicarle ai nodi cluster:
   </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
  </important>

  <para>
   Questi file vengono inclusi dal file modello <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename> e corrispondono alle diverse sezioni accettate dal file di configurazione Ceph. L'inserimento di un frammento di configurazione nel file corretto consente a DeepSea di posizionarlo nella sezione esatta. Non è necessario aggiungere alcuna intestazione di sezione.
  </para>

  <tip>
   <para>
    Per applicare un'opzione di configurazione a istanze specifiche di un daemon, aggiungere un'intestazione come <literal>[osd.1]</literal>. Le opzioni di configurazione seguenti verranno applicate solo al daemon OSD con ID 1.
   </para>
  </tip>

  <sect2>
   <title>Sostituzione delle impostazioni di default</title>
   <para>
    Le istruzioni più recenti in una sezione sostituiscono quelle precedenti. Pertanto, è possibile sostituire la configurazione di default come specificato nel modello <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>. Ad esempio, per disattivare l'autenticazione cephx, aggiungere le tre righe seguenti al file <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/global.conf</filename>:
   </para>
<screen>auth cluster required = none
auth service required = none
auth client required = none</screen>
  </sect2>

  <sect2>
   <title>Inclusione di file di configurazione</title>
   <para>
    Se è necessario applicare numerose configurazioni personalizzate, utilizzare le istruzioni di inclusione seguenti nei file di configurazione per rendere più semplice la gestione dei file. Di seguito è riportato un esempio di file <filename>osd.conf</filename>:
   </para>
<screen>[osd.1]
{% include "ceph/configuration/files/ceph.conf.d/osd1.conf" ignore missing %}
[osd.2]
{% include "ceph/configuration/files/ceph.conf.d/osd2.conf" ignore missing %}
[osd.3]
{% include "ceph/configuration/files/ceph.conf.d/osd3.conf" ignore missing %}
[osd.4]
{% include "ceph/configuration/files/ceph.conf.d/osd4.conf" ignore missing %}</screen>
   <para>
    Nell'esempio precedente, i file <filename>osd1.conf</filename>, <filename>osd2.conf</filename>, <filename>osd3.conf</filename> e <filename>osd4.conf</filename> contengono le opzioni di configurazione specifiche per l'OSD correlato.
   </para>
   <tip>
    <title>configurazione di runtime</title>
    <para>
     Le modifiche apportate ai file di configurazione Ceph vengono applicate dopo il riavvio dei daemon Ceph correlati. Per ulteriori informazioni sulla modifica della configurazione di runtime Ceph, vedere <xref linkend="ceph.config.runtime"/>.
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph.config.runtime">
  <title>Configurazione Ceph di runtime</title>

  <para>
   Nella <xref linkend="ds.custom.cephconf"/> è illustrato come modificare il file di configurazione Ceph <filename>ceph.conf</filename>. Il comportamento effettivo del cluster non è tuttavia determinato dallo stato attuale del file <filename>ceph.conf</filename>, bensì dalla configurazione dei daemon Ceph in esecuzione, che è memorizzata.
  </para>

  <para>
   È possibile interrogare un daemon Ceph daemon individuale per una determinata impostazione di configurazione utilizzando il <emphasis>socket amministrativo</emphasis> sul nodo in cui è in esecuzione il daemon. Ad esempio, con il seguente comando si ottiene il valore del parametro di configurazione <option>osd_max_write_size</option> dal daemon denominato <literal>osd.0</literal>:
  </para>

<screen><prompt>root # </prompt>ceph --admin-daemon /var/run/ceph/ceph-osd.0.asok \
config get osd_max_write_size
{
  "osd_max_write_size": "90"
}</screen>

  <para>
   È inoltre possibile <emphasis>modificare</emphasis> le impostazioni dei daemon in fase di runtime. Tenere presente che questa modifica è temporanea e al riavvio successivo del daemon andrà persa. Ad esempio, con il seguente comando si modifica il parametro <option>osd_max_write_size</option> a "50" per tutti gli OSD nel cluster:
  </para>

<screen><prompt>root # </prompt>ceph tell osd.* injectargs --osd_max_write_size 50</screen>

  <warning>
   <title><command>injectargs</command> non è affidabile</title>
   <para>
    Sfortunatamente, se si modificano le impostazioni del cluster con il comando <command>injectargs</command>, l'operazione non è affidabile al 100%. Se è necessario avere la certezza che il parametro modificato sia attivo, modificarlo nel file di configurazione e riavviare tutti i daemon nel cluster.
   </para>
  </warning>
 </sect1>
</chapter>
