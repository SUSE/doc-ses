<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Upgrade dalle release precedenti</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:editurl>https://github.com/SUSE/doc-ses/edit/maintenance/ses6/xml/</dm:editurl>
   <dm:maintainer>tbazant@suse.com</dm:maintainer>
   <dm:status>modifica</dm:status>
   <dm:deadline/>
   <dm:priority/>
   <dm:translation>sì</dm:translation>
   <dm:languages/>
   <dm:release>SES 6</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Questo capitolo descrive le procedure per eseguire l'upgrade di SUSE Enterprise Storage 5.5 alla versione 6. Tenere presente che la versione 5.5 è sostanzialmente uguale alla versione 5, ma con tutte le patch più recenti applicate.
 </para>
 <note>
  <title>upgrade dalle release meno recenti non supportato</title>
  <para>
   L'upgrade dalle versioni di SUSE Enterprise Storage precedenti alla 5.5 non è supportato. Prima di seguire le procedure descritte in questo capitolo, è necessario eseguire l'upgrade alla versione più recente di SUSE Enterprise Storage 5.5.
  </para>
 </note>
 <sect1 xml:id="upgrade-consider-points">
  <title>Punti da tenere presente prima dell'upgrade</title>

  <itemizedlist>
   <listitem>
    <para>
     Per altre informazioni sulle modifiche apportate rispetto alla release precedente di SUSE Enterprise Storage, <emphasis>leggere le note di rilascio</emphasis>. Controllare le note di rilascio per vedere se:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       l'hardware necessita di considerazioni speciali;
      </para>
     </listitem>
     <listitem>
      <para>
       i pacchetti software utilizzati hanno subito modifiche significative;
      </para>
     </listitem>
     <listitem>
      <para>
       è necessario adottare precauzioni speciali per l'installazione.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Le note di rilascio forniscono inoltre informazioni che non si è fatto in tempo a riportare nel manuale. Contengono anche alcune note su problemi noti.
    </para>
    <para>
     Dopo aver installato il pacchetto <package>release-notes-ses</package>, individuare localmente le note di rilascio nella directory <filename>/usr/share/doc/release-notes</filename> o online all'indirizzo <link xlink:href="https://www.suse.com/releasenotes/"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se in precedenza è stato eseguito l'upgrade dalla versione 4, verificare che l'upgrade alla versione 5 sia stato completato correttamente:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Verificare la presenza del file
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.import</screen>
      <para>
       Viene creato dal processo di importazione durante l'upgrade dalla SES 4 a SES 5. Inoltre, nel file deve essere impostata l'opzione <option>configuration_init: default-import</option>
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <para>
       Se l'opzione <option>configuration_init</option> è ancora impostata su <option>default-import</option>, come file di configurazione il cluster utilizza <filename>ceph.conf.import</filename> e non la configurazione <filename>ceph.conf</filename> di default di DeepSea, compilata dai file in
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Pertanto, è necessario analizzare <filename>ceph.conf.import</filename> per rilevare eventuali configurazioni personalizzate e possibilmente spostare la configurazione in uno dei file in
      </para>
<screen>/srv/salt/ceph/configuration/files/ceph.conf.d/</screen>
      <para>
       Quindi, rimuovere la riga <option>configuration_init: default-import</option> da
      </para>
<screen>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</screen>
      <warning>
       <title>configurazione DeepSea di default</title>
       <para>
        Se <emphasis role="bold">non</emphasis> si unisce la configurazione da <filename>ceph.conf.import</filename> e si rimuove l'opzione <option>configuration_init: default-import</option>, le impostazioni di configurazione di default integrate in DeepSea (memorizzate in <filename>/srv/salt/ceph/configuration/files/ceph.conf.j2</filename>) non verranno applicate al cluster.
       </para>
      </warning>
     </listitem>
     <listitem>
      <para>
       Controllare se il cluster utilizza il nuovo tipo di compartimento "straw2":
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep straw
</screen>
     </listitem>
     <listitem>
      <para>
       Verificare che venga utilizzato il profilo "jewel":
      </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph osd crush dump | grep profile
</screen>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     Se sono in uso client del kernel RBD meno recenti (precedenti a SUSE Linux Enterprise Server 12 SP3), consultare questo riferimento: <xref linkend="rbd-old-clients-map"/>. Se possibile, si consiglia di eseguire l'upgrade dei client del kernel RBD meno recenti.
    </para>
   </listitem>
   <listitem>
    <para>
     Se openATTIC si trova sul nodo admin, non sarà disponibile in seguito all'upgrade del nodo. La nuova versione del Ceph Dashboard non sarà disponibile finché non ne viene eseguita la distribuzione tramite DeepSea.
    </para>
   </listitem>
   <listitem>
    <para>
     L'upgrade del cluster può richiedere diverso tempo, circa lo stesso necessario per eseguire l'upgrade di un computer moltiplicato per il numero di nodi del cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     Se è in esecuzione la release di SUSE Linux Enterprise Server precedente, non sarà possibile sottoporre un singolo nodo ad upgrade, ma occorrerà riavviarlo nell'utilità di installazione della nuova versione. Di conseguenza, i servizi forniti da tale nodo non saranno disponibili per qualche tempo. I Cluster Services di base saranno comunque disponibili: ad esempio, se un MON è inattivo durante l'upgrade, vi saranno almeno due MON attivi. Purtroppo, i servizi a istanza singola, come un singolo iSCSI Gateway, non saranno disponibili.
    </para>
   </listitem>
   <listitem>
    <para>
     Alcuni tipi di daemon dipendono da altri. Ad esempio, i Ceph Object Gateway dipendono dai daemon Ceph MON e OSD. Si consiglia di eseguire l'upgrade in questo ordine:
    </para>
    <orderedlist spacing="normal">
     <listitem>
      <para>
       Nodo admin
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor/Ceph Manager
      </para>
     </listitem>
     <listitem>
      <para>
       Metadata Server
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph OSD
      </para>
     </listitem>
     <listitem>
      <para>
       Object Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       iSCSI Gateway
      </para>
     </listitem>
     <listitem>
      <para>
       NFS Ganesha
      </para>
     </listitem>
     <listitem>
      <para>
       Gateway Samba
      </para>
     </listitem>
    </orderedlist>
   </listitem>
   <listitem>
    <para>
     Se è stato utilizzato AppArmor nella modalità "complain" o "enforce", sarà necessario impostare una variabile salt pillar prima di eseguire l'upgrade. Poiché per default SUSE Linux Enterprise Server 15 SP1 viene fornito con AppArmor, la gestione di tale software è stata integrata nella fase 0 di DeepSea. Per default, SUSE Enterprise Storage 6 rimuove AppArmor e i profili correlati. Se si desidera mantenere il comportamento configurato in SUSE Enterprise Storage 5.5, verificare che una delle righe seguenti sia presente nel file <filename>/srv/pillar/ceph/stack/global.yml</filename> prima di avviare l'upgrade:
    </para>
<screen>
apparmor_init: default-enforce
</screen>
    <para>
     oppure
    </para>
<screen>
apparmor_init: default-complain
</screen>
   </listitem>
   <listitem>
    <para>
     A partire da SUSE Enterprise Storage 6, i nomi MDS che iniziano con una cifra non sono più consentiti e i daemon MDS non si avvieranno. È possibile verificare se i daemon sono denominati in questo modo eseguendo il comando <command>ceph fs status</command> oppure riavviando un MDS e controllando la presenza del messaggio seguente nei relativi log:
    </para>
<screen>
deprecation warning: MDS id 'mds.1mon1' is invalid and will be forbidden in
a future version.  MDS names may not start with a numeric digit.
</screen>
    <para>
     Se viene visualizzato il messaggio riportato sopra, sarà necessario eseguire la migrazione dei nomi MDS prima di tentare di eseguire l'upgrade a SUSE Enterprise Storage 6. DeepSea coordina l'automatizzazione di tale migrazione. Nei nomi MDS che iniziano con una cifra verrà anteposto il prefisso "mds.":
    </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.mds.migrate-numerical-names
</screen>
    <tip>
     <title>configurazione personalizzata associata ai nomi MDS</title>
     <para>
      Se sono presenti impostazioni di configurazione associate ai nomi MDS e i nomi dei daemon MDS iniziano con una cifra, verificare che le impostazioni di configurazione si applichino anche ai nuovi nomi (con il prefisso "mds."). Consultare la sezione di esempio seguente nel file <filename>/etc/ceph/ceph.conf</filename>:
     </para>
<screen>
[mds.123-my-mds] # config setting specific to MDS name with a name starting with a digit
mds cache memory limit = 1073741824
mds standby for name = 456-another-mds
</screen>
     <para>
      L'unità di coordinamento <command>ceph.mds.migrate-numerical-names</command> modificherà il nome del daemon MDS "123-my-mds" in "mds.123-my-mds". È necessario modificare la configurazione per riflettere il nuovo nome:
     </para>
<screen>
[mds.mds,123-my-mds] # config setting specific to MDS name with the new name
mds cache memory limit = 1073741824
mds standby for name = mds.456-another-mds
</screen>
    </tip>
    <para>
     Questa operazione consente di aggiungere i daemon MDS con i nuovi nomi prima di rimuovere quelli precedenti. Il numero di daemon MDS raddoppierà per un breve intervallo di tempo. I client potranno accedere a CephFS solo dopo una breve pausa per il failover. Pertanto, conviene pianificare la migrazione in orari in cui sono previsti carichi CephFS minimi o nulli.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-backup">
  <title>Backup dei dati del cluster</title>

  <para>
   Sebbene la creazione di backup dei dati e della configurazione del cluster non sia obbligatoria, si consiglia di eseguire il backup dei dati del cluster e dei file di configurazione importanti. Per ulteriori dettagli, consultare la pagina all'indirizzo <xref linkend="cha-deployment-backup"/>.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-ntp">
  <title>Esecuzione della migrazione da <systemitem class="daemon">ntpd</systemitem> a <systemitem class="daemon">chronyd</systemitem></title>

  <para>
   SUSE Linux Enterprise Server 15 SP1 non utilizza più <systemitem class="daemon">ntpd</systemitem> per la sincronizzazione dell'ora dell'host locale. Adesso, viene utilizzato <systemitem class="daemon">chronyd</systemitem>. La migrazione del daemon di sincronizzazione dell'orario deve essere eseguita in ciascun nodo del cluster. La migrazione a <systemitem>chronyd</systemitem> può avvenire <emphasis role="bold">prima</emphasis> dell'upgrade del cluster; in alternativa è possibile eseguire la migrazione a <systemitem class="daemon">chronyd</systemitem>
   <emphasis role="bold"> dopo</emphasis> l'upgrade del cluster.
  </para>

  <procedure>
   <title>Eseguire la migrazione a <systemitem class="daemon">chronyd</systemitem> <emphasis>prima</emphasis> dell'upgrade del cluster</title>
   <step>
    <para>
     Installare il pacchetto <package>chrony</package> :
    </para>
<screen><prompt>root@minion &gt; </prompt>zypper install chrony</screen>
   </step>
   <step>
    <para>
     Modificare il file di configurazione di <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> e aggiungere le origini NTP della configurazione <systemitem class="daemon">ntpd</systemitem> corrente in <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>ulteriori dettagli sulla configurazione di <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Consultare la pagina all'indirizzo <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> per ulteriori dettagli su come includere le origini dell'orario nella configurazione di <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Disabilitare e interrompere il servizio <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Avviare e abilitare il servizio di <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Verificare lo stato di chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
  </procedure>

  <procedure>
   <title>Eseguire la migrazione a <systemitem class="daemon">chronyd</systemitem> <emphasis> dopo</emphasis> l'upgrade del cluster</title>
   <step>
    <para>
     Durante l'upgrade del cluster, aggiungere i seguenti archivi software:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Pool
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Legacy15-SP1-Updates
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Eseguire l'upgrade del cluster alla versione 6.
    </para>
   </step>
   <step>
    <para>
     Modificare il file di configurazione di <systemitem class="daemon">chronyd</systemitem> <filename>/etc/chrony.conf</filename> e aggiungere le origini NTP della configurazione <systemitem class="daemon">ntpd</systemitem> corrente in <filename>/etc/ntp.conf</filename>.
    </para>
    <tip>
     <title>ulteriori dettagli sulla configurazione di <systemitem class="daemon">chronyd</systemitem></title>
     <para>
      Consultare la pagina all'indirizzo <link xlink:href="https://documentation.suse.com/sles/15-SP1/html/SLES-all/cha-ntp.html"/> per ulteriori dettagli su come includere le origini dell'orario nella configurazione di <systemitem class="daemon">chronyd</systemitem>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Disabilitare e interrompere il servizio <systemitem class="daemon">ntpd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl disable ntpd.service &amp;&amp; systemctl stop ntpd.service</screen>
   </step>
   <step>
    <para>
     Avviare e abilitare il servizio di <systemitem class="daemon">chronyd</systemitem>:
    </para>
<screen><prompt>root@minion &gt; </prompt>systemctl start chronyd.service &amp;&amp; systemctl enable chronyd.service</screen>
   </step>
   <step>
    <para>
     Eseguire la migrazione da <systemitem class="daemon">ntpd</systemitem> a <systemitem class="daemon">chronyd</systemitem>.
    </para>
   </step>
   <step>
    <para>
     Verificare lo stato di chrony:
    </para>
<screen><prompt>root@minion &gt; </prompt>chronyc tracking</screen>
   </step>
   <step>
    <para>
     Rimuovere gli archivi software esistenti aggiunti per mantenere <systemitem class="daemon">ntpd</systemitem> nel sistema durante la procedura di upgrade.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-prepare">
  <title>Applicazione di patch al cluster prima dell'upgrade</title>

  <para>
   Applicare le patch più recenti a tutti i nodi del cluster prima di eseguire l'upgrade.
  </para>

  <sect2 xml:id="upgrade-prepare-repos">
   <title>Archivi software obbligatori</title>
   <para>
    Verificare che gli archivi obbligatori siano configurati in ciascun nodo del cluster. Per visualizzare un elenco di tutti gli archivi disponibili, eseguire
   </para>
<screen>
<prompt>root@minion &gt; </prompt>zypper lr
</screen>
   <para>
    SUSE Enterprise Storage 5.5 richiede:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLES12-SP3-Installer-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLES12-SP3-Updates
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SUSE-Enterprise-Storage-5-Updates
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Il gateway NFS/SMB su SLE-HA in SUSE Linux Enterprise Server 12 SP3 richiede:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      SLE-HA12-SP3-Pool
     </para>
    </listitem>
    <listitem>
     <para>
      SLE-HA12-SP3-Updates
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-staging">
   <title>Sistemi di gestione provvisoria dell'archivio</title>
   <para>
    Se si utilizza uno dei sistemi di gestione provvisoria dell'archivio (SMT, RMT o SUSE Manager), creare un nuovo livello di patch bloccato per la versione corrente e per quella nuova di SUSE Enterprise Storage.
   </para>
   <para>
    Per ulteriori informazioni, vedere:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html"/>,
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/book_rmt.html"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      <link xlink:href="https://www.suse.com/documentation/suse-manager-3/index.html"/>,
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-prepare-patch">
   <title>Applicazione delle patch più recenti a tutto il cluster</title>
   <procedure>
    <step>
     <para>
      Applicare le patch più recenti di SUSE Enterprise Storage 5.5 e SUSE Linux Enterprise Server 12 SP3 a ciascun nodo del cluster Ceph. Verificare che a ogni nodo del cluster siano connessi gli archivi software corretti (vedere la <xref linkend="upgrade-prepare-repos"/>) ed eseguire la fase 0 di DeepSea:
     </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0</screen>
    </step>
    <step>
     <para>
      Al completamento della fase 0, verificare che nello stato di ogni nodo del cluster sia incluso il testo "HEALTH_OK". Se non lo è, risolvere il problema prima dei possibili riavvii previsti nelle fasi successive.
     </para>
    </step>
    <step>
     <para>
      Eseguire <command>zypper ps</command> per verificare la presenza di processi in esecuzione con librerie o binari meno recenti e riavviarli.
     </para>
    </step>
    <step>
     <para>
      Verificare che il kernel in esecuzione sia il più recente disponibile e riavviarlo in caso contrario. Controllare gli output dei comandi seguenti:
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>uname -a
<prompt>cephadm@adm &gt; </prompt>rpm -qa kernel-default
</screen>
    </step>
    <step>
     <para>
      Verificare che la versione del pacchetto <package>ceph</package> sia 12.2.12 o precedente. Verificare che la versione del pacchetto <package>deepsea</package> sia 0.8.9 o precedente.
     </para>
    </step>
    <step>
     <para>
      Se in precedenza è stata utilizzata una delle impostazioni <option>bluestore_cache</option>, tenere presente che queste non sono più effettive a partire dalla versione 12.2.10 di <package>ceph.</package>
      La nuova impostazione <option>bluestore_cache_autotune</option>, configurata su "true" per default, disabilita il dimensionamento manuale della cache. Per attivare il comportamento precedente, è necessario impostare <option>bluestore_cache_autotune=false</option>. Per ulteriori dettagli, vedere <xref linkend="config-auto-cache-sizing"/>.
     </para>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-verify-current">
  <title>Verifica dell'ambiente corrente</title>

  <itemizedlist>
   <listitem>
    <para>
     Correggere gli eventuali problemi evidenti del sistema prima di avviare l'upgrade. Il processo di upgrade non corregge mai i problemi di sistema esistenti.
    </para>
   </listitem>
   <listitem>
    <para>
     Verificare le prestazioni del cluster. È possibile utilizzare comandi come <command>rados bench</command>, <command>ceph tell osd.* bench</command> oppure <command>iperf3</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Verificare l'accesso ai gateway (come iSCSI Gateway oppure Object Gateway) e al dispositivo di blocco RADOS.
    </para>
   </listitem>
   <listitem>
    <para>
     Documentare le parti specifiche della configurazione di sistema, come i dettagli della configurazione di rete, del partizionamento o dell'installazione.
    </para>
   </listitem>
   <listitem>
    <para>
     Utilizzare <command>supportconfig</command> per raccogliere le informazioni di sistema importanti e salvarle al di fuori dei nodi del cluster. Per ulteriori informazioni, vedere <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_admsupport_supportconfig.html"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Assicurarsi che in ciascun nodo del cluster sia disponibile sufficiente spazio libero su disco. Verificare lo spazio libero su disco con <command>df-h</command>. Se necessario, liberare dello spazio sul disco rimuovendo le directory/i file non necessari o le snapshot del sistema operativo obsolete. Se lo spazio libero sul disco non è sufficiente, non proseguire con l'upgrade finché non si sarà liberato spazio sufficiente.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="upgrade-verify-state">
  <title>Verifica dello stato del cluster</title>

  <itemizedlist>
   <listitem>
    <para>
     Verificare il comando <command>cluster health</command> prima di avviare la procedura di upgrade. Non avviare l'upgrade a meno che ogni su ogni nodo del cluster non sia riportato il testo "HEALTH_OK".
    </para>
   </listitem>
   <listitem>
    <para>
     Verificare che tutti i servizi siano in esecuzione:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Salt master e daemon Salt master.
      </para>
     </listitem>
     <listitem>
      <para>
       Ceph Monitor e Ceph Manager Daemon.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemon del server di metadati.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemon Ceph OSD.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemon Object Gateway.
      </para>
     </listitem>
     <listitem>
      <para>
       Daemon iSCSI Gateway.
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
  </itemizedlist>

  <para>
   I comandi seguenti forniscono i dettagli dello stato del cluster e della configurazione specifica:
  </para>

  <variablelist>
   <varlistentry>
    <term><command>ceph -s</command></term>
    <listitem>
     <para>
      Stampa un breve riepilogo sullo stato del cluster Ceph, sui servizi in esecuzione, sull'utilizzo dei dati e sulle statistiche I/O. Verificare che sia presente il testo "HEALTH_OK" prima di avviare l'upgrade.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph health detail</command></term>
    <listitem>
     <para>
      Stampa i dettagli se lo stato del cluster Ceph non è valido.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph versions</command></term>
    <listitem>
     <para>
      Stampa le versioni dei daemon Ceph in esecuzione.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph df</command></term>
    <listitem>
     <para>
      Stampa lo spazio totale e libero su disco del cluster. Non avviare l'upgrade se lo spazio libero su disco del cluster è inferiore al 25% dello spazio su disco totale.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>salt '*' cephprocesses.check results=true</command></term>
    <listitem>
     <para>
      Stampa i processi Ceph in esecuzione e i relativi PID ordinati in base ai Salt minion.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term><command>ceph osd dump | grep ^flags</command></term>
    <listitem>
     <para>
      Verificare che siano presenti i flag "recovery_deletes" e "purged_snapdirs". Se non lo sono, è possibile forzare una pulitura su tutti i gruppi di posizionamento eseguendo il comando seguente. Si tenga presente che questa pulitura forzata ha un impatto negativo sulle prestazioni dei client Ceph.
     </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph pg dump pgs_brief | cut -d " " -f 1 | xargs -n1 ceph pg scrub
</screen>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1>
  <title>Upgrade offline dei cluster CTDB</title>

  <para>
   CTDB fornisce un database gestito in cluster utilizzato dai gateway Samba. Il protocollo CTDB è molto semplice e non supporta i cluster dei nodi che comunicano con versioni di protocollo diverse. Pertanto, occorre impostare i nodi CTDB sullo stato offline prima di eseguire l'upgrade.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-one-node">
  <title>Upgrade per nodo - Procedura di base</title>

  <para>
   Per assicurarsi che i Cluster Services di base del cluster siano disponibili durante la procedura, è necessario eseguire l'upgrade dei nodi in modo sequenziale. È possibile eseguire l'upgrade di un nodo in due modi diversi: tramite il <emphasis>DVD del programma di installazione</emphasis> o tramite il <emphasis>sistema di migrazione della distribuzione</emphasis>.
  </para>

  <para>
   Dopo aver eseguito l'upgrade di tutti i nodi, si consiglia di eseguire <command>rpmconfigcheck</command> per verificare la presenza di eventuali file di configurazione modificati in locale. Se il comando restituisce un elenco di nomi di file con un suffisso <filename>.rpmnew</filename>, <filename>.rpmorig</filename> o <filename>.rpmsave</filename>, confrontare tali file con i file di configurazione correnti per assicurarsi che nessuna modifica locale sia andata persa. Se necessario, aggiornare i file interessati. Per ulteriori informazioni su come utilizzare i file <filename>.rpmnew</filename>, <filename>.rpmorig</filename> e <filename>.rpmsave</filename>, consultare la pagina all'indirizzo <link xlink:href="https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#sec-rpm-packages-manage"/>.
  </para>

  <tip>
   <title>pacchetti orfani</title>
   <para>
    In seguito all'upgrade di un nodo, alcuni pacchetti saranno nello stato orfano ("orphaned") e non disporranno di un archivio superiore. Ciò si verifica perché i pacchetti relativi a python3 non rendono obsoleti i pacchetti python2.
   </para>
   <para>
    All'indirizzo <link xlink:href="https://www.suse.com/documentation/sles-15/book_sle_admin/data/sec_zypper.html#sec_zypper_softup_orphaned"/> sono disponibili ulteriori informazioni sugli elenchi dei pacchetti orfani.
   </para>
  </tip>

  <sect2 xml:id="upgrade-one-node-manual">
   <title>Esecuzione dell'upgrade manuale dei nodi tramite il DVD del programma di installazione</title>
   <procedure>
    <step>
     <para>
      Riavviare il nodo dall'immagine o dal DVD del programma di installazione di SUSE Linux Enterprise Server 15 SP1.
     </para>
    </step>
    <step>
     <para>
      Selezionare <guimenu>Upgrade</guimenu> (Esegui l'upgrade) dal menu di avvio.
     </para>
    </step>
    <step>
     <para>
      Nella schermata <guimenu/> (Seleziona destinazione di migrazione), verificare che "SUSE Linux Enterprise Server 15 SP1" sia selezionato e attivare la casella di controllo <guimenu>Manually Adjust the Repositories for Migration</guimenu> (Modifica manualmente gli archivi per la migrazione).
     </para>
     <figure>
      <title>Selezione della destinazione della migrazione</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="migration-target.png" width="75%"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Selezionare i moduli seguenti da installare:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SUSE Enterprise Storage 6 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Basesystem Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Desktop Applications Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Legacy Module 15 SP1 x86_64
       </para>
      </listitem>
      <listitem>
       <para>
        Server Applications Module 15 SP1 x86_64
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Nella schermata <guimenu>Previously Used Repositories</guimenu> (Archivi utilizzati in precedenza), verificare che siano stati selezionati gli archivi corretti. Se il sistema non è registrato su SCC/SMT, è necessario aggiungere gli archivi manualmente.
     </para>
     <para>
      SUSE Enterprise Storage 6 richiede:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Basesystem15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Basesystem15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Module-Server-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Desktop-Applications15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SLE-Product-SLES15-SP1-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SLE15-SP1-Installer-Updates
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Pool
       </para>
      </listitem>
      <listitem>
       <para>
         SUSE-Enterprise-Storage-6-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Se si intende eseguire la migrazione di <systemitem>ntpd</systemitem> a <systemitem class="daemon">chronyd</systemitem> dopo la migrazione di SES (fare riferimento alla <xref linkend="upgrade-ntp"/>), includere gli archivi seguenti:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Module-Legacy15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Il gateway NFS/SMB su SLE-HA su SUSE Linux Enterprise Server 15 SP1 richiede:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Pool
       </para>
      </listitem>
      <listitem>
       <para>
        SLE-Product-HA15-SP1-Updates
       </para>
      </listitem>
     </itemizedlist>
    </step>
    <step>
     <para>
      Rivedere le <guimenu>impostazioni di installazione</guimenu> e avviare la procedura di installazione facendo clic su <guimenu>Aggiorna</guimenu>.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-one-node-auto">
   <title>Esecuzione dell'upgrade del nodo tramite il Distribution Migration System di SUSE</title>
   <para>
    Il <emphasis>Distribution Migration System</emphasis> (DMS) fornisce un percorso di upgrade per un sistema SUSE Linux Enterprise installato da una versione principale a un'altra. Nella procedura seguente viene utilizzato DMS per eseguire l'upgrade di SUSE Enterprise Storage 5.5 alla versione 6, inclusa la migrazione sottostante da SUSE Linux Enterprise Server 12 SP3 a SUSE Linux Enterprise Server 15 SP1.
   </para>
   <para>
    Consultare la pagina all'indirizzo <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/> per informazioni generali e dettagliate su DMS.
   </para>
   <procedure>
    <step>
     <para>
      Installare i pacchetti di migrazione RPM che consentono di impostare il boot loader GRUB sull'attivazione automatica dell'upgrade al riavvio successivo. Installare i pacchetti
      <package>SLES15-SES-Migration</package> e
      <package>suse-migration-sle15-activation</package> :
     </para>
<screen><prompt>root@minion &gt; </prompt>zypper install SLES15-SES-Migration suse-migration-sle15-activation</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        Se il nodo in fase di upgrade <emphasis role="bold">è</emphasis> registrato su un sistema di gestione provvisoria dell'archivio come SCC, SMT, RMT o SUSE Manager, creare il file <filename>/etc/sle-migration-service.yml</filename> con il contenuto seguente:
       </para>
<screen>
use_zypper_migration: true
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
      </step>
      <step>
       <para>
        Se il nodo in fase di upgrade <emphasis role="bold">non</emphasis> è registrato su un sistema di gestione provvisoria dell'archivio come SCC, SMT, RMT o SUSE Manager, apportare le modifiche seguenti:
       </para>
       <substeps>
        <step>
         <para>
          Creare il file <filename>/etc/sle-migration-service.yml</filename> con il contenuto seguente:
         </para>
<screen>
use_zypper_migration: false
preserve:
  rules:
    - /etc/udev/rules.d/70-persistent-net.rules
</screen>
        </step>
        <step>
         <para>
          Disabilitare o rimuovere gli archivi SLE 12 SP3 e SES 5 e aggiungere gli archivi SLE 15 SP1 e SES6. Nella <xref linkend="upgrade-prepare-repos"/> è riportato l'elenco degli archivi correlati.
         </para>
        </step>
       </substeps>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      Riavviare per eseguire l'upgrade. Mentre l'upgrade è in corso, è possibile eseguire il login al nodo di cui è stato eseguito l'upgrade tramite <command>ssh</command> come utente della migrazione utilizzando la chiave SSH esistente del sistema host, come descritto nella pagina all'indirizzo <link xlink:href="https://documentation.suse.com/suse-distribution-migration-system/1.0/single-html/distribution-migration-system/"/>. Per SUSE Enterprise Storage, se si dispone dell'accesso fisico o dell'accesso diretto alla console sul computer, è possibile inoltre eseguire il login come <systemitem class="username">root</systemitem> alla console di sistema tramite la password <literal>sesupgrade</literal>. In seguito all'upgrade, il nodo verrà riavviato automaticamente.
     </para>
     <tip>
      <title>upgrade non riuscito</title>
      <para>
       Se l'upgrade non riesce, esaminare <filename>/var/log/distro_migration.log</filename>. Risolvere il problema, installare nuovamente i pacchetti RPM di migrazione e riavviare il nodo.
      </para>
     </tip>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-adm">
  <title>Esecuzione dell'upgrade del nodo admin</title>

  <itemizedlist>
   <listitem>
    <para>
     I comandi seguenti continueranno a funzionare, anche se sui Salt minion sono in esecuzione versioni meno recenti di Ceph e Salt: <command>salt '*' test.ping</command> e <command>ceph status</command>
    </para>
   </listitem>
   <listitem>
    <para>
     In seguito all'upgrade del nodo admin, openATTIC non sarà più installato.
    </para>
   </listitem>
   <listitem>
    <para>
     Se sul nodo admin è ospitato SMT, completarne la migrazione a RMT (consultare la pagina all'indirizzo <link xlink:href="https://www.suse.com/documentation/sles-15/book_rmt/data/cha_rmt_migrate.html"/>).
    </para>
   </listitem>
   <listitem>
    <para>
     <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>stato dei nodi del cluster</title>
   <para>
    In seguito all'upgrade del nodo admin, è possibile eseguire il comando <command>salt-run upgrade.status</command> per visualizzare informazioni utili sui nodi del cluster. Questo comando elenca le versioni di Ceph e del sistema operativo di tutti i nodi e suggerisce in che ordine eseguire l'upgrade dei nodi su cui sono ancora in esecuzione le versioni meno recenti.
   </para>
<screen><prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
  ceph: ceph version 14.2.1-468-g994fd9e0cc (994fd9e0ccc50c2f3a55a3b7a3d4e0ba74786d50) nautilus (stable)
  os: SUSE Linux Enterprise Server 15 SP1

Nodes running these software versions:
  admin.ceph (assigned roles: master)
  mon2.ceph (assigned roles: admin, mon, mgr)

Nodes running older software versions must be upgraded in the following order:
   1: mon1.ceph (assigned roles: admin, mon, mgr)
   2: mon3.ceph (assigned roles: admin, mon, mgr)
   3: data1.ceph (assigned roles: storage)
[...]</screen>
  </tip>
 </sect1>
 <sect1 xml:id="upgrade-mons">
  <title>Esecuzione dell'upgrade dei nodi Ceph Monitor/Ceph Manager</title>

  <itemizedlist>
   <listitem>
    <para>
     Se il cluster <emphasis role="bold">non utilizza</emphasis> i ruoli MDS, eseguire l'upgrade dei nodi MON/MGR uno alla volta.
    </para>
   </listitem>
   <listitem>
    <para>
     Se il cluster <emphasis role="bold">utilizza</emphasis> i ruoli MDS e i ruoli MON/MGR e MDS sono co-ubicati, è necessario ridurre il cluster MDS e quindi eseguire l'upgrade dei nodi co-ubicati. Per ulteriori dettagli, fare riferimento alla <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se il cluster <emphasis role="bold">utilizza</emphasis> i ruoli MDS e se questi sono in esecuzione su server <emphasis role="bold">dedicati</emphasis>, eseguire l'upgrade dei nodi MON/MGR uno alla volta, quindi ridurre il cluster MDS ed eseguirne l'upgrade. Per ulteriori dettagli, fare riferimento alla <xref linkend="upgrade-mds"/>.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <title>upgrade di Ceph Monitor</title>
   <para>
    A causa di una limitazione della progettazione di Ceph Monitor, dopo l'upgrade di due MON a Suse Enterprise Storage 6 e la conseguente formazione di un quorum, il terzo MON (ancora su SUSE Enterprise Storage 5.5) non si unirà al cluster MON se quest'ultimo è stato riavviato per qualsiasi motivo, incluso per un riavvio del nodo. Pertanto, in seguito all'upgrade di due MON, è consigliabile eseguire l'upgrade dei MON restanti il prima possibile.
   </para>
  </note>

  <para>
   <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
  </para>
 </sect1>
 <sect1 xml:id="upgrade-mds">
  <title>Esecuzione dell'upgrade dei server di metadati</title>

  <para>
   È necessario ridurre il cluster del server di metadati (MDS) A causa di funzioni incompatibili tra le versioni 5.5 e 6 di SUSE Enterprise Storage, i daemon MDS meno recenti verranno chiusi non appena un MDS singolo del livello SES 6 si unisce al cluster. Di conseguenza, per tutta la durata dei processi di upgrade del nodo MDS, è necessario ridurre il cluster MDS a un MDS singolo attivo (e non di standby). Non appena viene eseguito l'upgrade del secondo nodo, è possibile estendere nuovamente il cluster MDS.
  </para>

  <tip>
   <para>
    Sui cluster MDS con carico elevato, potrebbe essere necessario ridurre tale carico (ad esempio interrompendo i client) per fare in modo che un MDS singolo attivo possa gestire il workload.
   </para>
  </tip>

  <procedure>
   <step>
    <para>
     Notare il valore attuale dell'opzione <option>max_mds</option>:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs get cephfs | grep max_mds
</screen>
   </step>
   <step>
    <para>
     Ridurre il cluster MDS se è presente più di 1 daemon MDS attivo, ad es. <option>max_mds</option> è maggiore di 1. Per ridurre il cluster MDS, eseguire
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds 1
</screen>
    <para>
     dove <replaceable>FS_NAME</replaceable> è il nome dell'istanza CephFS ("cephfs" per default).
    </para>
   </step>
   <step>
    <para>
     Individuare il nodo su cui è ospitato uno dei daemon MDS di standby. Esaminare l'output del comando <command>ceph fs status</command> e avviare l'upgrade del cluster MDS su questo nodo.
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs status
cephfs - 2 clients
======
+------+--------+--------+---------------+-------+-------+
| Rank | State  |  MDS   |    Activity   |  dns  |  inos |
+------+--------+--------+---------------+-------+-------+
|  0   | active | mon1-6 | Reqs:    0 /s |   13  |   16  |
+------+--------+--------+---------------+-------+-------+
+-----------------+----------+-------+-------+
|       Pool      |   type   |  used | avail |
+-----------------+----------+-------+-------+
| cephfs_metadata | metadata | 2688k | 96.8G |
|   cephfs_data   |   data   |    0  | 96.8G |
+-----------------+----------+-------+-------+
+-------------+
| Standby MDS |
+-------------+
|    mon3-6   |
|    mon2-6   |
+-------------+
</screen>
    <para>
     In questo esempio, è necessario avviare la procedura di upgrade sul nodo "mon3-6" o "mon2-6".
    </para>
   </step>
   <step>
    <para>
     Eseguire l'upgrade del nodo con il daemon MDS di standby. In seguito all'avvio dell'upgrade del nodo MDS, i daemon MDS obsoleti verranno chiusi automaticamente. A questo punto, potrebbe verificarsi un breve tempo di fermo del servizio CephFS sui client.
    </para>
    <para>
     <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Eseguire l'upgrade dei nodi MDS rimanenti.
    </para>
   </step>
   <step>
    <para>
     Reimpostare <option>max_mds</option> alla configurazione desiderata:
    </para>
<screen>
<prompt>cephadm@adm &gt; </prompt>ceph fs set <replaceable>FS_NAME</replaceable> max_mds <replaceable>ACTIVE_MDS_COUNT</replaceable>
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-main-osd">
  <title>Esecuzione dell'upgrade dei Ceph OSD</title>

  <para>
   Per ciascun nodo di storage, seguire la procedura indicata di seguito:
  </para>

  <procedure>
   <step>
    <para>
     Identificare i daemon OSD in esecuzione su un determinato nodo:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd tree
</screen>
   </step>
   <step>
    <para>
     Impostare il flag "noout" per ciascun daemon OSD sul nodo in fase di upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd add-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Ad esempio:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd add-noout osd.$i; done</screen>
    <para>
     Verificare con:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     oppure
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
      6 OSDs or CRUSH {nodes, device-classes} have {NOUP,NODOWN,NOIN,NOOUT} flags set</screen>
   </step>
   <step>
    <para>
     Creare i file <filename>/etc/ceph/osd/*.json</filename> per tutti gli OSD esistenti eseguendo il comando seguente sul nodo su cui verrà eseguito l'upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan --force
</screen>
   </step>
   <step>
    <para>
     Eseguire l'upgrade del nodo OSD. <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </step>
   <step>
    <para>
     Attivare tutti gli OSD trovati nel sistema:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>;ceph-volume simple activate --all
</screen>
    <tip>
     <title>attivazione individuale delle partizioni dei dati</title>
     <para>
      Se si desidera attivare le partizioni dei dati individualmente, è necessario trovare il comando <command>ceph-volume</command> corretto per ciascuna partizione. Sostituire <replaceable>X1</replaceable> con la lettera o il numero corretto della partizione:
     </para>
<screen>
 <prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/sd<replaceable>X1</replaceable>
</screen>
     <para>
      Ad esempio:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple scan /dev/vdb1
[...]
--&gt; OSD 8 got scanned and metadata persisted to file:
/etc/ceph/osd/8-d7bd2685-5b92-4074-8161-30d146cd0290.json
--&gt; To take over management of this scanned OSD, and disable ceph-disk
and udev, run:
--&gt;     ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
     <para>
      L'ultima riga dell'output contiene il comando per l'attivazione della partizione:
     </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph-volume simple activate 8 d7bd2685-5b92-4074-8161-30d146cd0290
[...]
--&gt; All ceph-disk systemd units have been disabled to prevent OSDs
getting triggered by UDEV events
[...]
Running command: /bin/systemctl start ceph-osd@8
--&gt; Successfully activated OSD 8 with FSID
d7bd2685-5b92-4074-8161-30d146cd0290
</screen>
    </tip>
   </step>
   <step>
    <para>
     Verificare che il nodo OSD venga avviato correttamente dopo il riavvio.
    </para>
   </step>
   <step>
    <para>
     Indirizzare il messaggio "Legacy BlueStore stats reporting detected on XX OSD(s)":
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
    <para>
     Tale avviso viene visualizzato durante l'upgrade di Ceph alla versione 14.2.2. Per disabilitarlo, impostare:
    </para>
<screen>bluestore_warn_on_legacy_statfs = false</screen>
    <para>
     La correzione più adatta consiste nell'eseguire il comando indicato di seguito su tutti gli OSD mentre si trovano nello stato di interruzione:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-XXX</screen>
    <para>
     Di seguito è riportato uno script di supporto che esegue <command>ceph-bluestore-tool repair</command> per tutti gli OSD sul nodo <replaceable>NODE_NAME</replaceable>:
    </para>
<screen>OSDNODE=<replaceable>OSD_NODE_NAME</replaceable>;\
 for OSD in $(ceph osd ls-tree $OSDNODE);\
 do echo "osd=" $OSD;\
 salt $OSDNODE cmd.run 'systemctl stop ceph-osd@$OSD';\
 salt $OSDNODE cmd.run 'ceph-bluestore-tool repair --path /var/lib/ceph/osd/ceph-$OSD';\
 salt $OSDNODE cmd.run 'systemctl start ceph-osd@$OSD';\
 done</screen>
   </step>
   <step>
    <para>
     Annullare l'impostazione del flag "noout" per ciascun daemon OSD sul nodo in fase di upgrade:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph osd rm-noout osd.<replaceable>OSD_ID</replaceable>
</screen>
    <para>
     Ad esempio:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>for i in $(ceph osd ls-tree <replaceable>OSD_NODE_NAME</replaceable>);do echo "osd: $i"; ceph osd rm-noout osd.$i; done</screen>
    <para>
     Verificare con:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph health detail | grep noout</screen>
    <para>
     Nota:
    </para>
<screen><prompt>cephadm@osd &gt; </prompt>ceph –s
cluster:
 id:     44442296-033b-3275-a803-345337dc53da
 health: HEALTH_WARN
 <emphasis role="bold">Legacy BlueStore stats reporting detected on 6 OSD(s)</emphasis></screen>
   </step>
   <step>
    <para>
     Verificare lo stato del cluster. Sarà analogo all'output seguente:
    </para>
<screen>
<prompt>cephadm@osd &gt; </prompt>ceph status
cluster:
  id:     e0d53d64-6812-3dfe-8b72-fd454a6dcf12
  health: HEALTH_WARN
          3 monitors have not enabled msgr2

services:
  mon: 3 daemons, quorum mon1,mon2,mon3 (age 2h)
  mgr: mon2(active, since 22m), standbys: mon1, mon3
  osd: 30 osds: 30 up, 30 in

data:
  pools:   1 pools, 1024 pgs
  objects: 0 objects, 0 B
  usage:   31 GiB used, 566 GiB / 597 GiB avail
  pgs:     1024 active+clean
</screen>
   </step>
   <step>
    <para>
     Verificare che tutti i nodi OSD siano stati riavviati e che gli OSD si siano avviati automaticamente in seguito al riavvio.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="filestore2bluestore">
  <title>Migrazione OSD a BlueStore</title>

  <para>
   OSD BlueStore è un nuovo back-end per i daemon OSD. È l'opzione predefinita da SUSE Enterprise Storage 5. Rispetto a FileStore, che memorizza gli oggetti come file in un file system XFS, BlueStore è in grado di fornire prestazioni migliori perché memorizza gli oggetti direttamente sul dispositivo di blocco sottostante. BlueStore dispone inoltre di altre funzionalità, come la compressione integrata e sovrascrittura EC, non disponibili in FileStore.
  </para>

  <para>
   Specificamente per BlueStore, un OSD ha un dispositivo "wal" (Write Ahead Log) e un dispositivo "db" (RocksDB database). Il database RocksDB contiene i metadati per un OSD BlueStore. Questi due dispositivi risiedono di default sullo stesso dispositivo di un OSD, ma è possibile posizionare uno o l'altro su supporti diversi, ad esempio più veloci.
  </para>

  <para>
   In SUSE Enterprise Storage 5, sono supportati FileStore e BlueStore ed è possibile che gli OSD FileStore e BlueStore coesistano in un singolo cluster. Durante la procedura di upgrade di SUSE Enterprise Storage, gli OSD FileStore non vengono convertiti automaticamente a BlueStore. Ricordare che le funzionalità specifiche di BlueStore non sono disponibili sugli OSD non migrati a BlueStore.
  </para>

  <para>
   Prima della conversione a BlueStore, gli OSD devono eseguire SUSE Enterprise Storage 5. La conversione è un processo lento, in quanto tutti i dati vengono riscritti due volte. Benché il processo di migrazione possa richiedere molto tempo per il completamento, non vi è interruzione dell'attività del cluster e tutti i client possono continuare ad accedere al cluster durante questo periodo. Tuttavia, durante il processo di migrazione le prestazioni saranno ridotte, perché i dati del cluster vengono ribilanciati e ricostituiti.
  </para>

  <para>
   Per migrare gli OSD FileStore a BlueStore, utilizzare la procedura seguente:
  </para>

  <tip>
   <title>disattivare tutte le misure di sicurezza</title>
   <para>
    I comandi Salt necessari per eseguire la migrazione sono bloccati da misure di sicurezza. Per disattivare queste precauzioni, eseguire questo comando:
   </para>
<screen>
 <prompt>root@master # </prompt>salt-run disengage.safety
 </screen>
   <para>
    Ricompilare i nodi prima di continuare:
   </para>
<screen>
 <prompt>root@master # </prompt> salt-run rebuild.node <replaceable>TARGET</replaceable>
 </screen>
   <para>
    È inoltre possibile scegliere di ricompilare ciascun nodo individualmente. Ad esempio:
   </para>
<screen>
<prompt>root@master # </prompt> salt-run rebuild.node data1.ceph
 </screen>
   <para>
    <literal>rebuild.node</literal> consente sempre di rimuovere e creare nuovamente tutti gli OSD sul nodo.
   </para>
   <important>
    <para>
     Se la conversione di un OSD non riesce, l'esecuzione di una nuova ricompilazione distruggerà gli OSD BlueStore già convertiti. Invece di ripetere la ricompilazione, è possibile eseguire:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.deploy <replaceable>TARGET</replaceable>
 </screen>
   </important>
  </tip>

  <para>
   Dopo la migrazione a BlueStore, il numero di oggetti rimane lo stesso e l'utilizzo del disco quasi uguale.
  </para>
 </sect1>
 <sect1 xml:id="upgrade-appnodes-order">
  <title>Esecuzione dell'upgrade dei nodi dell'applicazione</title>

  <para>
   Eseguire l'upgrade dei nodi dell'applicazione nell'ordine seguente:
  </para>

  <orderedlist>
   <listitem>
    <para>
     Object Gateway
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Se gli Object Gateway sono diretti da un servizio di bilanciamento del carico, è possibile eseguire un upgrade in sequenza di questi ultimi senza interruzioni.
      </para>
     </listitem>
     <listitem>
      <para>
       Verificare che i daemon Object Gateway siano in esecuzione dopo ogni upgrade ed effettuare dei test con il client S3/Swift.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     iSCSI Gateway
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Se per gli iniziatori iSCSI è attiva la configurazione multipath, è possibile eseguire un upgrade in sequenza degli iSCSI Gateway senza interruzioni.
      </para>
     </listitem>
     <listitem>
      <para>
       Convalidare l'esecuzione del daemon <systemitem class="daemon">lrbd</systemitem> dopo ogni upgrade ed effettuare il test con l'iniziatore.
      </para>
     </listitem>
     <listitem>
      <para>
       <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
      </para>
     </listitem>
    </itemizedlist>
   </listitem>
   <listitem>
    <para>
     NFS Ganesha. <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
   <listitem>
    <para>
     Gateway Samba. <emphasis role="bold">Seguire la procedura descritta nella <xref linkend="upgrade-one-node"/>.</emphasis>
    </para>
   </listitem>
  </orderedlist>
 </sect1>
 <sect1 xml:id="upgrade-main-policy">
  <title>Aggiornamento di <filename>policy.cfg</filename> e distribuzione del Ceph Dashboard tramite DeepSea</title>

  <para>
   Sul nodo admin, modificare <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> e applicare le modifiche seguenti:
  </para>

  <important>
   <title>nuovi servizi non consentiti</title>
   <para>
    Durante l'upgrade del cluster, non aggiungere nuovi servizi al file <filename>policy.cfg</filename>. Modificare l'architettura del cluster soltanto al termine dell'upgrade.
   </para>
  </important>

  <procedure>
   <step>
    <para>
     Rimuovere <literal>role-openattic</literal>.
    </para>
   </step>
   <step>
    <para>
     Aggiungere <literal>role-prometheus</literal> e <literal>role-grafana</literal> al nodo su cui sono stati installati Prometheus e Grafana, di solito il nodo admin.
    </para>
   </step>
   <step>
    <para>
     Il ruolo <literal>profile-<replaceable>PROFILE_NAME</replaceable></literal> viene adesso ignorato. Aggiungere il nuovo ruolo corrispondente, la riga <literal>role-storage</literal>. Ad esempio, per l'esistente
    </para>
<screen>
profile-default/cluster/*.sls
</screen>
    <para>
     aggiungere
    </para>
<screen>
role-storage/cluster/*.sls
</screen>
   </step>
   <step>
    <para>
     Sincronizzare tutti i moduli Salt:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.sync_all</screen>
   </step>
   <step>
    <para>
     Aggiornare salt pillar eseguendo le fasi 1 e 2 di DeepSea:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2</screen>
   </step>
   <step>
    <para>
     Ripulire openATTIC:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.rescind.openattic
<prompt>root@master # </prompt>salt <replaceable>OA_MINION</replaceable> state.apply ceph.remove.openattic</screen>
   </step>
   <step>
    <para>
     Annullare l'impostazione del grain "restart_igw" per impedire che iSCSI Gateway, che non è stato ancora installato, venga riavviato durante la fase 0:
    </para>
<screen>Salt mastersalt '*' grains.delkey restart_igw</screen>
   </step>
   <step>
    <para>
     Infine, eseguire le fasi 0-4 di DeepSea:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.stage.0
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.1
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.3
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.4</screen>
    <tip>
     <title>errori "subvolume missing" durante la fase 3</title>
     <para>
      La fase 3 di DeepSea potrebbe generare un errore simile al seguente:
     </para>
<screen>subvolume : ['/var/lib/ceph subvolume missing on 4510-2', \
'/var/lib/ceph subvolume missing on 4510-1', \
[...]
'See /srv/salt/ceph/subvolume/README.md']</screen>
     <para>
      In questo caso, è necessario modificare il file <filename role="bold">/srv/pillar/ceph/stack/global.yml</filename> e aggiungere la riga seguente:
     </para>
<screen>subvolume_init: disabled</screen>
     <para>
      Quindi, aggiornare salt pillar ed eseguire nuovamente la fase 3 di DeepSea:
     </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar
 <prompt>root@master # </prompt>salt-run state.orch ceph.stage.3</screen>
     <para>
      Al completamento della fase 3 di DeepSea, verrà eseguito il Ceph Dashboard. Per una panoramica dettagliata delle funzioni del Ceph Dashboard, consultare questo riferimento: <xref linkend="ceph-dashboard"/>.
     </para>
     <para>
      Per visualizzare un elenco dei nodi che eseguono il dashboard, eseguire:
     </para>
<screen><prompt>cephadm@adm &gt; </prompt>ceph mgr services | grep dashboard</screen>
     <para>
      Per visualizzare un elenco delle credenziali amministratore, eseguire:
     </para>
<screen><prompt>root@master # </prompt>salt-call grains.get dashboard_creds</screen>
    </tip>
   </step>
   <step>
    <para>
     Riavviare in sequenza i servizi Object Gateway per utilizzare il server Web "beast" al posto del server "civetweb" obsoleto:
    </para>
<screen><prompt>root@master # </prompt>salt-run state.orch ceph.restart.rgw.force</screen>
   </step>
   <step>
    <para>
     Prima di continuare, si consiglia di abilitare il modulo di telemetria Ceph. Per ulteriori informazioni e istruzioni, consultare questo riferimento: <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-drive-groups">
  <title>Migrazione da distribuzioni basate sul profilo ai DriveGroups</title>

  <para>
   In SUSE Enterprise Storage 5.5, tramite DeepSea erano disponibili i cosiddetti "profili" per la descrizione del layout degli OSD. A partire da SUSE Enterprise Storage 6, viene utilizzato un approccio diverso denominato <emphasis>DriveGroups</emphasis> (ulteriori dettagli nella <xref linkend="ds-drive-groups"/>).
  </para>

  <note>
   <para>
    La migrazione al nuovo approccio non è immediatamente obbligatoria. Le operazioni distruttive, come <command>salt-run osd.remove</command>, <command>salt-run osd.replace</command> o <command>salt-run osd.purge</command> sono ancora disponibili. Tuttavia, per l'aggiunta di nuovi OSD è necessario l'intervento dell'utente.
   </para>
  </note>

  <para>
   Per via del diverso approccio di tali implementazioni, non viene offerto un percorso di migrazione automatico. Tuttavia, per semplificare il più possibile la migrazione, sono disponibili diversi strumenti (strumenti di esecuzione Salt).
  </para>

  <sect2>
   <title>Analisi del layout corrente</title>
   <para>
    Per visualizzare le informazioni sugli OSD attualmente distribuiti, utilizzare il comando seguente:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.discover
</screen>
   <para>
    In alternativa, è possibile analizzare il contenuto dei file nelle directory <filename>/srv/pillar/ceph/proposals/profile-*/</filename>. La struttura è analoga alla seguente:
   </para>
<screen>
ceph:
  storage:
    osds:
      /dev/disk/by-id/scsi-drive_name: format: bluestore
      /dev/disk/by-id/scsi-drive_name2: format: bluestore
     </screen>
  </sect2>

  <sect2>
   <title>Creazione di DriveGroups corrispondenti al layout corrente</title>
   <para>
    Per ulteriori dettagli sulla specifica dei DriveGroups, fare riferimento alla <xref linkend="ds-drive-groups-specs"/>.
   </para>
   <para>
    La differenza tra una distribuzione da zero e uno scenario di upgrade consiste nel fatto che le unità da migrare sono già "utilizzate". Poiché
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list
</screen>
   <para>
    cerca soltanto i dischi non utilizzati, utilizzare
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.list include_unavailable=True
</screen>
   <para>
    Modificare i DriveGroups finché non viene trovata una corrispondenza con la configurazione corrente. Per una rappresentazione visiva della procedura, utilizzare il comando seguente. Si noti che non verrà restituito alcun output se non sono presenti dischi liberi:
   </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report bypass_pillar=True
</screen>
   <para>
    Se dopo aver verificato che i DriveGroups siano stati configurati correttamente si desidera applicare il nuovo approccio, rimuovere i file dalla directory <filename>/srv/pillar/ceph/proposals/profile-<replaceable>PROFILE_NAME</replaceable>/</filename>, rimuovere le righe <literal>profile-<replaceable>PROFILE_NAME</replaceable>/cluster/*.sls</literal> corrispondenti dal file <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> ed eseguire la fase 2 di DeepSea per aggiornare salt pillar.
   </para>
<screen>
<prompt>root@master # </prompt>salt-run state.orch ceph.stage.2
</screen>
   <para>
    Verificare i risultati eseguendo i comandi seguenti:
   </para>
<screen>
<prompt>root@master # </prompt>salt target_node pillar.get ceph:storage
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   <warning>
    <title>configurazione errata dei DriveGroups</title>
    <para>
     Se i DriveGroups non sono configurati correttamente e se nella configurazione sono presenti dischi di riserva, questi verranno distribuiti nel modo in cui sono stati specificati dall'utente. Si consiglia di eseguire:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run disks.report
</screen>
   </warning>
  </sect2>

  <sect2 xml:id="upgrade-osd-deployment">
   <title>Distribuzione OSD</title>
   <para>
    Per i casi più semplici, come gli OSD stand-alone, la migrazione verrà eseguita nel tempo. Ogni volta che si rimuove o si sostituisce un OSD nel cluster, il nuovo OSD sarà basato su LVM.
   </para>
   <tip>
    <title>esecuzione della migrazione al formato LVM</title>
    <para>
     Ogni volta che è necessario sostituire un singolo OSD "esistente" su un nodo, occorre eseguire la migrazione al formato basato su LVM di tutti gli OSD che condividono i dispositivi con l'OSD sostituito.
    </para>
    <para>
     Per completezza, considerare di eseguire la migrazione degli OSD su tutto il nodo.
    </para>
   </tip>
  </sect2>

  <sect2>
   <title>Configurazioni più complesse</title>
   <para>
    Se la configurazione attiva è più complessa rispetto a quella dei semplici OSD stand-alone, se ad esempio sono presenti OSD crittografati o WAL/DB dedicati, è possibile eseguire la migrazione soltanto se tutti gli OSD assegnati al dispositivo WAL/DB specifico vengono rimossi. Ciò dipende dal fatto che il comando <command>ceph-volume</command> crea volumi logici sui dischi prima della distribuzione, impedendo all'utente di combinare le distribuzioni basate sulle partizioni con quelle basate su LV. In questi casi, è consigliabile rimuovere manualmente tutti gli OSD assegnati a un dispositivo WAL/DB e ridistribuirli con l'approccio DriveGroups.
   </para>
  </sect2>
 </sect1>
</chapter>
