<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_monitoring_alerting.xml" version="5.0" xml:id="monitoring-alerting">
 <title>Supervisión y alertas</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sí</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  En SUSE Enterprise Storage 7, cephadm distribuye una pila de alertas y supervisión. Los usuarios deben definir los servicios (como Prometheus, Alertmanager y Grafana) que desean distribuir con cephadm en un archivo de configuración YAML, o bien pueden utilizar la interfaz de línea de comandos para distribuirlos. Cuando se distribuyen varios servicios del mismo tipo, se distribuye una configuración de alta disponibilidad. El exportador de nodos es una excepción a esta regla.
 </para>
 <para>
  Los siguientes servicios de supervisión se pueden distribuir con cephadm:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis role="bold">Prometheus</emphasis> es el kit de herramientas de supervisión y alertas. Recopila los datos proporcionados por los exportadores de Prometheus y activa alertas preconfiguradas si se alcanzan los umbrales predefinidos.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Alertmanager</emphasis> gestiona las alertas enviadas por el servidor de Prometheus. Desduplica, agrupa y dirige las alertas al receptor correcto. Por defecto, Ceph Dashboard se configura automáticamente como receptor.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Grafana</emphasis> es el software de visualización y alertas. Esta pila de supervisión no utiliza la función de alertas de Grafana. Para las alertas, se utiliza Alertmanager.
   </para>
  </listitem>
  <listitem>
   <para>
    El <emphasis role="bold">exportador de nodos</emphasis> es un exportador de Prometheus que proporciona datos sobre el nodo en el que está instalado. Se recomienda instalar el exportador de nodos en todos los nodos.
   </para>
  </listitem>
 </itemizedlist>
 <para>
  El módulo de gestor de Prometheus proporciona un exportador de Prometheus para pasar los contadores de rendimiento de Ceph desde el punto de recopilación en <literal>ceph-mgr</literal>.
 </para>
 <para>
  La configuración de Prometheus, incluidos los destinos de <emphasis>scrape</emphasis> (métricas que proporcionan daemons), se configura automáticamente mediante cephadm. cephadm también distribuye una lista de alertas por defecto, por ejemplo, <literal>error de estado</literal>, <literal>10% de OSD inactivos</literal> o <literal>pgs inactivos</literal>.
 </para>
 <para>
  Por defecto, el tráfico a Grafana se cifra con TLS. Puede proporcionar su propio certificado TLS o utilizar uno autofirmado. Si no se ha configurado ningún certificado personalizado antes de la distribución de Grafana, se crea y se configura automáticamente un certificado autofirmado para Grafana.
 </para>
 <para>
  Los certificados personalizados para Grafana se pueden configurar mediante los comandos siguientes:
 </para>
<screen>
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_key -i $PWD/key.pem
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_crt -i $PWD/certificate.pem
  </screen>
 <para>
  Alertmanager gestiona las alertas enviadas por el servidor de Prometheus. Se encarga de desduplicarlos, agruparlos y enrutarlos al receptor correcto. Las alertas se pueden silenciar mediante el Alertmanager, pero los silencios también se pueden gestionar mediante Ceph Dashboard.
 </para>
 <para>
  Se recomienda que el <systemitem class="daemon">exportador de nodos</systemitem> se distribuya en todos los nodos. Esto se puede hacer mediante el archivo <filename>monitoring.yaml</filename> con el tipo de servicio <literal>node-exporter</literal>. Consulte el <xref linkend="deploy-cephadm-day2-service-monitoring"/> para obtener más información sobre la distribución de servicios.
 </para>
 <sect1 xml:id="monitoring-custom-images">
  <title>Configuración de imágenes personalizadas o locales</title>

  <tip>
   <para>
    En esta sección se describe cómo cambiar la configuración de las imágenes de contenedor que se utilizan al distribuir o actualizar los servicios. No incluye los comandos necesarios para distribuir o volver a distribuir servicios.
   </para>
   <para>
    El método recomendado para distribuir la pila de supervisión consiste en aplicar su especificación como se describe en el <xref linkend="deploy-cephadm-day2-service-monitoring"/>.
   </para>
  </tip>

  <para>
   Para distribuir imágenes de contenedor personalizadas o locales, las imágenes deben definirse en cephadm. Para ello, deberá ejecutar el comando siguiente:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable> <replaceable>VALUE</replaceable></screen>

  <para>
   Donde <replaceable>OPTION_NAME</replaceable> es uno de estos nombres:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     container_image_prometheus
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_node_exporter
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_alertmanager
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_grafana
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Si no se ha definido ninguna opción o si se ha eliminado el ajuste, se utilizan las imágenes siguientes como <replaceable>VALUE</replaceable>:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-server:2.18.0
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-node-exporter:0.18.1
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-alertmanager:0.16.2
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/ses/7/ceph/grafana:7.0.3
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Por ejemplo:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/container_image_prometheus prom/prometheus:v1.4.1</screen>

  <note>
   <para>
    Al definir una imagen personalizada, el valor por defecto se anula (pero no se sobrescribe). El valor por defecto cambia cuando hay actualizaciones disponibles. Al definir una imagen personalizada, no podrá actualizar automáticamente el componente para el que ha definido la imagen personalizada. Deberá actualizar manualmente la configuración (el nombre de la imagen y la etiqueta) para poder instalar actualizaciones.
   </para>
   <para>
    Si decide seguir las recomendaciones, puede restablecer la imagen personalizada que haya definido anteriormente. Después, se volverá a utilizar el valor por defecto. Utilice <command>ceph config rm</command> para restablecer la opción de configuración:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable></screen>
   <para>
    Por ejemplo:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/container_image_prometheus</screen>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-applying-updates">
  <title>Actualización de los servicios de supervisión</title>

  <para>
   Como se menciona en la <xref linkend="monitoring-custom-images"/>, cephadm incluye las URL de las imágenes de contenedor recomendadas y probadas, que se utilizan por defecto.
  </para>

  <para>
   Al actualizar los paquetes de Ceph, se pueden incluir nuevas versiones de estas URL. Esto solo actualiza de dónde se extraen las imágenes del contenedor, pero no actualiza ningún servicio.
  </para>

  <para>
   Después de actualizar las URL de las nuevas imágenes de contenedor, ya sea manualmente como se describe en la <xref linkend="monitoring-custom-images"/>, o automáticamente mediante una actualización del paquete de Ceph, los servicios de supervisión se pueden actualizar.
  </para>

  <para>
   Para ello, utilice <command>ceph orch redeploy</command> así:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy prometheus
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy grafana
</screen>

  <para>
   Actualmente no existe un comando único para actualizar todos los servicios de supervisión. El orden en el que se actualizan estos servicios no es importante.
  </para>

  <note>
   <para>
    Si utiliza imágenes de contenedor personalizadas, las URL especificadas para los servicios de supervisión no cambiarán automáticamente si se actualizan los paquetes de Ceph. Si ha especificado imágenes de contenedor personalizadas, deberá especificar manualmente las URL de las nuevas imágenes de contenedor. Este puede ser el caso si utiliza un registro de contenedor local.
   </para>
   <para>
    En la <xref linkend="monitoring-custom-images"/>, encontrará las URL de las imágenes de contenedor recomendadas.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-stack-disable">
  <title>Inhabilitación de la supervisión</title>

  <para>
   Para inhabilitar la pila de supervisión, ejecute los comandos siguientes:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch rm grafana
<prompt>cephuser@adm &gt; </prompt>ceph orch rm prometheus --force   # this will delete metrics data collected so far
<prompt>cephuser@adm &gt; </prompt>ceph orch rm node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch rm alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph mgr module disable prometheus
      </screen>
 </sect1>
 <sect1 xml:id="monitoring-grafana-config">
  <title>Configuración de Grafana</title>

  <para>
   El procesador final de Ceph Dashboard requiere la URL de Grafana para poder verificar la existencia de consolas de Grafana antes de que el procesador frontal las cargue. Debido a cómo se implementa Grafana en Ceph Dashboard, esto significa que se requieren dos conexiones en funcionamiento para poder ver los gráficos de Grafana en Ceph Dashboard:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     El procesador final (módulo Ceph MGR) debe verificar la existencia del gráfico solicitado. Si esta petición se realiza correctamente, el procesador frontal sabe que puede acceder a Grafana de forma segura.
    </para>
   </listitem>
   <listitem>
    <para>
     A continuación, el procesador frontal pide los gráficos de Grafana directamente desde el navegador del usuario mediante un <literal>iframe</literal>. Se accede directamente a la instancia de Grafana sin ningún desvío a través de Ceph Dashboard.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Ahora bien, puede darse el caso de que su entorno dificulte el acceso directo del navegador del usuario a la URL configurada en Ceph Dashboard. Para solucionar este problema, es posible configurar una URL independiente que se utilizará únicamente para indicar al procesador frontal (el navegador del usuario) qué URL debe utilizar para acceder a Grafana.
  </para>

  <para>
   Para cambiar la URL que se devuelve al procesador frontal, emita el comando siguiente:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph dashboard set-grafana-frontend-api-url <replaceable>GRAFANA-SERVER-URL</replaceable></screen>

  <para>
   Si no se define ningún valor para esa opción, simplemente se recurrirá al valor de la opción <replaceable>GRAFANA_API_URL</replaceable>, que cephadm define de forma automática y actualiza periódicamente. Si se define, indicará al navegador que utilice esta URL para acceder a Grafana.
  </para>
 </sect1>
 <sect1 xml:id="monitoring-cephadm-config">
  <title>Configuración del módulo de gestor de Prometheus</title>

  <para>
   El módulo de gestor de Prometheus es un módulo de Ceph que amplía la funcionalidad de Ceph. El módulo lee metadatos de Ceph acerca de su estado y actividad, proporcionando los datos extraídos en un formato que Prometheus puede consumir.
  </para>

  <note>
   <para>
    Es necesario reiniciar el módulo de gestor de Prometheus para que se apliquen los cambios de configuración.
   </para>
  </note>

  <sect2 xml:id="monitoring-http-requests">
   <title>Configuración de la interfaz de red</title>
   <para>
    Por defecto, el módulo de gestor de Prometheus acepta peticiones HTTP en el puerto 9283 en todas las direcciones IPv4 e IPv6 del host. El puerto y la dirección de escucha se pueden configurar con <option>ceph config-key set</option>, con las claves <option>mgr/prometheus/server_addr</option> y <option>mgr/prometheus/server_port</option>. Este puerto está indicado en el registro de Prometheus.
   </para>
   <para>
    Para actualizar <literal>server_addr</literal>, ejecute el comando siguiente:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_addr <replaceable>0.0.0.0</replaceable>
      </screen>
   <para>
    Para actualizar <literal>server_port</literal>, ejecute el comando siguiente:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_port <replaceable>9283</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-scrape-intervals">
   <title>Configuración de <literal>scrape_interval</literal></title>
   <para>
    Por defecto, el módulo de gestor de Prometheus se configura con un intervalo de scrape de 15 segundos. No se recomienda utilizar un intervalo inferior a 10 segundos. Para definir un intervalo diferente en el módulo de Prometheus, defina el valor que desee en <literal>scrape_interval</literal>:
   </para>
   <important>
    <para>
     Para que funcione correctamente y no se produzcan problemas, el valor de <literal>scrape_interval</literal> de este módulo siempre debe coincidir con el intervalo de scrape de Prometheus.
    </para>
   </important>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/scrape_interval <replaceable>15</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-stale-cache">
   <title>Configuración de caché</title>
   <para>
    En clústeres grandes (de más de 1000 OSD), el tiempo necesario para obtener las métricas puede ser considerable. Sin la memoria caché, el módulo de gestor de Prometheus puede sobrecargar el gestor y provocar que las instancias de Ceph Manager no respondan o se bloqueen. Como resultado, la memoria caché está habilitada por defecto y no se puede inhabilitar, pero esto significa que la caché puede quedarse obsoleta. Se considera obsoleta cuando el tiempo para obtener las métricas de Ceph supera el valor de <literal>scrape_interval</literal> configurado.
   </para>
   <para>
    Si este es el caso, se registrará una advertencia y el módulo:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Responde con un código de estado HTTP 503 (servicio no disponible).
     </para>
    </listitem>
    <listitem>
     <para>
      Devuelve el contenido de la caché, aunque esté obsoleta.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Este comportamiento se puede configurar mediante los comandos <command>ceph config set</command>.
   </para>
   <para>
    Para pedirle al módulo que responda con la indicación de que los datos posiblemente estén obsoletos, añada <literal>return</literal>:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy return</screen>
   <para>
    Para pedirle al módulo que responda con <literal>servicio no disponible</literal>, añada <literal>fail</literal>:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy fail</screen>
  </sect2>

  <sect2 xml:id="monitoring-rbd-image">
   <title>Habilitación de la supervisión de imágenes RBD</title>
   <para>
    El módulo de gestor de Prometheus puede recopilar, opcionalmente, estadísticas de E/S por imagen RBD habilitando contadores de rendimiento de OSD dinámicos. Las estadísticas se recopilan para todas las imágenes de los repositorios especificados en el parámetro de configuración <literal>mgr/prometheus/rbd_stats_pools</literal>.
   </para>
   <para>
    El parámetro es una lista separada por comas o espacios de entradas <literal>pool[/namespace]</literal>. Si no se especifica el espacio de nombres, las estadísticas se recopilan para todos los espacios de nombres del repositorio.
   </para>
   <para>
    Por ejemplo:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools "<replaceable>pool1,pool2,poolN</replaceable>"
      </screen>
   <para>
    El módulo explora los repositorios y espacios de nombres especificados, crea una lista de todas las imágenes disponibles y la actualiza periódicamente. El intervalo se puede configurar mediante el parámetro <literal>mgr/prometheus/rbd_stats_pools_refresh_interval</literal> (en segundos) y es de 300 segundos (cinco minutos) por defecto
   </para>
   <para>
    Por ejemplo, si cambia el intervalo de sincronización a 10 minutos:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools_refresh_interval <replaceable>600</replaceable>
      </screen>
  </sect2>
 </sect1>
 <sect1 xml:id="prometheus-security-model">
  <title>Modelo de seguridad de Prometheus</title>

  <para>
   El modelo de seguridad de Prometheus presupone que los usuarios que no son de confianza tienen acceso al puesto final HTTP y los registros de Prometheus. Los usuarios que no son de confianza tienen acceso a todos los metadatos que Prometheus recopila y que se encuentran en la base de datos, además de a distinta información operativa y de depuración.
  </para>

  <para>
   Sin embargo, la API HTTP de Prometheus está limitada a operaciones de solo lectura. Las configuraciones no se pueden cambiar mediante la API y los secretos no se revelan. Además, Prometheus tiene medidas integradas para mitigar el impacto de los ataques de denegación de servicio.
  </para>
 </sect1>
 <sect1 xml:id="prometheus-webhook-snmp">
  <title>Receptor de alertas SNMP Alertmanager de Prometheus</title>

  <para>
   Si desea recibir una notificación sobre las alertas de Prometheus mediante alertas SNMP, puede instalar el receptor de alertas SNMP Alertmanager de Prometheus a través de cephadm. Para ello, debe crear un archivo de especificación de servicio y colocación con el contenido siguiente:
  </para>

  <note>
   <para>
    Para obtener más información sobre los archivos de servicio y colocación, consulte <xref linkend="cephadm-service-and-placement-specs"/>.
   </para>
  </note>

<screen>
service_type: container
service_id: prometheus-webhook-snmp
placement:
    <replaceable>ADD_PLACEMENT_HERE</replaceable>
image: registry.suse.com/ses/7/prometheus-webhook-snmp:latest
args:
    - "--publish 9099:9099"
envs:
    - ARGS="--debug --snmp-host=<replaceable>ADD_HOST_GATEWAY_HERE</replaceable>"
    - RUN_ARGS="--metrics"
EOF
</screen>

  <para>
   Utilice esta especificación de servicio para que el servicio se ejecute con sus ajustes por defecto.
  </para>

  <para>
   Debe publicar el puerto en el que escucha el receptor de Prometheus mediante el argumento de línea de comandos <literal>--publish <replaceable>PUERTO_DE_HOST</replaceable>:<replaceable>PUERTO_DE_CONTENEDOR</replaceable></literal> cuando se ejecuta el servicio, ya que el contenedor no expone automáticamente el puerto. Esto se puede hacer añadiendo las líneas siguientes a la especificación:
  </para>

<screen>
args:
    - "--publish 9099:9099"
</screen>

  <para>
   Como alternativa, conecte el contenedor a la red del host mediante el argumento de línea de comandos <literal>--network=host</literal>.
  </para>

<screen>
args:
    - "--network=host"
</screen>

  <para>
   Si el receptor de mensajes de alerta SNMP no está instalado en el mismo host que el contenedor, también debe especificar el nombre completo del host SNMP. Utilice la pasarela de red del contenedor para poder recibir mensajes de alerta SNMP fuera del contenedor/host:
  </para>

<screen>
envs:
    - ARGS="--debug --snmp-host=<replaceable>CONTAINER_GATEWAY</replaceable>"
</screen>

  <sect2 xml:id="configure-prometheus-webhook-snmp">
   <title>Configuración del servicio <literal>prometheus-webhook-snmp</literal></title>
   <para>
    El contenedor se puede configurar mediante variables de entorno o mediante un archivo de configuración.
   </para>
   <para>
    Para las variables de entorno, utilice <literal>ARGS</literal> para definir las opciones globales y <literal>RUN_ARGS</literal> para las opciones del comando <command>run</command>. Debe adaptar la especificación de servicio de la siguiente manera:
   </para>
<screen>
envs:
    - ARGS="--debug --snmp-host=<replaceable>CONTAINER_GATEWAY</replaceable>"
    - RUN_ARGS="--metrics --port=9101"
</screen>
   <para>
    Para utilizar un archivo de configuración, la especificación de servicio debe adaptarse de la siguiente forma:
   </para>
<screen>
files:
    etc/prometheus-webhook-snmp.conf:
        - "debug: True"
        - "snmp_host: <replaceable>ADD_HOST_GATEWAY_HERE</replaceable>"
        - "metrics: True"
volume_mounts:
    etc/prometheus-webhook-snmp.conf: /etc/prometheus-webhook-snmp.conf
</screen>
   <para>
    Para distribuir, ejecute el comando siguiente:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>SERVICE_SPEC_FILE</replaceable></screen>
   <para>
    Consulte el <xref linkend="deploy-cephadm-day2-services"/> para obtener más información. 
   </para>
  </sect2>

  <sect2 xml:id="configure-prometheus-alertmanager-for-snmp">
   <title>Configuración de Alertmanager de Prometheus para SNMP</title>
   <para>
    Por último, Alertmanager de Prometheus debe configurarse específicamente para las alertas SNMP. Si este servicio aún no se ha distribuido, cree un archivo de especificación de servicio. Debe sustituir <literal>IP_OR_FQDN</literal> por la dirección IP o el nombre completo del host en el que se ha instalado el receptor de alertas SNMP Alertmanager de Prometheus. Por ejemplo:
   </para>
   <note>
    <para>
     Si ya ha distribuido este servicio, para asegurarse de que Alertmanager está configurado correctamente para SNMP, vuelva a distribuirlo con los ajustes siguientes:
    </para>
   </note>
<screen>
  service_type: alertmanager
  placement:
    hosts:
    - <replaceable>HOSTNAME</replaceable>
  webhook_configs:
    - 'http://<replaceable>IP_OR_FQDN</replaceable>:9099/'
</screen>
   <para>
    Aplique la especificación de servicio con el comando siguiente:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>SERVICE_SPEC_FILE</replaceable></screen>
  </sect2>
 </sect1>
</chapter>
