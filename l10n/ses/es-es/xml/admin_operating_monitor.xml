<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>Determinación del estado del clúster</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sí</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Si dispone de un clúster en ejecución, puede utilizar la herramienta <command>ceph</command> para supervisarlo. Normalmente, determinar el estado del clúster implica el estado de los daemons Ceph OSD, los monitores Ceph Monitor, los grupos de colocación y los servidores de metadatos.
 </para>
 <tip>
  <title>modo interactivo</title>
  <para>
   Para ejecutar la herramienta <command>ceph</command> en el modo interactivo, escriba <command>ceph</command> en la línea de comandos sin ningún argumento. El modo interactivo es más cómodo si se van a introducir más comandos <command>ceph</command> en una fila. Por ejemplo:
  </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon stat</screen>
 </tip>
 <sect1 xml:id="monitor-status">
  <title>Comprobación del estado de un clúster</title>

  <para>
   Puede averiguar el estado inmediato del clúster mediante <command>ceph status</command> o <command>ceph -s</command>:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph -s
cluster:
    id:     b4b30c6e-9681-11ea-ac39-525400d7702d
    health: HEALTH_OK

  services:
    mon: 5 daemons, quorum ses-min1,ses-master,ses-min2,ses-min4,ses-min3 (age 2m)
    mgr: ses-min1.gpijpm(active, since 3d), standbys: ses-min2.oopvyh
    mds: my_cephfs:1 {0=my_cephfs.ses-min1.oterul=up:active}
    osd: 3 osds: 3 up (since 3d), 3 in (since 11d)
    rgw: 2 daemons active (myrealm.myzone.ses-min1.kwwazo, myrealm.myzone.ses-min2.jngabw)

  task status:
    scrub status:
        mds.my_cephfs.ses-min1.oterul: idle

  data:
    pools:   7 pools, 169 pgs
    objects: 250 objects, 10 KiB
    usage:   3.1 GiB used, 27 GiB / 30 GiB avail
    pgs:     169 active+clean
</screen>

  <para>
   La salida proporciona la siguiente información:
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     ID del clúster
    </para>
   </listitem>
   <listitem>
    <para>
     Estado del clúster
    </para>
   </listitem>
   <listitem>
    <para>
     Valor epoch de la asignación de monitores y estado del quórum de monitores
    </para>
   </listitem>
   <listitem>
    <para>
     Valor epoch de asignación de OSD y estado de los OSD
    </para>
   </listitem>
   <listitem>
    <para>
     El estado de las instancias de Ceph Manager
    </para>
   </listitem>
   <listitem>
    <para>
     El estado de las pasarelas Object Gateway
    </para>
   </listitem>
   <listitem>
    <para>
     La versión de asignación del grupo de colocación
    </para>
   </listitem>
   <listitem>
    <para>
     El número de grupos de colocación y de repositorios
    </para>
   </listitem>
   <listitem>
    <para>
     La cantidad <emphasis>teórica</emphasis> de datos almacenados y el número de objetos almacenados
    </para>
   </listitem>
   <listitem>
    <para>
     La cantidad total de datos almacenados
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>cómo calcula Ceph el uso de datos</title>
   <para>
    El valor <literal>used</literal> (utilizado) refleja la cantidad real de almacenamiento en bruto utilizado. El número menor del valor <literal>xxx GB / xxx GB</literal> indica la cantidad disponible de la capacidad de almacenamiento global del clúster. El número teórico refleja el tamaño de los datos almacenados antes de que se repliquen, se clonen o se capturen en una instantánea. Por lo tanto, la cantidad de datos que se almacena realmente suele superar el almacenamiento teórico, dado que Ceph crea réplicas de los datos y también puede utilizar la capacidad de almacenamiento para tareas de clonación y de captura de instantáneas.
   </para>
  </tip>

  <para>
   Otros comandos que muestran la información de estado inmediato son los siguientes:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Para obtener la información actualizada en tiempo real, coloque cualquiera de estos comandos (incluyendo <command>ceph -s</command>) como argumento del comando <command>watch</command>:
  </para>

<screen><prompt role="root">root # </prompt>watch -n 10 'ceph -s'</screen>

  <para>
   Pulse <keycombo><keycap function="control"/><keycap>C</keycap></keycombo> cuando quiera detener la visualización.
  </para>
 </sect1>
 <sect1 xml:id="monitor-health">
  <title>Comprobación del estado del clúster</title>

  <para>
   Una vez iniciado el clúster y antes de empezar a leer o escribir datos, compruebe su estado:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <tip>
   <para>
    Si ha especificado ubicaciones distintas de las establecidas por defecto para la configuración o el anillo de claves, puede indicarlas:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>

  <para>
   El clúster de Ceph devolverá uno de los siguientes códigos de estado:
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      Uno o varios OSD están señalados como inactivos. Se ha detenido el daemon OSD o los pares OSD no pueden acceder al OSD a través de la red. Algunas de las causas pueden ser un daemon detenido o bloqueado, un host caído o una interrupción de la red.
     </para>
     <para>
      Compruebe que el host está en buen estado, el daemon se inicia y la red está funcionando. Si el daemon se ha bloqueado, el archivo de registro de daemon (<filename>/var/log/ceph/ceph-osd.*</filename>) puede contener información de depuración.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>tipo de bloqueo</replaceable>_DOWN; por ejemplo: OSD_HOST_DOWN</term>
    <listitem>
     <para>
      Todos los OSD con un determinado subárbol CRUSH se marcan como inactivos, por ejemplo, todos los OSD de un host.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      Se hace referencia a un OSD en la jerarquía de asignaciones CRUSH, pero no existe. El OSD se puede quitar de la jerarquía CRUSH con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      Los umbrales de uso para <emphasis>backfillfull</emphasis> (el valor por defecto es 0,90), <emphasis>nearfull</emphasis> (por defecto, 0,85), <emphasis>full</emphasis> (por defecto, 0,95) o <emphasis>failsafe_full</emphasis> no son ascendentes. En concreto, esperamos <emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>, <emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis> y <emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis>.
     </para>
     <para>
      Para leer los valores actuales, ejecute:
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph health detail
HEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)
osd.3 is full at 97%
osd.4 is backfill full at 91%
osd.2 is near full at 87%
</screen>
     <para>
      Los umbrales se pueden ajustar con los comandos siguientes:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      Uno o varios OSD han excedido el umbral <emphasis>full</emphasis>, lo que impide que el clúster de servicio a las operaciones de escritura. El uso del repositorio se puede comprobar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
     <para>
      La proporción de <emphasis>full</emphasis> definida actualmente se puede consultar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      Una solución a corto plazo para restaurar la disponibilidad de las operaciones de escritura es aumentar el umbral "full" en una pequeña cantidad:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      Añada nuevo espacio de almacenamiento al clúster mediante la implantación de más OSD o suprima datos existentes para liberar espacio.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      Uno o varios OSD han excedido el umbral <emphasis>backfillfull</emphasis>, lo que impide que los datos se puedan reequilibrar en este dispositivo. Se trata de una advertencia previa de que podría resultar imposible completar el reequilibrio y de que el clúster está casi lleno. El uso del repositorio se puede comprobar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      Uno o varios OSD han excedido el umbral <emphasis>nearfull</emphasis>. Se trata de una advertencia previa de que el clúster está casi lleno. El uso del repositorio se puede comprobar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      Se han definido uno o varios indicadores de interés en el clúster. Con la excepción de <emphasis>full</emphasis>, estos indicadores se pueden establecer o borrar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      Los indicadores son los siguientes:
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         El clúster se marca como lleno y no permite realizar operaciones de escritura.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd, pausewr</term>
       <listitem>
        <para>
         Operaciones de lectura o de escritura en pausa.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         No se pueden iniciar los OSD.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Se omiten los informes de fallo de los OSD, de modo que los monitores no marquen los OSD como caídos (<emphasis>down</emphasis>).
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Los OSD que se hayan marcado como <emphasis>out</emphasis> (fuera) no se volverán a marcar como <emphasis>in</emphasis> (dentro) cuando se inicien.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Los OSD caídos (<emphasis>down</emphasis>) no se marcarán automáticamente como <emphasis>out</emphasis> (fuera) después del intervalo configurado.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill, norecover, norebalance</term>
       <listitem>
        <para>
         Las operaciones de recuperación o de reequilibrio de datos están suspendidas.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub, nodeep_scrub</term>
       <listitem>
        <para>
         Las operaciones de borrado seguro (consulte la <xref linkend="scrubbing-pgs"/>) están inhabilitadas.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         Las actividades de niveles de caché están suspendidas.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      Uno o varios OSD tienen establecido un indicador de interés por OSD. Los indicadores son los siguientes:
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         El OSD no se puede iniciar.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Se omitirán los informes de errores para este OSD.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Si este OSD se ha marcado anteriormente como <emphasis>out</emphasis> (fuera) tras un fallo, no se marcará como <emphasis>in</emphasis> (dentro) cuando se inicie.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Si este OSD está apagado, no se marcará automáticamente como <emphasis>out</emphasis> (fuera) después del intervalo configurado.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      Los indicadores por OSD se pueden definir y desactivar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      La asignación CRUSH utiliza una configuración muy antigua y se debe actualizar. Los tunables más antiguos que se pueden utilizar (es decir, es la versión más antigua del cliente que se puede conectar al clúster) sin que se active esta advertencia de estado está determinada por la opción de configuración <option>mon_crush_min_required_version</option>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      La asignación CRUSH utiliza un método más antiguo y no óptimo para calcular los valores de peso intermedio para el ordenamiento por casilleros. La asignación CRUSH debe actualizarse para utilizar el método más reciente (<option>straw_calc_version</option>=1).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      Uno o varios repositorios de caché no están configurados con un conjunto de resultados para realizar el seguimiento del uso, lo que impide que el agente de niveles de caché identifique los objetos fríos que debe limpiar y expulsar del caché. Los conjuntos de resultados se pueden configurar en el repositorio de caché con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      No hay ningún OSD anterior a Luminous versión 12 en ejecución, pero no se ha definido el indicador <option>sortbitwise</option>. Debe definir el indicador <option>sortbitwise</option> para que se puedan iniciar los OSD de Luminous 12 o versiones más recientes:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Uno o varios repositorios han alcanzado su cuota y ya no permiten más operaciones de escritura. Es posible definir cuotas de repositorio y límites de uso con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df detail</screen>
     <para>
      Puede aumentar la cuota de repositorio con
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      o suprimir algunos datos para reducir el uso.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      Hay una disponibilidad reducida de los datos, lo que significa que el clúster no puede responder a posibles peticiones de lectura o escritura de algunos de los datos del clúster. En particular, uno o varios grupos de colocación se encuentran en un estado que no permite atender las peticiones de E/S. Los estados de los grupos de colocación afectados son <emphasis>peering</emphasis> (emparejando), <emphasis>stale</emphasis> (detenido), <emphasis>incomplete</emphasis> (incompleto) y la ausencia de <emphasis>active</emphasis> (activo) (si dichos estados no desaparecen rápidamente). Encontrará información detallada sobre los grupos de colocación afectados en:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph health detail</screen>
     <para>
      En la mayoría de los casos, la causa raíz es que uno o varios OSD están caídos. Se puede consultar el estado de los grupos de colocación afectados específicos con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      Se reduce la redundancia de algunos datos, lo que significa que el clúster no tiene el número deseado de réplicas de todos los datos (para los repositorios replicados) o fragmentos de código de borrado (para los repositorios codificados de borrado). En concreto, uno o varios grupos de colocación tienen establecido el indicador <emphasis>degraded</emphasis> (degradado) o <emphasis>undersized</emphasis> (tamaño insuficiente) (no hay suficientes instancias de ese grupo de colocación en el clúster), o bien hace tiempo que no cuenta con el indicador <emphasis>clean</emphasis> (limpio). Encontrará información detallada sobre los grupos de colocación afectados en:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph health detail</screen>
     <para>
      En la mayoría de los casos, la causa raíz es que uno o varios OSD están caídos. Se puede consultar el estado de los grupos de colocación afectados específicos con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      La redundancia de datos se puede reducir o estar en peligro para algunos datos debido a la falta de espacio disponible en el clúster. En concreto, uno o varios grupos de colocación tienen establecidos los indicadores <emphasis>backfill_toofull</emphasis> o <emphasis>recovery_toofull</emphasis>, lo que significa que el clúster no puede migrar o recuperar datos debido a que uno o varios OSD superan el umbral <emphasis>backfillfull</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      El proceso de borrado seguro de datos (consulte la <xref linkend="scrubbing-pgs"/>) ha detectado problemas con la coherencia de los datos en el clúster. Específicamente, hay uno o varios grupos de colocación con el indicador <emphasis>inconsistent</emphasis> o <emphasis>snaptrim_error</emphasis>, que indican que una operación anterior de borrado seguro ha detectado un problema, o bien se ha establecido el indicador <emphasis>repair</emphasis>, lo que significa que hay una reparación de dicha incoherencia en curso.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      Los procesos de borrado seguro de OSD recientes han revelado incoherencias.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Un repositorio de nivel de caché está casi lleno. La capacidad en este contexto está determinada por las propiedades <emphasis>target_max_bytes</emphasis> y <emphasis>target_max_objects</emphasis> que aparecen en el repositorio de caché. Cuando el repositorio alcanza el umbral objetivo, las peticiones de escritura para el repositorio podrían bloquearse hasta que los datos se limpien y se expulsen del caché, un estado que suele producir latencias muy altas y un rendimiento deficiente. El objetivo de tamaño del repositorio de caché se puede ajustar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      Las actividades normales de limpieza y expulsión del caché también se pueden atascar por una reducción de la disponibilidad o el rendimiento del nivel base o por la carga global del clúster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      El número de grupos de colocación en uso está por debajo del umbral configurable de grupos de colocación por OSD (<option>mon_pg_warn_min_per_osd</option>). Esto puede producir una distribución y reequilibrio de datos subóptimo entre los OSD del clúster y reducir el rendimiento general.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      El número de grupos de colocación en uso está por encima del umbral configurable de grupos de colocación por OSD (<option>mon_pg_warn_max_per_osd</option>). Esto puede dar lugar a un uso más elevado de memoria para los daemons de OSD, un emparejamiento más lento después de cambios de estado del clúster (por ejemplo, reinicios, incorporaciones o eliminaciones de OSD) y una mayor carga mayor en los gestores y monitores de Ceph.
     </para>
     <para>
      Aunque no es posible reducir el valor de <option>pg_num</option> para los repositorios existentes, sí se puede reducir el valor de <option>pgp_num</option>. A efectos prácticos, esto sitúa algunos grupos de colocación en los mismos conjuntos de OSD, mitigando algunos de los impactos negativos descritos anteriormente. El valor <option>pgp_num</option> se puede ajustar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      Uno o varios repositorios tienen un valor <option>pgp_num</option> inferior a <option>pg_num</option>. Por lo general, esto suele indicar que se ha aumentado el número de grupos de colocación sin aumentar al mismo tiempo el comportamiento de colocación. Normalmente, el problema se resuelve definiendo <option>pgp_num</option> para que coincida con <option>pg_num</option>, lo que activa la migración de datos:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      Uno o varios repositorios tienen un número medio de objetos por grupo de colocación significativamente superior al promedio general del clúster. El umbral específico se controla mediante el valor de configuración <option>mon_pg_warn_max_object_skew</option>. Esto suele indicar que los repositorios que contienen la mayoría de los datos del clúster disponen de muy pocos grupos de colocación o que los demás repositorios, que no contienen tantos datos, tienen demasiados grupos de colocación. Se puede elevar el umbral para silenciar la advertencia de estado; para ello, ajuste la opción de configuración <option>mon_pg_warn_max_object_skew</option> en los monitores.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      Existe un repositorio que contiene uno o varios objetos, pero no se ha etiquetado para su uso por parte de una aplicación determinada. Para resolver esta advertencia, etiquete el repositorio para su uso por parte de una aplicación. Por ejemplo, si el repositorio lo utiliza RBD:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      Si el repositorio está siendo utilizado por una aplicación personalizada "foo", también se puede etiquetar mediante el comando de bajo nivel:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Uno o varios repositorios han alcanzado su cuota (o van a alcanzarla muy pronto). El umbral para que se active esta situación de error depende de la opción de configuración <option>mon_pool_quota_crit_threshold</option>. Las cuotas del repositorio se pueden aumentar, reducir o eliminar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Si define el valor de la cuota como 0, la cuota se inhabilitará.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Uno o varios repositorios se están aproximando a su cuota. El umbral para que se active esta situación de advertencia depende de la opción de configuración <option>mon_pool_quota_warn_threshold</option>. Las cuotas del repositorio se pueden aumentar, reducir o eliminar con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Si define el valor de la cuota como 0, la cuota se inhabilitará.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      Uno o varios objetos del clúster no se almacenan en el nodo en el que clúster pretende hacerlo. Esto indica que una migración de datos debida a algunos cambios recientes del clúster aún no se ha completado. El almacenamiento de datos en el lugar equivocado no es una situación peligrosa por sí misma. La coherencia de los datos nunca corre peligro y las copias antiguas de los objetos no se eliminan hasta que se alcanza el número de copias nuevas deseadas (en las ubicaciones correctas).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      No es posible encontrar uno o más objetos en el clúster. En concreto, los OSD saben que debe existir una copia nueva o actualizada de un objeto, pero no se ha encontrado ninguna copia de esa versión del objeto en los OSD que están actualmente activos. Las peticiones de lectura o escritura a los objetos "unfound" (no encontrados) se bloquean. Idealmente, el OSD inactivo que tiene la copia más reciente del objeto no encontrado se puede volver a activar. Los OSD candidatos se pueden identificar a partir del estado de emparejamiento de los grupos de colocación responsables del objeto no encontrado:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      Una o varias peticiones de OSD tardan mucho tiempo en procesarse. Esto puede indicar un nivel de carga extremo, un dispositivo de almacenamiento lento o un fallo de software. Puede consultar la cola de peticiones de los OSD en cuestión ejecutando el siguiente comando desde el host OSD:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      Puede consultar un resumen de las peticiones más lentas realizadas recientemente:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      Puede consultar la ubicación de un OSD con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      Una o más peticiones de OSD se han bloqueado durante un tiempo relativamente largo, por ejemplo 4096 segundos. Esto indica que el clúster lleva un periodo prolongado de tiempo en un estado incorrecto (por ejemplo, no hay suficientes OSD en ejecución o grupos de colocación inactivos) o que hay algún problema interno con el OSD.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      A uno o varios de los grupos de colocación no se les ha aplicado el borrado seguro (consulte la <xref linkend="scrubbing-pgs"/>) recientemente. Normalmente, a los grupos de colocación se les aplica el borrado seguro cuando transcurre el número de segundos indicado en <option>mon_scrub_interval</option>; esta advertencia se activa cuando transcurren los intervalos indicados en <option>mon_warn_not_scrubbed</option> sin que se realice un borrado seguro. A los grupos de colocación no se les aplicará el borrado seguro si no están marcados como limpios; esto puede ocurrir si se extravían o se degradan (consulte PG_AVAILABILITY y PG_DEGRADED más arriba). Puede iniciar manualmente el borrado seguro de un grupo de colocación limpio con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      Uno o varios grupos de colocación no se han sometido a un borrado seguro profundo (consulte la <xref linkend="scrubbing-pgs"/>) recientemente. Normalmente, a los grupos de colocación se les aplica un borrado seguro profundo cuando transcurre el número de segundos indicado en <option>osd_deep_mon_scrub_interval</option>; esta advertencia se activa cuando transcurren los segundos indicados en <option>mon_warn_not_deep_scrubbed</option> sin que se realice un borrado seguro profundo. A los grupos de colocación no se les aplicará el borrado seguro profundo si no están marcados como limpios; esto puede ocurrir si se extravían o se degradan (consulte PG_AVAILABILITY y PG_DEGRADED más arriba). Puede iniciar manualmente el borrado seguro de un grupo de colocación limpio con:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    Si ha especificado ubicaciones distintas de las establecidas por defecto para la configuración o el anillo de claves, puede indicarlas:
   </para>
<screen><prompt role="root">root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>Comprobación de las estadísticas de uso de un clúster</title>

  <para>
   Para comprobar el uso de datos de un clúster y la distribución de datos entre los repositorios, utilice el comando <command>ceph df</command>. Para obtener más detalles, utilice <command>ceph df detail</command>.
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph df
--- RAW STORAGE ---
CLASS  SIZE    AVAIL   USED     RAW USED  %RAW USED
hdd    30 GiB  27 GiB  121 MiB   3.1 GiB      10.40
TOTAL  30 GiB  27 GiB  121 MiB   3.1 GiB      10.40

--- POOLS ---
POOL                   ID  STORED   OBJECTS  USED     %USED  MAX AVAIL
device_health_metrics   1      0 B        0      0 B      0    8.5 GiB
cephfs.my_cephfs.meta   2  1.0 MiB       22  4.5 MiB   0.02    8.5 GiB
cephfs.my_cephfs.data   3      0 B        0      0 B      0    8.5 GiB
.rgw.root               4  1.9 KiB       13  2.2 MiB      0    8.5 GiB
myzone.rgw.log          5  3.4 KiB      207    6 MiB   0.02    8.5 GiB
myzone.rgw.control      6      0 B        8      0 B      0    8.5 GiB
myzone.rgw.meta         7      0 B        0      0 B      0    8.5 GiB
</screen>

  <para>
   La sección <literal>RAW STORAGE</literal> del resultado proporciona una descripción general de la cantidad de almacenamiento que utiliza el clúster para los datos.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>CLASS</literal>: la clase de almacenamiento del dispositivo. Consulte la <xref linkend="crush-devclasses"/> para obtener más información sobre las clases de dispositivos.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>SIZE</literal>: capacidad de almacenamiento global del clúster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal>: cantidad de espacio disponible en el clúster.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: el espacio (acumulado en todos los OSD) asignado exclusivamente para objetos de datos conservados en el dispositivo de bloques.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal>: la suma del espacio "USED" y el espacio asignado/reservado en el dispositivo de bloques para propósitos de Ceph, por ejemplo la parte BlueFS para BlueStore.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal>: porcentaje de almacenamiento en bruto utilizado. Utilice este número junto con <literal>full ratio</literal> (lleno) y <literal>near full ratio</literal> (casi lleno) para asegurarse de que no se alcanza la capacidad de su clúster. Consulte la <xref linkend="storage-capacity"/> para obtener más información.
    </para>
    <note>
     <title>nivel de llenado de clúster</title>
     <para>
      Cuando un nivel de llenado de almacenamiento en bruto se acerca al 100 %, debe añadir nuevo almacenamiento al clúster. Un nivel de uso más elevado puede provocar que algunos OSD se llenen y se produzcan problemas de estado del clúster.
     </para>
     <para>
      Utilice el comando <command>ceph osd df tree</command> para que se muestre el nivel de llenado de todos los OSD.
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   La sección <literal>POOLS</literal> de la salida proporciona una lista de los repositorios y el uso teórico de cada uno de ellos. La salida de esta sección <emphasis>no</emphasis> refleja las réplicas, las clonaciones ni las instantáneas. Por ejemplo, si almacena un objeto con 1 MB de datos, el uso teórico es de 1 MB, pero el uso real puede ser de 2 MB o más, según el número de réplicas, clonaciones e instantáneas.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>POOL</literal>: el nombre del repositorio.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal>: ID del repositorio.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>STORED</literal>: la cantidad de datos almacenados por el usuario.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal>: el número teórico de objetos almacenados por repositorio.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal>: la cantidad de espacio asignado exclusivamente para los datos por todos los nodos de OSD, en kB.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>%USED</literal>: el porcentaje teórico del almacenamiento utilizado por repositorio.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal>: el espacio máximo disponible en el repositorio especificado.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    Las cifras de la sección POOLS son teóricas. No incluyen el número de réplicas, clonaciones o instantáneas. Por lo tanto, la suma de las cantidades de <literal>USED</literal> y <literal>%USED</literal> no se sumará a las cantidades de <literal>RAW USED</literal> y <literal>%RAW USED</literal> de la sección <literal>RAW STORAGE</literal> del resultado.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>Comprobación del estado de los OSD</title>

  <para>
   Para comprobar los OSD y asegurarse de que estén activos y conectados, ejecute:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd stat</screen>

  <para>
   O bien
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd dump</screen>

  <para>
   También puede ver los OSD según su posición en la asignación de CRUSH.
  </para>

  <para>
   <command>ceph osd tree</command> imprime un árbol de CRUSH con un host, sus OSD, su estado de funcionamiento y su peso:
  </para>

<screen>
   <prompt>cephuser@adm &gt; </prompt>ceph osd tree
ID  CLASS  WEIGHT   TYPE NAME              STATUS  REWEIGHT  PRI-AFF
-1      3  0.02939  root default
-3      3  0.00980    rack mainrack
-2      3  0.00980            host osd-host
0       1  0.00980                    osd.0   up   1.00000   1.00000
1       1  0.00980                    osd.1   up   1.00000   1.00000
2       1  0.00980                    osd.2   up   1.00000   1.00000
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>Comprobación de OSD llenos</title>

  <para>
   Ceph impide escribir en un OSD lleno para que no se pierden datos. En un clúster en funcionamiento, debería aparecer una advertencia cuando el clúster se esté aproximando al máximo de su capacidad. El valor por defecto de <command>mon osd full ratio</command> es de 0,95 o un 95 % de capacidad para impedir la escritura de datos a los clientes. El valor por defecto de <command>mon osd nearfull ratio</command> es de 0,85 o 85 % de capacidad para generar una advertencia de estado.
  </para>

  <para>
   El comando <command>ceph health</command> informa de los nodos de OSD llenos:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   O bien
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   La mejor forma de ocuparse de un clúster lleno es añadir hosts de OSD o discos para que el clúster redistribuya los datos en el nuevo espacio de almacenamiento disponible.
  </para>

  <tip>
   <title>cómo evitar que los OSD se llenen</title>
   <para>
    Si un OSD se llena (usa el 100 % de su espacio de disco), normalmente se bloqueará de inmediato y sin previo aviso. A continuación indicamos algunos consejos que conviene recordar al administrar nodos de OSD.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      El espacio de disco de cada OSD (normalmente montado en <filename>/var/lib/ceph/osd/osd-{1,2..}</filename>) debe colocarse en un disco o en una partición de uso dedicado.
     </para>
    </listitem>
    <listitem>
     <para>
      Compruebe los archivos de configuración de Ceph y asegúrese de que Ceph no almacena el archivo de registro en las particiones o los discos cuyo uso esté dedicado a los OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      Asegúrese de que ningún otro proceso escribe en los discos o en las particiones de uso dedicado de los OSD.
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Comprobación del estado del monitor</title>

  <para>
   Después de iniciar el clúster y antes de leer o escribir datos por primera vez, compruebe el estado de quórum de los monitores Ceph Monitor. Si el clúster ya está sirviendo peticiones, compruebe periódicamente el estado de los monitores Ceph Monitor para asegurarse de que se están ejecutando.
  </para>

  <para>
   Para ver la asignación de monitores, ejecute lo siguiente:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph mon stat</screen>

  <para>
   O bien
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph mon dump</screen>

  <para>
   Para comprobar el estado de quórum del clúster de monitores, ejecute lo siguiente:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph quorum_status</screen>

  <para>
   Ceph devolverá el estado de quórum. Por ejemplo, un clúster de Ceph que consta de tres monitores podría devolver lo siguiente:
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "192.168.1.10:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "192.168.1.11:6789\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "192.168.1.12:6789\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>Comprobación del estado de los grupos de colocación</title>

  <para>
   Los grupos de colocación asignan objetos a los OSD. Al supervisar los grupos de colocación, es conveniente que tengan los estados <literal>active</literal> (activo) y <literal>clean</literal> (limpio). Para obtener información detallada, consulte la <xref linkend="op-mon-osd-pg"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-capacity">
  <title>Capacidad de almacenamiento</title>

  <para>
   Cuando un clúster de almacenamiento de Ceph se acerca a su capacidad máxima, Ceph impide escribir o leer desde los Ceph OSD como medida de seguridad para evitar la pérdida de datos. Por lo tanto, permitir que un clúster de producción se acerque a su máximo de capacidad no es una buena práctica, ya que se sacrifica la alta disponibilidad. El máximo de capacidad por defecto se define en .95, lo que significa el 95 % de la capacidad. Se trata de un valor muy agresivo para un clúster de pruebas con un número pequeño de OSD.
  </para>

  <tip>
   <title>aumento de la capacidad de almacenamiento</title>
   <para>
    Al supervisar el clúster, esté alerta a las advertencias relacionadas con la proporción de <literal>nearfull</literal> (casi lleno). Significa que un error de algunos OSD podría dar lugar a una interrupción temporal del servicio si se produce un error en uno o más OSD. Considere la posibilidad de añadir más OSD para aumentar la capacidad de almacenamiento.
   </para>
  </tip>

  <para>
   Un escenario habitual para los clústeres de prueba es la de un administrador del sistema que elimina un Ceph OSD del clúster de almacenamiento de Ceph para observar el reequilibrio del clúster. A continuación, quita otro Ceph OSD, y así sucesivamente hasta que el clúster finalmente alcanza su máxima capacidad y se bloquea. Se recomienda cierta planificación de la capacidad incluso en el caso de un clúster de pruebas. La planificación permite estimar la capacidad de repuesto que se necesitará para poder mantener la alta disponibilidad. En una situación ideal, desea planear una serie de errores del Ceph OSD en los que el clúster puede recuperarse a un estado <literal>activo + limpio</literal> sin tener que sustituir esos Ceph OSD de inmediato. Puede ejecutar un clúster en un estado <literal>activo + degradado</literal>, pero no es lo ideal para condiciones de funcionamiento normales.
  </para>

  <para>
   En el diagrama siguiente se muestra un clúster de almacenamiento de Ceph simplificado que contiene 33 nodos Ceph con un Ceph OSD por host. Cada uno de ellos lee y escribe en una unidad de 3 TB. Este clúster de ejemplo tiene una capacidad real máxima de 99 TB. La opción <option>mon osd full ratio</option> se define en 0,95. Si el clúster cae por debajo de los 5 TB de capacidad restante, no permitirá que los clientes lean y escriban datos. Por lo tanto, la capacidad operativa del clúster de almacenamiento es de 95 TB, no de 99 TB.
  </para>

  <figure>
   <title>Clúster de Ceph</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   En este tipo de clúster, es normal que uno o dos OSD fallen. Un escenario menos frecuente, aunque razonable, implica que el router o la fuente de alimentación de un bastidor falle, lo que desactiva varios OSD simultáneamente (por ejemplo, los OSD del 7 al 12). En esa situación, debe seguir intentando que un clúster pueda permanecer operativo y logre un estado <literal>activo + limpio</literal>, incluso si eso significa añadir algunos hosts con OSD adicionales a corto plazo. Si el uso de la capacidad es demasiado alto, es posible que no pierda datos. Sin embargo, aún podría sacrificar la disponibilidad de los datos y resolver al mismo tiempo una interrupción dentro de un dominio de error si el uso de capacidad del clúster supera el máximo. Por este motivo, se recomienda que se realice al menos una planificación aproximada de la capacidad.
  </para>

  <para>
   Identifique dos valores para el clúster:
  </para>

  <orderedlist>
   <listitem>
    <para>
     El número de OSD.
    </para>
   </listitem>
   <listitem>
    <para>
     La capacidad total del clúster.
    </para>
   </listitem>
  </orderedlist>

  <para>
   Si divide la capacidad total del clúster por el número de OSD del clúster, encontrará la capacidad media de un OSD dentro del clúster. También puede multiplicar ese número por el número de OSD que espera que fallen simultáneamente durante las operaciones normales (un número relativamente pequeño). Por último, multiplique la capacidad del clúster por la capacidad máxima para descubrir la capacidad operativa máxima. A continuación, reste la cantidad de datos de los OSD que espera que no lleguen al máximo de capacidad razonable. Repita el proceso anterior con un mayor número de errores de OSD (un bastidor de OSD) para llegar a un número razonable capacidad casi máxima.
  </para>

  <para>
   Los valores siguiente solo se aplica durante la creación del clúster y, después, se almacena en el mapa de OSD:
  </para>

<screen>
[global]
 mon osd full ratio = .80
 mon osd backfillfull ratio = .75
 mon osd nearfull ratio = .70
</screen>

  <tip>
   <para>
    Estos valores solo se aplican durante la creación del clúster. Después deben cambiarse en el mapa de OSD utilizando los comandos <command>ceph osd set-nearfull-ratio</command> y <command>ceph osd set-full-ratio</command>.
   </para>
  </tip>

  <variablelist>
   <varlistentry>
    <term>mon osd full ratio</term>
    <listitem>
     <para>
      El porcentaje de espacio en disco utilizado antes de un OSD se considera que está <literal>lleno</literal>. El valor por defecto es .95.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd backfillfull ratio</term>
    <listitem>
     <para>
      El porcentaje de espacio en disco utilizado antes de un OSD se considera que está demasiado <literal>lleno</literal> para la reposición. El valor por defecto es .90.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd nearfull ratio</term>
    <listitem>
     <para>
      El porcentaje de espacio en disco utilizado antes de un OSD se considera que está <literal>casi lleno</literal>. El valor por defecto es .85.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <title>comprobación del peso del OSD</title>
   <para>
    Si algunos OSD están <literal>casi llenos</literal>, pero otros tienen mucha capacidad, es posible que tenga un problema con el peso de CRUSH para los OSD <literal>casi llenos</literal>.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="op-mon-osd-pg">
  <title>Supervisión de los OSD y los grupos de colocación</title>

  <para>
   La alta disponibilidad y la alta confiabilidad requieren un enfoque tolerante a fallos para gestionar problemas de hardware y software. Ceph no tiene un único punto de error y puede atender peticiones de datos en un modo "degradado". La colocación de datos de Ceph introduce una capa de direccionamiento indirecto para garantizar que los datos no se enlacen directamente a determinadas direcciones de OSD. Eso significa que para el seguimiento de los errores del sistema es necesario buscar el grupo de colocación y los OSD subyacentes en la raíz del problema.
  </para>

  <tip>
   <title>acceso en caso de fallo</title>
   <para>
    Un error en una parte del clúster puede impedir que se acceda a un objeto determinado. Eso no significa que no se pueda acceder a otros objetos. Si encuentra un error, siga los pasos para supervisar los OSD y los grupos de colocación. A continuación, comience el proceso de solución de problemas.
   </para>
  </tip>

  <para>
   Ceph, generalmente, se puede autorreparar. Sin embargo, si los problemas persisten, la supervisión de los OSD y los grupos de colocación ayudará a identificar el problema.
  </para>

  <sect2 xml:id="op-mon-osds">
   <title>Supervisión de OSD</title>
   <para>
    El estado de un OSD se encuentra <emphasis>en el clúster</emphasis> ("in") o <emphasis>fuera del clúster</emphasis> ("out"). Al mismo tiempo, está en <emphasis>activo y en ejecución</emphasis> ("up") o <emphasis>desactivado y sin ejecutarse</emphasis> ("down"). Si un OSD está "up", puede estar en el clúster (es posible leer y escribir datos) o fuera del clúster. Si estaba en el clúster y se movió recientemente fuera del clúster, Ceph migrará los grupos de colocación a otros OSD. Si un OSD está fuera del clúster, CRUSH no le asignará grupos de colocación. Si un OSD está "down", también debe estar "out".
   </para>
   <note>
    <title>estado incorrecto</title>
    <para>
     Si un OSD está "down" e "in", hay un problema y el clúster no estará en un estado correcto.
    </para>
   </note>
   <para>
    Si ejecuta un comando como <command>ceph health</command>, <command>ceph -s</command> o <command>ceph -w</command>, puede darse el caso de que el clúster no siempre devuelva el estado <literal>HEALTH OK</literal>. Con respecto a los OSD, debe esperar que el clúster <emphasis>no</emphasis> devuelva <literal>HEALTH OK</literal> en las siguientes circunstancias:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Todavía no ha iniciado el clúster (no responderá).
     </para>
    </listitem>
    <listitem>
     <para>
      Ha iniciado o reiniciado el clúster y aún no está listo, ya que se están creando los grupos de colocación y los OSD están en proceso de emparejamiento.
     </para>
    </listitem>
    <listitem>
     <para>
      Ha añadido o eliminado un OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      Ha modificado el mapa del clúster.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Un aspecto importante de la supervisión de los OSD es asegurarse de que cuando el clúster está activo y en ejecución, todos los OSD del clúster también lo estén. Para comprobar si todos los OSD se están ejecutando, ejecute:
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd stat
x osds: y up, z in; epoch: eNNNN
</screen>
   <para>
    El resultado debería indicarle el número total de OSD (x), cuántos están "up" (y), cuántos están "in" (z) y la época del mapa (eNNNN). Si el número de OSD que están "in" en el clúster es mayor que el número de OSD que están "up", ejecute el comando siguiente para identificar los daemons <literal>ceph-osd</literal> que no se están ejecutando:
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd tree
#ID CLASS WEIGHT  TYPE NAME             STATUS REWEIGHT PRI-AFF
-1       2.00000 pool openstack
-3       2.00000 rack dell-2950-rack-A
-2       2.00000 host dell-2950-A1
0   ssd 1.00000      osd.0                up  1.00000 1.00000
1   ssd 1.00000      osd.1              down  1.00000 1.00000
</screen>
   <para>
    Por ejemplo, si un OSD con ID 1 está inactivo, para iniciarlo:
   </para>
<screen>
<prompt>cephuser@osd &gt; </prompt>sudo systemctl start ceph-<replaceable>CLUSTER_ID</replaceable>@osd.0.service
</screen>
   <para>
    Consulte el <xref linkend="bp-troubleshooting-not-running"/> para consultar los problemas asociados con los OSD que se han detenido o que no se reinician.
   </para>
  </sect2>

  <sect2 xml:id="op-pgsets">
   <title>Asignación de conjuntos de grupos de colocación</title>
   <para>
    Cuando CRUSH asigna grupos de colocación a los OSD, examina el número de réplicas del repositorio y asigna el grupo de colocación a los OSD de forma que cada réplica del grupo de colocación se asigne a un OSD diferente. Por ejemplo, si el repositorio requiere tres réplicas de un grupo de colocación, CRUSH puede asignarlas a <literal>osd.1</literal>, <literal>osd.2</literal> y <literal>osd.3</literal> respectivamente. CRUSH en realidad intenta realizar una colocación seudoaleatoria que tenga en cuenta los dominios de error que establezca en su mapa de CRUSH, por lo que rara vez verá grupos de colocación asignados a los OSD vecinos más cercanos en un clúster grande. El conjunto de OSD que deben contener las réplicas de un grupo de colocación determinado se conoce como <emphasis>conjunto que actúa</emphasis>. En algunos casos, un OSD del conjunto que actúa está inactivo o no puede atender las peticiones de objetos del grupo de colocación. Si se da ese caso, puede deberse a uno de los siguientes escenarios:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Ha añadido o eliminado un OSD. En tal caso, CRUSH reasignó el grupo de colocación a otros OSD y, por lo tanto, cambió la composición del <emphasis>conjunto que actúa</emphasis>, lo que provocó la migración de datos con un proceso de "reposición".
     </para>
    </listitem>
    <listitem>
     <para>
      Un OSD con el estado "down", se ha reiniciado y ahora se está recuperando.
     </para>
    </listitem>
    <listitem>
     <para>
      Un OSD del <emphasis>conjunto que actúa</emphasis> tiene el estado "down" o no puede atender peticiones, y otro OSD ha asumido temporalmente sus funciones.
     </para>
     <para>
      Ceph procesa la petición de un cliente con <emphasis>conjunto activo</emphasis>, que es el conjunto de OSD que realmente controlarán las peticiones. En la mayoría de los casos, el <emphasis>conjunto activo</emphasis> y el <emphasis>conjunto que actúa</emphasis> son prácticamente idénticos. Cuando no lo son, puede indicar que Ceph está migrando datos, que un OSD se está recuperando o que hay un problema (por ejemplo, Ceph suele responde a un estado <literal>HEALTH WARN</literal> con un mensaje "bloqueo obsoleto" en tales casos).
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Para recuperar una lista de grupos de colocación, ejecute:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump
</screen>
   <para>
    Para ver qué OSD están dentro del <emphasis>conjunto que actúa</emphasis> o del <emphasis>conjunto activo</emphasis> para un grupo de colocación determinado, ejecute:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg map <replaceable>PG_NUM</replaceable>
osdmap eNNN pg <replaceable>RAW_PG_NUM</replaceable> (<replaceable>PG_NUM</replaceable>) -&gt; up [0,1,2] acting [0,1,2]
</screen>
   <para>
    El resultado debe indicar la época de osdmap (eNNN), el número del grupo de colocación (<replaceable>PG_NUM</replaceable>), los OSD del <emphasis>conjunto activo</emphasis> ("up") y los OSD del <emphasis>conjunto que actúa</emphasis> ("acting"):
   </para>
   <tip>
    <title>indicador de problema del clúster</title>
    <para>
     Si el <emphasis>conjunto activo</emphasis> y el <emphasis>conjunto que actúa</emphasis> no coinciden, puede ser un indicador de que el clúster se está reequilibrando o de que hay un posible problema con el clúster.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="op-peering">
   <title>Emparejamiento</title>
   <para>
    Para poder escribir datos en un grupo de colocación, este debe estar en un estado <literal>activo</literal> y es recomendable que esté en un estado <literal>limpio</literal>. Para que Ceph determine el estado actual de un grupo de colocación, el OSD primario del grupo de colocación (el primer OSD del <emphasis>conjunto que actúa</emphasis>) se empareja con los OSD secundario y terciario para establecer un acuerdo sobre el estado actual del grupo de colocación (suponiendo que el repositorio tenga tres réplicas del grupo de colocación).
   </para>
   <figure>
    <title>Esquema de emparejamiento</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="op-mon-pg-states">
   <title>Supervisión de los estados del grupo de colocación</title>
   <para>
    Si ejecuta un comando como <command>ceph health</command>, <command>ceph -s</command> o <command>ceph -w</command>, puede darse el caso de que el clúster no siempre devuelva el mensaje <literal>HEALTH OK</literal>. Después de comprobar si los OSD se están ejecutando, también debe comprobar los estados del grupo de colocación.
   </para>
   <para>
    Es previsible que el clúster <emphasis role="bold">no</emphasis> devuelva <literal>HEALTH OK</literal> en varias circunstancias relacionadas con el emparejamiento del grupo de colocación:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Ha creado un repositorio y los grupos de colocación aún no se han emparejado.
     </para>
    </listitem>
    <listitem>
     <para>
      Los grupos de colocación se están recuperando.
     </para>
    </listitem>
    <listitem>
     <para>
      Ha añadido o ha eliminado un OSD del clúster.
     </para>
    </listitem>
    <listitem>
     <para>
      Ha modificado el mapa de CRUSH y los grupos de colocación están migrando.
     </para>
    </listitem>
    <listitem>
     <para>
      Hay datos incoherentes en diferentes réplicas de un grupo de colocación.
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph está borrando de forma segura las réplicas de un grupo de colocación.
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph no tiene suficiente capacidad de almacenamiento para completar las operaciones de reposición.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Si una de las circunstancias mencionadas hace que Ceph devuelva el estado <literal>HEALTH WARN</literal>, no se preocupe. En muchos casos, el clúster se recuperará por sí solo. En algunos casos, es posible que deba tomar alguna medida. Un aspecto importante a la hora de supervisar los grupos de colocación es que debe asegurarse de que cuando el clúster esté activo y en funcionamiento, todos los grupos de colocación deben estar "activos" y, preferiblemente, en un "estado limpio". Para ver el estado de todos los grupos de colocación, ejecute:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg stat
x pgs: y active+clean; z bytes data, aa MB used, bb GB / cc GB avail
</screen>
   <para>
    El resultado debe indicar el número total de grupos de colocación (x); cuántos grupos de colocación están en un estado determinado, como "activo+limpio" (y) y la cantidad de datos almacenados (z).
   </para>
   <para>
    Además de los estados del grupo de colocación, Ceph también devolverá la cantidad de capacidad de almacenamiento utilizada (aa), la cantidad de capacidad de almacenamiento restante (bb) y la capacidad de almacenamiento total para el grupo de colocación. Estos valores pueden ser importantes en algunos casos:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Cuando se está alcanzando la <option>capacidad casi máxima</option> o la <option>capacidad máxima</option>.
     </para>
    </listitem>
    <listitem>
     <para>
      Cuando los datos no se están distribuyendo por el clúster debido a un error en la configuración de CRUSH.
     </para>
    </listitem>
   </itemizedlist>
   <tip>
    <title>ID de grupos de colocación</title>
    <para>
     Los ID de grupo de colocación constan del número de repositorio (no el nombre del repositorio ) seguido de un punto (.) y el ID del grupo de colocación (un número hexadecimal). Puede ver los números de repositorio y sus nombres en el resultado de <command>ceph osd lspools</command>. Por ejemplo, el repositorio por defecto <literal>rbd</literal> corresponde al número de repositorio 0. Un ID de grupo de colocación completo tiene el siguiente formato:
    </para>
<screen>
<replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable>
</screen>
    <para>
     Y, normalmente, este aspecto:
    </para>
<screen>
0.1f
</screen>
   </tip>
   <para>
    Para recuperar una lista de grupos de colocación, ejecute lo siguiente:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump
</screen>
   <para>
    También puede dar al resultado formato JSON y guardarlo en un archivo:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump -o <replaceable>FILE_NAME</replaceable> --format=json
</screen>
   <para>
    Para consultar un grupo de colocación determinado, ejecute lo siguiente:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg <replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable> query
</screen>
   <para>
    En la lista siguiente se describen en detalle los estados habituales del grupo de colocación.
   </para>
   <variablelist>
    <varlistentry>
     <term>CREATING (CREACIÓN)</term>
     <listitem>
      <para>
       Cuando se crea un repositorio, se crea el número de grupos de colocación especificados. Ceph devolverá el mensaje "creating" cuando está creando uno o más grupos de colocación. Cuando se creen, los OSD que formen parte del <emphasis>conjunto que actúa</emphasis> del grupo de colocación se emparejarán. Cuando el emparejamiento se haya completado, el estado del grupo de colocación debe ser "activo+limpio", lo que significa que un cliente de Ceph puede comenzar a escribir en el grupo de colocación.
      </para>
      <figure>
       <title>Estado de los grupos de colocación</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
       </mediaobject>
      </figure>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>PEERING (EMPAREJAMIENTO)</term>
     <listitem>
      <para>
       Cuando Ceph empareja un grupo de colocación, está poniendo de acuerdo los OSD donde se almacenan las réplicas del grupo de colocación sobre el estado de los objetos y los metadatos del grupo de colocación. Cuando Ceph completa el emparejamiento, significa que los OSD donde se almacenan el grupo de colocación están de acuerdo sobre el estado actual de dicho grupo. Sin embargo, que el proceso de emparejamiento haya finalizado <emphasis role="bold">no</emphasis> significa que cada réplica tenga el contenido más reciente.
      </para>
      <note>
       <title>historial oficial</title>
       <para>
        Ceph <emphasis role="bold">no</emphasis> reconocerá una operación de escritura a un cliente hasta que todos los OSD del <emphasis>conjunto que actúa</emphasis> persistan en la operación de escritura. Esta práctica garantiza que al menos un miembro del <emphasis>conjunto que actúa</emphasis> tendrá un registro de cada operación de escritura reconocida desde la última operación de emparejamiento correcta.
       </para>
       <para>
        Con un registro preciso de cada operación de escritura reconocida, Ceph puede construir y ampliar un nuevo historial oficial del grupo de colocación: un conjunto completo y completamente ordenado de operaciones que, si se realiza, actualizaría una copia del OSD de un grupo de colocación.
       </para>
      </note>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>ACTIVE (ACTIVO)</term>
     <listitem>
      <para>
       Cuando Ceph completa el proceso de emparejamiento, un grupo de colocación puede convertirse en <literal>activo</literal>. El estado <literal>activo</literal> significa que los datos del grupo de colocación están generalmente disponibles en el grupo de colocación primario y en las réplicas para las operaciones de lectura y escritura.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>CLEAN (LIMPIO)</term>
     <listitem>
      <para>
       Cuando un grupo de colocación está en estado <literal>limpio</literal>, el OSD primario y los OSD de réplica se han emparejado correctamente y no hay réplicas perdidas para el grupo de colocación. Ceph ha replicado todos los objetos del grupo de colocación el número correcto de veces.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>DEGRADED (DEGRADADO)</term>
     <listitem>
      <para>
       Si un cliente escribe un objeto en el OSD primario, este es responsable de escribir las réplicas en los OSD de réplica. Después de que el OSD primario escriba el objeto en el almacenamiento, el grupo de colocación permanecerá en un estado "degradado" hasta que el OSD primario haya recibido una confirmación de los OSD de réplica de que Ceph ha creado los objetos de réplica correctamente.
      </para>
      <para>
       La razón por la que un grupo de colocación puede tener el estado "activo+degradado" es que un OSD puede estar "activo" aunque aún no contenga todos los objetos. Si un OSD deja de estar activo, Ceph marca cada grupo de colocación asignado al OSD como "degradado". Los OSD deben emparejarse de nuevo cuando el OSD vuelva a funcionar. Sin embargo, un cliente todavía puede escribir un objeto nuevo en un grupo de colocación degradado si su estado es "activo".
      </para>
      <para>
       Si un OSD está "inactivo" y la condición "degradado" persiste, Ceph puede marcar el OSD inactivo como "externo" al clúster y volver a asignar los datos del OSD "inactivo" a otro OSD. El tiempo que transcurre entre que se marca como "inactivo" y se marca como "externo" se controla mediante la opción <option>mon osd out interval</option>, que se establece en 600 segundos por defecto.
      </para>
      <para>
       Un grupo de colocación también puede estar "degradado" porque Ceph no pueda encontrar uno o varios objetos que deberían estar en el grupo de colocación. Aunque no puede leer ni escribir en objetos no encontrados, puede acceder a todos los demás objetos del grupo de colocación "degradado".
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>RECOVERING (EN RECUPERACIÓN)</term>
     <listitem>
      <para>
       Ceph se ha diseñado para la tolerancia a fallos a una escala en la que los problemas de hardware y software son continuos. Cuando un OSD está "inactivo", su contenido puede quedar obsoleto respecto al de otras réplicas de los grupos de colocación. Cuando el OSD vuelve a estar "activo", el contenido de los grupos de colocación debe actualizarse para reflejar el estado actual. Durante ese período de tiempo, el OSD puede mostrar el estado de "en recuperación".
      </para>
      <para>
       La recuperación no siempre es sencilla, ya que un error de hardware puede provocar un error en cascada de varios OSD. Por ejemplo, puede fallar un conmutador de red de un bastidor o un archivador, lo que puede provocar que el estado actual de los OSD de varias máquinas host quede retrasado respecto al clúster. Cada uno de los OSD debe recuperarse cuando se resuelva el error.
      </para>
      <para>
       Ceph proporciona varios ajustes para equilibrar la contención de los recursos entre las peticiones de servicio nuevas y la necesidad de recuperar objetos de datos y restaurar los grupos de colocación al estado actual. El valor <option>osd recovery delay start</option> permite que un OSD se reinicie, vuelva a emparejarse e, incluso, que procese algunas peticiones de respuesta antes de iniciar el proceso de recuperación. El valor <option>osd recovery thread timeout</option> define un tiempo límite del hilo, ya que varios OSD pueden fallar, reiniciarse y volver a emparejarse escalonadamente. El valor <option>osd recovery max active</option> limita el número de peticiones de recuperación que un OSD procesará simultáneamente para evitar que el OSD no pueda atender las peticiones. El valor <option>osd recovery max chunk</option> limita el tamaño de los fragmentos de datos recuperados para evitar la congestión de la red.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>BACK FILLING (EN REPOSICIÓN)</term>
     <listitem>
      <para>
       Cuando un nuevo OSD se une al clúster, CRUSH reasignará los grupos de colocación de los OSD del clúster al OSD recién añadido. Forzar al nuevo OSD a aceptar los grupos de colocación reasignados de inmediato, podría suponer una carga excesiva en el OSD nuevo. Al reponer los grupos de colocación en el OSD, este proceso puede comenzar en segundo plano. Una vez completado la reposición, el nuevo OSD comenzará a atender las peticiones cuando esté listo.
      </para>
      <para>
       Durante las operaciones de reposición, es posible que vea uno de estos estados: "backfill_wait" indica que una operación de reposición está pendiente, pero aún no está en curso; "backfill" indica que una operación de reposición está en curso; "backfill_too_full" indica que se ha solicitado una operación de reposición, pero no se ha podido completar debido a que no hay capacidad de almacenamiento suficiente. Si no se puede realizar la reposición de un grupo de colocación, puede considerarse como "incompleto".
      </para>
      <para>
       Ceph proporciona varios ajustes para gestionar la carga asociada con la reasignación de grupos de colocación a un OSD (especialmente un OSD nuevo). Por defecto, <option>osd max backfills</option> define que el número máximo de reposiciones simultáneas hacia o desde un OSD sea de 10. El valor <option>backfill full ratio</option> permite que un OSD rechace una petición de reposición si el OSD se acerca a su capacidad máxima (90 %, por defecto), que se cambia con <command>ceph osd set-backfillfull-ratio</command>. Si un OSD rechaza una petición de reposición, el valor <option>osd backfill retry interval</option> permite que un OSD vuelva a intentar la petición (después de 10 segundos, por defecto). También es posible definir en los OSD los valores <option>osd backfill scan min</option> y <option>osd backfill scan max</option> para gestionar los intervalos de escaneo (64 y 512, por defecto).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>REMAPPED (REASIGNADO)</term>
     <listitem>
      <para>
       Cuando cambia el <emphasis>conjunto que actúa</emphasis> que atiende a un grupo de colocación, los datos migran del <emphasis>conjunto que actúa</emphasis> antiguo al nuevo<emphasis/>. El nuevo OSD primario puede tardar algún tiempo en atender las peticiones de servicio. Por lo tanto, puede pedir al OSD primario antiguo que continúe atendiendo las peticiones hasta que se complete la migración del grupo de colocación. Cuando se completa la migración de los datos, la asignación utiliza el OSD primario del <emphasis>conjunto que actúa</emphasis> nuevo.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>STALE (OBSOLETO)</term>
     <listitem>
      <para>
       Mientras Ceph utiliza subejecución de réplica para asegurarse de que los hosts y los daemons se están ejecutando, los daemons <literal>ceph-osd</literal> también pueden entrar en estado "bloqueo", en el que no informan sobre las estadísticas a tiempo (por ejemplo, si se produce un error temporal de la red). Por defecto, los daemons de OSD informan de las estadísticas de su grupo de colocación, del arranque y de los errores cada medio segundo (0,5), que es una frecuencia mayor a la de los umbrales de subejecución de réplica. Si el OSD primario del <emphasis>conjunto que actúa</emphasis> de un grupo de colocación no informa al monitor, o si otros OSD han informado de que el OSD primario está "inactivo", los monitores marcarán el grupo de colocación como "obsoleto".
      </para>
      <para>
       Al iniciar el clúster, es común ver el estado "obsoleto" hasta que se completa el proceso de emparejamiento. Después de que el clúster se haya estado ejecutando durante un tiempo, ver grupos de colocación con el estado "obsoleto" indica que el OSD primario para esos grupos de colocación está inactivo o no informa sobre las estadísticas del grupo de colocación al monitor.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="op-pg-objectfinding">
   <title>Búsqueda de una ubicación de objeto</title>
   <para>
    Para almacenar datos de objetos en el almacén de objetos de Ceph, es preciso que un cliente de Ceph defina un nombre de objeto y que especifique un repositorio relacionado. El cliente de Ceph recupera el mapa más reciente del clúster y el algoritmo CRUSH calcula cómo asignar el objeto a un grupo de colocación. A continuación, calcula cómo asignar el grupo de colocación a un OSD dinámicamente. Para localizar la ubicación del objeto, solo se necesita el nombre del objeto y el nombre del repositorio. Por ejemplo:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd map <replaceable>POOL_NAME</replaceable> <replaceable>OBJECT_NAME</replaceable> [<replaceable>NAMESPACE</replaceable>]
</screen>
   <example>
    <title>Localización de un objeto</title>
    <para>
     Como ejemplo, vamos a crear un objeto. Especifique el nombre de objeto "test-object-1", una vía al archivo de ejemplo "testfile.txt" que contiene algunos datos de objeto y el nombre de repositorio "data". Para ellos utilizaremos el comando <command>rados put</command> en la línea de comandos:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados put test-object-1 testfile.txt --pool=data
</screen>
    <para>
     Para verificar que el almacén de objetos de Ceph ha almacenado el objeto, ejecute lo siguiente:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados -p data ls
</screen>
    <para>
     Ahora, identifique la ubicación del objeto. Ceph generará la ubicación del objeto:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd map data test-object-1
osdmap e537 pool 'data' (0) object 'test-object-1' -&gt; pg 0.d1743484 \
(0.4) -&gt; up ([1,0], p0) acting ([1,0], p0)
</screen>
    <para>
     Para eliminar el objeto de ejemplo, basta con eliminarlo usando el comando <command>rados rm</command>:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados rm test-object-1 --pool=data
</screen>
   </example>
  </sect2>
 </sect1>
</chapter>
