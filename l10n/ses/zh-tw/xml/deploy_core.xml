<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deploy_core.xml" version="5.0" xml:id="deploy-core">
 <info>
  <title>使用 cephadm 部署其餘核心服務</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  部署基本 Ceph 叢集之後，請將核心服務部署到更多叢集節點。為使用戶端能夠存取叢集資料，還需要部署額外的服務。
 </para>
 <para>
  目前，我們支援使用 Ceph orchestrator (<command>ceph orch</command> 子指令) 在指令行上部署 Ceph 服務。
 </para>
 <sect1 xml:id="deploy-cephadm-day2-orch">
  <title><command>ceph orch</command> 指令</title>

  <para>
   Ceph orchestrator 指令 <command>ceph orch</command> 是 cephadm 模組的介面，它負責列出叢集元件並在新的叢集節點上部署 Ceph 服務。
  </para>

  <sect2 xml:id="deploy-cephadm-day2-orch-status">
   <title>顯示 orchestrator 狀態</title>
   <para>
    以下指令會顯示目前模式和 Ceph orchestrator 的狀態。
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch status</screen>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-orch-list">
   <title>列出裝置、服務和精靈</title>
   <para>
    若要列出所有磁碟裝置，請執行以下指令：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch device ls
Hostname   Path      Type  Serial  Size   Health   Ident  Fault  Available
ses-master /dev/vdb  hdd   0d8a... 10.7G  Unknown  N/A    N/A    No
ses-min1   /dev/vdc  hdd   8304... 10.7G  Unknown  N/A    N/A    No
ses-min1   /dev/vdd  hdd   7b81... 10.7G  Unknown  N/A    N/A    No
[...]
</screen>
   <tip>
    <title>服務和精靈</title>
    <para>
     <emphasis>服務</emphasis>是表示特定類型的 Ceph 服務的一般術語，例如 Ceph 管理員。
    </para>
    <para>
     <emphasis>精靈</emphasis>表示服務的特定例項，例如在名為 <literal>ses-min1</literal> 的節點上執行的程序 <literal>mgr.ses-min1.gdlcik</literal>。
    </para>
   </tip>
   <para>
    若要列出 cephadm 已知的所有服務，請執行：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch ls
NAME  RUNNING  REFRESHED  AGE  PLACEMENT  IMAGE NAME                  IMAGE ID
mgr       1/0  5m ago     -    &lt;no spec&gt;  registry.example.com/[...]  5bf12403d0bd
mon       1/0  5m ago     -    &lt;no spec&gt;  registry.example.com/[...]  5bf12403d0bd
</screen>
   <tip>
    <para>
     您可以使用選擇性的 <option>-–host</option> 參數使清單僅顯示特定節點上的服務，也可使用選擇性的 <option>--service-type</option> 參數使清單僅顯示特定類型的服務。可接受的類型有 <literal>mon</literal>、<literal>osd</literal>、<literal>mgr</literal>、<literal>mds</literal> 和 <literal>rgw</literal>。
    </para>
   </tip>
   <para>
    若要列出由 cephadm 部署的所有執行中精靈，請執行：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch ps
NAME            HOST     STATUS   REFRESHED AGE VERSION    IMAGE ID     CONTAINER ID
mgr.ses-min1.gd ses-min1 running) 8m ago    12d 15.2.0.108 5bf12403d0bd b8104e09814c
mon.ses-min1    ses-min1 running) 8m ago    12d 15.2.0.108 5bf12403d0bd a719e0087369
</screen>
   <tip>
    <para>
     若要查詢某個特定精靈的狀態，請使用 <option>--daemon_type</option> 和 <option>--daemon_id</option>。對於 OSD，ID 為數字 OSD ID。對於 MDS，ID 為檔案系統名稱：
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch ps --daemon_type osd --daemon_id 0
<prompt>cephuser@adm &gt; </prompt>ceph orch ps --daemon_type mds --daemon_id my_cephfs
</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="cephadm-service-and-placement-specs">
  <title>服務和放置規格</title>

  <para>
   指定 Ceph 服務部署的推薦方法是建立一個 YAML 格式的檔案，其中包含所要部署服務的規格。
  </para>

  <sect2 xml:id="cephadm-service-spec">
   <title>建立服務規格</title>
   <para>
    您可以為每種類型的服務建立單獨的規格檔案，例如：
   </para>
<screen>
<prompt>root@master # </prompt>cat nfs.yml
service_type: nfs
service_id: <replaceable>EXAMPLE_NFS</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
spec:
  pool: <replaceable>EXAMPLE_POOL</replaceable>
  namespace: <replaceable>EXAMPLE_NAMESPACE</replaceable>
</screen>
   <para>
    或者，您可以在一個描述哪些節點將執行特定服務的檔案 (例如 <filename>cluster.yml</filename>) 中指定多個 (或所有) 服務類型。請記得使用三個破折號 (<literal>---</literal>) 分隔各個服務類型：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>cat cluster.yml
service_type: nfs
service_id: <replaceable>EXAMPLE_NFS</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
spec:
  pool: <replaceable>EXAMPLE_POOL</replaceable>
  namespace: <replaceable>EXAMPLE_NAMESPACE</replaceable>
---
service_type: rgw
service_id: <replaceable>REALM_NAME</replaceable>.<replaceable>ZONE_NAME</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
---
[...]
</screen>
   <para>
    上述內容的含義如下：
   </para>
   <variablelist>
    <varlistentry>
     <term><literal>service_type</literal></term>
     <listitem>
      <para>
       服務的類型。它可以是 Ceph 服務 (<literal>mon</literal>、<literal>mgr</literal>、<literal>mds</literal>、<literal>crash</literal>、<literal>osd</literal> 或 <literal>rbd-mirror</literal>)、閘道 (<literal>nfs</literal> 或 <literal>rgw</literal>) 或部分監控堆疊 (<literal>alertmanager</literal>、<literal>grafana</literal>、<literal>node-exporter</literal> 或 <literal>prometheus</literal>)。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>service_id</literal></term>
     <listitem>
      <para>
       服務的名稱。<literal>mon</literal>、<literal>mgr</literal>、<literal>alertmanager</literal>、<literal>grafana</literal>、<literal>node-exporter</literal> 和 <literal>prometheus</literal> 類型的規格不需要 <literal>service_id</literal> 內容。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>placement</literal></term>
     <listitem>
      <para>
       指定哪些節點將執行服務。如需更多詳細資料，請參閱<xref linkend="cephadm-placement-specs"/>。
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><literal>spec</literal></term>
     <listitem>
      <para>
       與服務類型相關的其他規格。
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <tip>
    <title>套用特定服務</title>
    <para>
     Ceph 叢集服務通常具有許多專屬內容。如需各個服務規格的範例和詳細資料，請參閱<xref linkend="deploy-cephadm-day2-services"/>。
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="cephadm-placement-specs">
   <title>建立放置規格</title>
   <para>
    若要部署 Ceph 服務，cephadm 需要知道要在其上部署這些服務的節點。請使用 <literal>placement</literal> 內容並列出要套用服務的節點的主機簡短名稱：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>cat cluster.yml
[...]
placement:
  hosts:
  - host1
  - host2
  - host3
[...]
</screen>
  </sect2>

  <sect2 xml:id="cephadm-apply-cluster-specs">
   <title>套用叢集規格</title>
   <para>
    建立包含所有服務及其放置的規格的完整 <filename>cluster.yml</filename> 檔案後，您便可透過執行以下指令來套用叢集：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i cluster.yml</screen>
   <para>
    若要檢視叢集的狀態，請執行 <command>ceph orch status</command> 指令。如需詳細資訊，請參閱<xref linkend="deploy-cephadm-day2-orch-status"/>。
   </para>
  </sect2>

  <sect2 xml:id="cephadm-apply-cluster-specs-">
   <title>輸出執行中叢集的規格</title>
   <para>
    雖然您使用<xref linkend="cephadm-service-and-placement-specs"/>中所述的規格檔案將服務部署到 Ceph 叢集，但在實際操作期間，叢集的組態可能會偏離原始規格。另外，您也可能會無意間移除規格檔案。
   </para>
   <para>
    若要擷取執行中叢集的完整規格，請執行：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch ls --export
placement:
  hosts:
  - hostname: ses-min1
    name: ''
    network: ''
service_id: my_cephfs
service_name: mds.my_cephfs
service_type: mds
---
placement:
  count: 2
service_name: mgr
service_type: mgr
---
[...]
</screen>
   <tip>
    <para>
     您可以附加 <option>--format</option> 選項以變更預設的 <literal>yaml</literal> 輸出格式。您可以從 <literal>json</literal>、<literal>json-pretty</literal> 或 <literal>yaml</literal> 中進行選取。例如：
    </para>
<screen>ceph orch ls --export --format json</screen>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="deploy-cephadm-day2-services">
  <title>部署 Ceph 服務</title>

  <para>
   在執行基本叢集之後，您可以將 Ceph 服務部署到其他節點。
  </para>

  <sect2 xml:id="deploy-cephadm-day2-service-mon">
   <title>部署 Ceph 監控程式和 Ceph 管理員</title>
   <para>
    Ceph 叢集的不同節點之間部署了三個或五個 MON。如果叢集中有五個或更多節點，則建議部署五個 MON。好的做法是，將 MGR 部署在與 MON 相同的節點上。
   </para>
   <important>
    <title>包含開機 MON</title>
    <para>
     在部署 MON 和 MGR 時，請記得包含在<xref linkend="deploy-cephadm-configure-mon"/>中設定基本叢集時新增的第一個 MON。
    </para>
   </important>
   <para>
    若要部署 MON，請套用以下規格：
   </para>
<screen>
service_type: mon
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
</screen>
   <note>
    <para>
     如果需要新增另一個節點，請在同一 YAML 清單中附加主機名稱。例如：
    </para>
<screen>
service_type: mon
placement:
 hosts:
 - ses-min1
 - ses-min2
 - ses-min3
 - ses-min4
</screen>
   </note>
   <para>
    同樣，若要部署 MGR，請套用以下規格：
   </para>
   <important>
    <para>
     確定您的部署在每個部署中至少具有三個 Ceph 管理員。
    </para>
   </important>
<screen>
service_type: mgr
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
</screen>
   <tip>
    <para>
     如果 MON 或 MGR <emphasis>不</emphasis>在同一子網路中，則需要附加子網路位址。例如：
    </para>
<screen>
service_type: mon
placement:
  hosts:
  - ses-min1:10.1.2.0/24
  - ses-min2:10.1.5.0/24
  - ses-min3:10.1.10.0/24
</screen>
   </tip>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-osd">
   <title>部署 Ceph OSD</title>
   <important>
    <title>當儲存裝置可用時</title>
    <para>
     如果滿足以下所有條件，則儲存裝置將被視為<emphasis>可用</emphasis>：
    </para>
    <itemizedlist>
     <listitem>
      <para>
       裝置沒有分割區。
      </para>
     </listitem>
     <listitem>
      <para>
       裝置沒有任何 LVM 狀態。
      </para>
     </listitem>
     <listitem>
      <para>
       裝置未掛接。
      </para>
     </listitem>
     <listitem>
      <para>
       裝置不包含檔案系統。
      </para>
     </listitem>
     <listitem>
      <para>
       裝置不包含 BlueStore OSD。
      </para>
     </listitem>
     <listitem>
      <para>
       裝置大於 5 GB。
      </para>
     </listitem>
    </itemizedlist>
    <para>
     如果不滿足上述條件，Ceph 將拒絕佈建此類 OSD。
    </para>
   </important>
   <para>
    可以使用以下兩種方式來部署 OSD：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      告知 Ceph 使用所有可用和未使用的儲存裝置：
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply osd --all-available-devices</screen>
    </listitem>
    <listitem>
     <para>
      使用 DriveGroups (參閱<xref linkend="drive-groups"/>) 建立 OSD 規格，該規格描述了將依據裝置內容 (例如裝置類型 (SSD 或 HDD)、裝置型號名稱、大小或裝置所在的節點) 部署的裝置。然後透過執行以下指令套用規格：
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply osd -i drive_groups.yml</screen>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-mds">
   <title>部署中繼資料伺服器</title>
   <para>
    CephFS 需要一或多個中繼資料伺服器 (MDS) 服務。若要建立 CephFS，首先要透過套用以下規格來建立 MDS 伺服器：
   </para>
   <note>
    <para>
     在套用以下規格之前，請確定至少建立了兩個池，一個用於儲存 CephFS 資料，另一個用於儲存 CephFS 中繼資料。
    </para>
   </note>
<screen>
service_type: mds
service_id: <replaceable>CEPHFS_NAME</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
</screen>
   <para>
    MDS 正常執行後，建立 CephFS：
   </para>
<screen>ceph fs new <replaceable>CEPHFS_NAME</replaceable> <replaceable>metadata_pool</replaceable> <replaceable>data_pool</replaceable></screen>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-ogw">
   <title>部署物件閘道</title>
   <para>
    cephadm 會將物件閘道部署為管理特定<emphasis>領域</emphasis>和<emphasis>區域</emphasis>的精靈的集合。
   </para>
   <para>
    您可以將物件閘道服務與現有的領域和區域相關聯 (如需更多詳細資料，請參閱<xref linkend="ceph-rgw-fed"/>)，也可以指定不存在的 <replaceable>REALM_NAME</replaceable> 和 <replaceable>ZONE_NAME</replaceable>，套用以下組態後會自動建立相應領域和區域：
   </para>
<screen>
service_type: rgw
service_id: <replaceable>REALM_NAME</replaceable>.<replaceable>ZONE_NAME</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
spec:
  rgw_realm: <replaceable>RGW_REALM</replaceable>
  rgw_zone: <replaceable>RGW_ZONE</replaceable>
</screen>
   <sect3 xml:id="cephadm-deploy-using-secure-ssl-access">
    <title>使用安全 SSL 存取</title>
    <para>
     若要使用連接至物件閘道的安全 SSL 連接，您需要一組有效的 SSL 證書和金鑰檔案 (如需更多詳細資料，請參閱<xref linkend="ceph-rgw-https"/>)。您需要啟用 SSL，指定 SSL 連接的連接埠號碼以及 SSL 證書和金鑰檔案。
    </para>
    <para>
     若要啟用 SSL 並指定連接埠號碼，請在規格中包含以下內容：
    </para>
<screen>
spec:
  ssl: true
  rgw_frontend_port: 443
</screen>
    <para>
     若要指定 SSL 證書和金鑰，可以將其內容直接貼至 YAML 規格檔案中。行末的縱線符號 (<literal>|</literal>) 告知剖析程式預期的值為多行字串。例如：
    </para>
<screen>
spec:
  ssl: true
  rgw_frontend_port: 443
  rgw_frontend_ssl_certificate: |
   -----BEGIN CERTIFICATE-----
   MIIFmjCCA4KgAwIBAgIJAIZ2n35bmwXTMA0GCSqGSIb3DQEBCwUAMGIxCzAJBgNV
   BAYTAkFVMQwwCgYDVQQIDANOU1cxHTAbBgNVBAoMFEV4YW1wbGUgUkdXIFNTTCBp
   [...]
   -----END CERTIFICATE-----
   rgw_frontend_ssl_key: |
   -----BEGIN PRIVATE KEY-----
   MIIJRAIBADANBgkqhkiG9w0BAQEFAASCCS4wggkqAgEAAoICAQDLtFwg6LLl2j4Z
   BDV+iL4AO7VZ9KbmWIt37Ml2W6y2YeKX3Qwf+3eBz7TVHR1dm6iPpCpqpQjXUsT9
   [...]
   -----END PRIVATE KEY-----
</screen>
    <tip>
     <para>
      您可以省略 <literal>rgw_frontend_ssl_certificate:</literal> 和 <literal>rgw_frontend_ssl_key:</literal> 關鍵字，並將它們上傳到組態資料庫，而不是粘貼 SSL 證書和金鑰檔案的內容：
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config-key set rgw/cert/<replaceable>REALM_NAME</replaceable>/<replaceable>ZONE_NAME</replaceable>.crt \
 -i <replaceable>SSL_CERT_FILE</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph config-key set rgw/cert/<replaceable>REALM_NAME</replaceable>/<replaceable>ZONE_NAME</replaceable>.key \
 -i <replaceable>SSL_KEY_FILE</replaceable>
</screen>
    </tip>
    <sect4 xml:id="cephadm-deploy-ogw-ports">
     <title>將物件閘道設定為同時監聽連接埠 443 和 80</title>
     <para>
      若要將物件閘道設定為同時監聽連接埠 443 (HTTPS) 和 80 (HTTP)，請執行以下步驟：
     </para>
     <note>
      <para>
       該程序中的指令使用 <literal>default</literal> 領域和區域。
      </para>
     </note>
     <procedure>
      <step>
       <para>
        提供規格檔案以部署物件閘道。如需物件閘道規格的更多詳細資訊，請參閱<xref linkend="deploy-cephadm-day2-service-ogw"/>。使用以下指令：
       </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>SPEC_FILE</replaceable></screen>
      </step>
      <step>
       <para>
        如果規格檔案中未提供 SSL 證書，請使用以下指令新增證書：
       </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config-key set rgw/cert/default/default.crt -i certificate.pem
<prompt>cephuser@adm &gt; </prompt>ceph config-key set rgw/cert/default/default.key -i key.pem
</screen>
      </step>
      <step>
       <para>
        變更 <option>rgw_frontends</option> 選項的預設值：
       </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set client.rgw.default.default rgw_frontends \
 "beast port=80 ssl_port=443"
</screen>
      </step>
      
      <step>
       <para>
        移除 cephadm 建立的特定組態。執行以下指令以識別 <option>rgw_frontends</option> 選項是為哪個目標設定的：
       </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config dump | grep rgw</screen>
       <para>
        例如，目標是 <literal>client.rgw.default.default.node4.yiewdu</literal>。移除 <option>rgw_frontends</option> 目前的具體值：
       </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm client.rgw.default.default.node4.yiewdu rgw_frontends</screen>
       <tip>
        <para>
         您也可以不移除 <option>rgw_frontends</option> 的值，而是指定其值。例如：
        </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set client.rgw.default.default.node4.yiewdu \
 rgw_frontends "beast port=80 ssl_port=443"
</screen>
       </tip>
      </step>
      
      <step>
       <para>
        重新啟動物件閘道：
       </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch restart rgw.default.default</screen>
      </step>
     </procedure>
    </sect4>
   </sect3>
   <sect3 xml:id="cephadm-deploy-with-subcluster">
    <title>使用子叢集部署</title>
    <para>
     <emphasis>子叢集</emphasis>可協助您組織叢集中的節點，以隔離工作負載，讓彈性縮放更輕鬆。如果使用子叢集進行部署，請套用以下組態：
    </para>
<screen>
service_type: rgw
service_id: <replaceable>REALM_NAME</replaceable>.<replaceable>ZONE_NAME</replaceable>.<replaceable>SUBCLUSTER</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
spec:
  rgw_realm: <replaceable>RGW_REALM</replaceable>
  rgw_zone: <replaceable>RGW_ZONE</replaceable>
  subcluster: <replaceable>SUBCLUSTER</replaceable>
</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-igw">
   <title>部署 iSCSI 閘道</title>
   <para>
    cephadm 可部署 iSCSI 閘道，它是一種儲存區域網路 (SAN) 通訊協定，可讓用戶端 (稱為啟動器) 將 SCSI 指令傳送至遠端伺服器上的 SCSI 儲存裝置 (目標)。
   </para>
   <para>
    套用以下組態進行部署。確定 <literal>trusted_ip_list</literal> 包含所有 iSCSI 閘道和 Ceph 管理員節點的 IP 位址 (請參閱下面的輸出範例)。
   </para>
   <note>
    <para>
     請確定在套用以下規格之前建立池。
    </para>
   </note>
<screen>
service_type: iscsi
service_id: <replaceable>EXAMPLE_ISCSI</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
spec:
  pool: <replaceable>EXAMPLE_POOL</replaceable>
  api_user: <replaceable>EXAMPLE_USER</replaceable>
  api_password: <replaceable>EXAMPLE_PASSWORD</replaceable>
  trusted_ip_list: "<replaceable>IP_ADDRESS_1</replaceable>,<replaceable>IP_ADDRESS_2</replaceable>"
</screen>
   <note>
    <para>
     請確定針對 <literal>trusted_ip_list</literal> 列出的 IP 在逗號分隔後<emphasis>沒有</emphasis>空白。
    </para>
   </note>
   <sect3>
    <title>安全 SSL 組態</title>
    <para>
     若要在 Ceph Dashboard 和 iSCSI 目標 API 之間使用安全 SSL 連接，您需要一組有效的 SSL 證書和金鑰檔案。它們可以是 CA 核發的，也可以是自行簽署的 (參閱<xref linkend="self-sign-certificates"/>)。若要啟用 SSL，請在您的規格檔案中包含 <literal>api_secure: true</literal> 設定：
    </para>
<screen>
spec:
  api_secure: true
</screen>
    <para>
     若要指定 SSL 證書和金鑰，可以將其內容直接貼至 YAML 規格檔案中。行末的縱線符號 (<literal>|</literal>) 告知剖析程式預期的值為多行字串。例如：
    </para>
<screen>
spec:
  pool: EXAMPLE_POOL
  api_user: EXAMPLE_USER
  api_password: EXAMPLE_PASSWORD
  trusted_ip_list: "IP_ADDRESS_1,IP_ADDRESS_2"
  api_secure: true
  ssl_cert: |
    -----BEGIN CERTIFICATE-----
    MIIDtTCCAp2gAwIBAgIYMC4xNzc1NDQxNjEzMzc2MjMyXzxvQ7EcMA0GCSqGSIb3
    DQEBCwUAMG0xCzAJBgNVBAYTAlVTMQ0wCwYDVQQIDARVdGFoMRcwFQYDVQQHDA5T
    [...]
    -----END CERTIFICATE-----
  ssl_key: |
    -----BEGIN PRIVATE KEY-----
    MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC5jdYbjtNTAKW4
    /CwQr/7wOiLGzVxChn3mmCIF3DwbL/qvTFTX2d8bDf6LjGwLYloXHscRfxszX/4h
    [...]
    -----END PRIVATE KEY-----
</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-nfs">
   <title>部署 NFS Ganesha</title>
    
<important>
 <para>
  NFS Ganesha 支援 NFS 4.1 和更新版本，不支援 NFS 3 版本。
 </para>
</important>

    <para>
    cephadm 可使用預先定義的 RADOS 池和選擇性的名稱空間來部署 NFS Ganesha。若要部署 NFS Ganesha，請套用以下規格：
   </para>
   <note>
    <para>
     您需要有一個預先定義的 RADOS 池，否則 <command>ceph orch apply</command> 操作將失敗。如需建立池的詳細資訊，請參閱<xref linkend="ceph-pools-operate-add-pool"/>。
    </para>
   </note>
<screen>
service_type: nfs
service_id: <replaceable>EXAMPLE_NFS</replaceable>
placement:
  hosts:
  - ses-min1
  - ses-min2
spec:
  pool: <replaceable>EXAMPLE_POOL</replaceable>
  namespace: <replaceable>EXAMPLE_NAMESPACE</replaceable>
</screen>
   <itemizedlist>
    <listitem>
     <para>
      <replaceable>EXAMPLE_NFS</replaceable>，包含用於識別 NFS 輸出項的任意字串。
     </para>
    </listitem>
    <listitem>
     <para>
      <replaceable>EXAMPLE_POOL</replaceable>，包含將要儲存 NFS Ganesha RADOS 組態物件的池的名稱。
     </para>
    </listitem>
    <listitem>
     <para>
      <replaceable>EXAMPLE_NAMESPACE</replaceable> (選擇性)，包含所需的物件閘道 NFS 名稱空間 (例如，<literal>ganesha</literal>)。
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-rbdmirror">
   <title>部署 <systemitem class="daemon">rbd-mirror</systemitem></title>
   <para>
    <systemitem class="daemon">rbd-mirror</systemitem> 服務負責在兩個 Ceph 叢集之間同步 RADOS 區塊裝置影像 (如需更多詳細資料，請參閱<xref linkend="ceph-rbd-mirror"/>)。若要部署 <systemitem class="daemon">rbd-mirror</systemitem>，請使用以下規格：
   </para>
<screen>
service_type: rbd-mirror
service_id: <replaceable>EXAMPLE_RBD_MIRROR</replaceable>
placement:
  hosts:
  - ses-min3
</screen>
  </sect2>

  <sect2 xml:id="deploy-cephadm-day2-service-monitoring">
   <title>部署監控堆疊</title>
   <para>
    監控堆疊包含 Prometheus、Prometheus 輸出程式、Prometheus 警示管理員和 Grafana。Ceph Dashboard 使用這些元件來儲存並直觀呈現有關叢集使用率和效能的詳細度量。
   </para>
   <tip>
    <para>
     如果您的部署需要監控堆疊服務的自訂或本地提供的容器影像，請參閱<xref linkend="monitoring-custom-images"/>。
    </para>
   </tip>
   <para>
    若要部署監控堆疊，請執行以下步驟：
   </para>
   <procedure>
    <step>
     <para>
      在 Ceph 管理員精靈中啟用 <literal>prometheus</literal> 模組。這將公開內部 Ceph 度量，以便 Prometheus 可以讀取這些資訊：
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph mgr module enable prometheus</screen>
     <note>
      <para>
       請確定在部署 Prometheus 之前執行此指令。如果部署前未執行該指令，則必須重新部署 Prometheus 才能更新 Prometheus 的組態：
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch redeploy prometheus</screen>
     </note>
    </step>
    <step>
     <para>
      建立包含如下內容的規格檔案 (例如 <filename>monitoring.yaml</filename>)：
     </para>
<screen>
service_type: prometheus
placement:
  hosts:
  - ses-min2
---
service_type: node-exporter
---
service_type: alertmanager
placement:
  hosts:
  - ses-min4
---
service_type: grafana
placement:
  hosts:
  - ses-min3
</screen>
    </step>
    <step>
     <para>
      透過執行以下指令套用監控服務：
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i monitoring.yaml</screen>
     <para>
      部署監控服務可能需要一到兩分鐘。
     </para>
    </step>
   </procedure>
   <important>
    <para>
     Prometheus、Grafana 和 Ceph Dashboard 全都會自動設定為相互通訊，因此如上述般進行部署時，Ceph Dashboard 中將實現功能完整的 Grafana 整合。
    </para>
    <para>
     但使用 RBD 影像進行監控時不適用於此規則。如需詳細資訊，請參閱<xref linkend="monitoring-rbd-image"/>。
    </para>
   </important>
  </sect2>
 </sect1>
</chapter>
