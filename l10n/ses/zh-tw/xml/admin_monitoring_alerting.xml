<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_monitoring_alerting.xml" version="5.0" xml:id="monitoring-alerting">
 <title>監控和警示</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  在 SUSE Enterprise Storage 7.1 中，cephadm 會部署一個監控和警示堆疊。使用者需要在 YAML 組態檔案中定義要使用 cephadm 部署的服務 (例如 Prometheus、警示管理員和 Grafana)，也可以使用 CLI 來部署這些服務。當部署多個相同類型的服務時，會部署高可用性設定。但 Node Exporter 不適用於此規則。
 </para>
 <para>
  使用 cephadm 可以部署以下監控服務：
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis role="bold">Prometheus</emphasis> 是監控和警示工具套件。它會收集 Prometheus 輸出程式提供的資料，並在達到預先定義的閾值時觸發預先設定的警示。
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Alertmanager</emphasis> 用於處理 Prometheus 伺服器傳送的警示。它將負責重複資訊刪除、分組並將警示路由到正確的接收器。依預設，Ceph Dashboard 將自動設定為接收器。
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Grafana</emphasis> 是虛擬化和警示軟體。此監控堆疊不使用 Grafana 的警示功能。而是使用警示管理員進行警示。
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Node Exporter</emphasis> 是 Prometheus 的輸出程式，用於提供其所安裝到之節點的相關資料。建議您在所有節點上安裝 Node Exporter。
   </para>
  </listitem>
 </itemizedlist>
 <para>
  Prometheus 管理員模組提供了 Prometheus 輸出程式，可從 <literal>ceph-mgr</literal> 中的收集點傳遞 Ceph 效能計數器。
 </para>
 <para>
  Prometheus 組態 (包括<emphasis>抓取</emphasis>目標 (度量提供精靈)) 由 cephadm 自動設定。cephadm 還會部署預設警示清單，例如 <literal>health error</literal>、<literal>10% OSDs down</literal> 或 <literal>pgs inactive</literal>。
 </para>
 <para>
  依預設，傳送到 Grafana 的流量會使用 TLS 加密。您可以提供自己的 TLS 證書，也可以使用自行簽署的證書。如果在部署 Grafana 之前未設定自訂證書，則將自動為 Grafana 建立和設定自行簽署的證書。
 </para>
 <para>
  可以透過執行以下步驟來為 Grafana 設定自訂證書：
 </para>
 <procedure>
  <step>
   <para>
    設定證書檔案：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_key -i $PWD/key.pem
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_crt -i $PWD/certificate.pem
</screen>
  </step>
  <step>
   <para>
    重新啟動 Ceph 管理員服務：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch restart mgr</screen>
  </step>
  <step>
   <para>
    重新設定 Grafana 服務，以反映新證書路徑並為 Ceph Dashboard 設定正確的 URL：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch reconfig grafana</screen>
  </step>
 </procedure>
 <para>
  Alertmanager 處理 Prometheus 伺服器傳送的警示。它負責重複資訊刪除、分組，並將它們路由到正確的接收器。可以使用警示管理員消除警示，但也可以使用 Ceph Dashboard 管理靜默功能。
 </para>
 <para>
  建議您在所有節點上部署 <systemitem class="daemon">Node exporter</systemitem>。可以使用含有 <literal>node-exporter</literal> 服務類型的 <filename>monitoring.yaml</filename> 檔案執行此操作。如需部署服務的詳細資訊，請參閱<xref linkend="deploy-cephadm-day2-service-monitoring"/>。
 </para>
 <sect1 xml:id="monitoring-custom-images">
  <title>設定自訂或本地影像</title>

  <tip>
   <para>
    本節說明如何變更部署或更新服務時所使用的容器影像組態。不包括部署或重新部署服務所需的指令。
   </para>
   <para>
    部署監控堆疊的推薦方法是依據<xref linkend="deploy-cephadm-day2-service-monitoring"/>中所述套用其規格。
   </para>
  </tip>

  <para>
   若要部署自訂或本地容器影像，需要在 cephadm 中設定影像。為此，您需要執行以下指令：
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable> <replaceable>VALUE</replaceable></screen>

  <para>
   其中，<replaceable>OPTION_NAME</replaceable> 為以下任何名稱：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     container_image_prometheus
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_node_exporter
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_alertmanager
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_grafana
    </para>
   </listitem>
  </itemizedlist>

  <para>
   如果未設定任何選項或已移除該設定，則將使用以下影像做為 <replaceable>VALUE</replaceable>：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     registry.suse.com/ses/7.1/ceph/prometheus-server:2.32.1
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/ses/7.1/ceph/prometheus-node-exporter:1.1.2
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/ses/7.1/ceph/prometheus-alertmanager:0.21.0
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/ses/7.1/ceph/grafana:7.5.12
    </para>
   </listitem>
  </itemizedlist>

  <para>
   例如：
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/container_image_prometheus prom/prometheus:v1.4.1</screen>

  <note>
   <para>
    設定自訂影像將覆蓋預設值 (但並不會覆寫)。當有可用更新時，預設值將發生變更。設定自訂影像後，您將無法自動更新設定了自訂影像的元件。您需要手動更新組態 (影像名稱和標記) 才能安裝更新。
   </para>
   <para>
    如果您選擇遵循這些建議，則可以重設先前設定的自訂影像。之後，將再次使用預設值。使用 <command>ceph config rm</command> 重設組態選項：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable></screen>
   <para>
    例如：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/container_image_prometheus</screen>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-applying-updates">
  <title>更新監控服務</title>

  <para>
   依據<xref linkend="monitoring-custom-images"/>中所述，cephadm 隨附了推薦且經過測試之容器影像的 URL，預設會使用這些 URL。
  </para>

  <para>
   更新 Ceph 套件後，可能會隨附這些 URL 的新版本。如此只會更新容器影像的提取位置，而不會更新任何服務。
  </para>

  <para>
   更新新容器影像的 URL (可以依據<xref linkend="monitoring-custom-images"/>中所述執行手動更新，也可以透過更新 Ceph 套件進行自動更新) 後，便可以更新監控服務。
  </para>

  <para>
   若要執行此操作，請使用 <command>ceph orch reconfig</command>，如下所示：
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch reconfig node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch reconfig prometheus
<prompt>cephuser@adm &gt; </prompt>ceph orch reconfig alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph orch reconfig grafana
</screen>

  <para>
   目前沒有可更新所有監控服務的單一指令。這些服務的更新順序並不重要。
  </para>

  <note>
   <para>
    如果您使用自訂容器影像，則在更新 Ceph 套件時為監控服務指定的 URL 將不會自動變更。如果您已指定自訂容器影像，則需要手動指定新容器影像的 URL。使用本地容器登錄時，可能會出現這種情況。
   </para>
   <para>
    您可以在<xref linkend="monitoring-custom-images"/>一節中找到要使用的推薦容器影像的 URL。
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-stack-disable">
  <title>停用監控</title>

  <para>
   若要停用監控堆疊，請執行以下指令：
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch rm grafana
<prompt>cephuser@adm &gt; </prompt>ceph orch rm prometheus --force   # this will delete metrics data collected so far
<prompt>cephuser@adm &gt; </prompt>ceph orch rm node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch rm alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph mgr module disable prometheus
      </screen>
 </sect1>
 <sect1 xml:id="monitoring-grafana-config">
  <title>設定 Grafana</title>

  <para>
   Ceph Dashboard 後端要求 Grafana URL 能夠在前端均衡載入 Grafana 儀表板之前確認其是否存在。由於 Grafana 在 Ceph Dashboard 中實作方式的本質，意味著需要兩個有效連接才能在 Ceph Dashboard 中看到 Grafana 圖形：
  </para>

  <itemizedlist>
   <listitem>
    <para>
     後端 (Ceph MGR 模組) 需要確認所要求的圖形是否存在。如果此要求成功，便會告知前端它可以安全地存取 Grafana。
    </para>
   </listitem>
   <listitem>
    <para>
     然後，前端會使用 <literal>iframe</literal> 直接從使用者的瀏覽器要求 Grafana 圖形。可以直接存取 Grafana 例項，而無需再經由 Ceph Dashboard。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   現在，您的環境可能會讓使用者的瀏覽器難以直接存取 Ceph Dashboard 中設定的 URL。為解決此問題，可以設定一個單獨的 URL，專用於告知前端 (使用者的瀏覽器) 應使用哪個 URL 來存取 Grafana。
  </para>

  <para>
   若要變更傳回給前端的 URL，請發出以下指令：
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph dashboard set-grafana-frontend-api-url <replaceable>GRAFANA-SERVER-URL</replaceable></screen>

  <para>
   如果沒有為該選項設定任何值，它將回復為 <replaceable>GRAFANA_API_URL</replaceable> 選項的值，該選項值自動設定並由 cephadm 定期更新。如果設定了值，它將指示瀏覽器使用此 URL 來存取 Grafana。
  </para>
 </sect1>
 <sect1 xml:id="monitoring-cephadm-config">
  <title>設定 Prometheus 管理員模組</title>

  <para>
   Prometheus 管理員模組是一個 Ceph 內部模組，它延伸了 Ceph 的功能。該模組會從 Ceph 讀取有關其狀態和狀況的 (中繼) 資料，並以可使用的格式向 Prometheus 提供 (抓取的) 資料。
  </para>

  <note>
   <para>
    需要重新啟動 Prometheus 管理員模組才能套用組態變更。
   </para>
  </note>

  <sect2 xml:id="monitoring-http-requests">
   <title>設定網路介面</title>
   <para>
    依預設，Prometheus 管理員模組接受主機上所有 IPv4 和 IPv6 位址的連接埠 9283 上的 HTTP 要求。連接埠和監聽位址都可使用 <option>ceph config-key set</option> 進行設定，並使用機碼 <option>mgr/prometheus/server_addr</option> 和 <option>mgr/prometheus/server_port</option>。此連接埠已在 Prometheus 的登錄中註冊。
   </para>
   <para>
    若要更新 <literal>server_addr</literal>，請執行以下指令：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_addr <replaceable>0.0.0.0</replaceable>
      </screen>
   <para>
    若要更新 <literal>server_port</literal>，請執行以下指令：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_port <replaceable>9283</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-scrape-intervals">
   <title>設定 <literal>scrape_interval</literal></title>
   <para>
    依預設，Prometheus 管理員模組設定了 15 秒的抓取間隔。我們建議使用的抓取間隔不得少於 10 秒。若要在 Prometheus 模組中設定其他抓取間隔，請將 <literal>scrape_interval</literal> 設定為所需值：
   </para>
   <important>
    <para>
     若要正常運作而不會導致任何問題，此模組的 <literal>scrape_interval</literal> 應永遠依據 Prometheus 抓取間隔進行設定。
    </para>
   </important>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/scrape_interval <replaceable>15</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-stale-cache">
   <title>設定快取</title>
   <para>
    在大型叢集 (超過 1000 個 OSD) 上，擷取度量的時間可能會變得非常重要。如果沒有快取，Prometheus 管理員模組可能會令管理員超載，並導致 Ceph 管理員例項無回應或當機。因此，系統預設會啟用快取，並且不能停用快取，但這意味著快取可能會過時。當從 Ceph 擷取度量的時間超出所設定的 <literal>scrape_interval</literal> 時，快取將被視為過時。
   </para>
   <para>
    如果發生此情況，系統將記錄一則警告，並且模組將：
   </para>
   <itemizedlist>
    <listitem>
     <para>
      以 503 HTTP 狀態代碼 (服務不可用) 回應。
     </para>
    </listitem>
    <listitem>
     <para>
      傳回快取的內容，即使該內容可能已過時。
     </para>
    </listitem>
   </itemizedlist>
   <para>
    可使用 <command>ceph config set</command> 指令設定此行為。
   </para>
   <para>
    若要告知模組以可能過時的資料進行回應，請將其設定為 <literal>return</literal>：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy return</screen>
   <para>
    若要告知模組以 <literal>service unavailable</literal> 進行回應，請將其設定為 <literal>fail</literal>：
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy fail</screen>
  </sect2>

  <sect2 xml:id="monitoring-rbd-image">
   <title>啟用 RBD 影像監控</title>
   <para>
    Prometheus 管理員模組可以透過啟用動態 OSD 效能計數器來選擇性地收集 RBD 每個影像的 IO 統計資料。如此將為在 <literal>mgr/prometheus/rbd_stats_pools</literal> 組態參數中所指定池中的所有影像收集統計資料。
   </para>
   <para>
    參數是以逗號或空格分隔的 <literal>pool[/namespace]</literal> 項目清單。如果未指定名稱空間，則將收集池中所有名稱空間的統計資料。
   </para>
   <para>
    例如：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools "<replaceable>pool1,pool2,poolN</replaceable>"
      </screen>
   <para>
    該模組會掃描指定的池和名稱空間，列出所有可用影像，並定期重新整理該清單。此間隔可透過 <literal>mgr/prometheus/rbd_stats_pools_refresh_interval</literal> 參數進行設定 (以秒計)，預設值為 300 秒 (5 分鐘)。
   </para>
   <para>
    例如，如果您將同步間隔變更為 10 分鐘：
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools_refresh_interval <replaceable>600</replaceable>
      </screen>
  </sect2>
 </sect1>
 <sect1 xml:id="prometheus-security-model">
  <title>Prometheus 安全性模型</title>

  <para>
   Prometheus 的安全性模型假設不受信任的使用者有權存取 Prometheus HTTP 端點和記錄。不受信任的使用者有權存取資料庫中包含的 Prometheus 收集的所有 (中繼) 資料，以及各種操作和除錯資訊。
  </para>

  <para>
   不過，Prometheus 的 HTTP API 僅限唯讀操作。無法使用 API 變更組態，並且不會公開機密金鑰。此外，Prometheus 還有一些內建的措施可用於緩解拒絕服務攻擊的影響。
  </para>
 </sect1>
 <sect1 xml:id="prometheus-webhook-snmp">
  <title>Prometheus 警示管理員 SNMP 閘道</title>

  <para>
   如果您想透過 SNMP 設陷接收有關 Prometheus 警示的通知，可以透過 cephadm 或 Ceph Dashboard 安裝 Prometheus 警示管理員 SNMP 閘道。例如，如果要透過 SNMPv2c 接收此類通知，您需要建立包含以下內容的服務和放置規格檔案：
  </para>

  <note>
   <para>
    如需服務和放置檔案的詳細資訊，請參閱<xref linkend="cephadm-service-and-placement-specs"/>。
   </para>
  </note>

<screen>
service_type: snmp-gateway
service_name: snmp-gateway
placement:
    <replaceable>ADD_PLACEMENT_HERE</replaceable>
spec:
  credentials:
    snmp_community: <replaceable>ADD_COMMUNITY_STRING_HERE</replaceable>
  snmp_destination: <replaceable>ADD_FQDN_HERE</replaceable>:<replaceable>ADD_PORT_HERE</replaceable>
  snmp_version: V2c
</screen>

  <para>
   或者，您可以使用 Ceph Dashboard 部署適用於 SNMPv2c 和 SNMPv3 的 SNMP 閘道服務。如需詳細資訊，請參閱<xref linkend="dashboard-cluster-services"/>。
  </para>
 </sect1>
</chapter>
