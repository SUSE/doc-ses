<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_monitor.xml" version="5.0" xml:id="ceph-monitor">
 <title>Détermination de l'état d'une grappe</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>oui</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Lorsque vous disposez d'une grappe en cours d'exécution, vous pouvez utiliser l'outil <command>ceph</command> pour la surveiller. Pour déterminer l'état de la grappe, il faut généralement vérifier le statut des OSD Ceph, des moniteurs Ceph, des groupes de placement et des serveurs de métadonnées.
 </para>
 <tip>
  <title>mode interactif</title>
  <para>
   Pour exécuter l'outil <command>ceph</command> en mode interactif, tapez <command>ceph</command> sans argument sur la ligne de commande. Le mode interactif est plus pratique si vous voulez entrer plusieurs commandes <command>ceph</command> consécutives. Par exemple :
  </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph
ceph&gt; health
ceph&gt; status
ceph&gt; quorum_status
ceph&gt; mon stat</screen>
 </tip>
 <sect1 xml:id="monitor-status">
  <title>Vérification de l'état d'une grappe</title>

  <para>
   La commande <command>ceph status</command> ou <command>ceph -s</command> permet de connaître l'état immédiat de la grappe :
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph -s
cluster:
    id:     b4b30c6e-9681-11ea-ac39-525400d7702d
    health: HEALTH_OK

  services:
    mon: 5 daemons, quorum ses-min1,ses-master,ses-min2,ses-min4,ses-min3 (age 2m)
    mgr: ses-min1.gpijpm(active, since 3d), standbys: ses-min2.oopvyh
    mds: my_cephfs:1 {0=my_cephfs.ses-min1.oterul=up:active}
    osd: 3 osds: 3 up (since 3d), 3 in (since 11d)
    rgw: 2 daemons active (myrealm.myzone.ses-min1.kwwazo, myrealm.myzone.ses-min2.jngabw)

  task status:
    scrub status:
        mds.my_cephfs.ses-min1.oterul: idle

  data:
    pools:   7 pools, 169 pgs
    objects: 250 objects, 10 KiB
    usage:   3.1 GiB used, 27 GiB / 30 GiB avail
    pgs:     169 active+clean
</screen>

  <para>
   La sortie fournit les informations suivantes :
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     ID de grappe
    </para>
   </listitem>
   <listitem>
    <para>
     État d'intégrité de la grappe
    </para>
   </listitem>
   <listitem>
    <para>
     Époque d'assignation du moniteur et état du quorum du moniteur
    </para>
   </listitem>
   <listitem>
    <para>
     Époque d'assignation des OSD et état des OSD
    </para>
   </listitem>
   <listitem>
    <para>
     Statut des instances Ceph Manager
    </para>
   </listitem>
   <listitem>
    <para>
     Statut des instances Object Gateway
    </para>
   </listitem>
   <listitem>
    <para>
     Version d'assignation des groupes de placement
    </para>
   </listitem>
   <listitem>
    <para>
     Nombre de groupes de placement et de réserves
    </para>
   </listitem>
   <listitem>
    <para>
     Quantité <emphasis>théorique</emphasis> de données stockées et nombre d'objets stockés
    </para>
   </listitem>
   <listitem>
    <para>
     Quantité totale de données stockées
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>méthode utilisée par Ceph pour calculer l'utilisation des données</title>
   <para>
    La valeur de <literal>used</literal> reflète la quantité réelle de stockage brut utilisée. La valeur de <literal>xxx Go/xxx Go</literal> désigne la quantité disponible de la capacité de stockage globale de la grappe (la quantité disponible correspond à la valeur inférieure). Le nombre théorique reflète la taille des données stockées avant qu'elles soient répliquées ou clonées ou qu'elles fassent l'objet d'un instantané. Par conséquent, la quantité de données réellement stockée dépasse généralement la quantité théorique stockée, car Ceph crée des répliques des données et peut également utiliser la capacité de stockage pour le clonage et la création d'instantanés.
   </para>
  </tip>

  <para>
   Les autres commandes affichant des informations d'état immédiat sont les suivantes :
  </para>

  <itemizedlist>
   <listitem>
    <para>
     <command>ceph pg stat</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph osd pool stats</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df</command>
    </para>
   </listitem>
   <listitem>
    <para>
     <command>ceph df detail</command>
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Pour obtenir les informations mises à jour en temps réel, utilisez l'une de ces commandes (y compris <command>ceph -s</command>) comme argument de la commande <command>watch</command> :
  </para>

<screen><prompt role="root">root # </prompt>watch -n 10 'ceph -s'</screen>

  <para>
   Appuyez sur <keycombo><keycap function="control"/><keycap>C</keycap></keycombo> pour refermer la sortie de la commande.
  </para>
 </sect1>
 <sect1 xml:id="monitor-health">
  <title>Vérification de l'état de santé de la grappe</title>

  <para>
   Après avoir démarré votre grappe et avant de commencer à lire et/ou à écrire des données, vérifiez l'état d'intégrité de votre grappe :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
HEALTH_WARN 10 pgs degraded; 100 pgs stuck unclean; 1 mons down, quorum 0,2 \
node-1,node-2,node-3</screen>

  <tip>
   <para>
    Si vous avez choisi des emplacements autres que ceux par défaut pour votre configuration ou votre trousseau de clés, vous pouvez les indiquer ici :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>

  <para>
   La grappe Ceph renvoie l'un des codes d'intégrité suivants :
  </para>

  <variablelist>
   <varlistentry>
    <term>OSD_DOWN</term>
    <listitem>
     <para>
      Un ou plusieurs OSD sont marqués comme étant arrêtés. Le daemon OSD peut avoir été arrêté ou les OSD homologues peuvent ne pas être en mesure d'accéder à l'OSD via le réseau. Un daemon arrêté ou bloqué, un hôte en panne ou une panne réseau font partie des causes les plus courantes de ce problème.
     </para>
     <para>
      Vérifiez que l'hôte est intègre, que le daemon a été démarré et que le réseau fonctionne. Si le daemon est tombé en panne, le fichier journal du daemon (<filename>/var/log/ceph/ceph-osd.*</filename>) peut contenir des informations de débogage.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_<replaceable>type crush</replaceable>_DOWN, par exemple, OSD_HOST_DOWN</term>
    <listitem>
     <para>
      Tous les OSD d'une sous-arborescence CRUSH particulière sont marqués comme étant arrêtés, par exemple tous les OSD d'un hôte.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_ORPHAN</term>
    <listitem>
     <para>
      Un OSD est référencé dans la hiérarchie des cartes CRUSH, mais n'existe pas. L'OSD peut être retiré de la hiérarchie CRUSH avec :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd crush rm osd.<replaceable>ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_OUT_OF_ORDER_FULL</term>
    <listitem>
     <para>
      Les seuils d'utilisation pour <emphasis>backfillfull</emphasis> (par défaut : 0,90), <emphasis>nearfull</emphasis> (par défaut : 0,85), <emphasis>full</emphasis> (par défaut : 0,95) et/ou <emphasis>failsafe_full</emphasis> ne sont pas croissants. <emphasis>backfillfull</emphasis> &lt; <emphasis>nearfull</emphasis>, <emphasis>nearfull</emphasis> &lt; <emphasis>full</emphasis> et <emphasis>full</emphasis> &lt; <emphasis>failsafe_full</emphasis> sont agencés dans cet ordre.
     </para>
     <para>
      Pour lire les valeurs actuelles, exécutez la commande suivante :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph health detail
HEALTH_ERR 1 full osd(s); 1 backfillfull osd(s); 1 nearfull osd(s)
osd.3 is full at 97%
osd.4 is backfill full at 91%
osd.2 is near full at 87%
</screen>
     <para>
      Les seuils peuvent être ajustés avec les commandes suivantes :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set-backfillfull-ratio <replaceable>ratio</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd set-nearfull-ratio <replaceable>ratio</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FULL</term>
    <listitem>
     <para>
      Un ou plusieurs OSD ont dépassé le seuil <emphasis>full</emphasis> et empêchent la grappe de gérer les écritures. L'utilisation par réserve peut être vérifiée comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
     <para>
      Le ratio <emphasis>full</emphasis> actuellement défini peut être vu avec :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd dump | grep full_ratio</screen>
     <para>
      Une solution à court terme de restauration de la disponibilité en écriture consiste à augmenter légèrement le seuil full :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set-full-ratio <replaceable>ratio</replaceable></screen>
     <para>
      Ajoutez un nouveau stockage à la grappe en déployant plus d'OSD ou supprimez les données existantes afin de libérer de l'espace.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_BACKFILLFULL</term>
    <listitem>
     <para>
      Un ou plusieurs OSD ont dépassé le seuil <emphasis>backfillfull</emphasis>, ce qui empêche le rééquilibrage des données sur ce périphérique. Cet avertissement anticipé indique que le rééquilibrage peut ne pas aboutir et que la grappe approche de sa pleine capacité. L'utilisation par réserve peut être vérifiée comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NEARFULL</term>
    <listitem>
     <para>
      Un ou plusieurs OSD ont dépassé le seuil <emphasis>nearfull</emphasis>. Cet avertissement anticipé indique que la grappe approche de sa pleine capacité. L'utilisation par réserve peut être vérifiée comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSDMAP_FLAGS</term>
    <listitem>
     <para>
      Un ou plusieurs indicateurs de grappe présentant un intérêt ont été définis. À l'exception de <emphasis>full</emphasis>, ces indicateurs peuvent être définis ou effacés comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set <replaceable>flag</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd unset <replaceable>flag</replaceable></screen>
     <para>
      Ces indicateurs comprennent :
     </para>
     <variablelist>
      <varlistentry>
       <term>full</term>
       <listitem>
        <para>
         La grappe est marquée comme pleine et ne peut donc pas traiter les écritures.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>pauserd, pausewr</term>
       <listitem>
        <para>
         Les lectures et les écritures sont mises en pause.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         Les OSD ne sont pas autorisés à démarrer.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Les rapports d'échec OSD sont ignorés de sorte que les moniteurs ne marquent pas les OSD comme <emphasis>down</emphasis> (arrêtés).
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Les OSD précédemment marqués comme <emphasis>out</emphasis> (hors service) ne sont pas marqués comme <emphasis>in</emphasis> (en service) lors de leur démarrage.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Les OSD <emphasis>down</emphasis> (arrêtés) ne seront pas automatiquement marqués comme <emphasis>out</emphasis> (hors service) à l'issue de l'intervalle configuré.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nobackfill, norecover, norebalance</term>
       <listitem>
        <para>
         La récupération ou le rééquilibrage des données est suspendu.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noscrub, nodeep_scrub</term>
       <listitem>
        <para>
         Le nettoyage (reportez-vous à la <xref linkend="scrubbing-pgs"/>) est désactivé.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>notieragent</term>
       <listitem>
        <para>
         L'activité de hiérarchisation du cache est suspendue.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_FLAGS</term>
    <listitem>
     <para>
      Un ou plusieurs OSD possèdent chacun un indicateur OSD. Ces indicateurs comprennent :
     </para>
     <variablelist>
      <varlistentry>
       <term>noup</term>
       <listitem>
        <para>
         L'OSD n'est pas autorisé à démarrer.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>nodown</term>
       <listitem>
        <para>
         Les rapports d'échec sont ignorés pour cet OSD.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noin</term>
       <listitem>
        <para>
         Si cet OSD était auparavant marqué comme <emphasis>out</emphasis> automatiquement après un échec, il ne sera pas marqué comme <emphasis>in</emphasis> lors du démarrage.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>noout</term>
       <listitem>
        <para>
         Si cet OSD est arrêté, il n'est pas automatiquement marqué comme <emphasis>out</emphasis> à l'issue de l'intervalle configuré.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      Les indicateurs OSD peuvent être définis et effacés comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd add-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd rm-<replaceable>flag</replaceable> <replaceable>osd-ID</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_TUNABLES</term>
    <listitem>
     <para>
      La carte CRUSH doit être mise à jour, car elle utilise des paramètres très anciens. Les paramètres les plus anciens qui peuvent être utilisés (c'est-à-dire la version client la plus ancienne pouvant se connecter à la grappe) sans déclencher cet avertissement d'intégrité sont déterminés par l'option de configuration <option>mon_crush_min_required_version</option>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OLD_CRUSH_STRAW_CALC_VERSION</term>
    <listitem>
     <para>
      La carte CRUSH utilise une méthode non optimale plus ancienne afin de calculer les valeurs de pondération intermédiaires des compartiments straw. La carte CRUSH doit être mise à jour pour utiliser la nouvelle méthode (<option>straw_calc_version</option>=1).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NO_HIT_SET</term>
    <listitem>
     <para>
      Une ou plusieurs réserves de cache ne sont pas configurées avec un jeu d'accès pour le suivi de l'utilisation, ce qui empêche l'agent de hiérarchisation d'identifier les objets inactifs à évincer du cache. Les jeux d'accès peuvent être configurés sur la réserve de cache comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_type <replaceable>type</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_period <replaceable>period-in-seconds</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_count <replaceable>number-of-hitsets</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> hit_set_fpp <replaceable>target-false-positive-rate</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_NO_SORTBITWISE</term>
    <listitem>
     <para>
      Aucun OSD d'une version antérieure à la version 12 « Luminous » ne s'exécute actuellement, mais l'indicateur <option>sortbitwise</option> n'est pas défini. Vous devez définir l'indicateur <option>sortbitwise</option> pour permettre le démarrage des OSD antérieurs à la version 12 « Luminous » ou plus récents :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set sortbitwise</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Une ou plusieurs réserves ont atteint leur quota et n'autorisent plus les écritures. Vous pouvez définir des quotas de réserve et leur utilisation comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph df detail</screen>
     <para>
      Vous pouvez augmenter le quota de réserve comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_objects <replaceable>num-objects</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>poolname</replaceable> max_bytes <replaceable>num-bytes</replaceable></screen>
     <para>
      ou supprimer des données existantes pour réduire l'utilisation.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_AVAILABILITY</term>
    <listitem>
     <para>
      La disponibilité des données est réduite, ce qui signifie que la grappe ne peut pas traiter les requêtes de lecture ou d'écriture potentielles pour certaines de ses données. Plus précisément, un ou plusieurs groupes de placement se trouvent dans un état qui ne permet pas de traiter les requêtes d'E/S. Les états de groupe de placement posant problème sont les suivants : <emphasis>peering</emphasis> (homologation), <emphasis>stale</emphasis> (périmé), <emphasis>incomplete</emphasis> (incomplet) et l'absence d'état <emphasis>active</emphasis> (actif) (si ces conditions ne disparaissent pas rapidement). Pour plus de détails sur les groupes de placement affectés, exécutez la commande suivante :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph health detail</screen>
     <para>
      Dans la plupart des cas, la cause première est due au fait qu'un ou plusieurs OSD sont actuellement arrêtés. Pour connaître l'état des groupes de placement incriminés, exécutez la commande suivante :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED</term>
    <listitem>
     <para>
      La redondance des données est réduite pour certaines données, ce qui signifie que la grappe ne dispose pas du nombre de répliques souhaité pour toutes les données (pour les réserves répliquées) ou pour les fragments de code d'effacement (pour les réserves codées à effacement). Plus précisément, l'indicateur <emphasis>degraded</emphasis> (altéré) ou <emphasis>undersized</emphasis> (de taille insuffisante) est associé à un ou plusieurs groupes de placement (le nombre d'instances de ce groupe de placement est insuffisant dans la grappe) ou l'indicateur <emphasis>clean</emphasis> ne leur est pas associé depuis un certain temps. Pour plus de détails sur les groupes de placement affectés, exécutez la commande suivante :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph health detail</screen>
     <para>
      Dans la plupart des cas, la cause première est due au fait qu'un ou plusieurs OSD sont actuellement arrêtés. Pour connaître l'état des groupes de placement incriminés, exécutez la commande suivante :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DEGRADED_FULL</term>
    <listitem>
     <para>
      La redondance des données peut être réduite ou menacée pour certaines données en raison d'un manque d'espace libre dans la grappe. Plus précisément, l'indicateur <emphasis>backfill_toofull</emphasis> ou <emphasis>recovery_toofull</emphasis> est associé à un ou plusieurs groupes de placement, ce qui signifie que la grappe ne parvient pas à migrer ou à récupérer les données, car un ou plusieurs OSD ont dépassé le seuil <emphasis>backfillfull</emphasis>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_DAMAGED</term>
    <listitem>
     <para>
      Le nettoyage des données (voir <xref linkend="scrubbing-pgs"/>) a détecté des problèmes de cohérence des données dans la grappe. Plus précisément, l'indicateur <emphasis>inconsistent</emphasis> ou <emphasis>snaptrim_error</emphasis> est associé à un ou plusieurs groupes de placement, ce qui indique qu'une opération de nettoyage antérieure a détecté un problème ou que l'indicateur <emphasis>repair</emphasis> est défini, car une réparation est actuellement en cours pour une telle incohérence.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OSD_SCRUB_ERRORS</term>
    <listitem>
     <para>
      Les nettoyages récents d'OSD ont révélé des incohérences.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CACHE_POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Une réserve de niveau de cache est presque pleine. Dans ce contexte, l'état Full est déterminé par les propriétés <emphasis>target_max_bytes</emphasis> et <emphasis>target_max_objects</emphasis> de la réserve de cache. Lorsque la réserve atteint le seuil cible, les requêtes d'écriture dans la réserve peuvent être bloquées pendant que les données sont vidées et évincées du cache, un état qui entraîne généralement des latences très élevées et des performances médiocres. La taille cible de la réserve de cache peut être définie ainsi :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>cache-pool-name</replaceable> target_max_objects <replaceable>objects</replaceable></screen>
     <para>
      L'activité normale de vidage et d'éviction du cache peut également être entravée en raison de la disponibilité ou des performances réduites du niveau de base ou de la charge globale de la grappe.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_FEW_PGS</term>
    <listitem>
     <para>
      Le nombre de groupes de placement utilisés est inférieur au seuil configurable de <option>mon_pg_warn_min_per_osd</option> groupes de placement par OSD. Cela peut entraîner une distribution et un équilibrage sous-optimaux des données entre les OSD de la grappe, ce qui fait baisser les performances globales.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>TOO_MANY_PGS</term>
    <listitem>
     <para>
      Le nombre de groupes de placement utilisés est supérieur au seuil configurable de <option>mon_pg_warn_max_per_osd</option> groupes de placement par OSD. Cela peut conduire à une utilisation plus importante de la mémoire pour les daemons OSD, à une homologation plus lente après des changements d'état de grappe (redémarrages, ajouts ou suppressions d'OSD, par exemple) et à une charge plus élevée des instances Ceph Manager et Ceph Monitor.
     </para>
     <para>
      Contrairement à la valeur <option>pg_num</option>, la valeur <option>pgp_num</option> peut être réduite pour des réserves existantes. Cela permet de regrouper efficacement certains groupes de placement sur les mêmes ensembles d'OSD, atténuant ainsi quelques-uns des effets négatifs décrits ci-dessus. Il est possible d'ajuster la valeur de <option>pgp_num</option> comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>SMALLER_PGP_NUM</term>
    <listitem>
     <para>
      La valeur de <option>pgp_num</option> est inférieure à celle de <option>pg_num</option> pour une ou plusieurs réserves. Ceci indique normalement que le nombre de groupes de placement a été augmenté indépendamment du comportement de placement. Ce problème est résolu en définissant <option>pgp_num</option> et <option>pg_num</option> sur la même valeur, ce qui déclenche la migration de données, comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>pool</replaceable> pgp_num <replaceable>pg_num_value</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>MANY_OBJECTS_PER_PG</term>
    <listitem>
     <para>
      Pour une ou plusieurs réserves, le nombre moyen d'objets par groupe de placement est sensiblement supérieur à la moyenne globale de la grappe. Le seuil spécifique est contrôlé par la valeur de configuration de <option>mon_pg_warn_max_object_skew</option>. Cela indique généralement que la ou les réserves contenant la plupart des données de la grappe possèdent un nombre trop faible de groupes de placement et/ou que les autres réserves ne contenant pas autant de données possèdent un nombre excessif de groupes de placement. Pour ne plus afficher l'avertissement d'intégrité, vous pouvez relever le seuil en ajustant l'option de configuration <option>mon_pg_warn_max_object_skew</option> sur les moniteurs.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_APP_NOT_ENABLED</term>
    <listitem>
     <para>
      Il existe une réserve qui contient un ou plusieurs objets, mais qui n'a pas été marquée pour une utilisation par une application particulière. Pour que cet avertissement ne s'affiche plus, étiquetez la réserve pour qu'elle soit utilisée par une application. Par exemple, si la réserve est utilisée par RBD :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>rbd pool init <replaceable>pool_name</replaceable></screen>
     <para>
      Si la réserve est utilisée par une application personnalisée « foo », vous pouvez également l'étiqueter à l'aide de la commande de bas niveau :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool application enable foo</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_FULL</term>
    <listitem>
     <para>
      Une ou plusieurs réserves ont atteint leur quota (ou sont proches des 100 %). Le seuil de déclenchement de cette condition d'erreur est contrôlé par l'option de configuration <option>mon_pool_quota_crit_threshold</option>. Les quotas de réserve peuvent être ajustés à la hausse ou à la baisse (voire supprimés) comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Définir la valeur de quota sur 0 désactive le quota.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_NEAR_FULL</term>
    <listitem>
     <para>
      Une ou plusieurs réserves se rapprochent de leur quota. Le seuil de déclenchement de cette condition d'avertissement est contrôlé par l'option de configuration <option>mon_pool_quota_warn_threshold</option>. Les quotas de réserve peuvent être ajustés à la hausse ou à la baisse (voire supprimés) comme suit :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_bytes <replaceable>bytes</replaceable>
<prompt>cephuser@adm &gt; </prompt>ceph osd osd pool set-quota <replaceable>pool</replaceable> max_objects <replaceable>objects</replaceable></screen>
     <para>
      Définir la valeur de quota sur 0 désactive le quota.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_MISPLACED</term>
    <listitem>
     <para>
      Un ou plusieurs objets de la grappe ne sont pas stockés sur le noeud prévu par la grappe. Cela indique que la migration de données due à une modification récente de la grappe n'a pas encore abouti. Un mauvais placement des données n'est pas dangereux en soi. La cohérence des données n'est jamais compromise et les anciennes copies d'objets ne sont jamais supprimées tant que le nombre de nouvelles copies souhaité n'est pas atteint (dans les emplacements souhaités).
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>OBJECT_UNFOUND</term>
    <listitem>
     <para>
      Un ou plusieurs objets de la grappe sont introuvables. Plus précisément, les OSD savent qu'une copie nouvelle ou mise à jour d'un objet doit exister, mais la copie de cette version de l'objet est introuvable sur les OSD actuellement opérationnels. Les requêtes de lecture ou d'écriture sur les objets « introuvables » seront bloquées. Idéalement, l'OSD hors service qui héberge la copie la plus récente de l'objet introuvable peut être remis en service. Les OSD candidats peuvent être identifiés à partir de l'état d'homologation du ou des groupes de placement associés à l'objet introuvable :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph tell <replaceable>pgid</replaceable> query</screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_SLOW</term>
    <listitem>
     <para>
      Une ou plusieurs requêtes OSD sont longues à traiter. Cela peut indiquer une charge extrême, un périphérique de stockage lent ou un bogue logiciel. Vous pouvez interroger la file d'attente des requêtes sur le ou les OSD en question, exécutez la commande suivante à partir de l'hôte OSD :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> ops</screen>
     <para>
      Vous pouvez afficher le résumé des requêtes récentes les plus lentes :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph daemon osd.<replaceable>id</replaceable> dump_historic_ops</screen>
     <para>
      Vous pouvez trouver l'emplacement d'un OSD avec :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd find osd.<replaceable>id</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>REQUEST_STUCK</term>
    <listitem>
     <para>
      Une ou plusieurs requêtes d'OSD ont été bloquées pendant une période relativement longue, par exemple 4 096 secondes. Cela indique que l'état de santé de la grappe n'est pas bon depuis un certain temps (par exemple, en raison du faible nombre d'OSD actifs ou de groupes de placement inactifs), ou que l'OSD concernée présente un problème interne.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_SCRUBBED</term>
    <listitem>
     <para>
      Un ou plusieurs groupes de placement n'ont pas été nettoyés récemment (reportez-vous à la <xref linkend="scrubbing-pgs"/>). Les groupes de placement sont normalement nettoyés toutes les <option>mon_scrub_interval</option> secondes ; cet avertissement se déclenche lorsque <option>mon_warn_not_scrubbed</option> intervalles se sont écoulés sans nettoyage. Les groupes de placement ne sont pas nettoyés s'ils ne sont pas marqués comme propres, ce qui peut arriver s'ils sont mal placés ou altérés (voir PG_AVAILABILITY et PG_DEGRADED ci-dessus). Vous pouvez lancer manuellement le nettoyage d'un groupe de placement :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph pg scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>PG_NOT_DEEP_SCRUBBED</term>
    <listitem>
     <para>
      Un ou plusieurs groupes de placement n'ont pas été nettoyés en profondeur récemment (reportez-vous à la <xref linkend="scrubbing-pgs"/>). Les groupes de placement sont normalement nettoyés toutes les <option>osd_deep_mon_scrub_interval</option> secondes ; cet avertissement se déclenche lorsque <option>mon_warn_not_deep_scrubbed</option> secondes se sont écoulées sans nettoyage. Les groupes de placement n'ont pas été nettoyés (en profondeur) s'ils ne sont pas marqués comme propres, ce qui peut arriver s'ils sont mal placés ou altérés (voir PG_AVAILABILITY et PG_DEGRADED ci-dessus). Vous pouvez lancer manuellement le nettoyage d'un groupe de placement :
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph pg deep-scrub <replaceable>pgid</replaceable></screen>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <para>
    Si vous avez choisi des emplacements autres que ceux par défaut pour votre configuration ou votre trousseau de clés, vous pouvez les indiquer ici :
   </para>
<screen><prompt role="root">root # </prompt>ceph -c <replaceable>/path/to/conf</replaceable> -k <replaceable>/path/to/keyring</replaceable> health</screen>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-stats">
  <title>Vérification des statistiques d'utilisation d'une grappe</title>

  <para>
   Pour vérifier l'utilisation des données d'une grappe et leur distribution entre les réserves, utilisez la commande <command>ceph df</command>. Pour obtenir plus de détails, utilisez <command>ceph df detail</command>.
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph df
--- RAW STORAGE ---
CLASS  SIZE    AVAIL   USED     RAW USED  %RAW USED
hdd    30 GiB  27 GiB  121 MiB   3.1 GiB      10.40
TOTAL  30 GiB  27 GiB  121 MiB   3.1 GiB      10.40

--- POOLS ---
POOL                   ID  STORED   OBJECTS  USED     %USED  MAX AVAIL
device_health_metrics   1      0 B        0      0 B      0    8.5 GiB
cephfs.my_cephfs.meta   2  1.0 MiB       22  4.5 MiB   0.02    8.5 GiB
cephfs.my_cephfs.data   3      0 B        0      0 B      0    8.5 GiB
.rgw.root               4  1.9 KiB       13  2.2 MiB      0    8.5 GiB
myzone.rgw.log          5  3.4 KiB      207    6 MiB   0.02    8.5 GiB
myzone.rgw.control      6      0 B        8      0 B      0    8.5 GiB
myzone.rgw.meta         7      0 B        0      0 B      0    8.5 GiB
</screen>

  <para>
   La section <literal>RAW STORAGE</literal> de la sortie donne un aperçu de la quantité de stockage utilisée pour vos données par la grappe.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>CLASS</literal> : classe de stockage du périphérique. Reportez-vous à la <xref linkend="crush-devclasses"/> pour plus d'informations sur les classes de périphériques.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>SIZE</literal> : capacité de stockage globale de la grappe.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>AVAIL</literal> : quantité d'espace disponible dans la grappe.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal> : espace (accumulé sur tous les OSD) alloué uniquement pour les objets de données conservés sur le périphérique de bloc.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>RAW USED</literal> : somme de l'espace « USED » et de l'espace alloué/réservé au niveau du périphérique de bloc pour Ceph, par exemple la partie blueFS pour BlueStore.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% RAW USED</literal> : pourcentage de stockage brut utilisé. Utilisez ce nombre avec le ratio <literal>full</literal> et le ratio <literal>near full</literal> pour vous assurer que vous n'atteignez pas la capacité de votre grappe. Reportez-vous à la <xref linkend="storage-capacity"/> pour plus de détails.
    </para>
    <note>
     <title>niveau de remplissage de grappe</title>
     <para>
      Lorsqu'un niveau de remplissage de stockage brut se rapproche de 100 %, vous devez ajouter un nouveau stockage à la grappe. Une utilisation plus élevée peut conduire à la saturation de certains OSD et à des problèmes d'intégrité de la grappe.
     </para>
     <para>
      Utilisez la commande <command>ceph osd df tree</command> pour établir la liste de niveau de remplissage de tous les OSD.
     </para>
    </note>
   </listitem>
  </itemizedlist>

  <para>
   La section <literal>POOLS</literal> de la sortie fournit la liste des réserves et l'utilisation théorique de chaque réserve. La sortie de cette section ne reflète <emphasis>pas</emphasis> les répliques, les clones ou les instantanés existants. Par exemple, si vous stockez un objet de 1 Mo de données, l'utilisation théorique est de 1 Mo, mais l'utilisation réelle peut être de 2 Mo ou plus selon le nombre de répliques, de clones et d'instantanés.
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     <literal>POOL</literal> : nom de la réserve.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>ID</literal> : identifiant de la réserve.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>STORED</literal> : quantité de données stockées par l'utilisateur.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>OBJECTS</literal> : nombre théorique d'objets stockés par réserve.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>USED</literal> : quantité d'espace allouée exclusivement aux données par tous les noeuds OSD (en ko).
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>% USED</literal> : pourcentage de stockage théorique utilisé par réserve.
    </para>
   </listitem>
   <listitem>
    <para>
     <literal>MAX AVAIL</literal> : espace maximal disponible dans la réserve indiquée.
    </para>
   </listitem>
  </itemizedlist>

  <note>
   <para>
    Les nombres figurant dans la section POOLS sont théoriques. Ils n'incluent pas le nombre de répliques, d'instantanés ou de clones. Par conséquent, la somme des montants <literal>USED</literal> et <literal>%USED</literal> ne correspond pas aux montants <literal>RAW USED</literal> et <literal>%RAW USED</literal> dans la section <literal>RAW STORAGE</literal> de la sortie.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitor-osdstatus">
  <title>Vérification de l'état des OSD</title>

  <para>
   Vous pouvez vérifier les OSD pour vous assurer qu'ils sont opérationnels et activés à l'aide de la commande suivante :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd stat</screen>

  <para>
   ou
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd dump</screen>

  <para>
   Vous pouvez également afficher les OSD en fonction de leur position dans la carte CRUSH.
  </para>

  <para>
   <command>ceph osd tree</command> permet d'afficher une arborescence CRUSH avec un hôte, ses OSD, leur état et leur pondération :
  </para>

<screen>
   <prompt>cephuser@adm &gt; </prompt>ceph osd tree
ID  CLASS  WEIGHT   TYPE NAME              STATUS  REWEIGHT  PRI-AFF
-1      3  0.02939  root default
-3      3  0.00980    rack mainrack
-2      3  0.00980            host osd-host
0       1  0.00980                    osd.0   up   1.00000   1.00000
1       1  0.00980                    osd.1   up   1.00000   1.00000
2       1  0.00980                    osd.2   up   1.00000   1.00000
</screen>
 </sect1>
 <sect1 xml:id="storage-bp-monitoring-fullosd">
  <title>Contrôle des OSD pleins</title>

  <para>
   Ceph vous empêche d'écrire sur un OSD plein afin de vous éviter de perdre des données. Pour une grappe opérationnelle, un message d'avertissement doit s'afficher lorsque celle-ci est sur le point d'atteindre son ratio complet. La valeur par défaut de <command>monosd full ratio</command> est 0.95, c'est-à-dire 95 % de la capacité au-delà de laquelle les clients ne peuvent plus écrire de données dans la grappe. La valeur par défaut de <command>monosd nearfull ratio</command> est de 0.85, c'est-à-dire 85 % de la capacité à partir de laquelle un message d'avertissement d'intégrité est émis.
  </para>

  <para>
   Les noeuds OSD pleins sont signalés par la commande <command>ceph health</command> :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
  HEALTH_WARN 1 nearfull osds
  osd.2 is near full at 85%</screen>

  <para>
   ou
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph health
  HEALTH_ERR 1 nearfull osds, 1 full osds
  osd.2 is near full at 85%
  osd.3 is full at 97%</screen>

  <para>
   La meilleure façon de gérer une grappe pleine consiste à ajouter de nouveaux hôtes/disques OSD permettant à la grappe de redistribuer les données à l'espace de stockage récemment disponible.
  </para>

  <tip>
   <title>prévention de la saturation des OSD</title>
   <para>
    Un OSD plein utilise 100 % de son espace disque. Lorsqu'il atteint ce taux de remplissage, l'OSD se bloque sans avertissement. Voici quelques conseils à retenir lors de l'administration de noeuds OSD.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      L'espace disque de chaque OSD (généralement monté sous <filename>/var/lib/ceph/osd/osd-{1,2..}</filename>) doit être placé sur une partition ou un disque sous-jacent dédié.
     </para>
    </listitem>
    <listitem>
     <para>
      Vérifiez les fichiers de configuration Ceph et assurez-vous que Ceph ne stocke pas son fichier journal sur les partitions/disques dédiés aux OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      Assurez-vous qu'aucun autre processus n'écrit sur les partitions/disques dédiés aux OSD.
     </para>
    </listitem>
   </itemizedlist>
  </tip>
 </sect1>
 <sect1 xml:id="monitor-monstatus">
  <title>Vérification de l'état des instances Monitor</title>

  <para>
   Après avoir démarré la grappe et avant la première lecture et/ou écriture de données, vérifiez le statut du quorum des instances Ceph Monitor. Lorsque la grappe dessert déjà des requêtes, vérifiez périodiquement le statut des instances Ceph Monitor pour vous assurer qu'elles sont en cours d'exécution.
  </para>

  <para>
   Pour afficher l'assignation des moniteurs, exécutez la commande suivante :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph mon stat</screen>

  <para>
   ou
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph mon dump</screen>

  <para>
   Pour contrôler l'état du quorum de la grappe de moniteurs, exécutez la commande suivante :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph quorum_status</screen>

  <para>
   Ceph renvoie l'état du quorum. Par exemple, une grappe Ceph composée de trois moniteurs peut renvoyer les éléments suivants :
  </para>

<screen>{ "election_epoch": 10,
  "quorum": [
        0,
        1,
        2],
  "monmap": { "epoch": 1,
      "fsid": "444b489c-4f16-4b75-83f0-cb8097468898",
      "modified": "2011-12-12 13:28:27.505520",
      "created": "2011-12-12 13:28:27.505520",
      "mons": [
            { "rank": 0,
              "name": "a",
              "addr": "192.168.1.10:6789\/0"},
            { "rank": 1,
              "name": "b",
              "addr": "192.168.1.11:6789\/0"},
            { "rank": 2,
              "name": "c",
              "addr": "192.168.1.12:6789\/0"}
           ]
    }
}</screen>
 </sect1>
 <sect1 xml:id="monitor-pgroupstatus">
  <title>Vérification des états des groupes de placement</title>

  <para>
   Les groupes de placement assignent des objets aux OSD. Lorsque vous surveillez vos groupes de placement, vous voulez qu'ils soient <literal>actifs</literal> (active) et <literal>propres</literal> (clean). Pour une explication détaillée, reportez-vous à la <xref linkend="op-mon-osd-pg"/>.
  </para>
 </sect1>
 <sect1 xml:id="storage-capacity">
  <title>Capacité de stockage</title>

  <para>
   Lorsqu'une grappe de stockage Ceph se rapproche de sa capacité maximale, Ceph vous empêche d'écrire ou de lire à partir d'OSD Ceph afin d'éviter toute perte de données. Par conséquent, laisser une grappe de production s'approcher de son ration « full » n'est pas une bonne pratique, car cela nuit au principe de haute disponibilité. Le ratio « full » par défaut est défini sur 0,95, soit 95 % de la capacité. C'est une valeur très agressive pour une grappe de test avec un petit nombre d'OSD.
  </para>

  <tip>
   <title>augmentation de la capacité de stockage</title>
   <para>
    Lorsque vous surveillez votre grappe, soyez attentif aux avertissements liés au ratio <literal>nearfull</literal>. Cela signifie qu'une défaillance de certains OSD pourrait entraîner une interruption de service temporaire en cas d'échec d'un ou de plusieurs OSD. Pensez à ajouter d'autres OSD pour augmenter la capacité de stockage.
   </para>
  </tip>

  <para>
   Un scénario courant pour les grappes de test implique qu'un administrateur système supprime un OSD Ceph de la grappe de stockage Ceph pour examiner le rééquilibrage de la grappe. Il supprime ensuite un autre OSD Ceph, puis encore un autre, et ainsi de suite jusqu'à ce que la grappe atteigne le ratio « full » et se verrouille. Nous recommandons un minimum de planification de la capacité, même avec une grappe de test. La planification vous permet d'estimer la capacité de réserve dont vous avez besoin pour maintenir une haute disponibilité. Idéalement, vous souhaitez envisager une série de défaillances Ceph OSD où la grappe peut récupérer un état actif et propre (<literal>active + clean</literal>) sans remplacer ces Ceph OSD immédiatement. Vous pouvez exécuter une grappe dans un état actif et altéré (<literal>active + degraded</literal>), mais ce n'est pas idéal pour des conditions de fonctionnement normales.
  </para>

  <para>
   Le diagramme suivant représente une grappe de stockage Ceph simpliste contenant 33 noeuds Ceph avec un Ceph OSD par hôte, chacun d'eux disposant d'un accès en lecture-écriture pour une unité de 3 To. Cette grappe présente une capacité réelle maximale de 99 To. L'option <option>mon osd full ratio</option> est définie sur 0,95. Si la grappe arrive à 5 To de la capacité restante, elle ne permettra plus aux clients de lire et d'écrire des données. Par conséquent, la capacité d'exploitation de la grappe de stockage est de 95 To, et pas de 99.
  </para>

  <figure>
   <title>grappe Ceph</title>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_cluster.png" width="85%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <para>
   Il est normal dans une telle grappe qu'un ou deux OSD échouent. Un scénario moins fréquent, mais plausible, implique une défaillance du routeur ou de l'alimentation d'un rack, ce qui met hors service plusieurs OSD simultanément (par exemple, les OSD 7 à 12). Dans un tel scénario, vous devez toujours viser à disposer d'une grappe qui peut rester opérationnelle et atteindre un état <literal>active + clean</literal>, même si cela implique d'ajouter sans délai plusieurs hôtes avec des OSD supplémentaires. Si l'utilisation de votre capacité est trop élevée, vous ne pouvez pas risquer de perdre des données. Cela dit, vous pourriez encore sacrifier la disponibilité des données pendant la résolution d'une panne au sein d'un domaine défaillant si l'utilisation de la capacité de la grappe dépasse le ratio « full ». C'est pour cette raison que nous recommandons au moins une certaine planification approximative de la capacité.
  </para>

  <para>
   Identifiez deux nombres pour votre grappe :
  </para>

  <orderedlist>
   <listitem>
    <para>
     Le nombre d'OSD.
    </para>
   </listitem>
   <listitem>
    <para>
     La capacité totale de la grappe.
    </para>
   </listitem>
  </orderedlist>

  <para>
   Si vous divisez la capacité totale de votre grappe par le nombre d'OSD que celle-ci contient, vous obtenez la capacité moyenne d'un OSD au sein de votre grappe. Pensez à multiplier cette valeur par le nombre d'OSD qui, selon vous, pourraient échouer simultanément lors d'opérations normales (un nombre relativement faible). Enfin, multipliez la capacité de la grappe par le ratio « full » pour arriver à une capacité d'exploitation maximale. Ensuite, soustrayez la quantité de données des OSD susceptibles d'échouer pour obtenir un ratio « full » raisonnable. Répétez ce processus avec un nombre plus élevé de défaillances OSD (un rack d'OSD) afin d'obtenir un nombre raisonnable pour un ratio « nearfull ».
  </para>

  <para>
   Les paramètres suivants ne s'appliquent qu'à la création d'une grappe et sont ensuite stockés dans la carte OSD :
  </para>

<screen>
[global]
 mon osd full ratio = .80
 mon osd backfillfull ratio = .75
 mon osd nearfull ratio = .70
</screen>

  <tip>
   <para>
    Ces paramètres ne s'appliquent que lors de la création d'une grappe. Par la suite, ils doivent être modifiés dans la carte OSD à l'aide des commandes <command>ceph osd set-nearfull-ratio</command> et <command>ceph osd set-full-ratio</command>.
   </para>
  </tip>

  <variablelist>
   <varlistentry>
    <term>mon osd full ratio</term>
    <listitem>
     <para>
      Pourcentage d'espace disque utilisé avant qu'un OSD soit considéré comme complet (<literal>full</literal>). La valeur par défaut est 0,95.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd backfillfull ratio</term>
    <listitem>
     <para>
      Pourcentage d'espace disque utilisé avant qu'un OSD soit considéré comme trop rempli (<literal>full</literal>) pour un renvoi. La valeur par défaut est 0,90.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>mon osd nearfull ratio</term>
    <listitem>
     <para>
      Pourcentage d'espace disque utilisé avant qu'un OSD soit considéré comme presque complet (<literal>nearfull</literal>). La valeur par défaut est 0,85.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <tip>
   <title>vérification de la pondération des OSD</title>
   <para>
    Si certains OSD sont presque complets (<literal>nearfull</literal>), mais que d'autres ont beaucoup de capacité, la pondération CRUSH peut être problématique pour les OSD <literal>nearfull</literal>.
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="op-mon-osd-pg">
  <title>Surveillance des OSD et des groupes de placement</title>

  <para>
   Les principes de haute disponibilité et de haute fiabilité exigent une approche de tolérance aux pannes dans le cadre de la gestion des problèmes matériels et logiciels. Ceph n'a pas de point d'échec unique et peut desservir les requêtes de données en mode altéré (« degraded »). Le placement de données de Ceph introduit une couche d'indirection pour s'assurer que les données ne se lient pas directement à des adresses OSD particulières. Cela signifie que le suivi des pannes du système nécessite de trouver le groupe de placement et les OSD sous-jacents à l'origine du problème.
  </para>

  <tip>
   <title>accès en cas de défaillance</title>
   <para>
    Une panne dans une partie de la grappe peut vous empêcher d'accéder à un objet particulier. Cela ne signifie pas que vous ne pouvez pas accéder à d'autres objets. Lorsque vous rencontrez une panne, suivez les étapes de surveillance de vos OSD et groupes de placement. Commencez ensuite le dépannage.
   </para>
  </tip>

  <para>
   Ceph peut généralement se réparer lui-même. Toutefois, lorsque des problèmes persistent, la surveillance des OSD et des groupes de placement vous aide à identifier ce qui ne va pas.
  </para>

  <sect2 xml:id="op-mon-osds">
   <title>Surveillance des OSD</title>
   <para>
    Le statut d'un OSD est soit <emphasis>dans la grappe</emphasis> (« rentré », c'est-à-dire « in » en anglais), soit <emphasis>hors de la grappe</emphasis> (« sorti » - « out »). Par ailleurs, il est soit <emphasis>opérationnel et en cours d'exécution</emphasis> (« opérationnel » - « up »), soit <emphasis>arrêté et pas en cours d'exécution</emphasis> (« arrêté » - « down »). Si un OSD est « opérationnel », il peut être dans la grappe (vous pouvez lire et écrire des données) ou hors de celle-ci. S'il était dans la grappe et a été sorti récemment de cette dernière, Ceph migre les groupes de placement vers d'autres OSD. Si un OSD est hors de la grappe, CRUSH ne lui assigne pas de groupes de placement. Si un OSD est « arrêté », il doit également être « sorti ».
   </para>
   <note>
    <title>état altéré</title>
    <para>
     Si un OSD est « arrêté » et « rentré », il y a un problème et la grappe présente un état altéré.
    </para>
   </note>
   <para>
    Si vous exécutez une commande telle que <command>ceph health</command>, <command>ceph -s</command> ou <command>ceph -w</command>, vous pouvez remarquer que la grappe ne renvoie pas toujours la valeur <literal>HEALTH OK</literal> (État de santé OK). En ce qui concerne les OSD, vous devez vous attendre à ce que la grappe ne renvoie <emphasis>pas</emphasis> la valeur <literal>HEALTH OK</literal> dans les circonstances suivantes :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Vous n'avez pas encore démarré la grappe (elle ne répondra pas).
     </para>
    </listitem>
    <listitem>
     <para>
      Vous avez démarré ou redémarré la grappe et elle n'est pas encore prête, car les groupes de placement sont en cours de création et les OSD, en cours d'homologation.
     </para>
    </listitem>
    <listitem>
     <para>
      Vous avez ajouté ou supprimé un OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      Vous avez modifié votre assignation de grappe.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Un aspect important de la surveillance des OSD consiste à s'assurer que lorsque la grappe est opérationnelle et en cours d'exécution, tous ses OSD le sont aussi. Pour vérifier si tous les OSD sont en cours d'exécution, utilisez la commande suivante :
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd stat
x osds: y up, z in; epoch: eNNNN
</screen>
   <para>
    Le résultat devrait vous indiquer le nombre total d'OSD (x), combien sont « opérationnels » (y), combien sont « rentrés » (z), et l'époque d'assignation (eNNNN). Si le nombre d'OSD « rentrés » dans la grappe est supérieur au nombre d'OSD qui sont « opérationnels », exécutez la commande suivante pour identifier les daemons <literal>ceph-osd</literal> qui ne sont pas en cours d'exécution :
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd tree
#ID CLASS WEIGHT  TYPE NAME             STATUS REWEIGHT PRI-AFF
-1       2.00000 pool openstack
-3       2.00000 rack dell-2950-rack-A
-2       2.00000 host dell-2950-A1
0   ssd 1.00000      osd.0                up  1.00000 1.00000
1   ssd 1.00000      osd.1              down  1.00000 1.00000
</screen>
   <para>
    Par exemple, si un OSD avec l'ID 1 est arrêté, démarrez-le :
   </para>
<screen>
<prompt>cephuser@osd &gt; </prompt>sudo systemctl start ceph-<replaceable>CLUSTER_ID</replaceable>@osd.0.service
</screen>
   <para>
    Reportez-vous au <xref linkend="bp-troubleshooting-not-running"/> pour obtenir des informations sur les problèmes associés aux OSD qui se sont arrêtés ou qui ne redémarrent pas.
   </para>
  </sect2>

  <sect2 xml:id="op-pgsets">
   <title>Assignation d'ensembles de groupes de placement</title>
   <para>
    Lorsque CRUSH assigne des groupes de placement aux OSD, il examine le nombre de répliques pour la réserve et attribue le groupe de placement aux OSD de telle sorte que chaque réplique du groupe de placement soit assignée à un OSD différent. Par exemple, si la réserve nécessite trois répliques d'un groupe de placement, CRUSH peut les assigner à <literal>osd.1</literal>, <literal>osd.2</literal> et <literal>osd.3</literal> respectivement. CRUSH vise en fait un placement pseudo-aléatoire qui tiendra compte des domaines de défaillance que vous avez définis dans votre carte CRUSH, de sorte que vous verrez rarement des groupes de placement assignés à des OSD voisins les plus proches dans une vaste grappe. Nous nous référons à l'ensemble d'OSD qui devraient contenir les répliques d'un groupe de placement particulier en tant qu'<emphasis>ensemble agissant</emphasis>. Dans certains cas, un OSD de l'ensemble agissant est arrêté ou n'est pas en mesure de desservir les requêtes d'objets dans le groupe de placement pour l'une ou l'autre raison. Ces situations peuvent se présenter dans l'un des scénarios suivants :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Vous avez ajouté ou supprimé un OSD. Ensuite, CRUSH a réassigné le groupe de placement à d'autres OSD et a donc modifié la composition de l'<emphasis>ensemble agissant</emphasis>, provoquant la migration de données avec un processus de renvoi (« backfill »).
     </para>
    </listitem>
    <listitem>
     <para>
      Un OSD était « arrêté », a été redémarré et est maintenant en cours de récupération.
     </para>
    </listitem>
    <listitem>
     <para>
      Un OSD de l'<emphasis>ensemble agissant</emphasis> est « arrêté » ou n'est pas en mesure de desservir les requêtes, et un autre OSD a assumé temporairement ses fonctions.
     </para>
     <para>
      Ceph traite une requête client à l'aide de l'<emphasis>ensemble opérationnel</emphasis>, qui est l'ensemble d'OSD qui traitera réellement les requêtes. Dans la plupart des cas, l'<emphasis>ensemble opérationnel</emphasis> et l'<emphasis>ensemble agissant</emphasis> sont pratiquement identiques. Lorsqu'ils ne le sont pas, cela peut indiquer que Ceph migre des données, qu'un OSD est en cours de récupération ou qu'il existe un problème (par exemple, dans de tels scénarios, Ceph renvoie habituellement un état <literal>HEALTH WARN</literal> avec un message « stuck stale » [obsolète bloqué]).
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Pour récupérer une liste des groupes de placement, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump
</screen>
   <para>
    Pour voir quels OSD se trouvent dans l'<emphasis>ensemble agissant</emphasis> ou dans l'<emphasis>ensemble opérationnel</emphasis> pour un groupe de placement donné, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg map <replaceable>PG_NUM</replaceable>
osdmap eNNN pg <replaceable>RAW_PG_NUM</replaceable> (<replaceable>PG_NUM</replaceable>) -&gt; up [0,1,2] acting [0,1,2]
</screen>
   <para>
    Le résultat devrait vous indiquer l'époque osdmap (eNNN), le nombre de groupes de placement (<replaceable>PG_NUM</replaceable>), les OSD dans l'<emphasis>ensemble opérationnel</emphasis> (« up ») et les OSD dans l'<emphasis>ensemble agissant</emphasis> (« acting ») :
   </para>
   <tip>
    <title>indicateur de problème de grappe</title>
    <para>
     Si <emphasis>l'ensemble opérationnel</emphasis> et l'<emphasis>ensemble agissant</emphasis> ne correspondent pas, cela peut indiquer que la grappe est occupée à se rééquilibrer ou qu'elle rencontre un problème potentiel.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="op-peering">
   <title>Homologation</title>
   <para>
    Avant de pouvoir écrire des données dans un groupe de placement, celui-ci doit présenter un état <literal>actif</literal> (« active ») et <literal>propre</literal> (« clean »). Pour que Ceph puisse déterminer l'état actuel d'un groupe de placement, l'OSD primaire du groupe de placement (le premier OSD dans l'<emphasis>ensemble agissant</emphasis>) effectue une homologation avec les OSD secondaires et tertiaires pour établir un accord sur l'état actuel du groupe de placement (dans le cas d'une réserve avec trois répliques du groupe de placement).
   </para>
   <figure>
    <title>Schéma d'homologation</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="ceph_peering.png" width="70%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="op-mon-pg-states">
   <title>Surveillance des états des groupes de placement</title>
   <para>
    Si vous exécutez une commande telle que <command>ceph health</command>, <command>ceph -s</command> ou <command>ceph -w</command>, vous remarquerez peut-être que la grappe ne renvoie pas toujours un message <literal>HEALTH OK</literal> (État de santé OK). Après avoir vérifié si les OSD sont en cours d'exécution, vous devez également vérifier l'état des groupes de placement.
   </para>
   <para>
    Attendez-vous à ce que la grappe ne renvoie <emphasis role="bold">pas</emphasis> un message <literal>HEALTH OK</literal> dans un certain nombre de circonstances liées aux homologations des groupes de placement :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Vous avez créé une réserve et les groupes de placement n'ont pas encore effectué l'homologation.
     </para>
    </listitem>
    <listitem>
     <para>
      Les groupes de placement sont en cours de récupération.
     </para>
    </listitem>
    <listitem>
     <para>
      Vous avez ajouté ou supprimé un OSD au niveau de la grappe.
     </para>
    </listitem>
    <listitem>
     <para>
      Vous avez modifié votre carte CRUSH et vos groupes de placement sont en cours de migration.
     </para>
    </listitem>
    <listitem>
     <para>
      Les données sont incohérentes entre différentes répliques d'un groupe de placement.
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph est en train de nettoyer les répliques d'un groupe de placement.
     </para>
    </listitem>
    <listitem>
     <para>
      Ceph ne dispose pas de suffisamment de capacité de stockage pour effectuer des opérations de renvoi.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Si en raison de l'une des circonstances mentionnées ci-dessus, Ceph renvoie un message <literal>HEALTH WARN</literal>, ne paniquez pas. Dans de nombreux cas, la grappe se rétablit d'elle-même. Parfois, il peut cependant arriver que vous deviez intervenir. Un aspect important de la surveillance des groupes de placement consiste à vous assurer que lorsque la grappe est opérationnelle et en cours d'exécution, tous les groupes de placement sont actifs et, de préférence, dans un état propre. Pour voir l'état de tous les groupes de placement, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg stat
x pgs: y active+clean; z bytes data, aa MB used, bb GB / cc GB avail
</screen>
   <para>
    Le résultat devrait vous indiquer le nombre total de groupes de placement (x), le nombre de groupes de placement dans un état particulier tel que le « active + clean » (y) et la quantité de données stockées (z).
   </para>
   <para>
    En plus des états des groupes de placement, Ceph renverra également la quantité de capacité de stockage utilisée (aa), la quantité de capacité de stockage restante (bb) et la capacité de stockage totale pour le groupe de placement. Ces chiffres peuvent être importants dans certains cas :
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Vous vous approchez de votre ratio <option>nearfull</option> (presque complet) ou <option>full</option> (complet).
     </para>
    </listitem>
    <listitem>
     <para>
      Vos données ne sont pas distribuées dans l'ensemble de la grappe en raison d'une erreur dans votre configuration CRUSH.
     </para>
    </listitem>
   </itemizedlist>
   <tip>
    <title>ID de groupe de placement</title>
    <para>
     Les ID de groupe de placement se composent du numéro de la réserve (pas de son nom) suivi d'un point (.) et de l'ID du groupe de placement (un nombre hexadécimal). Vous pouvez consulter les numéros des réserves et leur nom dans la sortie de la commande <command>ceph osd lspools</command>. Par exemple, la réserve par défaut <literal>rbd</literal> correspond au numéro de réserve 0. Un ID de groupe de placement complet se présente sous la forme suivante :
    </para>
<screen>
<replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable>
</screen>
    <para>
     Il ressemble généralement à ceci :
    </para>
<screen>
0.1f
</screen>
   </tip>
   <para>
    Pour récupérer une liste des groupes de placement, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump
</screen>
   <para>
    Vous pouvez également mettre la sortie au format JSON et l'enregistrer dans un fichier :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg dump -o <replaceable>FILE_NAME</replaceable> --format=json
</screen>
   <para>
    Pour interroger un groupe de placement particulier, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph pg <replaceable>POOL_NUM</replaceable>.<replaceable>PG_ID</replaceable> query
</screen>
   <para>
    La liste suivante décrit en détail les statuts courants des groupes de placement.
   </para>
   <variablelist>
    <varlistentry>
     <term>CREATING</term>
     <listitem>
      <para>
       Lorsque vous créez une réserve, celle-ci crée le nombre de groupes de placement que vous avez spécifié. Ceph renvoie le statut « creating » (en cours de création) lorsqu'un ou plusieurs groupes de placement sont en cours de création. Une fois les groupes créés, les OSD qui font partie de l'<emphasis>ensemble agissant</emphasis> du groupe de placement effectuent l'homologation. Lorsque l'homologation est terminée, le statut du groupe de placement doit être « active + clean », ce qui signifie qu'un client Ceph peut commencer à écrire dans le groupe de placement.
      </para>
      <figure>
       <title>État des groupes de placement</title>
       <mediaobject>
        <imageobject role="fo">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
        <imageobject role="html">
         <imagedata fileref="ceph_pg_creating.png" width="80%" format="PNG"/>
        </imageobject>
       </mediaobject>
      </figure>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>PEERING</term>
     <listitem>
      <para>
       Lorsque Ceph effectue l'homologation (« peering ») d'un groupe de placement, il amène les OSD qui stockent les répliques du groupe de placement à un accord concernant l'état des objets et des métadonnées que ce dernier contient. Lorsque Ceph termine l'homologation, cela signifie que les OSD qui stockent le groupe de placement s'accordent sur l'état actuel du groupe de placement. Toutefois, l'achèvement du processus d'homologation ne signifie <emphasis role="bold">pas</emphasis> que chaque réplique dispose du contenu le plus récent.
      </para>
      <note>
       <title>historique faisant autorité</title>
       <para>
        Ceph ne reconnaîtra une opération d'écriture pour un client <emphasis role="bold">que</emphasis> lorsque tous les OSD de l'<emphasis>ensemble agissant</emphasis> conserveront l'opération d'écriture. Cette pratique garantit qu'au moins un membre de l'<emphasis>ensemble agissant</emphasis> aura un enregistrement de chaque opération d'écriture reconnue depuis la dernière opération d'homologation réussie.
       </para>
       <para>
        Avec un enregistrement précis de chaque opération d'écriture reconnue, Ceph peut construire et développer un nouvel historique faisant autorité pour le groupe de placement, à savoir un ensemble complet et organisé d'opérations qui, si elles sont effectuées, permettent de mettre à jour la copie d'un OSD de groupe de placement.
       </para>
      </note>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>ACTIVE</term>
     <listitem>
      <para>
       Une fois que Ceph a terminé le processus d'homologation, un groupe de placement peut devenir <literal>actif</literal> (« active »). L'état « <literal>active</literal> » signifie que les données du groupe de placement sont généralement disponibles dans le groupe de placement primaire et les répliques pour les opérations de lecture et d'écriture.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>CLEAN</term>
     <listitem>
      <para>
       Lorsqu'un groupe de placement est dans l'état <literal>propre</literal> (« clean »), cela signifie que l'OSD primaire et les OSD des répliques ont été homologués, et qu'il n'y a pas de répliques errantes pour le groupe de placement. Ceph a effectué le bon nombre de répliques de tous les objets du groupe de placement.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>DEGRADED</term>
     <listitem>
      <para>
       Lorsqu'un client écrit un objet sur l'OSD primaire, ce dernier est responsable de l'écriture des répliques sur les OSD des répliques. Une fois que l'OSD primaire a écrit l'objet dans le stockage, le groupe de placement reste dans un état altéré (« degraded ») jusqu'à ce que l'OSD primaire ait reçu une confirmation des OSD des répliques indiquant que Ceph a bien créé les objets des répliques.
      </para>
      <para>
       La raison pour laquelle un groupe de placement peut être à la fois actif et altéré (« active + degraded ») est qu'un OSD peut être actif même s'il ne détient pas encore tous les objets. Si un OSD s'arrête, Ceph marque chaque groupe de placement assigné à l'OSD comme altéré. Lorsque l'OSD en question redevient opérationnel, tous les OSD doivent à nouveau effectuer l'homologation. Toutefois, un client peut toujours écrire un nouvel objet sur un groupe de placement altéré s'il est actif.
      </para>
      <para>
       Si un OSD est arrêté et que la condition d'altération persiste, Ceph peut marquer l'OSD arrêté comme étant sorti (« out ») de la grappe et réassigne les données de l'OSD arrêté à un autre OSD. Le délai entre le moment où un OSD est marqué comme arrêté et celui où il est considéré comme sorti de la grappe est déterminé par l'option <option>mon osd down out interval</option>, qui est définie par défaut sur 600 secondes.
      </para>
      <para>
       Un groupe de placement peut également être marqué comme altéré parce que Ceph ne parvient pas à trouver un ou plusieurs objets qui devraient être dans le groupe de placement. Bien que vous ne puissiez pas lire ou écrire sur des objets introuvables, vous pouvez toujours accéder à tous les autres objets du groupe de placement altéré.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>RECOVERING</term>
     <listitem>
      <para>
       Ceph a été conçu pour permettre une tolérance aux pannes dans un environnement où les problèmes matériels et logiciels sont permanents. Lorsqu'un OSD est arrêté, son contenu peut devenir obsolète par rapport à l'état actuel d'autres répliques dans les groupes de placement. Lorsque l'OSD redevient opérationnel, le contenu des groupes de placement doit alors être mis à jour pour refléter l'état actuel. Durant cette opération, l'état de l'OSD peut indiquer qu'il est en cours de récupération (« recovering»).
      </para>
      <para>
       La récupération n'est pas toujours simple, car une défaillance matérielle peut provoquer une défaillance en cascade de plusieurs OSD. Par exemple, un commutateur réseau pour un rack ou une armoire peut tomber en panne, de sorte les OSD de plusieurs machines hôtes se retrouvent dans un état obsolète par rapport à celui de la grappe. Chacun de ces OSD doit alors récupérer une fois la panne résolue.
      </para>
      <para>
       Ceph fournit un certain nombre de paramètres pour équilibrer les conflits de ressources entre les nouvelles requêtes de service et la nécessité de récupérer les objets de données et de restaurer les groupes de placement vers l'état actuel. Le paramètre <option>osd recovery delay start</option> permet à un OSD de redémarrer, d'effectuer un nouveau processus d'homologation et même de traiter certaines demandes de relecture avant d'entamer sa récupération. Le paramètre <option>osd recovery thread timeout</option> définit un timeout de thread, car plusieurs OSD peuvent échouer, redémarrer et effectuer une nouvelle homologation à des moments différents. Le paramètre <option>osd recovery max active</option> limite le nombre de demandes de récupération qu'un OSD traite simultanément afin d'éviter qu'il échoue. Le paramètre <option>osd recovery max chunk</option> limite la taille des tranches de données récupérées pour éviter la congestion du réseau.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>BACK FILLING</term>
     <listitem>
      <para>
       Lorsqu'un nouvel OSD rejoint la grappe, CRUSH réassigne des groupes de placement des OSD de la grappe à l'OSD récemment ajouté. Obliger le nouvel OSD à accepter immédiatement les groupes de placement réassignés peut lui imposer une charge excessive. Le principe de renvoi (« backfilling ») de l'OSD avec les groupes de placement permet à ce processus de commencer en arrière-plan. Une fois le renvoi terminé, le nouvel OSD commence à desservir les requêtes lorsqu'il est prêt.
      </para>
      <para>
       Pendant les opérations de renvoi, vous pouvez voir l'un des états suivants : « backfill_wait » indique qu'une opération de renvoi est en attente, mais pas encore en cours ; « backfill » indique qu'une opération de renvoi est en cours ; « backfill_too_full » indique qu'une opération de renvoi a été demandée, mais n'a pas pu être effectuée en raison d'une capacité de stockage insuffisante. Lorsqu'un groupe de placement ne peut pas être renvoyé, il peut être considéré comme incomplet (« incomplete »).
      </para>
      <para>
       Ceph fournit plusieurs paramètres pour gérer la charge associée à la réassignation de groupes de placement à un OSD (en particulier un nouvel OSD). Par défaut, le paramètre <option>osd max backfills</option> définit le nombre maximal de renvois simultanés vers un OSD ou à partir de celui-ci à 10. Le paramètre <option>backfill full ratio</option> permet à un OSD de refuser une demande de renvoi si l'OSD se rapproche de son ratio « full » (90 % par défaut) et de changer avec la commande <command>ceph osd set-backfillfull-ratio</command>. Si un OSD refuse une demande de renvoi, le paramètre <option>osd backfill retry interval</option> permet à un OSD de réessayer la demande (après 10 secondes, par défaut). Les OSD peuvent également définir les paramètres <option>osd backfill scan min</option> et <option>osd backfill scan max</option> pour gérer les intervalles d'analyse (64 et 512, par défaut).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>REMAPPED</term>
     <listitem>
      <para>
       Lorsque l'<emphasis>ensemble agissant</emphasis> qui dessert un groupe de placement change, les données migrent de l'ancien <emphasis>ensemble agissant</emphasis> ver le nouvel <emphasis>ensemble agissant</emphasis>. Un nouvel OSD primaire peut nécessiter un certain temps pour desservir des requêtes. C'est pourquoi il peut demander à l'ancien OSD primaire de continuer à traiter les requêtes jusqu'à ce que la migration du groupe de placement soit terminée. Une fois la migration des données terminée, l'assignation utilise l'OSD primaire du nouvel <emphasis>ensemble agissant</emphasis>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>STALE</term>
     <listitem>
      <para>
       Tandis que Ceph utilise des pulsations pour s'assurer que les hôtes et les daemons sont en cours d'exécution, les daemons <literal>ceph-osd</literal> peuvent également se retrouver dans un état bloqué (« stuck ») dans lequel ils ne rendent pas compte des statistiques en temps opportun (par exemple, en cas de défaillance temporaire du réseau). Par défaut, les daemons OSD signalent leurs statistiques de groupe de placement, de démarrage et d'échec toutes les demi-secondes (0,5), ce qui est plus fréquent que les seuils de pulsation. Si l'OSD primaire de l'<emphasis>ensemble agissant</emphasis> d'un groupe de placement ne parvient pas à rendre compte au moniteur ou si d'autres OSD ont signalé l'OSD primaire comme étant arrêté, les moniteurs marquent le groupe de placement comme obsolète (« stale »).
      </para>
      <para>
       Lorsque vous démarrez votre grappe, il est courant de voir l'état « stale » tant que le processus d'homologation n'est pas terminé. En revanche, lorsque votre grappe est en cours d'exécution depuis un certain temps, si des groupes de placement sont dans l'état « stale », cela indique que l'OSD primaire pour ces groupes de placement est arrêté ou ne rend pas compte de ses statistiques de groupe de placement au moniteur.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="op-pg-objectfinding">
   <title>Identification de l'emplacement d'un objet</title>
   <para>
    Pour stocker les données d'objet dans le magasin d'objets Ceph, un client Ceph doit définir un nom d'objet et spécifier une réserve associée. Le client Ceph récupère la dernière assignation de grappe et l'algorithme CRUSH calcule comment assigner l'objet à un groupe de placement, puis calcule comment assigner le groupe de placement à un OSD de façon dynamique. Pour trouver l'emplacement de l'objet, tout ce dont vous avez besoin est le nom de l'objet et le nom de la réserve. Par exemple :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd map <replaceable>POOL_NAME</replaceable> <replaceable>OBJECT_NAME</replaceable> [<replaceable>NAMESPACE</replaceable>]
</screen>
   <example>
    <title>localisation d'un objet</title>
    <para>
     À titre d'exemple, créons un objet. Spécifiez un nom d'objet « test-object-1 », un chemin vers un fichier d'exemple « testfile.txt » contenant certaines données d'objet et un nom de réserve « data » à l'aide de la commande <command>rados put</command> sur la ligne de commande :
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados put test-object-1 testfile.txt --pool=data
</screen>
    <para>
     Pour vérifier que le magasin d'objets Ceph a stocké l'objet, exécutez la commande suivante :
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados -p data ls
</screen>
    <para>
     Maintenant, identifiez l'emplacement de l'objet. Ceph renverra l'emplacement de l'objet :
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd map data test-object-1
osdmap e537 pool 'data' (0) object 'test-object-1' -&gt; pg 0.d1743484 \
(0.4) -&gt; up ([1,0], p0) acting ([1,0], p0)
</screen>
    <para>
     Pour supprimer l'exemple d'objet, il suffit de le supprimer à l'aide de la commande <command>rados rm</command> :
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados rm test-object-1 --pool=data
</screen>
   </example>
  </sect2>
 </sect1>
</chapter>
