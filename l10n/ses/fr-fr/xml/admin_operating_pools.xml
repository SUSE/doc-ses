<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_operating_pools.xml" version="5.0" xml:id="ceph-pools">
 <title>Gestion des réserves de stockage</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>oui</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Ceph stocke les données dans des réserves. Les réserves sont des groupes logiques pour le stockage des objets. Lorsque vous déployez une grappe pour la première fois sans créer de réserve, Ceph utilise les réserves par défaut pour stocker les données. Les points importants suivants concernent les réserves Ceph :
 </para>
 <itemizedlist mark="bullet" spacing="normal">
  <listitem>
   <para>
    <emphasis>Résilience</emphasis> : les réserves Ceph garantissent une résilience en répliquant ou en codant les données qu'elles contiennent. Chaque réserve peut être configurée pour être <literal>répliquée</literal> (« replicated ») ou <literal>codée à effacement</literal> (« erasure coded »). Pour les réserves répliquées, vous devez également définir le nombre de répliques, ou copies, dont disposera chaque objet de données de la réserve. Le nombre de copies (OSD, compartiments/feuilles CRUSH) pouvant être perdues est inférieur d'une unité au nombre de répliques. Avec le codage à effacement, vous devez définir les valeurs de <option>k</option> et <option>m</option>, <option>k</option> correspondant au nombre de tranches de données et <option>m</option> au nombre de tranches de codage. Pour les réserves utilisant le codage à effacement, c'est le nombre de tranches de codage qui détermine le nombre d'OSD (compartiments/feuilles CRUSH) pouvant être perdus sans perte de données.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis>Groupes de placement</emphasis> : vous pouvez définir le nombre de groupes de placement pour la réserve. Une configuration type utilise environ 100 groupes de placement par OSD pour fournir un équilibrage optimal sans nécessiter trop de ressources informatiques. Lors de la configuration de plusieurs grappes, veillez à définir un nombre raisonnable de groupes de placement pour la réserve et la grappe dans leur ensemble.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis>Règles CRUSH</emphasis> : lorsque vous stockez des données dans une réserve, les objets et leurs répliques (ou tranches en cas de réserves codées à effacement) sont placés selon l'ensemble de règles CRUSH assignées à la réserve. Vous pouvez créer une règle CRUSH personnalisée pour votre réserve.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis>Instantanés</emphasis> : lorsque vous créez des instantanés avec <command>ceph osd pool mksnap</command>, vous prenez effectivement un instantané d'une réserve en particulier.
   </para>
  </listitem>
 </itemizedlist>
 <para>
  Pour organiser les données en réserves, vous pouvez répertorier, créer et supprimer des réserves. Vous pouvez également afficher les statistiques d'utilisation pour chaque réserve.
 </para>
 <sect1 xml:id="ceph-pools-operate-add-pool">
  <title>Création d'une réserve</title>

  <para>
   Une réserve peut être de type <literal>replicated</literal> (répliquée) pour récupérer des OSD perdus en conservant plusieurs copies des objets, ou de type <literal>erasure</literal> (à effacement) pour obtenir une sorte de fonctionnalité RAID5/6 généralisée. Les réserves répliquées nécessitent plus de stockage brut, tandis que les réserves codées à effacement en exigent moins. Le paramètre par défaut est <literal>replicated</literal>. Pour plus d'informations sur les réserves codées à effacement, reportez-vous au <xref linkend="cha-ceph-erasure"/>.
  </para>

  <para>
   Pour créer une réserve répliquée, exécutez :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool create <replaceable>POOL_NAME</replaceable></screen>

  <note>
   <para>
    La mise à l'échelle automatique se chargera des arguments facultatifs restants. Pour plus d'informations, reportez-vous à la <xref linkend="op-pgs-autoscaler"/>.
   </para>
  </note>

  <para>
   Pour créer une réserve codée à effacement, exécutez :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool create <replaceable>POOL_NAME</replaceable> erasure <replaceable>CRUSH_RULESET_NAME</replaceable> \
<replaceable>EXPECTED_NUM_OBJECTS</replaceable></screen>

  <para>
   La commande <command>ceph osd pool create</command> peut échouer si vous dépassez la limite de groupes de placement par OSD. La limite est définie avec l'option <option>mon_max_pg_per_osd</option>.
  </para>

  <variablelist>
   <varlistentry>
    <term>POOL_NAME</term>
    <listitem>
     <para>
      Nom de la réserve. Il doit être unique. Cette option est obligatoire. 
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>POOL_TYPE</term>
    <listitem>
     <para>
      Le type de réserve qui peut être soit <literal>répliqué</literal> pour récupérer des OSD perdus en conservant plusieurs copies des objets ou <literal>à effacement</literal> pour obtenir une sorte de fonctionnalité RAID5 généralisée. Les réserves répliquées nécessitent plus de stockage brut mais implémentent toutes les opérations Ceph. Les réserves à effacement nécessitent moins de stockage brut, mais implémentent uniquement un sous-ensemble des opérations disponibles. La valeur par défaut de <literal>POOL_TYPE</literal> est <literal>replicated</literal>.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>CRUSH_RULESET_NAME</term>
    <listitem>
     <para>
      Nom de l'ensemble de règles CRUSH de cette réserve. Si l'ensemble de règles indiqué n'existe pas, la création de réserves répliquées échoue avec -ENOENT. Pour les réserves répliquées, il s'agit de l'ensemble de règles spécifié par la variable de configuration <varname>osd pool default CRUSH replicated ruleset</varname>. Cet ensemble de règles doit exister. Pour les réserves à effacement, il s'agit de « erasure-code » si le profil de code à effacement par défaut est utilisé, sinon de <replaceable>NOM_RÉSERVE</replaceable>. Cet ensemble de règles sera créé implicitement s'il n'existe pas déjà.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>erasure_code_profile=profile</term>
    <listitem>
     <para>
      Pour les réserves codées à effacement uniquement. Utilisez le profil de code d'effacement. Il doit s'agir d'un profil existant tel que défini par <command>osd erasure-code-profile set</command>.
     </para>
     <note>
      <para>
       Si, pour une raison quelconque, la mise à l'échelle automatique a été désactivée (<literal>pg_autoscale_mode</literal> désactivé) sur une réserve, vous pouvez calculer et définir manuellement le nombre de groupes de placement. Reportez-vous à la <xref linkend="op-pgs"/> pour plus d'informations sur le calcul du nombre de groupes de placement approprié pour votre réserve.
      </para>
     </note>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>EXPECTED_NUM_OBJECTS</term>
    <listitem>
     <para>
      Nombre d'objets attendu pour cette réserve. En définissant cette valeur (avec un seuil <option>filestore merge threshold</option> négatif), le fractionnement du dossier de groupes de placement se produit au moment de la création de la réserve. Cela évite l'impact de latence lié au fractionnement du dossier à l'exécution.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>
 <sect1 xml:id="ceph-listing-pools">
  <title>Liste des réserves</title>

  <para>
   Pour afficher la liste des réserves de la grappe, exécutez :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool ls</screen>
 </sect1>
 <sect1 xml:id="ceph-renaming-pool">
  <title>Modification du nom d'une réserve</title>

  <para>
   Pour renommer une réserve, exécutez :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool rename <replaceable>CURRENT_POOL_NAME</replaceable> <replaceable>NEW_POOL_NAME</replaceable></screen>

  <para>
   Si vous renommez une réserve et que vous disposez de fonctions de réserve pour un utilisateur authentifié, vous devez mettre à jour les fonctions de l'utilisateur avec le nouveau nom de réserve.
  </para>
 </sect1>
 <sect1 xml:id="ceph-pools-operate-del-pool">
  <title>Suppression d'une réserve</title>

  <warning>
   <title>la suppression d'une réserve est irréversible</title>
   <para>
    Les réserves peuvent contenir des données importantes. La suppression d'une réserve entraîne la disparition de toutes les données qu'elle contient et l'impossibilité de la récupérer.
   </para>
  </warning>

  <para>
   Comme la suppression accidentelle d'une réserve constitue un réel danger, Ceph implémente deux mécanismes qui empêchent cette suppression. Ces deux mécanismes doivent être désactivés avant la suppression d'une réserve.
  </para>

  <para>
   Le premier mécanisme consiste à utiliser l'indicateur <literal>NODELETE</literal>. Chaque réserve possède cet indicateur dont la valeur par défaut est « false ». Pour connaître la valeur de cet indicateur sur une réserve, exécutez la commande suivante :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool get <replaceable>pool_name</replaceable> nodelete</screen>

  <para>
   Si elle génère <literal>nodelete: true</literal>, il n'est pas possible de supprimer la réserve tant que vous ne modifiez pas l'indicateur à l'aide de la commande suivante :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>pool_name</replaceable> nodelete false</screen>

  <para>
   Le second mécanisme est le paramètre de configuration de la grappe <option>mon allow pool delete</option>, qui est « false » par défaut. Cela signifie que, par défaut, il n'est pas possible de supprimer une réserve. Le message d'erreur affiché est le suivant :
  </para>

<screen>Error EPERM: pool deletion is disabled; you must first set the
mon_allow_pool_delete config option to true before you can destroy a pool</screen>

  <para>
   Pour supprimer la réserve malgré ce paramètre de sécurité, vous pouvez définir temporairement <option>mon allow pool delete</option> sur « true », supprimer la réserve, puis renvoyer le paramètre avec « false » :
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph tell mon.* injectargs --mon-allow-pool-delete=true
<prompt>cephuser@adm &gt; </prompt>ceph osd pool delete pool_name pool_name --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph tell mon.* injectargs --mon-allow-pool-delete=false</screen>

  <para>
   La commande <command>injectargs</command> affiche le message suivant :
  </para>

<screen>injectargs:mon_allow_pool_delete = 'true' (not observed, change may require restart)</screen>

  <para>
   Cela confirme simplement que la commande a été exécutée avec succès. Il ne s'agit pas d'une erreur.
  </para>

  <para>
   Si vous avez défini vos propres ensembles de règles et règles pour une réserve que vous avez créée, vous devez envisager de les supprimer lorsque vous n'avez plus besoin de la réserve.
  </para>
 </sect1>
 <sect1 xml:id="ceph-pool-other-operations">
  <title>Autres opérations</title>

  <sect2 xml:id="ceph-pools-associate">
   <title>Association de réserves à une application</title>
   <para>
    Pour pouvoir utiliser les réserves, vous devez les associer à une application. Les réserves qui seront utilisées avec CephFS ou les réserves créées automatiquement par Object Gateway sont automatiquement associées.
   </para>
   <para>
    Pour les autres cas, vous pouvez associer manuellement un nom de l'application de format libre à une réserve :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool application enable <replaceable>POOL_NAME</replaceable> <replaceable>APPLICATION_NAME</replaceable></screen>
   <tip>
    <title>noms d'application par défaut</title>
    <para>
     CephFS utilise le nom de l'application <literal>cephfs</literal>, le périphérique de bloc RADOS emploie <literal>rbd</literal> et la passerelle Object Gateway fait appel à <literal>rgw</literal>.
    </para>
   </tip>
   <para>
    Une réserve peut être associée à plusieurs applications et chaque application peut avoir ses propres métadonnées. Pour lister l'application (ou les applications) associée(s) à une réserve, exécutez la commande suivante :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool application get <replaceable>pool_name</replaceable></screen>
  </sect2>

  <sect2 xml:id="ceph-set-pool-quotas">
   <title>Définition de quotas de réserve</title>
   <para>
    Vous pouvez définir des quotas de réserve pour le nombre maximal d'octets et/ou le nombre maximal d'objets par réserve.
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota <replaceable>POOL_NAME</replaceable> <replaceable>MAX_OBJECTS</replaceable> <replaceable>OBJ_COUNT</replaceable> <replaceable>MAX_BYTES</replaceable> <replaceable>BYTES</replaceable></screen>
   <para>
    Par exemple :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set-quota data max_objects 10000</screen>
   <para>
    Pour supprimer un quota, définissez sa valeur sur 0.
   </para>
  </sect2>

  <sect2 xml:id="ceph-showing-pool-statistics">
   <title>Affichage des statistiques d'une réserve</title>
   <para>
    Pour afficher les statistiques d'utilisation d'une réserve, exécutez :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>rados df
 POOL_NAME                    USED OBJECTS CLONES COPIES MISSING_ON_PRIMARY UNFOUND DEGRADED  RD_OPS      RD  WR_OPS      WR USED COMPR UNDER COMPR
 .rgw.root                 768 KiB       4      0     12                  0       0        0      44  44 KiB       4   4 KiB        0 B         0 B
 cephfs_data               960 KiB       5      0     15                  0       0        0    5502 2.1 MiB      14  11 KiB        0 B         0 B
 cephfs_metadata           1.5 MiB      22      0     66                  0       0        0      26  78 KiB     176 147 KiB        0 B         0 B
 default.rgw.buckets.index     0 B       1      0      3                  0       0        0       4   4 KiB       1     0 B        0 B         0 B
 default.rgw.control           0 B       8      0     24                  0       0        0       0     0 B       0     0 B        0 B         0 B
 default.rgw.log               0 B     207      0    621                  0       0        0 5372132 5.1 GiB 3579618     0 B        0 B         0 B
 default.rgw.meta          961 KiB       6      0     18                  0       0        0     155 140 KiB      14   7 KiB        0 B         0 B
 example_rbd_pool          2.1 MiB      18      0     54                  0       0        0 3350841 2.7 GiB     118  98 KiB        0 B         0 B
 iscsi-images              769 KiB       8      0     24                  0       0        0 1559261 1.3 GiB      61  42 KiB        0 B         0 B
 mirrored-pool             1.1 MiB      10      0     30                  0       0        0  475724 395 MiB      54  48 KiB        0 B         0 B
 pool2                         0 B       0      0      0                  0       0        0       0     0 B       0     0 B        0 B         0 B
 pool3                     333 MiB      37      0    111                  0       0        0 3169308 2.5 GiB   14847 118 MiB        0 B         0 B
 pool4                     1.1 MiB      13      0     39                  0       0        0 1379568 1.1 GiB   16840  16 MiB        0 B         0 B
 </screen>
   <para>
    Une description de chaque colonne suit :
   </para>
   <variablelist>
    <varlistentry>
     <term>USED</term>
     <listitem>
      <para>
       Nombre d'octets utilisés par la réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>OBJECTS</term>
     <listitem>
      <para>
       Nombre d'objets stockés dans la réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>CLONES</term>
     <listitem>
      <para>
       Nombre de clones stockés dans la réserve. Lorsqu'un instantané est créé et que l'on écrit dans un objet, au lieu de modifier l'objet d'origine, son clone est créé de sorte que le contenu de l'objet instantané d'origine n'est pas modifié.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>COPIES</term>
     <listitem>
      <para>
       Nombre de répliques d'objets. Par exemple, si une réserve répliquée avec le facteur de réplication 3 a « x » objets, elle aura normalement 3 * x copies.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>MISSING_ON_PRIMARY</term>
     <listitem>
      <para>
       Nombre d'objets dans l'état altéré (toutes les copies n'existent pas) alors que la copie est manquante sur l'OSD primaire.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>UNFOUND</term>
     <listitem>
      <para>
       Nombre d'objets introuvables.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>DEGRADED</term>
     <listitem>
      <para>
       Nombre d'objets altérés.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>RD_OPS</term>
     <listitem>
      <para>
       Nombre total d'opérations de lecture demandées pour cette réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>RD</term>
     <listitem>
      <para>
       Nombre total d'octets lus à partir de cette réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>WR_OPS</term>
     <listitem>
      <para>
       Nombre total d'opérations d'écriture demandées pour cette réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>WR</term>
     <listitem>
      <para>
       Nombre total d'octets écrits dans la réserve. Notez que cela n'est pas la même chose que l'utilisation de la réserve, car vous pouvez écrire plusieurs fois sur le même objet. Au final, l'utilisation de la réserve restera la même, mais le nombre d'octets qui y sont écrits augmentera.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>USED COMPR</term>
     <listitem>
      <para>
       Nombre d'octets alloués aux données compressées.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>UNDER COMPR</term>
     <listitem>
      <para>
       Nombre d'octets occupés par les données compressées lorsqu'elles ne sont pas compressées.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ceph-getting-pool-values">
   <title>Obtention de valeurs d'une réserve</title>
   <para>
    Pour obtenir une valeur à partir d'une réserve, exécutez la commande <command>get</command> suivante :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool get <replaceable>POOL_NAME</replaceable> <replaceable>KEY</replaceable></screen>
   <para>
    Vous pouvez obtenir des valeurs pour les clés répertoriées à la <xref linkend="ceph-pools-values"/> ainsi que les clés suivantes :
   </para>
   <variablelist>
    <varlistentry>
     <term>PG_NUM</term>
     <listitem>
      <para>
       Nombre de groupes de placement pour la réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>PGP_NUM</term>
     <listitem>
      <para>
       Nombre effectif de groupes de placement à utiliser lors du calcul du placement des données. La plage valide est inférieure ou égale à <option>PG_NUM</option>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <tip>
    <title>toutes les valeurs d'une réserve</title>
    <para>
     Pour répertorier toutes les valeurs associées à une réserve spécifique, exécutez :
    </para>
<screen>
 <prompt>cephuser@adm &gt; </prompt>ceph osd pool get <replaceable>POOL_NAME</replaceable> all
 </screen>
   </tip>
  </sect2>

  <sect2 xml:id="ceph-pools-values">
   <title>Définition des valeurs d'une réserve</title>
   <para>
    Pour définir une valeur d'une réserve, exécutez :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>POOL_NAME</replaceable> <replaceable>KEY</replaceable> <replaceable>VALUE</replaceable></screen>
   <para>
    La liste ci-dessous répertorie les valeurs de réserve triées par type de réserve :
   </para>
   <variablelist>
    <title>Valeurs de réserve commune</title>
    <varlistentry>
     <term>crash_replay_interval</term>
     <listitem>
      <para>
       Nombre de secondes pendant lesquelles les clients peuvent relire les requêtes acquittées mais non validées.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>pg_num</term>
     <listitem>
      <para>
       Nombre de groupes de placement pour la réserve. Si vous ajoutez des OSD à la grappe, vérifiez la valeur des groupes de placement sur toutes les réserves ciblées pour les nouveaux OSD.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>pgp_num</term>
     <listitem>
      <para>
       Nombre effectif de groupes de placement à utiliser lors du calcul du placement des données.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>crush_ruleset</term>
     <listitem>
      <para>
       Ensemble de règles à utiliser pour l'assignation de placement d'objets dans la grappe.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hashpspool</term>
     <listitem>
      <para>
       Définissez (1) ou désélectionnez (0) l'indicateur HASHPSPOOL sur une réserve donnée. L'activation de cet indicateur modifie l'algorithme pour mieux répartir les PG sur les OSD. Après avoir activé ce drapeau sur une réserve dont le drapeau HASHPSPOOL avait été défini par défaut sur 0, la grappe commence à effectuer des renvois afin de rétablir le placement correct de tous les groupes de placement. Cette activation pouvant créer une charge d'E/S assez importante sur une grappe, ne passez pas le drapeau de 0 à 1 sur les grappes de production très chargées.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>nodelete</term>
     <listitem>
      <para>
       Empêche la suppression de la réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>nopgchange</term>
     <listitem>
      <para>
       Empêche la modification des options <option>pg_num</option> et <option>pgp_num</option> de la réserve.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>noscrub, nodeep-scrub</term>
     <listitem>
      <para>
       Désactive le nettoyage (en profondeur) des données pour la réserve en particulier afin de résoudre une charge d'E/S élevée temporaire.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>write_fadvise_dontneed</term>
     <listitem>
      <para>
       Sélectionnez ou désélectionnez l'indicateur <literal>WRITE_FADVISE_DONTNEED</literal> sur les requêtes de lecture/d'écriture d'une réserve donnée afin de contourner la mise en cache des données. La valeur par défaut est <literal>false</literal>. S'applique aux réserves répliquées et EC.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>scrub_min_interval</term>
     <listitem>
      <para>
       Intervalle minimal en secondes pour le nettoyage des réserves lorsque la charge de la grappe est faible. La valeur par défaut <literal>0</literal> signifie que la valeur de <option>osd_scrub_min_interval</option> du fichier de configuration Ceph est utilisée.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>scrub_max_interval</term>
     <listitem>
      <para>
       Intervalle maximal en secondes pour le nettoyage des réserves, quelle que soit la charge de la grappe. La valeur par défaut <literal>0</literal> signifie que la valeur de <option>osd_scrub_max_interval</option> du fichier de configuration Ceph est utilisée.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>deep_scrub_interval</term>
     <listitem>
      <para>
       Intervalle en secondes pour le nettoyage <emphasis>en profondeur</emphasis> de la grappe. La valeur par défaut <literal>0</literal> signifie que la valeur de <option>osd_deep_scrub</option> du fichier de configuration Ceph est utilisée.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <variablelist>
    <title>Valeurs de réserve répliquée</title>
    <varlistentry>
     <term>size</term>
     <listitem>
      <para>
       Définit le nombre de répliques d'objets dans la réserve. Pour plus d'informations, reportez-vous à la <xref linkend="ceph-pools-options-num-of-replicas"/>. Réserves répliquées uniquement.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>min_size</term>
     <listitem>
      <para>
       Définit le nombre minimum de répliques requises pour les E/S. Reportez-vous à la <xref linkend="ceph-pools-options-num-of-replicas"/> pour plus de détails. Réserves répliquées uniquement.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>nosizechange</term>
     <listitem>
      <para>
       Empêche la modification de la taille de la réserve. Lorsqu'une réserve est créée, la valeur par défaut est tirée de la valeur du paramètre <option>osd_pool_default_flag_nosizechange</option>, lequel est défini par défaut sur <literal>false</literal>. S'applique uniquement aux réserves répliquées, car la taille des réserves EC ne peut pas être modifiée.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_type</term>
     <listitem>
      <para>
       Active le suivi des jeux d'accès pour les réserves de cache. Reportez-vous à l'article <link xlink:href="http://en.wikipedia.org/wiki/Bloom_filter">Filtre de Bloom</link> pour obtenir des informations complémentaires. Cette option accepte l'une des valeurs suivantes : <literal>bloom</literal>, <literal>explicit_hash</literal>, <literal>explicit_object</literal>. La valeur par défaut est <literal>bloom</literal>, les autres valeurs sont utilisées à des fins de test uniquement.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_count</term>
     <listitem>
      <para>
       Nombre de jeux d'accès à stocker dans les réserves de cache. Plus le nombre est élevé, plus le daemon <systemitem>ceph-osd</systemitem> consomme une quantité importante de mémoire vive. La valeur par défaut est <literal>0</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_period</term>
     <listitem>
      <para>
       Durée d'une période de jeu d'accès définie en secondes pour les réserves de cache. Plus le nombre est élevé, plus le daemon <systemitem>ceph-osd</systemitem> consomme une quantité importante de mémoire vive. Lorsqu'une réserve est créée, la valeur par défaut est tirée de la valeur du paramètre <option>osd_tier_default_cache_hit_set_period</option>, lequel est défini par défaut sur <literal>1200</literal>. S'applique uniquement aux réserves répliquées, car les réserves EC ne peuvent pas être utilisées en tant que niveau de cache.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_fpp</term>
     <listitem>
      <para>
       Probabilité de faux positifs pour le type de jeu d'accès de filtre de Bloom. Reportez-vous à l'article <link xlink:href="http://en.wikipedia.org/wiki/Bloom_filter">Filtre de Bloom</link> pour obtenir des informations complémentaires. La plage valide est comprise entre 0.0 et 1.0. La valeur par défaut est <literal>0.05</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>use_gmt_hitset</term>
     <listitem>
      <para>
       Forcez les OSD à utiliser les horodatages GMT (Greenwich Mean Time) lors de la création d'un jeu d'accès pour la hiérarchisation du cache. Cela garantit que les noeuds situés dans des fuseaux horaires différents retournent le même résultat. La valeur par défaut est <literal>1</literal>. Cette valeur ne doit pas être modifiée.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cache_target_dirty_ratio</term>
     <listitem>
      <para>
       Pourcentage de la réserve de cache contenant des objets modifiés (altérés) avant que l'agent de hiérarchisation du cache les transfère à la réserve de stockage de sauvegarde. La valeur par défaut est <literal>0.4</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cache_target_dirty_high_ratio</term>
     <listitem>
      <para>
       Vous pouvez indiquer l'âge minimal d'un objet récemment modifié (altéré) avant que l'agent de hiérarchisation du cache le transfère à la réserve de stockage de sauvegarde à une vitesse supérieure. La valeur par défaut est <literal>0.6</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cache_target_full_ratio</term>
     <listitem>
      <para>
       Pourcentage de la réserve de cache contenant des objets non modifiés (propres) avant que l'agent de hiérarchisation du cache les élimine de la réserve de cache. La valeur par défaut est <literal>0.8</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>target_max_bytes</term>
     <listitem>
      <para>
       Ceph commence à vider ou à éliminer des objets lorsque le seuil <option>max_bytes</option> est déclenché.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>target_max_objects</term>
     <listitem>
      <para>
       Ceph commence à vider ou à éliminer des objets lorsque le seuil <option>max_objects</option> est déclenché.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_grade_decay_rate</term>
     <listitem>
      <para>
       Taux de baisse de la température entre deux <literal>hit_set</literal> successifs. Valeur par défaut : <literal>20</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>hit_set_search_last_n</term>
     <listitem>
      <para>
       Comptez au plus <literal>N</literal> apparitions dans les valeurs de <literal>hit_set</literal> pour le calcul de la température. La valeur par défaut est <literal>1</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cache_min_flush_age</term>
     <listitem>
      <para>
       Durée (en secondes) avant que l'agent de hiérarchisation du cache vide un objet de la réserve de cache vers la réserve de stockage.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>cache_min_evict_age</term>
     <listitem>
      <para>
       Durée (en secondes) avant que l'agent de hiérarchisation du cache élimine un objet de la réserve de cache.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <variablelist xml:id="pool-values-ec">
    <title>Valeurs de réserve codée à effacement</title>
    <varlistentry>
     <term>fast_read</term>
     <listitem>
      <para>
       Si cet indicateur est activé sur les réserves de codage à effacement, la demande de lecture émet des sous-lectures sur toutes les partitions et attend de recevoir un nombre suffisant de fragments à décoder afin de servir le client. Dans le cas des plug-ins <emphasis>jerasure</emphasis> et <emphasis>isa</emphasis>, lorsque les premières réponses <literal>K</literal> sont retournées, la requête du client est servie immédiatement avec les données décodées issues de ces réponses. Cette approche augmente la charge de processeur et diminue la charge de disque/réseau. Pour le moment, cet indicateur est pris en charge uniquement pour les réserves de codage à effacement. La valeur par défaut est <literal>0</literal>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ceph-pools-options-num-of-replicas">
   <title>Définition du nombre de répliques d'objets</title>
   <para>
    Pour définir le nombre de répliques d'objets sur un réserve répliquée, exécutez la commande suivante :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set <replaceable>poolname</replaceable> size <replaceable>num-replicas</replaceable></screen>
   <para>
    <replaceable>num-replicas</replaceable> inclut l'objet lui-même. Si vous souhaitez, par exemple, l'objet et deux copies de l'objet pour obtenir au total trois instances de l'objet, indiquez 3.
   </para>
   <warning>
    <title>ne définissez pas moins de 3 répliques</title>
    <para>
     Si vous définissez <replaceable>num-replicas</replaceable> sur 2, <emphasis>une seule</emphasis> copie de vos données est disponible. Si vous perdez une instance d'objet, vous devez être sûr que l'autre copie n'a pas été endommagée, par exemple depuis le dernier nettoyage pendant la récupération (pour plus d'informations, reportez-vous à la <xref linkend="scrubbing-pgs"/>).
    </para>
    <para>
     La définition d'une réserve à réplique unique implique qu'il existe exactement <emphasis>une</emphasis> instance de l'objet de données dans la réserve. Si l'OSD échoue, vous perdez les données. Une utilisation possible d'une réserve avec une réplique consiste à stocker des données temporaires pendant une courte période.
    </para>
   </warning>
   <tip>
    <title>définition de plus de 3 répliques</title>
    <para>
     La définition de 4 répliques pour une réserve augmente la fiabilité de 25 %.
    </para>
    <para>
     Dans le cas de deux centres de données, vous devez définir au moins 4 répliques pour une réserve de sorte à avoir deux copies dans chaque centre de données. De cette façon, en cas de perte d'un centre de données, il existe toujours deux copies et vous pouvez perdre un disque sans perdre de données.
    </para>
   </tip>
   <note>
    <para>
     Un objet peut accepter des E/S en mode dégradé avec moins de <literal>pool size</literal> répliques. Pour définir un nombre minimum de répliques requis pour les E/S, vous devez utiliser le paramètre <literal>min_size</literal>. Par exemple :
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool set data min_size 2</screen>
    <para>
     Cela garantit qu'aucun objet de la réserve de données ne recevra d'E/S avec moins de <literal>min_size</literal> répliques.
    </para>
   </note>
   <tip>
    <title>obtention du nombre de répliques d'objets</title>
    <para>
     Pour obtenir le nombre de répliques d'objet, exécutez la commande suivante :
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd dump | grep 'replicated size'</screen>
    <para>
     Ceph dresse la liste des réserves en mettant en surbrillance l'attribut <literal>replicated size</literal>. Par défaut, Ceph crée deux répliques d'un objet (soit un total de trois copies ou une taille de 3).
    </para>
   </tip>
  </sect2>
 </sect1>
 <sect1 xml:id="pools-migration">
  <title>Migration d'une réserve</title>

  <para>
   Lors de la création d'une réserve (voir <xref linkend="ceph-pools-operate-add-pool"/>), vous devez indiquer ses paramètres initiaux, tels que le type de réserve ou le nombre de groupes de placement. Si vous décidez ultérieurement de modifier l'un de ces paramètres, par exemple lors de la conversion d'une réserve répliquée en réserve codée à effacement ou de la diminution du nombre de groupes de placement, vous devez migrer les données de réserve vers une autre réserve dont les paramètres conviennent à votre déploiement.
  </para>

  <para>
   Cette section décrit deux méthodes de migration : une méthode de <emphasis>niveau de cache</emphasis> pour la migration générale des données d'une réserve, et une méthode utilisant des sous-commandes <command>rbd migrate</command> pour migrer des images RBD vers une nouvelle réserve. Chaque méthode a ses spécificités et ses limites.
  </para>

  <sect2 xml:id="pool-migrate-limits">
   <title>Limites</title>
   <itemizedlist>
    <listitem>
     <para>
      Vous pouvez utiliser la méthode de <emphasis>niveau de cache</emphasis> pour migrer une réserve répliquée vers une réserve EC ou vers une autre réserve répliquée. La migration à partir d'une réserve EC n'est pas prise en charge.
     </para>
    </listitem>
    <listitem>
     <para>
      Vous ne pouvez pas migrer des images RBD et des exportations CephFS depuis une réserve répliquée vers une réserve codée à effacement (EC), car les réserves EC ne prennent pas en charge <literal>omap</literal>, alors que RBD et CephFS utilisent <literal>omap</literal> pour stocker leurs métadonnées. Par exemple, l'objet d'en-tête de RBD ne sera pas vidé. En revanche, vous pouvez migrer des données vers une réserve EC, en laissant les métadonnées dans la réserve répliquée.
     </para>
    </listitem>
    <listitem>
     <para>
      La méthode <command>rbd migration</command> permet de migrer des images avec un temps hors service minimal du client. Vous ne devez arrêter le client qu'avant l'étape de <option>préparation</option> et pouvez le redémarrer après. Notez que seul un client <systemitem>librbd</systemitem> qui prend en charge cette fonction (Ceph Nautilus ou plus récent) sera en mesure d'ouvrir l'image juste après l'étape de <option>préparation</option>. Les clients <systemitem>librbd</systemitem> plus anciens ou les clients <systemitem>krbd</systemitem> ne pourront pas ouvrir l'image avant l'exécution de l'étape de <option>validation</option>.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="pool-migrate-cache-tier">
   <title>Migration à l'aide du niveau de cache</title>
   <para>
    Le principe est simple : incluez la réserve dont vous avez besoin pour migrer dans un niveau de cache dans l'ordre inverse. L'exemple suivant illustre la migration d'une réserve répliquée appelée « testpool » vers une réserve codée à effacement :
   </para>
   <procedure>
    <title>Migration d'une réserve répliquée vers une réserve codée à effacement</title>
    <step>
     <para>
      Créez une réserve codée à effacement nommée « newpool ». Pour plus d'informations sur les paramètres de création d'une réserve, reportez-vous à la <xref linkend="ceph-pools-operate-add-pool"/>.
     </para>
<screen>
 <prompt>cephuser@adm &gt; </prompt>ceph osd pool create newpool erasure default
</screen>
     <para>
      Vérifiez que le trousseau de clés client utilisé fournit au moins les mêmes fonctionnalités pour « newpool » que pour « testpool ».
     </para>
     <para>
      Vous avez maintenant deux réserves : la réserve répliquée initiale « testpool » contenant des données et la nouvelle réserve codée à effacement « newpool » :
     </para>
     <figure>
      <title>Réserves avant migration</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="pool_migrate1.png" width="60%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="pool_migrate1.png" width="60%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Configurez le niveau de cache et la réserve répliquée « testpool » en tant que réserve de cache. L'option <option>-force-nonempty</option> permet d'ajouter un niveau de cache même si la réserve a déjà des données :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph tell mon.* injectargs \
 '--mon_debug_unsafe_allow_tier_with_nonempty_snaps=1'
<prompt>cephuser@adm &gt; </prompt>ceph osd tier add newpool testpool --force-nonempty
<prompt>cephuser@adm &gt; </prompt>ceph osd tier cache-mode testpool proxy
</screen>
     <figure>
      <title>Configuration du niveau de cache</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="pool_migrate2.png" width="60%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="pool_migrate2.png" width="60%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Forcez la réserve de cache à déplacer tous les objets vers la nouvelle réserve :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados -p testpool cache-flush-evict-all
</screen>
     <figure>
      <title>Vidage des données</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="pool_migrate3.png" width="60%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="pool_migrate3.png" width="60%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Tant que toutes les données n'ont pas été vidées vers la nouvelle réserve codée à effacement, vous devez indiquer une superposition afin que les recherches d'objets s'effectuent dans l'ancienne réserve :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd tier set-overlay newpool testpool
</screen>
     <para>
      Avec la superposition, toutes les opérations sont réacheminées vers l'ancienne réserve « testpool » répliquée :
     </para>
     <figure>
      <title>Définition de la superposition</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="pool_migrate4.png" width="60%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="pool_migrate4.png" width="60%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
     <para>
      Vous pouvez maintenant basculer tous les clients pour accéder aux objets de la nouvelle réserve.
     </para>
    </step>
    <step>
     <para>
      Une fois toutes les données migrées vers la réserve codée à effacement « newpool », supprimez la superposition et l'ancienne réserve de cache « testpool » :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd tier remove-overlay newpool
<prompt>cephuser@adm &gt; </prompt>ceph osd tier remove newpool testpool
</screen>
     <figure>
      <title>Migration effectuée</title>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="pool_migrate5.png" width="60%" format="PNG"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="pool_migrate5.png" width="60%" format="PNG"/>
       </imageobject>
      </mediaobject>
     </figure>
    </step>
    <step>
     <para>
      Exécutez :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph tell mon.* injectargs \
 '--mon_debug_unsafe_allow_tier_with_nonempty_snaps=0'
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="migrate-rbd-image">
   <title>Migration d'images RBD</title>
   <para>
    Voici la méthode recommandée pour migrer des images RBD d'une réserve répliquée vers une autre réserve répliquée.
   </para>
   <procedure>
    <step>
     <para>
      Empêchez les clients (une machine virtuelle, par exemple) d'accéder à l'image RBD.
     </para>
    </step>
    <step>
     <para>
      Créez une image dans la réserve cible, avec le parent défini sur l'image source :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rbd migration prepare <replaceable>SRC_POOL</replaceable>/<replaceable>IMAGE</replaceable> <replaceable>TARGET_POOL</replaceable>/<replaceable>IMAGE</replaceable>
</screen>
     <tip>
      <title>migration de données uniquement vers une réserve codée à effacement</title>
      <para>
       Si vous devez migrer uniquement les données d'image vers une nouvelle réserve EC et laisser les métadonnées dans la réserve répliquée d'origine, exécutez la commande suivante à la place :
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rbd migration prepare <replaceable>SRC_POOL</replaceable>/<replaceable>IMAGE</replaceable> \
 --data-pool <replaceable>TARGET_POOL</replaceable>/<replaceable>IMAGE</replaceable>
</screen>
     </tip>
    </step>
    <step>
     <para>
      Laissez les clients accéder à l'image dans la réserve cible.
     </para>
    </step>
    <step>
     <para>
      Migrez les données vers la réserve cible :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rbd migration execute <replaceable>SRC_POOL</replaceable>/<replaceable>IMAGE</replaceable>
</screen>
    </step>
    <step>
     <para>
      Supprimez l'ancienne image :
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rbd migration commit <replaceable>SRC_POOL</replaceable>/<replaceable>IMAGE</replaceable>
</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="cha-ceph-snapshots-pool">
  <title>Instantanés de réserve</title>

  <para>
   Les instantanés de réserve sont des instantanés de l'état de l'ensemble de la réserve Ceph. Avec les instantanés de réserve, vous pouvez conserver l'historique de l'état de la réserve. La création d'instantanés de réserve consomme un espace de stockage proportionnel à la taille de la réserve. Vérifiez toujours que le stockage associé possède un espace disque suffisant avant de créer un instantané d'une réserve.
  </para>

  <sect2 xml:id="ceph-make-snapshot-pool">
   <title>Création d'un instantané d'une réserve</title>
   <para>
    Pour créer un instantané d'une réserve, exécutez :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool mksnap <replaceable>POOL-NAME</replaceable> <replaceable>SNAP-NAME</replaceable>
</screen>
   <para>
    Par exemple :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool mksnap pool1 snap1
created pool pool1 snap snap1</screen>
  </sect2>

  <sect2 xml:id="ceph-listing-snapshots-pool">
   <title>Liste des instantanés d'une réserve</title>
   <para>
    Pour lister les instantanés existants d'une réserve, exécutez :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados lssnap -p <replaceable>POOL_NAME</replaceable>
</screen>
   <para>
    Par exemple :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>rados lssnap -p pool1
1	snap1	2018.12.13 09:36:20
2	snap2	2018.12.13 09:46:03
2 snaps
</screen>
  </sect2>

  <sect2 xml:id="ceph-removing-snapshot-pool">
   <title>Suppression d'un instantané d'une réserve</title>
   <para>
    Pour supprimer un instantané d'une réserve, exécutez :
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool rmsnap <replaceable>POOL-NAME</replaceable> <replaceable>SNAP-NAME</replaceable></screen>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-ceph-pool-compression">
  <title>Compression des données</title>

  <para>
   BlueStore (voir <xref linkend="about-bluestore"/> pour plus de détails) fournit la compression des données à la volée pour économiser de l'espace disque. Le rapport de compression dépend des données stockées sur le système. Notez que la compression/décompression nécessite davantage de ressources processeur.
  </para>

  <para>
   Vous pouvez configurer la compression des données globalement (voir <xref linkend="sec-ceph-pool-bluestore-compression-options"/>), puis remplacer les paramètres de compression spécifiques pour chaque réserve.
  </para>

  <para>
   Vous pouvez activer ou désactiver la compression des données de réserve, ou modifier l'algorithme et le mode de compression à tout moment, que la réserve contienne des données ou non.
  </para>

  <para>
   Aucune compression ne sera appliquée aux données existantes après avoir activé la compression de la réserve.
  </para>

  <para>
   Après avoir désactivé la compression d'une réserve, toutes ses données seront décompressées.
  </para>

  <sect2 xml:id="sec-ceph-pool-compression-enable">
   <title>Activation de la compression</title>
   <para>
    Pour activer la compression des données pour une réserve nommée <replaceable>POOL_NAME</replaceable>, exécutez la commande suivante :
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>ceph</command> osd pool set <replaceable>POOL_NAME</replaceable> compression_algorithm <replaceable>COMPRESSION_ALGORITHM</replaceable>
<prompt>cephuser@adm &gt; </prompt><command>ceph</command> osd pool set <replaceable>POOL_NAME</replaceable> compression_mode <replaceable>COMPRESSION_MODE</replaceable>
</screen>
   <tip>
    <title>désactivation de la compression d'une réserve</title>
    <para>
     Pour désactiver la compression des données pour une réserve, utilisez « none » comme algorithme de compression :
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>ceph</command> osd pool set <replaceable>POOL_NAME</replaceable> compression_algorithm none
</screen>
   </tip>
  </sect2>

  <sect2 xml:id="sec-ceph-pool-compression-options">
   <title>Options de compression de réserve</title>
   <para>
    Liste complète de paramètres de compression :
   </para>
   <variablelist>
    <varlistentry xml:id="compr-algorithm">
     <term>compression_algorithm</term>
     <listitem>
      <para>
       Les valeurs possibles sont <literal>none</literal>, <literal>zstd</literal>, <literal>snappy</literal>. La valeur par défaut est <literal>snappy</literal>.
      </para>
      <para>
       L'algorithme de compression à utiliser dépend du cas d'utilisation particulier. Voici quelques recommandations :
      </para>
      <itemizedlist>
       <listitem>
        <para>
         Utilisez la valeur par défaut <literal>snappy</literal> tant que vous n'avez pas une raison valable d'en changer.
        </para>
       </listitem>
       <listitem>
        <para>
         <literal>zstd</literal> offre un bon rapport de compression, mais provoque un overhead important du processeur lors de la compression de petites quantités de données.
        </para>
       </listitem>
       <listitem>
        <para>
         Effectuez un banc d'essai de ces algorithmes sur un échantillon de vos données réelles tout en gardant un oeil sur l'utilisation du processeur et de la mémoire de votre grappe.
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
    <varlistentry xml:id="compr-mode">
     <term>compression_mode</term>
     <listitem>
      <para>
       Les valeurs possibles sont <literal>none</literal>, <literal>aggressive</literal>, <literal>passive</literal> et <literal>force</literal>. La valeur par défaut est <literal>none</literal>.
      </para>
      <itemizedlist>
       <listitem>
        <para>
         <literal>none</literal> : jamais de compression
        </para>
       </listitem>
       <listitem>
        <para>
         <literal>passive</literal> : compresser si <literal>COMPRESSIBLE</literal> est suggéré
        </para>
       </listitem>
       <listitem>
        <para>
         <literal>aggressive</literal> : compresser sauf si <literal>INCOMPRESSIBLE</literal> est suggéré
        </para>
       </listitem>
       <listitem>
        <para>
         <literal>force</literal> : compresser toujours
        </para>
       </listitem>
      </itemizedlist>
     </listitem>
    </varlistentry>
    <varlistentry xml:id="compr-ratio">
     <term>compression_required_ratio</term>
     <listitem>
      <para>
       Valeur : Double, Ratio = SIZE_COMPRESSED / SIZE_ORIGINAL. La valeur par défaut est <literal>0,875</literal>, ce qui signifie que si la compression ne réduit pas l'espace occupé d'au moins 12,5 %, l'objet ne sera pas compressé.
      </para>
      <para>
       Les objets au-dessus de ce ratio ne seront pas stockés dans un format compressé en raison du faible gain net.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>compression_max_blob_size</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>0</literal>
      </para>
      <para>
       Taille maximale des objets compressés.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>compression_min_blob_size</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>0</literal>
      </para>
      <para>
       Taille minimale des objets compressés.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="sec-ceph-pool-bluestore-compression-options">
   <title>Options de compression globales</title>
   <para>
    Les options de configuration suivantes peuvent être définies dans la configuration Ceph et s'appliquent à tous les OSD et non pas seulement à une réserve. La configuration spécifique de la réserve répertoriée à la <xref linkend="sec-ceph-pool-compression-options"/> prévaut.
   </para>
   <variablelist>
    <varlistentry>
     <term>bluestore_compression_algorithm</term>
     <listitem>
      <para>
       Reportez-vous à la section <xref linkend="compr-algorithm"/>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_mode</term>
     <listitem>
      <para>
       Reportez-vous à la section <xref linkend="compr-mode"/>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_required_ratio</term>
     <listitem>
      <para>
       Reportez-vous à la section <xref linkend="compr-ratio"/>
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_min_blob_size</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>0</literal>
      </para>
      <para>
       Taille minimale des objets compressés. Le paramètre est ignoré par défaut en faveur de <option>bluestore_compression_min_blob_size_hdd</option> et <option>bluestore_compression_min_blob_size_ssd</option>. Il est prioritaire lorsqu'il est défini sur une valeur différente de zéro.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_max_blob_size</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>0</literal>
      </para>
      <para>
       Taille maximale des objets qui sont compressés avant d'être divisés en petites tranches. Le paramètre est ignoré par défaut en faveur de <option>bluestore_compression_max_blob_size_hdd</option> et <option>bluestore_compression_max_blob_size_ssd</option>. Il est prioritaire lorsqu'il est défini sur une valeur différente de zéro.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_min_blob_size_ssd</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>8 000</literal>
      </para>
      <para>
       Taille minimale des objets compressés et stockés sur une unité SSD.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_max_blob_size_ssd</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>64 000</literal>
      </para>
      <para>
       Taille maximale des objets qui sont compressés et stockés sur disque SSD (Solid-State Drive) avant qu'ils ne soient divisés en plus petites tranches.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_min_blob_size_hdd</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>128 000</literal>
      </para>
      <para>
       Taille minimale des objets compressés et stockés sur disques durs.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>bluestore_compression_max_blob_size_hdd</term>
     <listitem>
      <para>
       Valeur : entier non signé, taille en octets. Valeur par défaut : <literal>512 000</literal>
      </para>
      <para>
       Taille maximale des objets qui sont compressés et stockés sur des disques durs avant qu'ils ne soient divisés en plus petites tranches.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>
 </sect1>
</chapter>
