<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_gateway.xml" version="5.0" xml:id="cha-ceph-gw">

 <title>Ceph Object Gateway</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>Ja</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Dieses Kapitel enthält detaillierte Informationen zu Verwaltungsaufgaben, die für Object Gateway relevant sind, wie Prüfen des Servicestatus, Verwalten der Konten, Gateways an mehreren Standorten oder LDAP-Authentifizierung.
 </para>
 <sect1 xml:id="sec-ceph-rgw-limits">
  <title>Object-Gateway-Beschränkungen und Benennungseinschränkungen</title>

  <para>
   Nachfolgend sehen Sie eine Liste der wichtigen Object-Gateway-Beschränkungen:
  </para>

  <sect2 xml:id="ogw-limits-bucket">
   <title>Bucket-Einschränkungen</title>
   <para>
    Wenn Sie Object Gateway über die S3 API verwenden, sind Bucket-Namen auf DNS-fähige Namen mit einem Bindestrich „-“ beschränkt. Wenn Sie Object Gateway über die Swift API verwenden, können Sie jede beliebige Kombination aus durch UTF-8 unterstützten Zeichen verwenden, mit Ausnahme des Schrägstrichs „/“. Die maximale Länge eines Bucket-Namens beträgt 255 Zeichen. Bucket-Namen müssen eindeutig sein.
   </para>
   <tip>
    <title>Verwenden Sie DNS-fähige Bucket-Namen</title>
    <para>
     Auch wenn Sie auf UTF-8 basierende Bucket-Namen über die Swift API verwenden, empfehlen wir, Buckets unter Berücksichtigung der S3-Benennungseinschränkungen zu benennen, um Probleme beim Zugriff auf diesen Bucket über die S3 API zu vermeiden.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ogw-limits-object">
   <title>Einschränkungen für gespeicherte Objekte</title>
   <variablelist>
    <varlistentry>
     <term>Maximale Anzahl der Objekte pro Benutzer</term>
     <listitem>
      <para>
       Standardmäßig keine Einschränkung (beschränkt durch ~ 2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Maximale Anzahl der Objekte pro Bucket</term>
     <listitem>
      <para>
       Standardmäßig keine Einschränkung (beschränkt durch ~ 2^63).
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>Maximale Größe eines Objekts zum Heraufladen/Speichern</term>
     <listitem>
      <para>
       Einzelne Uploads sind auf 5 GB beschränkt. Verwenden Sie Multipart für größere Objekte. Die maximale Anzahl der Multipart-Datenblöcke beträgt 10.000.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ogw-limits-http">
   <title>HTTP-Header-Beschränkungen</title>
   <para>
    Beschränkungen für HTTP-Header und Anforderungen hängen vom verwendeten Web-Frontend ab. In Beast ist die Größe des HTTP-Headers auf 16 kB beschränkt.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-deploy">
  <title>Bereitstellen des Object Gateways</title>

  <para>
   Die Bereitstellung von Ceph Object Gateway erfolgt nach dem gleichen Verfahren wie die Bereitstellung anderer Ceph-Services, nämlich mit cephadm. Weitere Informationen finden Sie im <xref linkend="cephadm-service-and-placement-specs"/> und insbesondere im <xref linkend="deploy-cephadm-day2-service-ogw"/>.
  </para>
 </sect1>
 <sect1 xml:id="ceph-rgw-operating">
  <title>Betrieb des Object Gateway Service</title>

  <para>
   Sie können die Object Gateways wie andere Ceph-Services betreiben. Identifizieren Sie dazu zunächst den Servicenamen mit dem Kommando <command>ceph orch ps</command> und führen Sie folgendes Kommando für den Betrieb von Services aus. Beispiel:
  </para>

<screen>ceph orch daemon restart <replaceable>OGW_SERVICE_NAME</replaceable></screen>

  <para>
   In <xref linkend="cha-ceph-operating"/> finden Sie alle Informationen über den Betrieb von Ceph-Services.
  </para>
 </sect1>
 <sect1 xml:id="ogw-config-parameters">
  <title>Konfigurationsoptionen</title>

  <para>
   Unter <xref linkend="config-ogw"/> finden Sie eine Liste der Object-Gateway-Konfigurationsoptionen.
  </para>
 </sect1>
 <sect1 xml:id="ceph-rgw-access">
  <title>Verwalten des Zugriffs auf Object Gateway</title>

  <para>
   Die Kommunikation mit Object Gateway ist entweder über eine S3-fähige Schnittstelle oder eine Swift-fähige Schnittstelle möglich.  Die S3-Schnittstelle ist kompatibel mit einer großen Teilmenge der S3 RESTful API. Die Swift-Schnittstelle ist kompatibel mit einer großen Teilmenge der OpenStack Swift API.
  </para>

  <para>
   Bei beiden Schnittstellen müssen Sie einen bestimmten Benutzer erstellen und die relevante Client-Software installieren, um mit dem Gateway unter Verwendung des geheimen Schlüssels des Benutzers zu kommunizieren.
  </para>

  <sect2 xml:id="accessing-ragos-gateway">
   <title>Zugreifen auf Object Gateway</title>
   <sect3 xml:id="ogw-s3-interface-access">
    <title>Zugriff auf die S3-Schnittstelle</title>
    <para>
     Für den Zugriff auf die S3-Schnittstelle benötigen Sie einen REST Client. <command>S3cmd</command> ist ein Kommandozeilen-S3 Client. Sie finden ihn im <link xlink:href="https://build.opensuse.org/package/show/Cloud:Tools/s3cmd">OpenSUSE Build Service</link>. Das Repository enthält Versionen für SUSE Linux Enterprise und für openSUSE-basierte Distributionen.
    </para>
    <para>
     Wenn Sie Ihren Zugriff auf die S3-Schnittstelle testen möchten, können Sie ein kleines Python-Skript schreiben. Das Skript stellt eine Verbindung zum Object Gateway her, erstellt einen neuen Bucket und listet alle Buckets auf. Die Werte für <option>aws_access_key_id</option> und <option>aws_secret_access_key</option> werden den Werten für <option>access_key</option> und <option>secret_key</option> entnommen, die vom Kommando <command>radosgw_admin</command> in <xref linkend="adding-s3-swift-users"/> zurückgegeben wurden.
    </para>
    <procedure>
     <step>
      <para>
       Installieren Sie das Paket <systemitem>phyton-boto</systemitem>:
      </para>
<screen><prompt role="root">root # </prompt>zypper in python-boto</screen>
     </step>
     <step>
      <para>
       Erstellen Sie ein neues Python-Skript namens <filename>s3test.py</filename> mit folgendem Inhalt: <remark role="fixme">Provide script in RPM? Is it really necessary to create pool? This script is not necessary at all, remove it from documentation?</remark>
      </para>
<screen>import boto
import boto.s3.connection
access_key = '11BS02LGFB6AL6H1ADMW'
secret_key = 'vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY'
conn = boto.connect_s3(
aws_access_key_id = access_key,
aws_secret_access_key = secret_key,
host = '<replaceable>HOSTNAME</replaceable>',
is_secure=False,
calling_format = boto.s3.connection.OrdinaryCallingFormat(),
)
bucket = conn.create_bucket('my-new-bucket')
for bucket in conn.get_all_buckets():
  print "<replaceable>NAME</replaceable>\t<replaceable>CREATED</replaceable>".format(
  name = bucket.name,
  created = bucket.creation_date,
  )</screen>
      <para>
       Ersetzen Sie <literal><replaceable>HOSTNAME</replaceable></literal> durch den Hostnamen des Hosts, auf dem Sie den Object-Gateway-Service konfiguriert haben, beispielsweise <literal>gateway_host</literal>.
      </para>
     </step>
     <step>
      <para>
       Führen Sie das Skript aus:
      </para>
<screen>python s3test.py</screen>
      <para>
       Das Skript gibt in etwa Folgendes aus:
      </para>
<screen>my-new-bucket 2015-07-22T15:37:42.000Z</screen>
     </step>
    </procedure>
   </sect3>
   <sect3 xml:id="swift-interface-access">
    <title>Zugriff auf die Swift-Schnittstelle</title>
    <para>
     Für den Zugriff auf das Object Gateway über die Swift-Schnittstelle benötigen Sie den <command>swift</command>-Kommandozeilen-Client. In der entsprechenden Handbuchseite <command>man 1 swift</command> erfahren Sie mehr über dessen Kommandozeilenoptionen.
    </para>
    <para>
     Das Paket befindet sich im Modul „Public Cloud“ für SUSE Linux Enterprise 12 ab SP3 und SUSE Linux Enterprise 15. Vor der Installation des Pakets müssen Sie das Modul aktivieren und das Software Repository aktualisieren:
    </para>
<screen><prompt role="root">root # </prompt>SUSEConnect -p sle-module-public-cloud/12/<replaceable>SYSTEM-ARCH</replaceable>
sudo zypper refresh</screen>
    <para>
     oder
    </para>
<screen><prompt role="root">root # </prompt>SUSEConnect -p sle-module-public-cloud/15/<replaceable>SYSTEM-ARCH</replaceable>
<prompt role="root">root # </prompt>zypper refresh</screen>
    <para>
     Führen Sie zur Installation des <command>swift</command>-Pakets folgendes Kommando aus:
    </para>
<screen><prompt role="root">root # </prompt>zypper in python-swiftclient</screen>
    <para>
     Beim Swift-Zugang wird die folgende Syntax verwendet:
    </para>
<screen><prompt>tux &gt; </prompt>swift -A http://<replaceable>IP_ADDRESS</replaceable>/auth/1.0 \
-U example_user:swift -K '<replaceable>SWIFT_SECRET_KEY</replaceable>' list</screen>
    <para>
     Ersetzen Sie <replaceable>IP_ADDRESS</replaceable> durch die IP-Adresse des Gateway Servers und <replaceable>SWIFT_SECRET_KEY</replaceable> durch dessen Wert der Ausgabe des Kommandos <command>radosgw-admin key create</command>, das für den <systemitem>swift</systemitem>-Benutzer in <xref linkend="adding-s3-swift-users"/> ausgeführt wurde.
    </para>
    <para>
     Beispiel:
    </para>
<screen><prompt>tux &gt; </prompt>swift -A http://gateway.example.com/auth/1.0 -U example_user:swift \
-K 'r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h' list</screen>
    <para>
     Die Ausgabe ist:
    </para>
<screen>my-new-bucket</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="s3-swift-accounts-managment">
   <title>Verwalten von S3- und Swift-Konten</title>
   <sect3 xml:id="adding-s3-swift-users">
    <title>Hinzufügen von S3- und Swift-Benutzern</title>
    <para>
     Sie müssen einen Benutzer, einen Zugriffsschlüssel und ein Geheimnis erstellen, um Endbenutzer für die Interaktion mit dem Gateway zu aktivieren. Es gibt zwei Arten von Benutzern: einen <emphasis>Benutzer</emphasis> und einen <emphasis>Unterbenutzer</emphasis>. <emphasis>Benutzer</emphasis> werden für die Interaktion mit der S3-Schnittstelle verwendet, während <emphasis>Unterbenutzer</emphasis> Benutzer der Swift-Schnittstelle sind. Jeder Unterbenutzer ist einem Benutzer zugeordnet.
    </para>
    <para>
     Führen Sie zum Erstellen eines Swift-Benutzers folgende Schritte aus:
    </para>
    <procedure>
     <step>
      <para>
       Zum Erstellen eines Swift-Benutzers (in unserer Terminologie ein <emphasis>Unterbenutzer</emphasis>) müssen Sie zunächst den zugeordneten <emphasis>Benutzer</emphasis> erstellen.
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user create --uid=<replaceable>USERNAME</replaceable> \
 --display-name="<replaceable>DISPLAY-NAME</replaceable>" --email=<replaceable>EMAIL</replaceable></screen>
      <para>
       Beispiel:
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
     </step>
     <step>
      <para>
       Zum Erstellen eines Unterbenutzers (Swift-Schnittstelle) für den Benutzer müssen Sie die Benutzer-ID (--uid=<replaceable>USERNAME</replaceable>), eine Unterbenutzer-ID und die Zugriffsstufe für den Unterbenutzer angeben.
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin subuser create --uid=<replaceable>UID</replaceable> \
 --subuser=<replaceable>UID</replaceable> \
 --access=[ <replaceable>read | write | readwrite | full</replaceable> ]</screen>
      <para>
       Beispiel:
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin subuser create --uid=example_user \
 --subuser=example_user:swift --access=full</screen>
     </step>
     <step>
      <para>
       Generieren Sie einen geheimen Schlüssel für den Benutzer.
      </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin key create \
   --gen-secret \
   --subuser=example_user:swift \
   --key-type=swift</screen>
     </step>
     <step>
      <para>
       Beide Kommandos geben JSON-formatierte Daten mit dem Benutzerstatus aus. Notieren Sie sich die folgenden Zeilen und merken Sie sich den Wert des <literal>secret_key</literal>:
      </para>
<screen>"swift_keys": [
   { "user": "example_user:swift",
     "secret_key": "r5wWIxjOCeEO7DixD1FjTLmNYIViaC6JVhi3013h"}],</screen>
     </step>
    </procedure>
    <para/>
    <para>
     Beim Zugriff auf das Object Gateway über die S3-Schnittstelle müssen Sie einen S3-Benutzer erstellen, indem Sie folgendes Kommando ausführen:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user create --uid=<replaceable>USERNAME</replaceable> \
 --display-name="<replaceable>DISPLAY-NAME</replaceable>" --email=<replaceable>EMAIL</replaceable></screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user create \
   --uid=example_user \
   --display-name="Example User" \
   --email=penguin@example.com</screen>
    <para>
     Das Kommando erstellt auch den Zugriff und geheimen Schlüssel des Benutzers. Überprüfen Sie dessen Ausgabe nach den Schlüsselwörtern <literal>access_key</literal> und <literal>secret_key</literal> und deren Werte:
    </para>
<screen>[...]
 "keys": [
       { "user": "example_user",
         "access_key": "11BS02LGFB6AL6H1ADMW",
         "secret_key": "vzCEkuryfn060dfee4fgQPqFrncKEIkh3ZcdOANY"}],
 [...]</screen>
   </sect3>
   <sect3 xml:id="removing-s3-swift-users">
    <title>Entfernen von S3- und Swift-Benutzern</title>
    <para>
     Das Verfahren zum Löschen von Benutzern ist bei S3- und Swift-Benutzern in etwa gleich. Im Fall von Swift-Benutzern müssen Sie jedoch möglicherweise den Benutzer einschließlich dessen Unterbenutzer löschen.
    </para>
    <para>
     Geben Sie zum Entfernen eines S3- oder Swift-Benutzers (einschließlich aller Unterbenutzer) <option>user rm</option> und die Benutzer-ID im folgenden Kommando an:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user rm --uid=example_user</screen>
    <para>
     Geben Sie zum Entfernen eines Unterbenutzers <option>subuser rm</option> und die Unterbenutzer-ID an.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin subuser rm --uid=example_user:swift</screen>
    <para>
     Die folgenden Optionen stehen Ihnen zur Verfügung:
    </para>
    <variablelist>
     <varlistentry>
      <term>--purge-data</term>
      <listitem>
       <para>
        Löscht alle Daten, die der Benutzer-ID zugeordnet sind.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>--purge-keys</term>
      <listitem>
       <para>
        Löscht alle Schlüssel, die der Benutzer-ID zugeordnet sind.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <tip>
     <title>Entfernen eines Unterbenutzers</title>
     <para>
      Wenn Sie einen Unterbenutzer entfernen, dann entfernen Sie auch den Zugriff auf die Swift-Schnittstelle. Der Benutzer bleibt im System.
     </para>
    </tip>
   </sect3>
   <sect3 xml:id="changing-s3-swift-users-password">
    <title>Ändern des Zugriffs und der geheimen Schlüssel von S3- und Swift-Benutzern</title>
    <para>
     Die Parameter <literal>access_key</literal> und <literal>secret_key</literal> kennzeichnen den Object-Gateway-Benutzer für den Zugriff auf das Gateway. Das Ändern der bestehenden Benutzerschlüssel ist identisch mit dem Erstellen neuer Schlüssel, weil die alten Schlüssel überschrieben werden.
    </para>
    <para>
     Führen Sie für S3-Benutzer folgendes Kommando aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin key create --uid=<replaceable>EXAMPLE_USER</replaceable> --key-type=s3 --gen-access-key --gen-secret</screen>
    <para>
     Führen Sie für Swift-Benutzer folgendes Kommando aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin key create --subuser=<replaceable>EXAMPLE_USER</replaceable>:swift --key-type=swift --gen-secret</screen>
    <variablelist>
     <varlistentry>
      <term><option>--key-type=<replaceable>TYPE</replaceable></option></term>
      <listitem>
       <para>
        Gibt den Typ des Schlüssels an, entweder <literal>swift</literal> oder <literal>s3</literal>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-access-key</option></term>
      <listitem>
       <para>
        Generiert einen Zugriffsschlüssel nach dem Zufallsprinzip (für S3-Benutzer standardmäßig).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--gen-secret</option></term>
      <listitem>
       <para>
        Generiert einen geheimen Schlüssel nach dem Zufallsprinzip.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--secret=<replaceable>KEY</replaceable></option></term>
      <listitem>
       <para>
        Gibt einen geheimen Schlüssel an, beispielsweise einen manuell generierten.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="user-quota-managment">
    <title>Aktivieren der Verwaltung von Benutzerquoten</title>
    <para>
     Mit dem Ceph Object Gateway können Sie Kontingente für Benutzer und Buckets für Benutzer festlegen. Kontingente umfassen die maximale Anzahl der Objekte in einem Bucket sowie die maximale Speichergröße in Megabyte.
    </para>
    <para>
     Vor dem Aktivieren einer Benutzerquote müssen Sie zunächst deren Parameter festlegen:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin quota set --quota-scope=user --uid=<replaceable>EXAMPLE_USER</replaceable> \
 --max-objects=1024 --max-size=1024</screen>
    <variablelist>
     <varlistentry>
      <term><option>--max-objects</option></term>
      <listitem>
       <para>
        Gibt die maximale Anzahl von Objekten an. Durch einen negativen Wert wird die Prüfung deaktiviert.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--max-size</option></term>
      <listitem>
       <para>
        Gibt die maximale Anzahl von Bytes an. Durch einen negativen Wert wird die Prüfung deaktiviert.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>--quota-scope</option></term>
      <listitem>
       <para>
        Legt das Volumen für das Kontingent fest. Die Optionen sind <literal>bucket</literal> und <literal>user</literal>. Bucket-Quoten gelten für Buckets, die ein Benutzer besitzt. Benutzerquoten gelten für einen Benutzer.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Sobald Sie eine Benutzerquote festgelegt haben, können Sie sie aktivieren:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin quota enable --quota-scope=user --uid=<replaceable>EXAMPLE_USER</replaceable></screen>
    <para>
     So deaktivieren Sie ein Kontingent:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin quota disable --quota-scope=user --uid=<replaceable>EXAMPLE_USER</replaceable></screen>
    <para>
     So listen Sie Kontingenteinstellungen auf:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user info --uid=<replaceable>EXAMPLE_USER</replaceable></screen>
    <para>
     So aktualisieren Sie die Kontingentstatistik:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user stats --uid=<replaceable>EXAMPLE_USER</replaceable> --sync-stats</screen>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-http-frontends">
  <title>HTTP-Frontends</title>

  <para>
   Das Ceph Object Gateway unterstützt zwei eingebettete HTTP-Front-Ends: <emphasis>Beast</emphasis> und <emphasis>Civetweb</emphasis>.
  </para>

  <para>
   Das Beast-Front-End führt das HTTP-Parsing mit der Boost.Beast-Bibliothek und die asynchrone Netzwerk-E/A mit der Boost.Asio-Bibliothek durch.
  </para>

  <para>
   Das Civetweb-Front-End greift auf die Civetweb-HTTP-Bibliothek zurück (ein Mongoose-Fork).
  </para>

  <para>
   Sie können diese über die Option <option>rgw_frontends</option> konfigurieren. Unter <xref linkend="config-ogw"/> finden Sie eine Liste der Konfigurationsoptionen.
  </para>
 </sect1>
 <sect1 xml:id="ceph-rgw-https">
  <title>Aktivieren von HTTPS/SSL für Object Gateways</title>

  <para>
   Zur Aktivierung des Object Gateways für die sichere Kommunikation über SSL benötigen Sie entweder ein von einer Zertifizierungsstelle ausgestelltes Zertifikat oder Sie müssen ein eigensigniertes Zertifikat erstellen.
  </para>

  <sect2 xml:id="ogw-selfcert">
   <title>Erstellen eines eigensignierten Zertifikats</title>
   <tip>
    <para>
     Überspringen Sie diesen Abschnitt, wenn Sie bereits über ein gültiges Zertifikat verfügen, das von einer Zertifizierungsstelle signiert wurde.
    </para>
   </tip>
   <para>
    Das folgende Verfahren beschreibt, wie ein eigensigniertes SSL-Zertifikat im Salt Master generiert wird.
   </para>
   <procedure>
    <step>
     <para>
      Wenn Ihr Object Gateway auch unter weiteren Subjektidentitäten bekannt sein soll, tragen Sie sie in die Option <option>subjectAltName</option> im Abschnitt <literal>[v3_req]</literal> in der Datei <filename>/etc/ssl/openssl.cnf</filename> ein:
     </para>
<screen>
[...]
[ v3_req ]
subjectAltName = DNS:server1.example.com DNS:server2.example.com
[...]
</screen>
     <tip>
      <title>IP-Adressen in <option>subjectAltName</option></title>
      <para>
       Sollen IP-Adressen anstelle von Domänennamen in der Option <option>subjectAltName</option> angegeben werden, ersetzen Sie die Beispielzeile wie folgt:
      </para>
<screen>
subjectAltName = IP:10.0.0.10 IP:10.0.0.11
</screen>
     </tip>
    </step>
    <step>
     <para>
      Erstellen Sie den Schlüssel und das Zertifikat mit <command>openssl</command>. Geben Sie alle Daten ein, die in Ihrem Zertifikat enthalten sein sollen. Wir empfehlen die Eingabe des FQDN als Eigenname. Verifizieren Sie vor dem Signieren des Zertifikats, dass 'X509v3 Subject Alternative Name:' in den angeforderten Erweiterungen enthalten ist und dass für das resultierende Zertifikat "X509v3 Subject Alternative Name:" festgelegt wurde.
     </para>
<screen>
<prompt>root@master # </prompt>openssl req -x509 -nodes -days 1095 \
 -newkey rsa:4096 -keyout rgw.key
 -out rgw.pem
</screen>
    </step>
    <step>
     <para>
      Hängen Sie den Schlüssel an die Zertifikatsdatei an:
     </para>
<screen>
<prompt>root@master # </prompt>cat rgw.key &gt;&gt; rgw.pem
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw-sssl-config">
   <title>Konfigurieren von Object Gateway mit SSL</title>
   <para>
    Konfigurieren Sie Object Gateway für die Verwendung von SSL-Zertifikaten über die Option <option>rgw_frontends</option>. Beispiel:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set <replaceable>WHO</replaceable> rgw_frontends \
 beast ssl_port=443 ssl_certificate=config://<replaceable>CERT</replaceable> ssl_key=config://<replaceable>KEY</replaceable>
</screen>
   <para>
    Wenn Sie die Konfigurationsschlüssel <replaceable>CERT</replaceable> und <replaceable>KEY</replaceable> nicht angeben, sucht der Object-Gateway-Service das SSL-Zertifikat und den Schlüssel unter den folgenden Konfigurationsschlüsseln:
   </para>
<screen>
rgw/cert/<replaceable>RGW_REALM</replaceable>/<replaceable>RGW_ZONE</replaceable>.key
rgw/cert/<replaceable>RGW_REALM</replaceable>/<replaceable>RGW_ZONE</replaceable>.crt
</screen>
   <para>
    Wenn Sie den Standard-SSL-Schlüssel und -Zertifikatsspeicherort außer Kraft setzen möchten, importieren Sie sie mit dem folgenden Kommando in die Konfigurationsdatenbank:
   </para>
<screen>ceph config-key set <replaceable>CUSTOM_CONFIG_KEY</replaceable> -i <replaceable>PATH_TO_CERT_FILE</replaceable></screen>
   <para>
    Verwenden Sie dann die benutzerdefinierten Konfigurationsschlüssel mit der Anweisung <literal>config://</literal>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-sync">
  <title>Synchronisierungsmodule</title>

  <para>
   Object Gateway wird als Service für mehrere Standorte bereitgestellt, wobei Sie Daten und Metadaten zwischen den Zonen spiegeln können. <emphasis>Synchronisierungsmodule</emphasis> werden auf das Framework für mehrere Standorte aufgesetzt und lassen die Weiterleitung von Daten und Metadaten zu einer anderen externen Schicht zu. Mit einem Synchronisierungsmodul kann eine Reihe von Aktionen durchgeführt werden, sobald eine Datenänderung vorgenommen wird (beispielsweise Metadaten-Operationen wie die Erstellung von Buckets oder Benutzern). Da die Object-Gateway-Änderungen an mehreren Standorten letztendlich an Remote-Standorten konsistent sind, werden die Änderungen asynchron verteilt. Damit sind Anwendungsfälle wie das Sichern des Objektspeichers in einem externen Cloud Cluster, eine benutzerdefinierte Sicherungslösung mit Bandlaufwerken oder die Indizierung von Metadaten in ElasticSearch abgedeckt.
  </para>

  <sect2 xml:id="ogw-sync-general-config">
   <title>Konfigurieren von Synchronisierungsmodulen</title>
   <para>
    Alle Synchronisierungsmodule werden auf ähnliche Weise konfiguriert. Sie müssen eine neue Zone erstellen (weitere Informationen siehe <xref linkend="ceph-rgw-fed"/>) und die Option <option>--tier_type</option> für diese Zone festlegen, beispielsweise <option>--tier-type=cloud</option> für das Cloud-Synchronisierungsmodul:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE-NAME</replaceable> \
 --endpoints=http://endpoint1.example.com,http://endpoint2.example.com, [...] \
 --tier-type=cloud
</screen>
   <para>
    Mit folgendem Kommando konfigurieren Sie die jeweilige Schicht:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE-NAME</replaceable> \
 --tier-config=<replaceable>KEY1</replaceable>=<replaceable>VALUE1</replaceable>,<replaceable>KEY2</replaceable>=<replaceable>VALUE2</replaceable>
</screen>
   <para>
    <replaceable>KEY</replaceable> in der Konfiguration bezeichnet die zu aktualisierende Konfigurationsvariable und <replaceable>VALUE</replaceable> bezeichnet den neuen Wert. Verschachtelte Werte können mithilfe von Punkten angegeben werden. Beispiel:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE-NAME</replaceable> \
 --tier-config=connection.access_key=<replaceable>KEY</replaceable>,connection.secret=<replaceable>SECRET</replaceable>
</screen>
   <para>
    Matrixeinträge können mithilfe von eckigen Klammern „[]“ um den referenzierten Eintrag angegeben werden. Soll ein neuer Matrixeintrag eingefügt werden, setzen Sie den Eintrag in eckige Klammern „[]“. Ein Indexwert von -1 verweist auf den letzten Eintrag in der Matrix. Es ist nicht möglich, einen neuen Eintrag anzulegen und im gleichen Kommando auf diesen Eintrag zu verweisen. Mit folgendem Kommando erstellen Sie beispielsweise ein neues Profil für Buckets, die mit <replaceable>PREFIX</replaceable> beginnen:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE-NAME</replaceable> \
 --tier-config=profiles[].source_bucket=<replaceable>PREFIX</replaceable>'*'
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE-NAME</replaceable> \
 --tier-config=profiles[-1].connection_id=<replaceable>CONNECTION_ID</replaceable>,profiles[-1].acls_id=<replaceable>ACLS_ID</replaceable>
</screen>
   <tip>
    <title>Hinzufügen und Entfernen von Konfigurationseinträgen</title>
    <para>
     Mit dem Parameter <option>--tier-config-add=<replaceable>KEY</replaceable>=<replaceable>VALUE</replaceable></option> fügen Sie einen neuen Schichtkonfigurationseintrag ein.
    </para>
    <para>
     Mit <option>--tier-config-rm=<replaceable>KEY</replaceable></option> entfernen Sie einen vorhandenen Eintrag.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ceph-rgw-sync-zones">
   <title>Synchronisieren von Zonen</title>
   <para>
    Die Konfiguration eines Synchronisierungsmoduls wird lokal in einer Zone vorgenommen. Das Synchronisierungsmodul bestimmt, ob die Zone Daten exportiert oder in einer anderen Zone geänderte Daten nur nutzen darf. Ab Luminous sind die unterstützten Synchronisierungs-Plugins <literal>ElasticSearch</literal>, <literal>rgw</literal> (das standardmäßige Synchronisierungs-Plugin zum Synchronisieren von Daten zwischen den Zonen) und <literal>log</literal> (ein Trivial-Synchronisierungs-Plugin zum Protokollieren der Metadaten-Operation in den Remote-Zonen). In den folgenden Abschnitten verwenden wir das Beispiel einer Zone mit dem Synchronisierungsmodul <literal>ElasticSearch</literal>. Bei·der·Konfiguration·eines·anderen·Synchronisierungs-Plugins wäre das Verfahren ähnlich.
   </para>
   <note>
    <title>Standardmäßiges Synchronisierungs-Plugin</title>
    <para>
     <literal>rgw</literal> ist das standardmäßige Synchronisierungs-Plugin. Es muss nicht explizit konfiguriert werden.
    </para>
   </note>
   <sect3 xml:id="ceph-rgw-sync-zones-req">
    <title>Anforderungen und Annahmen</title>
    <para>
     Nehmen wir eine einfache Konfiguration für mehrere Standorte an, wie in <xref linkend="ceph-rgw-fed"/> beschrieben. Sie besteht aus zwei Zonen: <literal>us-east</literal> und <literal>us-west</literal>. Nun fügen wir eine dritte Zone <literal>us-east-es</literal> hinzu. Diese Zone verarbeitet nur die Metadaten der anderen Standorte. Diese Zone kann sich im selben Ceph-Cluster befinden wie <literal>us-east</literal> oder auch in einer anderen Zone. Diese Zone würde nur die Metadaten aus anderen Zonen nutzen. Object Gateways in dieser Zone verarbeiten Endbenutzeranforderungen nicht direkt.
    </para>
   </sect3>
   <sect3 xml:id="ceph-rgw-sync-zones-configure">
    <title>Konfigurieren von Zonen</title>
    <procedure>
     <step>
      <para>
       Erstellen Sie die dritte Zone so ähnlich wie die Zonen, die in <xref linkend="ceph-rgw-fed"/> beschrieben sind. Beispiel:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>radosgw-admin</command> zone create --rgw-zonegroup=us --rgw-zone=us-east-es \
--access-key=<replaceable>SYSTEM-KEY</replaceable> --secret=<replaceable>SECRET</replaceable> --endpoints=http://rgw-es:80
      </screen>
     </step>
     <step>
      <para>
       Ein Synchronisierungsmodul kann für diese Zone mit folgendem Kommando konfiguriert werden:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>radosgw-admin</command> zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --tier-type=<replaceable>TIER-TYPE</replaceable> \
--tier-config={set of key=value pairs}
      </screen>
     </step>
     <step>
      <para>
       Beispiel im Synchronisierungsmodul <literal>ElasticSearch</literal>:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>radosgw-admin</command> zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --tier-type=elasticsearch \
--tier-config=endpoint=http://localhost:9200,num_shards=10,num_replicas=1
      </screen>
      <para>
       Die verschiedenen unterstützten „tier-config“-Optionen finden Sie in <xref linkend="ceph-rgw-sync-elastic"/>.
      </para>
     </step>
     <step>
      <para>
       Aktualisieren Sie schließlich den Zeitraum:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt><command>radosgw-admin</command> period update --commit
      </screen>
     </step>
     <step>
      <para>
       Starten Sie das Object Gateway in der Zone:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch start rgw.<replaceable>REALM-NAME</replaceable>.<replaceable>ZONE-NAME</replaceable>
      </screen>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-sync-elastic">
   <title>Synchronisierungsmodul ElasticSearch</title>
   <para>
    Dieses Synchronisierungsmodul schreibt die Metadaten aus anderen Zonen zu ElasticSearch. Ab Luminous ist es die JSON-Datei der Datenfelder, die aktuell in ElasticSearch gespeichert ist.
   </para>
<screen>
{
  "_index" : "rgw-gold-ee5863d6",
  "_type" : "object",
  "_id" : "34137443-8592-48d9-8ca7-160255d52ade.34137.1:object1:null",
  "_score" : 1.0,
  "_source" : {
    "bucket" : "testbucket123",
    "name" : "object1",
    "instance" : "null",
    "versioned_epoch" : 0,
    "owner" : {
      "id" : "user1",
      "display_name" : "user1"
    },
    "permissions" : [
      "user1"
    ],
    "meta" : {
      "size" : 712354,
      "mtime" : "2017-05-04T12:54:16.462Z",
      "etag" : "7ac66c0f148de9519b8bd264312c4d64"
    }
  }
}
   </screen>
   <sect3 xml:id="ceph-rgw-sync-elastic-config">
    <title>Parameter zur Konfiguration des ElasticSearch-Schichttyps</title>
    <variablelist>
     <varlistentry>
      <term>endpoint</term>
      <listitem>
       <para>
        Gibt den ElasticSearch Server-Endpunkt für den Zugriff an.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_shards</term>
      <listitem>
       <para>
        <emphasis>(Ganzzahl)</emphasis> Die Anzahl der Shards, mit denen ElasticSearch beim Initialisieren der Datensynchronisierung konfiguriert wird. Beachten Sie, dass dies nach der Initialisierung nicht mehr geändert werden kann. Zum Ändern muss der ElasticSearch-Index neu aufgebaut und der Datensynchronisierungsvorgang neu initialisiert werden.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>num_replicas</term>
      <listitem>
       <para>
        <emphasis>(Ganzzahl)</emphasis> Die Anzahl der Reproduktionen, mit denen ElasticSearch beim Initialisieren der Datensynchronisierung konfiguriert wird.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>explicit_custom_meta</term>
      <listitem>
       <para>
        <emphasis>(true | false)</emphasis> Gibt an, ob alle benutzerdefinierten Metadaten der Benutzer indiziert werden oder ob Benutzer (auf Bucket-Ebene) konfigurieren müssen, welche Kundenmetadaten-Einträge indiziert werden sollten. Standardmäßig ist dies auf „false“ festgelegt.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>index_buckets_list</term>
      <listitem>
       <para>
        <emphasis>(durch Komma getrennte Liste von Zeichenketten)</emphasis> Falls leer, werden alle Buckets indiziert. Andernfalls werden nur die hier genannten Buckets indiziert. Es ist möglich, Bucket-Präfixe (zum Beispiel „foo*“) oder Bucket-Suffixe (zum Beispiel „*bar“) anzugeben.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>approved_owners_list</term>
      <listitem>
       <para>
        <emphasis>(durch Komma getrennte Liste von Zeichenketten)</emphasis> Falls leer, werden die Buckets aller Eigentümer indiziert (falls keine anderen Einschränkungen vorhanden sind). Andernfalls werden nur die Buckets bestimmter Eigentümer indiziert. Suffixe und Präfixe können ebenfalls angegeben werden.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>override_index_path</term>
      <listitem>
       <para>
        <emphasis>(Zeichenkette)</emphasis> Falls nicht leer, wird diese Zeichenkette als ElasticSearch-Indexpfad verwendet. Andernfalls wird der Indexpfad bei Initialisierung der Synchronisierung festgelegt und generiert.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>benutzername</term>
      <listitem>
       <para>
        Gibt einen Benutzernamen für ElasticSearch an, falls eine Authentifizierung erforderlich ist.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>kennwort</term>
      <listitem>
       <para>
        Gibt ein Passwort für ElasticSearch an, falls eine Authentifizierung erforderlich ist.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ceph-rgw-sync-elastic-query">
    <title>Metadatenabfragen</title>
    <para>
     Da der ElasticSearch Cluster nun Objekt-Metadaten speichert, ist es wichtig, dass der ElasticSearch-Endpunkt nicht öffentlich gemacht wird und nur für Cluster-Administratoren zugänglich ist. Die Anzeige von Metadaten-Abfragen für den Endbenutzer selbst ist problematisch, weil der Benutzer nur seine Metadaten abfragen soll und nicht die Metadaten anderer Benutzer. Der ElasticSearch Cluster müsste Benutzer ähnlich wie RGW authentifizieren, was ein Problem darstellt.
    </para>
    <para>
     Ab Luminous kann RGW in der Metadaten-Masterzone nun die Endbenutzeranforderungen verarbeiten. Dadurch ist es möglich, dass der ElasticSearch-Endpunkt nicht öffentlich zugänglich ist und gleichzeitig das Authentifizierungs- und Autorisierungsproblem gelöst ist, weil RGW selbst die Endbenutzeranforderungen authentifizieren kann. Zu diesem Zweck führt RGW eine neue Abfrage in den Bucket APIs ein, die ElasticSearch-Anforderungen verarbeiten können. Diese Anforderungen müssen an die Metadaten-Masterzone gesendet werden.
    </para>
    <variablelist>
     <varlistentry>
      <term>Abrufen einer ElasticSearch-Abfrage</term>
      <listitem>
<screen>
GET /<replaceable>BUCKET</replaceable>?query=<replaceable>QUERY-EXPR</replaceable>
       </screen>
       <para>
        Anforderungsparameter:
       </para>
       <itemizedlist>
        <listitem>
         <para>
          max-keys: maximale Anzahl der Einträge, die zurückgegeben werden sollen
         </para>
        </listitem>
        <listitem>
         <para>
          marker: Kennzeichnung für die Paginierung
         </para>
        </listitem>
       </itemizedlist>
<screen>
expression := [(]&lt;arg&gt; &lt;op&gt; &lt;value&gt; [)][&lt;and|or&gt; ...]
       </screen>
       <para>
        „op“ steht für eines der folgenden Zeichen: &lt;, &lt;=, ==, &gt;=, &gt;
       </para>
       <para>
        Beispiel:
       </para>
<screen>
GET /?query=name==foo
       </screen>
       <para>
        Gibt alle indizierten Schlüssel zurück, für die der Benutzer über Berechtigungen verfügt. Sie werden als „foo“ bezeichnet. Die Ausgabe ist eine Liste von Schlüsseln im XML-Format, die der S3-Antwort auf die Anforderung zum Auflisten von Buckets ähnlich ist.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Konfigurieren benutzerdefinierter Metadatenfelder</term>
      <listitem>
       <para>
        Definieren Sie, welche benutzerdefinierten Metadateneinträge (unter dem angegebenen Bucket) indiziert werden und welchen Typ diese Schlüssel haben sollen. Dies ist erforderlich, damit RGW die angegebenen benutzerdefinierten Metadatenwerte indiziert, wenn die explizite Indizierung von benutzerdefinierten Metadaten konfiguriert ist. Andernfalls ist es erforderlich in Fällen, in denen die indizierten Metadatenschlüssel keine Zeichenketten sind.
       </para>
<screen>
POST /<replaceable>BUCKET</replaceable>?mdsearch
x-amz-meta-search: &lt;key [; type]&gt; [, ...]
       </screen>
       <para>
        Mehrere Metadatenfelder müssen durch Komma getrennt werden. Ein Typ kann für ein Feld mit „;“ erzwungen werden. Derzeit sind Zeichenketten (Standard), Ganzzahlen und Datumsangaben als Typen zulässig. Mit folgendem Kommando indizieren Sie beispielsweise die Metadaten eines benutzerdefinierten Objekts („x-amz-meta-year“ als Ganzzahl, „x-amz-meta-date“ als Datum und „x-amz-meta-title“ als Zeichenkette):
       </para>
<screen>
POST /mybooks?mdsearch
x-amz-meta-search: x-amz-meta-year;int, x-amz-meta-release-date;date, x-amz-meta-title;string
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Löschen einer benutzerdefinierten Metadatenkonfiguration</term>
      <listitem>
       <para>
        Löschen Sie eine benutzerdefinierte Konfiguration eines Metadaten-Buckets.
       </para>
<screen>
DELETE /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Abrufen einer benutzerdefinierten Metadatenkonfiguration</term>
      <listitem>
       <para>
        Rufen Sie eine benutzerdefinierte Konfiguration eines Metadaten-Buckets ab.
       </para>
<screen>
GET /<replaceable>BUCKET</replaceable>?mdsearch
       </screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw-cloud-sync">
   <title>Cloud-Synchronisierungsmodul</title>
   <para>
    In diesem Abschnitt erhalten Sie Informationen zu einem Modul, mit dem die Zonendaten mit einem Remote-Cloud-Service synchronisiert werden. Die Synchronisierung läuft nur in eine Richtung ab – die Daten werden nicht aus der Remote-Zone zurück synchronisiert. Dieses Modul sorgt hauptsächlich dafür, dass Daten mit mehreren Cloud-Service-Anbietern synchronisiert werden können. Derzeit werden Cloud-Anbieter unterstützt, die mit AWS (S3) kompatibel sind.
   </para>
   <para>
    Für die Synchronisierung von Daten mit einem Remote-Cloud-Service müssen Sie Berechtigungsnachweise für Benutzer konfigurieren. Zahlreiche Cloud-Services beschränken die maximale Anzahl der Buckets, die von den einzelnen Benutzern erstellt werden können. Sie können daher die Zuordnung von Quellobjekten und Buckets, verschiedenen Zielen und verschiedenen Buckets sowie von Bucket-Präfixen konfigurieren. Die Quell-Zugriffslisten (ACLs) werden dabei nicht beibehalten. Sie können Berechtigungen bestimmter Quellbenutzer zu bestimmten Zielbenutzern zuordnen.
   </para>
   <para>
    Aufgrund der API-Einschränkungen ist es nicht möglich, die ursprüngliche Bearbeitungszeit und das HTTP-Entitäts-Tag (ETag) des Objekts beizubehalten. Das Cloud-Synchronisierungsmodul speichert diese Angaben als Metadaten-Attribute in den Zielobjekten.
   </para>
   <sect3 xml:id="cloud-sync-module">
    <title>Konfigurieren des Cloud-Synchronisierungsmoduls</title>
    <para>
     Die folgenden Beispiele zeigen eine Trivial- und eine Nicht-Trivial-Konfiguration für das Cloud-Synchronisierungsmodul. Hierbei ist zu beachten, dass die Trivial-Konfiguration mit der Nicht-Trivial-Konfiguration in Konflikt kommen kann.
    </para>
    <example>
     <title>Trivial-Konfiguration</title>
<screen>
{
  "connection": {
    "access_key": <replaceable>ACCESS</replaceable>,
    "secret": <replaceable>SECRET</replaceable>,
    "endpoint": <replaceable>ENDPOINT</replaceable>,
    "host_style": <replaceable>path | virtual</replaceable>,
  },
  "acls": [ { "type": <replaceable>id | email | uri</replaceable>,
    "source_id": <replaceable>SOURCE_ID</replaceable>,
    "dest_id": <replaceable>DEST_ID</replaceable> } ... ],
  "target_path": <replaceable>TARGET_PATH</replaceable>,
}
</screen>
    </example>
    <example>
     <title>Nicht-Trivial-Konfiguration</title>
<screen>
{
  "default": {
    "connection": {
      "access_key": <replaceable>ACCESS</replaceable>,
      "secret": <replaceable>SECRET</replaceable>,
      "endpoint": <replaceable>ENDPOINT</replaceable>,
      "host_style" <replaceable>path | virtual</replaceable>,
    },
    "acls": [
    {
      "type": <replaceable>id | email | uri</replaceable>,   #  optional, default is id
      "source_id": <replaceable>ID</replaceable>,
      "dest_id": <replaceable>ID</replaceable>
    } ... ]
    "target_path": <replaceable>PATH</replaceable> # optional
  },
  "connections": [
  {
    "connection_id": <replaceable>ID</replaceable>,
    "access_key": <replaceable>ACCESS</replaceable>,
    "secret": <replaceable>SECRET</replaceable>,
    "endpoint": <replaceable>ENDPOINT</replaceable>,
    "host_style": <replaceable>path | virtual</replaceable>,  # optional
  } ... ],
  "acl_profiles": [
  {
    "acls_id": <replaceable>ID</replaceable>, # acl mappings
    "acls": [ {
      "type": <replaceable>id | email | uri</replaceable>,
      "source_id": <replaceable>ID</replaceable>,
      "dest_id": <replaceable>ID</replaceable>
    } ... ]
  }
  ],
  "profiles": [
  {
   "source_bucket": <replaceable>SOURCE</replaceable>,
   "connection_id": <replaceable>CONNECTION_ID</replaceable>,
   "acls_id": <replaceable>MAPPINGS_ID</replaceable>,
   "target_path": <replaceable>DEST</replaceable>,          # optional
  } ... ],
}
</screen>
    </example>
    <para>
     Erläuterung der Konfigurationsbegriffe:
    </para>
    <variablelist>
     <varlistentry>
      <term>Verbindung</term>
      <listitem>
       <para>
        Eine Verbindung zum Remote-Cloud-Service. Umfasst „connection_id“, „access_key“, „secret“, „endpoint“ und „host_style“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>access_key</term>
      <listitem>
       <para>
        Remote-Cloud-Zugriffsschlüssel für die jeweilige Verbindung.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>secret</term>
      <listitem>
       <para>
        Geheimschlüssel für den Remote-Cloud-Service.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>endpoint</term>
      <listitem>
       <para>
        URL für den Endpunkt des Remote-Cloud-Service.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>host_style</term>
      <listitem>
       <para>
        Hosttyp („path“ oder „virtual“) für den Zugriff auf den Remote-Cloud-Endpunkt. Der Standardwert lautet „path“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>acls</term>
      <listitem>
       <para>
        Matrix der Zugriffslistenzuordnungen.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>acl_mapping</term>
      <listitem>
       <para>
        Jede „acl_mapping“-Struktur umfasst „type“, „source_id“ und „dest_id“. Hiermit wird die ACL-Mutation für die einzelnen Objekte definiert. Mit einer ACL-Mutation kann die Quellbenutzer-ID in eine Ziel-ID umgewandelt werden.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>type</term>
      <listitem>
       <para>
        ACL-Typ: „id“ definiert die Benutzer-ID, „email“ definiert den Benutzer nach E-Mail und „uri“ definiert den Benutzer nach URI (Gruppe).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>source_id</term>
      <listitem>
       <para>
        ID des Benutzers in der Quellzone.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>dest_id</term>
      <listitem>
       <para>
        ID des Benutzers im Ziel.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>target_path</term>
      <listitem>
       <para>
        Mit dieser Zeichenkette wird definiert, wie der Zielpfad erstellt wird. Der Zielpfad umfasst ein Präfix, an das der Quellobjektname angehängt wird. Das konfigurierbare Element für den Zielpfad kann die folgenden Variablen umfassen:
       </para>
       <variablelist>
        <varlistentry>
         <term>SID</term>
         <listitem>
          <para>
           Eindeutige Zeichenkette für die ID der Synchronisierungsinstanz.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>ZONEGROUP</term>
         <listitem>
          <para>
           Name der Zonengruppe.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>ZONEGROUP_ID</term>
         <listitem>
          <para>
           ID der Zonengruppe.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>ZONE</term>
         <listitem>
          <para>
           Name der Zone.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>ZONE_ID</term>
         <listitem>
          <para>
           ID der Zone.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>BUCKET</term>
         <listitem>
          <para>
           Name des Quell-Buckets.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>OWNER</term>
         <listitem>
          <para>
           ID für den Eigentümer des Quell-Buckets.
          </para>
         </listitem>
        </varlistentry>
       </variablelist>
       <para>
        Beispiel: target_path = rgwx-<replaceable>ZONE</replaceable>-<replaceable>SID</replaceable>/<replaceable>OWNER</replaceable>/<replaceable>BUCKET</replaceable>
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>acl_profiles</term>
      <listitem>
       <para>
        Matrix mit Zugriffslistenprofilen.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>acl_profile</term>
      <listitem>
       <para>
        Jedes Profil umfasst „acls_id“ für das Profil sowie eine „acls“-Matrix mit einer Liste der „acl_mappings“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Profile</term>
      <listitem>
       <para>
        Liste mit Profilen. Jedes Profil umfasst Folgendes:
       </para>
       <variablelist>
        <varlistentry>
         <term>source_bucket</term>
         <listitem>
          <para>
           Entweder der Name eines Buckets oder ein Bucket-Präfix (Endung auf *), mit dem der oder die Quell-Bucket(s) für dieses Profil definiert werden.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>target_path</term>
         <listitem>
          <para>
           Erläuterung siehe oben.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>connection_id</term>
         <listitem>
          <para>
           ID der Verbindung für dieses Profil.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>acls_id</term>
         <listitem>
          <para>
           ID des ACL-Profils für dieses Profil.
          </para>
         </listitem>
        </varlistentry>
       </variablelist>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="s3-specific-configurables">
    <title>S3-spezifische konfigurierbare Elemente</title>
    <para>
     Das Cloud-Synchronisierungsmodul arbeitet lediglich mit Back-Ends zusammen, die mit AWS S3 kompatibel sind. Dieses Verhalten kann beim Zugriff auf S3-Cloud-Services mithilfe bestimmter konfigurierbarer Elemente beeinflusst werden:
    </para>
<screen>
{
  "multipart_sync_threshold": <replaceable>OBJECT_SIZE</replaceable>,
  "multipart_min_part_size": <replaceable>PART_SIZE</replaceable>
}
</screen>
    <variablelist>
     <varlistentry>
      <term>multipart_sync_threshold</term>
      <listitem>
       <para>
        Objekte mit einer Größe größer oder gleich diesem Wert werden per Multipart-Upload mit dem Cloud-Service synchronisiert.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>multipart_min_part_size</term>
      <listitem>
       <para>
        Mindestgröße der Teile für die Synchronisierung von Objekten per Multipart-Upload.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>

  <sect2 xml:id="archive-sync-module">
   <title>Archiv-Synchronisierungsmodul</title>
   <para>
    Das <emphasis>Archiv-Synchronisierungsmodul</emphasis> verwendet die Versionierungsfunktion von S3-Objekten im Object Gateway. Sie können eine <emphasis>Archivzone</emphasis> konfigurieren, in der die verschiedenen Versionen von S3-Objekten erfasst werden, die im Lauf der Zeit in anderen Zonen auftreten. Der Versionsverlauf in der Archivzone kann nur mithilfe von Gateways beseitigt werden, die der Archivzone zugeordnet sind.
   </para>
   <para>
    Bei einer solchen Architektur können verschiedene nichtversionierte Zonen ihre Daten und Metadaten über die jeweiligen Zonen-Gateways spiegeln, sodass Hochverfügbarkeit für die Endbenutzer erzielt wird, während in der Archivzone alle Datenaktualisierungen erfasst und als Versionen der S3-Objekte konsolidiert werden.
   </para>
   <para>
    Wenn Sie die Archivzone in eine Mehrzonen-Konfiguration einbinden, erhalten Sie die Flexibilität eines S3-Objektverlaufs in einer einzelnen Zone, wobei Sie den Speicherplatz einsparen, den die Reproduktionen der versionierten S3-Objekte in den verbleibenden Zonen belegen würden.
   </para>
   <sect3 xml:id="archive-sync-module-configuration">
    <title>Konfigurieren des Archiv-Synchronisierungsmoduls</title>
    <tip>
     <title>Weitere Informationen</title>
     <para>
      Weitere Informationen zum Konfigurieren von Gateways für mehrere Standorte finden Sie in <xref linkend="ceph-rgw-fed"/>.
     </para>
     <para>
      Weitere Informationen zum Konfigurieren von Synchronisierungsmodulen finden Sie in <xref linkend="ceph-rgw-sync"/>.
     </para>
    </tip>
    <para>
     Zur Nutzung des Archiv-Synchronisierungsmoduls erstellen Sie eine neue Zone mit dem Schichttyp <literal>archive</literal>:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=<replaceable>ZONE_GROUP_NAME</replaceable> \
 --rgw-zone=<replaceable>OGW_ZONE_NAME</replaceable> \
 --endpoints=<replaceable>http://OGW_ENDPOINT1_URL[,http://OGW_ENDPOINT2_URL,...]</replaceable>
 --tier-type=archive
</screen>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-ldap">
  <title>LDAP-Authentifizierung</title>

  <para>
   Abgesehen von der standardmäßigen Authentifizierung lokaler Benutzer kann Object Gateway Benutzer auch über LDAP Server Services authentifizieren.
  </para>

  <sect2 xml:id="ceph-rgw-ldap-how-works">
   <title>Beglaubigungsverfahren</title>
   <para>
    Das Object Gateway extrahiert den Berechtigungsnachweis des Benutzers aus einem Token. Ein Suchfilter wird aus dem Benutzernamen erstellt. Das Object Gateway durchsucht anhand des konfigurierten Servicekontos das Verzeichnis nach einem passenden Eintrag. Wird ein Eintrag gefunden, versucht das Object Gateway, eine Bindung zum gefundenen eindeutigen Namen mit dem Passwort aus dem Token herzustellen. Wenn der Berechtigungsnachweis gültig ist, wird die Bindung hergestellt und das Object Gateway gewährt den Zugriff.
   </para>
   <para>
    Die Anzahl der Benutzer lässt sich begrenzen. Legen Sie dazu die Basis für die Suche auf eine bestimmte organisatorische Einheit fest oder geben Sie einen benutzerdefinierten Suchfilter an, beispielsweise eine bestimmte Gruppenmitgliedschaft, benutzerdefinierte Objektklassen oder Attribute.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-reqs">
   <title>Anforderungen</title>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>LDAP oder Active Directory</emphasis>: Eine aktive LDAP-Instanz, auf die Object Gateway zugreifen kann.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Servicekonto</emphasis>: LDAP-Berechtigungen, die vom Object Gateway mit Suchberechtigungen verwendet werden sollen.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Benutzerkonto</emphasis>: Mindestens ein Benutzerkonto im LDAP-Verzeichnis.
     </para>
    </listitem>
   </itemizedlist>
   <important>
    <title>LDAP-Benutzer und lokale Benutzer dürfen sich nicht überlappen</title>
    <para>
     Für lokale Benutzer und für Benutzer, die mit LDAP authentifiziert werden, sollten nicht dieselben Benutzernamen verwendet werden. Das Object Gateway kann sie nicht unterscheiden und behandelt sie als ein und denselben Benutzer.
    </para>
   </important>
   <tip>
    <title>Integritätsprüfungen</title>
    <para>
     Verifizieren Sie das Servicekonto oder die LDAP-Verbindung mit dem Dienstprogramm <command>ldapsearch</command>. Beispiel:
    </para>
<screen><prompt>tux &gt; </prompt>ldapsearch -x -D "uid=ceph,ou=system,dc=example,dc=com" -W \
-H ldaps://example.com -b "ou=users,dc=example,dc=com" 'uid=*' dn</screen>
    <para>
     Vergewissern Sie sich, dass Sie dieselben LDAP-Parameter verwenden wie in der Ceph-Konfigurationsdatei, um mögliche Probleme zu vermeiden.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-config">
   <title>Konfigurieren des Object Gateways zur Verwendung der LDAP-Authentifizierung</title>
   <para>
    Die folgenden Parameter beziehen sich auf die LDAP-Authentifizierung:
   </para>
   <variablelist>
    <varlistentry>
     <term><option>rgw_ldap_uri</option></term>
     <listitem>
      <para>
       Gibt den zu verwendenden LDAP-Server an. Vergewissern Sie sich, dass Sie den Parameter <literal>ldaps://<replaceable>FQDN</replaceable>:<replaceable>port</replaceable></literal> verwenden, um die offene Übertragung des Berechtigungsnachweises in Klartext zu verhindern.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_binddn</option></term>
     <listitem>
      <para>
       Der vom Object Gateway verwendete eindeutige Name des Servicekontos.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_secret</option></term>
     <listitem>
      <para>
       Das Passwort für das Service-Konto.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>rgw_ldap_searchdn</term>
     <listitem>
      <para>
       Gibt die Basis im Verzeichnisinformationsbaum zum Suchen von Benutzern an. Sie könnte die organisatorische Einheit Ihrer Benutzer oder eine spezifischere organisatorische Einheit sein.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_ldap_dnattr</option></term>
     <listitem>
      <para>
       Das Attribut, das im konstruierten Suchfilter zum Abgleich eines Benutzernamens verwendet wird. Abhängig von Ihrem Verzeichnisinformationsbaum (Directory Information Tree, DIT) wäre es wahrscheinlich <literal>uid</literal> oder <literal>cn</literal>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term><option>rgw_search_filter</option></term>
     <listitem>
      <para>
       Wenn dieser Parameter nicht angegeben ist, konstruiert das Object Gateway automatisch den Suchfilter mit der Einstellung <option>rgw_ldap_dnattr</option>. Mit diesem Parameter engen Sie die Liste der zulässigen Benutzer auf sehr flexible Weise ein. Weitere Details finden Sie in <xref linkend="ceph-rgw-ldap-filter"/>.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-filter">
   <title>Verwenden eines benutzerdefinierten Suchfilters zur Begrenzung des Benutzerzugriffs</title>
   <para>
    Den Parameter <option>rgw_search_filter</option> können Sie auf unterschiedliche Weise verwenden.
   </para>
   <sect3 xml:id="partial-filter-search-filter">
    <title>Teilfilter zur weiteren Beschränkung des konstruierten Suchfilters</title>
    <para>
     Beispiel eines Teilfilters:
    </para>
<screen>"objectclass=inetorgperson"</screen>
    <para>
     Das Object Gateway generiert den Suchfilter wie üblich mit dem Benutzernamen aus dem Token und dem Wert von <option>rgw_ldap_dnattr</option>. Der konstruierte Filter wird dann mit dem Teilfilter aus dem Attribut <option>rgw_search_filter</option> kombiniert. Abhängig vom Benutzernamen und den Einstellungen sieht der finale Suchfilter möglicherweise folgendermaßen aus:
    </para>
<screen>"(&amp;(uid=hari)(objectclass=inetorgperson))"</screen>
    <para>
     In diesem Fall erhält der Benutzer „hari“ nur dann Zugriff, wenn er im LDAP-Verzeichnis gefunden wird, über die Objektklasse „inetorgperson“ verfügt und ein gültiges Passwort angegeben hat.
    </para>
   </sect3>
   <sect3 xml:id="complete-filter">
    <title>Vollständiger Filter</title>
    <para>
     Ein vollständiger Filter muss einen Token <option>USERNAME</option> enthalten, der beim Authentifizierungsversuch durch den Benutzernamen ersetzt wird. Der Parameter <option>rgw_ldap_dnattr</option> wird in diesem Fall nicht mehr verwendet. Verwenden Sie beispielsweise folgenden Filter, um die gültigen Benutzer auf eine bestimmte Gruppe zu beschränken:
    </para>
<screen>"(&amp;(uid=USERNAME)(memberOf=cn=ceph-users,ou=groups,dc=mycompany,dc=com))"</screen>
    <note>
     <title>Attribut <literal>memberOf</literal></title>
     <para>
      Für die Verwendung des Attributs <literal>memberOf</literal> in LDAP-Suchen ist die serverseitige Unterstützung Ihrer spezifischen LDAP Server-Implementierung erforderlich.
     </para>
    </note>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-ldap-token">
   <title>Generieren eines Zugriffstokens für die LDAP-Authentifizierung</title>
   <para>
    Das Dienstprogramm <command>radosgw-token</command> generiert den Zugriffstoken basierend auf LDAP-Benutzername und Passwort. Es gibt eine mit base-64 verschlüsselte Zeichenkette aus, die der eigentliche Zugriffstoken ist. Verwenden Sie Ihren bevorzugten S3 Client (weitere Informationen hierzu finden Sie in <xref linkend="accessing-ragos-gateway"/>), geben Sie den Token als Zugriffsschlüssel an und verwenden Sie einen leeren geheimen Schlüssel.
   </para>
<screen><prompt>tux &gt; </prompt>export RGW_ACCESS_KEY_ID="<replaceable>USERNAME</replaceable>"
<prompt>tux &gt; </prompt>export RGW_SECRET_ACCESS_KEY="<replaceable>PASSWORD</replaceable>"
<prompt>cephuser@adm &gt; </prompt>radosgw-token --encode --ttype=ldap</screen>
   <important>
    <title>Klartext-Berechtigungsnachweis</title>
    <para>
     Der Zugriffstoken ist eine mit base-64 verschlüsselte JSON-Struktur und enthält den LDAP-Berechtigungsnachweis als Klartext.
    </para>
   </important>
   <note>
    <title>Active Directory</title>
    <para>
     Verwenden Sie für Active Directory den Parameter <option>--ttype=ad</option>.
    </para>
   </note>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-bucket-sharding">
  <title>Bucket-Index-Sharding</title>

  <para>
   Das Object Gateway speichert Bucket-Indexdaten in einem Index-Pool, der standardmäßig <literal>.rgw.buckets.index</literal> lautet. Wenn Sie zu viele (hunderttausende) Objekte in einen einzelnen Bucket stellen und das Kontingent für die maximale Anzahl der Objekte pro Bucket (<option>rgw bucket default quota max objects</option>) nicht festgelegt ist, dann verschlechtert sich möglicherweise die Leistung des Index-Pools. Ein <emphasis>Bucket-Index-Sharding</emphasis> verhindert derartige Leistungseinbußen und ermöglicht eine hohe Anzahl von Objekten pro Bucket.
  </para>

  <sect2 xml:id="ogw-bucket-reshard">
   <title>Bucket-Index-Resharding</title>
   <para>
    Wenn ein Bucket groß geworden ist und die anfängliche Konfiguration nicht mehr ausreicht, muss für den Indexpool des Buckets ein Resharding durchgeführt werden. Sie können entweder das automatische Online-Resharding für den Bucket-Index durchführen (Informationen hierzu finden Sie in <xref linkend="ogw-bucket-sharding-dyn"/>) oder ein manuelles Offline-Resharding des Bucket-Index (Informationen hierzu finden Sie in <xref linkend="ogw-bucket-sharding-re"/>).
   </para>
   <sect3 xml:id="ogw-bucket-sharding-dyn">
    <title>Dynamisches Resharding</title>
    <para>
     Seit SUSE Enterprise Storage 5 unterstützen wir das Online-Bucket-Resharding. Es erkennt, wenn die Anzahl der Objekte pro Bucket einen bestimmten Schwellwert erreicht, und erhöht automatisch die Anzahl der vom Bucket-Index verwendeten Shards. Dieser Vorgang reduziert die Anzahl der Einträge in jedem Bucket-Index-Shard.
    </para>
    <para>
     Der Erkennungsvorgang wird in folgenden Fällen ausgeführt:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Wenn neue Objekte zum Bucket hinzugefügt werden.
      </para>
     </listitem>
     <listitem>
      <para>
       In einem Hintergrundprozess, der regelmäßig alle Buckets absucht. Dies ist erforderlich, um bestehende Buckets zu verarbeiten, die nicht aktualisiert werden.
      </para>
     </listitem>
    </itemizedlist>
    <para>
     Ein Bucket, für den ein Resharding durchgeführt werden muss, wird zur Warteschlange <option>reshard_log</option> hinzugefügt und das Resharding wird für später geplant. Die Reshard-Threads werden im Hintergrund ausgeführt und führen das geplante Resharding für die einzelnen Buckets nacheinander durch.
    </para>
    <variablelist>
     <title>Konfigurieren eines dynamischen Reshardings</title>
     <varlistentry>
      <term><option>rgw_dynamic_resharding</option></term>
      <listitem>
       <para>
        Aktiviert oder deaktiviert das dynamische Index-Resharding. Mögliche Werte sind „true“ und „false“. Die Standardeinstellung ist „true“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_num_logs</option></term>
      <listitem>
       <para>
        Anzahl der Shards für das Resharding-Protokoll. Der Standardwert ist 16.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_bucket_lock_duration</option></term>
      <listitem>
       <para>
        Dauer der Sperre des Bucket-Objekts beim Resharding. Die Standardeinstellung ist 120 Sekunden.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_max_objs_per_shard</option></term>
      <listitem>
       <para>
        Maximale Anzahl der Objekte pro Bucket-Index-Shard. Der Standardwert ist 100.000 Objekte.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw_reshard_thread_interval</option></term>
      <listitem>
       <para>
        Maximale Zeit zwischen den Verarbeitungsrunden des Reshard-Threads. Die Standardeinstellung ist 600 Sekunden.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <variablelist>
     <title>Kommandos zum Verwalten des Resharding-Vorgangs</title>
     <varlistentry>
      <term>Fügen Sie ein Bucket zur Resharding-Warteschlange hinzu mit:</term>
      <listitem>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin reshard add \
 --bucket <replaceable>BUCKET_NAME</replaceable> \
 --num-shards <replaceable>NEW_NUMBER_OF_SHARDS</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Listen Sie die Resharding-Warteschlange auf mit:</term>
      <listitem>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin reshard list
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Verarbeiten/planen Sie ein Bucket-Resharding mit:</term>
      <listitem>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin reshard process
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Zeigen Sie den Bucket-Resharding-Status an mit:</term>
      <listitem>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin reshard status --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Brechen Sie das ausstehende Bucket-Resharding ab mit:</term>
      <listitem>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin reshard cancel --bucket <replaceable>BUCKET_NAME</replaceable>
</screen>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
   <sect3 xml:id="ogw-bucket-sharding-re">
    <title>Manuelles Resharding</title>
    <para>
     Das in <xref linkend="ogw-bucket-sharding-dyn"/> erwähnte dynamische Resharding wird nur für einfache Object-Gateway-Konfigurationen unterstützt. Bei Konfigurationen mit mehreren Standorten müssen Sie das in diesem Abschnitt erläuterte manuelle Resharding verwenden.
    </para>
    <para>
     Führen Sie für ein manuelles Offline-Resharding des Bucket-Index folgendes Kommando aus:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin bucket reshard
</screen>
    <para>
     Das Kommando <command>bucket reshard</command> führt Folgendes aus:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Es erstellt einen neuen Satz von Bucket-Index-Objekten für das angegebene Objekt.
      </para>
     </listitem>
     <listitem>
      <para>
       Es verteilt alle Einträge dieser Indexobjekte.
      </para>
     </listitem>
     <listitem>
      <para>
       Es erstellt eine neue Bucket-Instanz.
      </para>
     </listitem>
     <listitem>
      <para>
       Es verknüpft die neue Bucket-Instanz mit dem Bucket, sodass alle neuen Index-Operationen durch die neuen Bucket-Indizes gehen.
      </para>
     </listitem>
     <listitem>
      <para>
       Gibt die alte und die neue Bucket-ID an die Standardausgabe aus.
      </para>
     </listitem>
    </itemizedlist>
    <tip>
     <para>
      Bei der Wahl der Anzahl der Shards dürfen Sie nicht mehr als 100.000 Einträge pro Shard vorsehen. Bucket-Index-Shards, die Primzahlen sind, funktionieren tendenziell besser bei der gleichmäßigen Verteilung von Bucket-Indexeinträgen auf die Shards. Zum Beispiel sind 503 Bucket-Index-Shards besser als 500, da erstere Zahl eine Primzahl ist.
     </para>
    </tip>
    <procedure>
     <title>Resharding des Bucket-Index</title>
     <step>
      <para>
       Vergewissern Sie sich, dass alle Operationen zum Bucket gestoppt sind.
      </para>
     </step>
     <step>
      <para>
       Sichern Sie den ursprünglichen Bucket-Index:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin bi list \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 &gt; <replaceable>BUCKET_NAME</replaceable>.list.backup
</screen>
     </step>
     <step>
      <para>
       Führen Sie ein Resharding des Bucket-Index aus:
      </para>
<screen>
 <prompt>cephuser@adm &gt; </prompt>radosgw-admin bucket reshard \
 --bucket=<replaceable>BUCKET_NAME</replaceable> \
 --num-shards=<replaceable>NEW_SHARDS_NUMBER</replaceable>
</screen>
      <tip>
       <title>Alte Bucket-ID</title>
       <para>
        Als Teil seiner Ausgabe gibt dieses Kommando auch die neue und alte Bucket-ID aus.
       </para>
      </tip>
     </step>
    </procedure>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw-bucket-sharding-new">
   <title>Bucket-Index-Sharding für neue Buckets</title>
   <para>
    Für ein Bucket-Index-Sharding stehen zwei Optionen zur Verfügung:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Verwenden Sie bei einfachen Konfigurationen die Option <option>rgw_override_bucket_index_max_shards</option>.
     </para>
    </listitem>
    <listitem>
     <para>
      Verwenden Sie bei Konfigurationen mit mehreren Standorten die Option <option>bucket_index_max_shards</option>.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Das Bucket-Index-Sharding wird deaktiviert, wenn die Optionen auf <literal>0</literal> festgelegt sind. Ein Wert größer <literal>0</literal> aktiviert das Bucket-Index-Sharding und legt die maximale Anzahl von Shards fest.
   </para>
   <para>
    Die folgende Formel unterstützt Sie beim Berechnen der empfohlenen Anzahl von Shards:
   </para>
<screen>
number_of_objects_expected_in_a_bucket / 100000
</screen>
   <para>
    Beachten Sie, dass maximal 7877 Shards möglich sind.
   </para>
   <sect3 xml:id="multisite-config-bucket">
    <title>Konfigurationen für mehrere Standorte</title>
    <para>
     Konfigurationen für mehrere Standorte können einen anderen Index-Pool zum Verwalten von Failover haben. Legen Sie zum Konfigurieren einer konsistenten Anzahl von Shards für Zonen in einer Zonengruppe die Option <option>bucket_index_max_shards</option> in der Konfiguration der Zonengruppe fest:
    </para>
    <procedure>
     <step>
      <para>
       Exportieren Sie die Zonengruppenkonfiguration in die Datei <filename>zonegroup.json</filename>:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup get &gt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Bearbeiten Sie die Datei <filename>zonegroup.json</filename> und legen Sie die Option <option>bucket_index_max_shards</option> für jede benannte Zone fest.
      </para>
     </step>
     <step>
      <para>
       Setzen Sie die Zonengruppe zurück:
      </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup set &lt; zonegroup.json
</screen>
     </step>
     <step>
      <para>
       Aktualisieren Sie den Zeitraum mit. Siehe <xref linkend="ceph-rgw-fed-masterzone-updateperiod"/>.
      </para>
     </step>
    </procedure>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-keystone">
  <title>Integration von OpenStack Keystone</title>

  <para>
   OpenStack Keystone ist ein Identitätsservice für das OpenStack-Produkt. Sie können das Object Gateway mit Keystone integrieren, um ein Gateway einzurichten, das einen Keystone-Authentifizierungstoken akzeptiert. Ein Benutzer, der durch Keystone für den Zugriff auf das Gateway autorisiert ist, wird am Ceph Object Gateway verifiziert und gegebenenfalls automatisch erstellt. Das Object Gateway fragt Keystone regelmäßig nach einer Liste der entzogenen Token ab.
  </para>

  <sect2 xml:id="ogw-keystone-ostack">
   <title>Konfigurieren von OpenStack</title>
   <para>
    Vor dem Konfigurieren des Ceph Gateways müssen Sie OpenStack Keystone konfigurieren, um den Swift Service zu aktivieren und auf das Ceph Object Gateway auszurichten:
   </para>
   <procedure>
    <step>
     <para>
      <emphasis>Festlegen des Swift Service.</emphasis> Sie müssen zunächst den Swift Service erstellen, um OpenStack zur Validierung von Swift-Benutzern zu verwenden:
     </para>
<screen>
<prompt>tux &gt; </prompt>openstack service create \
 --name=swift \
 --description="Swift Service" \
 object-store
</screen>
    </step>
    <step>
     <para>
      <emphasis>Festlegen der Endpunkte.</emphasis> Nach dem Erstellen des Swift Service müssen Sie diesen auf das Ceph Object Gateway ausrichten. Ersetzen Sie <replaceable>REGION_NAME</replaceable> durch den Zonengruppennamen oder Regionsnamen des Gateways.
     </para>
<screen>
<prompt>tux &gt; </prompt>openstack endpoint create --region <replaceable>REGION_NAME</replaceable> \
 --publicurl   "http://radosgw.example.com:8080/swift/v1" \
 --adminurl    "http://radosgw.example.com:8080/swift/v1" \
 --internalurl "http://radosgw.example.com:8080/swift/v1" \
 swift
</screen>
    </step>
    <step>
     <para>
      <emphasis>Verifizieren der Einstellungen.</emphasis> Nach dem Erstellen des Swift Service und dem Festlegen der Endpunkte müssen Sie die Endpunkte anzeigen, um zu verifizieren, dass alle Einstellungen korrekt sind.
     </para>
<screen>
<prompt>tux &gt; </prompt>openstack endpoint show object-store
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ogw-keystone-ogw">
   <title>Konfigurieren des Ceph Object Gateways</title>
   <sect3>
    <title>Konfigurieren der SSL-Zertifikate</title>
    <para>
     Das Ceph Object Gateway fragt Keystone regelmäßig nach einer Liste der entzogenen Token ab. Diese Anforderungen sind verschlüsselt und signiert. Keystone kann ebenfalls konfiguriert werden, um eigensignierte Token bereitzustellen, die ebenfalls verschlüsselt und signiert sind. Sie müssen das Gateway so konfigurieren, dass es diese signierten Nachrichten entschlüsseln und verifizieren kann. Daher müssen die OpenSSL-Zertifikate, die Keystone zum Erstellen der Anforderungen verwendet, in das Format „nss db“ konvertiert werden:
    </para>
<screen>
<prompt role="root">root # </prompt>mkdir /var/ceph/nss
<prompt role="root">root # </prompt>openssl x509 -in /etc/keystone/ssl/certs/ca.pem \
 -pubkey | certutil -d /var/ceph/nss -A -n ca -t "TCu,Cu,Tuw"
<systemitem class="username">root</systemitem>openssl x509 -in /etc/keystone/ssl/certs/signing_cert.pem \
 -pubkey | certutil -A -d /var/ceph/nss -n signing_cert -t "P,P,P"
</screen>
    <para>
     OpenStack Keystone kann über ein eigensigniertes SSL-Zertifikat mit dem Ceph Object Gateway interagieren. Installieren Sie entweder das SSL-Zertifikat von Keystone im Knoten, auf dem das Ceph Object Gateway ausgeführt wird, oder legen Sie alternativ den Wert der Option <option>rgw keystone verify ssl</option> auf „false“ fest. Wenn Sie <option>rgw keystone verify ssl</option> auf „false“ festlegen, versucht das Gateway nicht, das Zertifikat zu verifizieren.
    </para>
   </sect3>
   <sect3 xml:id="config-ogw-options">
    <title>Konfigurieren der Optionen des Object Gateways</title>
    <para>
     Die Keystone-Integration wird mit folgenden Optionen konfiguriert:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone api version</option></term>
      <listitem>
       <para>
        Version der Keystone-API. Gültige Optionen sind 2 oder 3. Der Standardwert ist 2.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone url</option></term>
      <listitem>
       <para>
        Die URL und Portnummer der administrativen RESTful API am Keystone-Server. Folgt dem Schema <replaceable>SERVER_URL:PORTNUMMER</replaceable>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin token</option></term>
      <listitem>
       <para>
        Der Token oder das gemeinsame Geheimnis, der/das intern in Keystone für administrative Anforderungen konfiguriert wird.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted roles</option></term>
      <listitem>
       <para>
        Die Rollen zur Verarbeitung der Anforderungen. Die Standardeinstellung ist „Member, admin“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone accepted admin roles</option></term>
      <listitem>
       <para>
        Die Liste der Rollen, mit denen Benutzer Verwaltungsrechte erhalten können.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone token cache size</option></term>
      <listitem>
       <para>
        Die maximale Anzahl der Einträge im Keystone-Token-Cache.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone revocation interval</option></term>
      <listitem>
       <para>
        Die Dauer in Sekunden, bevor entzogene Token überprüft werden. Der Standardwert ist 15 * 60.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone implicit tenants</option></term>
      <listitem>
       <para>
        Neue Benutzer werden in ihren eigenen Mandanten mit demselben Namen erstellt. Die Standardeinstellung ist „false“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw s3 auth use keystone</option></term>
      <listitem>
       <para>
        Wird diese Option auf „true“ festgelegt, authentifiziert das Ceph Object Gateway Benutzer mit Keystone. Die Standardeinstellung ist „false“.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>nss db path</option></term>
      <listitem>
       <para>
        Der Pfad zur NSS-Datenbank.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Es ist auch möglich, den Keystone Service-Mandanten, den Benutzer und das Passwort für Keystone (für Version 2.0 der OpenStack Identity API) auf ähnliche Weise zu konfigurieren wie OpenStack Services normalerweise konfiguriert werden. Dadurch vermeiden Sie, das gemeinsame Geheimnis <option>rgw keystone admin token</option> in der Konfigurationsdatei festzulegen, das in Produktionsumgebungen deaktiviert sein sollte. Die Anmeldedaten des Service-Mandanten sollten Administratorrechte enthalten. Weitere Details finden Sie in der <link xlink:href="https://docs.openstack.org/keystone/latest/#setting-up-projects-users-and-roles">offiziellen OpenStack Keystone-Dokumentation</link>. Die entsprechenden Konfigurationsoptionen sind wie folgt:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin user</option></term>
      <listitem>
       <para>
        Der Benutzername des verwaltungsberechtigten Keystone-Benutzers.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin password</option></term>
      <listitem>
       <para>
        Das Passwort des verwaltungsberechtigten Keystone-Benutzers.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin tenant</option></term>
      <listitem>
       <para>
        Der Mandant des verwaltungsberechtigten Benutzers von Keystone Version 2.0.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Ein Ceph Object-Gateway-Benutzer wird einem Keystone-Mandanten zugeordnet. Einem Keystone-Benutzer sind verschiedene Rollen zugewiesen, möglicherweise zu mehr als einem Mandanten. Wenn das Ceph Object Gateway das Ticket erhält, sieht es sich den Mandanten und die Benutzerrollen an, die diesem Ticket zugewiesen sind, und akzeptiert die Anforderung oder weist sie zurück, je nach Einstellung der Option <option>rgw keystone accepted roles</option>.
    </para>
    <tip>
     <title>Zuordnung zu OpenStack-Mandanten</title>
     <para>
      Obgleich Swift-Mandanten standardmäßig zum Object-Gateway-Benutzer zugeordnet werden, ist mit der Option <option>rgw keystone implicit tenants</option> auch deren Zuordnung zu OpenStack-Mandanten möglich. Dadurch verwenden Container den Mandanten-Namespace statt des S3-ähnlichen globalen Namespace, das standardmäßig für Object Gateway verwendet wird. Wir empfehlen, die Zuordnungsmethode in der Planungsphase festzulegen, um Verwirrung zu vermeiden. Wenn eine Option später gewechselt wird, betrifft dies nur neuere Anforderungen, die unter einem Mandanten zugeordnet werden. Ältere Buckets, die vorher erstellt wurden, sind weiterhin in einem globalen Namespace enthalten.
     </para>
    </tip>
    <para>
     Bei Version 3 der OpenStack Identity API sollten Sie die Option <option>rgw keystone admin tenant</option> ersetzen durch:
    </para>
    <variablelist>
     <varlistentry>
      <term><option>rgw keystone admin domain</option></term>
      <listitem>
       <para>
        Die Domäne des verwaltungsberechtigten Keystone-Benutzers.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term><option>rgw keystone admin project</option></term>
      <listitem>
       <para>
        Das Projekt des verwaltungsberechtigten Keystone-Benutzers.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="ogw-storage-classes">
  <title>Pool-Platzierung und Speicherklassen</title>

  <sect2 xml:id="ogw-storage-classes-placement-targets">
   <title>Anzeigen von Platzierungszielen</title>
   <para>
    Mit Platzierungszielen wird gesteuert, welche Pools einem bestimmten Bucket zugeordnet werden. Das Platzierungsziel eines Buckets wird beim Erstellen festgelegt und kann nicht geändert werden. Mit folgendem Kommando rufen Sie die zugehörige <literal>placement_rule</literal> ab:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin bucket stats
</screen>
   <para>
    Die Zonengruppenkonfiguration umfasst eine Liste von Platzierungszielen mit dem anfänglichen Ziel „default-placement“. Anschließend ordnet die Zonenkonfiguration die Namen der einzelnen Zonengruppen-Platzierungsziele dem lokalen Speicher zu. Diese Zonenplatzierungsdaten umfassen den Namen „index_pool“ für den Bucket-Index, den Namen „data_extra_pool“ für Metadaten zu unvollständigen Multipart-Uploads sowie je einen Namen „data_pool“ für die einzelnen Speicherklassen.
   </para>
  </sect2>

  <sect2 xml:id="ogw-storage-classes-itself">
   <title>Speicherklassen</title>
   <para>
    Speicherklassen tragen dazu bei, die Platzierung von Objektdaten individuell anzupassen. Mithilfe von S3-Bucket-Lebenszyklusregeln lässt sich der Übergang von Objekten zwischen Speicherklassen automatisieren.
   </para>
   <para>
    Speicherklassen werden anhand von Platzierungszielen definiert. In den einzelnen Platzierungszielen der Zonengruppe sind die verfügbaren Speicherklassen jeweils mit der Anfangsklasse „STANDARD“ aufgelistet. Die Zonenkonfiguration stellt jeweils den Pool-Namen „data_pool“ für die einzelnen Speicherklassen der Zonengruppe bereit.
   </para>
  </sect2>

  <sect2 xml:id="ogw-storage-classes-zone-config">
   <title>Konfigurieren von Zonengruppen und Zonen</title>
   <para>
    Mit dem Kommando <command>radosgw-admin</command> konfigurieren Sie die Platzierung der Zonengruppen und Zonen. Mit folgendem Kommando rufen Sie die Platzierungskonfiguration der Zonengruppe ab:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup get
{
    "id": "ab01123f-e0df-4f29-9d71-b44888d67cd5",
    "name": "default",
    "api_name": "default",
    ...
    "placement_targets": [
        {
            "name": "default-placement",
            "tags": [],
            "storage_classes": [
                "STANDARD"
            ]
        }
    ],
    "default_placement": "default-placement",
    ...
}
</screen>
   <para>
    Mit folgendem Kommando rufen Sie die Platzierungskonfiguration der Zone ab:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone get
{
    "id": "557cdcee-3aae-4e9e-85c7-2f86f5eddb1f",
    "name": "default",
    "domain_root": "default.rgw.meta:root",
    ...
    "placement_pools": [
        {
            "key": "default-placement",
            "val": {
                "index_pool": "default.rgw.buckets.index",
                "storage_classes": {
                    "STANDARD": {
                        "data_pool": "default.rgw.buckets.data"
                    }
                },
                "data_extra_pool": "default.rgw.buckets.non-ec",
                "index_type": 0
            }
        }
    ],
    ...
}
</screen>
   <note>
    <title>Keine vorherige Konfiguration mit mehreren Standorten</title>
    <para>
     Falls Sie bislang noch keine Konfiguration mit mehreren Standorten vorgenommen haben, wird je eine „standardmäßige“ Zone und Zonengruppe erstellt. Änderungen an der Zone/Zonengruppe treten erst dann in Kraft, wenn Sie die Ceph Object Gateways neu starten. Wenn Sie einen Bereich für mehrere Standorte angelegt haben, treten Änderungen an der Zone/Zonengruppe in Kraft, sobald Sie diese Änderungen mit dem Kommando <command>radosgw-admin period update --commit</command> übergeben.
    </para>
   </note>
   <sect3 xml:id="adding-placement-target">
    <title>Hinzufügen eines Platzierungsziels</title>
    <para>
     Soll ein neues Platzierungsziel mit dem Namen „temporary“ erstellt werden, fügen Sie das Ziel zunächst in die Zonengruppe ein:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup placement add \
      --rgw-zonegroup default \
      --placement-id temporary
</screen>
    <para>
     Geben Sie dann die Zonenplatzierungsdaten für dieses Ziel an:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone placement add \
      --rgw-zone default \
      --placement-id temporary \
      --data-pool default.rgw.temporary.data \
      --index-pool default.rgw.temporary.index \
      --data-extra-pool default.rgw.temporary.non-ec
</screen>
   </sect3>
   <sect3 xml:id="adding-storage-class">
    <title>Hinzufügen einer Speicherklasse</title>
    <para>
     Soll eine neue Speicherklasse mit dem Namen „COLD“ in das Ziel „default-placement“ eingefügt werden, fügen Sie die Klasse zunächst in die Zonengruppe ein:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup placement add \
      --rgw-zonegroup default \
      --placement-id default-placement \
      --storage-class COLD
</screen>
    <para>
     Geben Sie dann die Zonenplatzierungsdaten für diese Speicherklasse an:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone placement add \
      --rgw-zone default \
      --placement-id default-placement \
      --storage-class COLD \
      --data-pool default.rgw.cold.data \
      --compression lz4
</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw-storage-classes-customizing-placement">
   <title>Anpassung der Platzierung</title>
   <sect3 xml:id="edit-default-zgroup-placement">
    <title>Bearbeiten der standardmäßigen Zonengruppenplatzierung</title>
    <para>
     Neue Buckets greifen standardmäßig auf das Ziel <literal>default_placement</literal> der Zonengruppe zurück. Mit folgendem Kommando können Sie diese Zonengruppeneinstellung ändern:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup placement default \
      --rgw-zonegroup default \
      --placement-id new-placement
</screen>
   </sect3>
   <sect3 xml:id="edit-default-user-placement">
    <title>Bearbeiten der standardmäßigen Benutzerplatzierung</title>
    <para>
     Ein Ceph Object-Gateway-Benutzer kann ein nicht leeres Feld <literal>default_placement</literal> in den Benutzerinformationen festlegen und ist damit in der Lage, das standardmäßige Platzierungsziel der Zonengruppe zu überschreiben. Ebenso kann <literal>default_storage_class</literal> die Speicherklasse <option>STANDARD</option> überschreiben, die standardmäßig auf Objekte angewendet wird.
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin user info --uid testid
{
    ...
    "default_placement": "",
    "default_storage_class": "",
    "placement_tags": [],
    ...
}
</screen>
    <para>
     Wenn das Platzierungsziel einer Zonengruppe Tags enthält, können die Benutzer nur dann Buckets mit diesem Platzierungsziel erstellen, wenn ihre Benutzerinformationen mindestens ein passendes Tag im Feld „placement_tags“ umfassen. Damit ist es möglich, den Zugriff auf bestimmte Speichertypen einzuschränken.
    </para>
    <para>
     Diese Felder können nicht direkt mit dem Kommando <command>radosgw-admin</command> bearbeitet werden. Sie müssen das JSON-Format daher manuell bearbeiten:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin metadata get user:<replaceable>USER-ID</replaceable> &gt; user.json
<prompt>tux &gt; </prompt>vi user.json     # edit the file as required
<prompt>cephuser@adm &gt; </prompt>radosgw-admin metadata put user:<replaceable>USER-ID</replaceable> &lt; user.json
</screen>
   </sect3>
   <sect3 xml:id="s3-bucket-default-placement">
    <title>Bearbeiten der standardmäßigen S3-Bucket-Platzierung</title>
    <para>
     Wird ein Bucket mit dem S3-Protokoll erstellt, kann ein Platzierungsziel als Teil von <option>LocationConstraint</option> angegeben werden, sodass die standardmäßigen Platzierungsziele des Benutzers und der Zonengruppe überschrieben werden.
    </para>
    <para>
     In der Regel muss <option>LocationConstraint</option> mit <option>api_name</option> der Zonengruppe übereinstimmen:
    </para>
<screen>&lt;LocationConstraint&gt;default&lt;/LocationConstraint&gt;</screen>
    <para>
     Sie können nach <option>api_name</option> einen Doppelpunkt und ein benutzerdefiniertes Platzierungsziel einfügen:
    </para>
<screen>&lt;LocationConstraint&gt;default:new-placement&lt;/LocationConstraint&gt;</screen>
   </sect3>
   <sect3 xml:id="swift-default-bucket-placement">
    <title>Bearbeiten der Swift-Bucket-Platzierung</title>
    <para>
     Wird ein Bucket mit dem Swift-Protokoll erstellt, können Sie ein Platzierungsziel im HTTP-Header unter <literal>X-Storage-Policy</literal> angeben:
    </para>
<screen>X-Storage-Policy: <replaceable>NEW-PLACEMENT</replaceable></screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ogw-storage-classes-usage">
   <title>Verwenden von Speicherklassen</title>
   <para>
    Alle Platzierungsziele umfassen eine Speicherklasse <option>STANDARD</option>, die standardmäßig auf neue Objekte angewendet wird. Diesen Standardwert können Sie mit <literal>default_storage_class</literal> überschreiben.
   </para>
   <para>
    Soll ein Objekt in einer nicht standardmäßigen Speicherklasse erstellt werden, geben Sie den Namen dieser Speicherklasse in einem HTTP-Header in der Anforderung an. Das S3-Protokoll greift auf den Header <literal>X-Amz-Storage-Class</literal> zurück, das Swift-Protokoll dagegen auf den Header <literal>X-Object-Storage-Class</literal>.
   </para>
   <para>
    In <emphasis>S3 Object Lifecycle Management</emphasis> können Sie Objektdaten zwischen Speicherklassen mithilfe von <option>Transition</option>-Aktionen verschieben.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="ceph-rgw-fed">
  <title>Object Gateways an mehreren Standorten</title>

  <para>
   Ceph unterstützt verschiedene Optionen zur Konfiguration für mehrere Standorte für das Ceph Object Gateway:
  </para>

  <variablelist>
   <varlistentry>
    <term>Mehrere Zonen</term>
    <listitem>
     <para>
      Eine Konfiguration, die aus einer Zonengruppe und mehreren Zonen besteht, jede Zone mit einer oder mehreren <systemitem class="daemon">ceph-radosgw</systemitem>-Instanzen. Jede Zone wird durch einen eigenen Ceph Storage Cluster unterstützt. Mehrere Zonen in einer Zonengruppe bieten eine Disaster Recovery für die Zonengruppe, wenn in einer der Zonen ein erheblicher Fehler auftritt. Jede Zone ist aktiv und kann Schreibvorgänge empfangen. Neben der Disaster Recovery können mehrere aktive Zonen auch als Grundlage für Content Delivery Networks dienen.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mehrfach-Zonengruppe</term>
    <listitem>
     <para>
      Ceph Object Gateway unterstützt mehrere Zonengruppen, jede Zonengruppe mit einer oder mehreren Zonen. Objekte, die in Zonen in einer Zonengruppe innerhalb desselben Bereichs wie eine andere Zonengruppe gespeichert sind, teilen sich einen globalen Objekt-Namespace, wodurch eindeutige Objekt-IDs über Zonengruppen und Zonen hinweg gewährleistet werden.
     </para>
     <note>
      <para>
       Es ist wichtig, zu beachten, dass Zonengruppen Metadaten <emphasis>nur</emphasis> untereinander synchronisieren. Daten und Metadaten werden zwischen den Zonen innerhalb der Zonengruppe repliziert. Es werden keine Daten oder Metadaten über einen Bereich hinweg gemeinsam genutzt.
      </para>
     </note>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Mehrere Bereiche</term>
    <listitem>
     <para>
      Ceph Object Gateway unterstützt das Konzept der Bereiche; ein global eindeutiger Namespace. Es werden mehrere Bereiche unterstützt, die einzelne oder mehrere Zonengruppen umfassen können.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Sie können jedes Object Gateway so konfigurieren, dass es in einer Aktiv/Aktiv-Zonenkonfiguration arbeitet und Schreibvorgänge in Nicht-Master-Zonen zulässt. Die Konfiguration für mehrere Standorte wird in einem Container gespeichert, der Bereich genannt wird. Der Bereich speichert Zonengruppen, Zonen und einen Zeitraum mit mehreren Epochen zur Verfolgung von Änderungen an der Konfiguration. Die <systemitem class="daemon">rgw</systemitem>-Daemons übernehmen die Synchronisierung, so dass kein separater Synchronisierungsagent erforderlich ist. Dieser Ansatz zur Synchronisierung ermöglicht es dem Ceph Object Gateway, mit einer Aktiv/Aktiv-Konfiguration anstelle von Aktiv/Passiv zu arbeiten.
  </para>

  <sect2 xml:id="ceph-rgw-multi-req-assump">
   <title>Anforderungen und Annahmen</title>
   <para>
    Für eine Konfiguration für mehrere Standorte sind mindestens zwei Ceph-Speichercluster erforderlich sowie mindestens zwei Ceph Object-Gateway-Instanzen, eine für jeden Ceph-Speichercluster. Die folgende Konfiguration setzt voraus, dass sich mindestens zwei Ceph-Speichercluster an geografisch getrennten Standorten befinden. Die Konfiguration kann jedoch am gleichen Standort funktionieren. Zum Beispiel mit den Namen <literal>rgw1</literal> und <literal>rgw2</literal>.
   </para>
   <para>
    Für eine Konfiguration für mehrere Standorte sind eine Master-Zonengruppe und eine Master-Zone erforderlich. Eine Master-Zone ist die Quelle der Wahrheit in Bezug auf alle Metadatenoperationen in einem Cluster mit mehreren Standorten. Zusätzlich benötigt jede Zonengruppe eine Master-Zone. Zonengruppen können eine oder mehrere Neben- oder Nicht-Master-Zonen umfassen. In dieser Anleitung dient der Host <literal>rgw1</literal> als Master-Zone der Master-Zonengruppe und der Host <literal>rgw2</literal> als sekundäre Zone der Master-Zonengruppe.
   </para>
  </sect2>

  <sect2 xml:id="ceph-rgw-config-master-zone">
   <title>Konfigurieren einer Master-Zone</title>
   <para>
    Alle Gateways in einer Konfiguration für mehrere Standorte rufen ihre Konfiguration von einem <systemitem class="daemon">ceph-radosgw</systemitem>-Daemon auf einem Host innerhalb der Master-Zonengruppe und der Master-Zone ab. Wählen Sie zur Konfiguration Ihrer Gateways in einer Konfiguration für mehrere Standorte eine <systemitem class="daemon">ceph-radosgw</systemitem>-Instanz aus, um die Master-Zonengruppe und die Master-Zone zu konfigurieren.
   </para>
   <sect3 xml:id="ceph-rgw-fed-realm">
    <title>Erstellen eines Bereichs</title>
    <para>
     Ein Bereich stellt einen global eindeutigen Namespace dar, der aus einer oder mehreren Zonengruppen mit einer oder mehreren Zonen besteht. Zonen enthalten Buckets, die ihrerseits Objekte enthalten. Durch einen Bereich kann das Ceph Object Gateway mehrere Namespaces und deren Konfiguration auf derselben Hardware unterstützen. Ein Bereich umfasst das Konzept von Zeiträumen. Jeder Zeitraum stellt den Zustand der Zonengruppe und der Zonenkonfiguration in der Zeit dar. Jedes Mal, wenn Sie eine Änderung an einer Zonengruppe oder Zone vornehmen, müssen Sie den Zeitraum aktualisieren und bestätigen. Standardmäßig erstellt das Ceph Object Gateway aus Gründen der Abwärtskompatibilität keinen Bereich. Als bewährtes Verfahren empfehlen wir, Bereiche für neue Cluster zu erstellen.
    </para>
    <para>
     Erstellen Sie einen neuen Bereich namens <literal>Gold</literal> für die Konfiguration für mehrere Standorte. Öffnen Sie dazu eine Kommandozeilenschnittstelle auf einem Host, der für die Master-Zonengruppe und -Zone identifiziert wurde. Führen Sie dann folgendes Kommando aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin realm create --rgw-realm=gold --default</screen>
    <para>
     Wenn der Cluster einen einzigen Bereich umfasst, geben Sie das Flag <option>--default</option> an. Wenn <option>‑‑default</option> angegeben wird, verwendet <command>radosgw-admin</command> standardmäßig diesen Bereich. Wenn <option>‑‑default</option> nicht angegeben ist, muss beim Hinzufügen von Zonengruppen und Zonen entweder das Flag <option>--rgw-realm</option> oder das Flag <option>--realm-id</option> angegeben werden, um den Bereich zu identifizieren.
    </para>
    <para>
     Nach dem Erstellen des Bereichs gibt <command>radosgw-admin</command> die Bereichskonfiguration zurück:
    </para>
<screen>
{
  "id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "name": "gold",
  "current_period": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "epoch": 1
}</screen>
    <note>
     <para>
      Ceph generiert eine eindeutige ID für den Bereich, die bei Bedarf die Umbenennung eines Bereichs ermöglicht.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-createmasterzonegrp">
    <title>Erstellen einer Master-Zonengruppe</title>
    <para>
     Ein Bereich muss mindestens eine Zonengruppe enthalten, die als Master-Zonengruppe für den Bereich dient. Erstellen Sie eine neue Master-Zonengruppe für die Konfiguration für mehrere Standorte. Öffnen Sie dazu eine Kommandozeilenschnittstelle auf einem Host, der für die Master-Zonengruppe und -Zone identifiziert wurde. Erstellen Sie mit folgendem Kommando eine Master-Zonengruppe mit dem Namen <literal>us</literal>:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup create --rgw-zonegroup=us \
--endpoints=http://rgw1:80 --master --default</screen>
    <para>
     Wenn der Bereich eine einzige Zonengruppe umfasst, geben Sie das Flag <option>--default</option> an. Wenn <option>--default</option> angegeben ist, verwendet <command>radosgw-admin</command> beim Hinzufügen neuer Zonen standardmäßig diese Zonengruppe. Wenn <option>--default</option> nicht angegeben ist, muss beim Hinzufügen von Zonen entweder das Flag <option>--rgw-zonegroup</option> oder das Flag <option>--zonegroup-id</option> angegeben werden, um den Bereich zu identifizieren.
    </para>
    <para>
     Nach dem Erstellen der Master-Zonengruppe gibt <command>radosgw-admin</command> die Zonengruppenkonfiguration zurück. Beispiel:
    </para>
<screen>{
 "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
 "name": "us",
 "api_name": "us",
 "is_master": "true",
 "endpoints": [
     "http:\/\/rgw1:80"
 ],
 "hostnames": [],
 "hostnames_s3website": [],
 "master_zone": "",
 "zones": [],
 "placement_targets": [],
 "default_placement": "",
 "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
}</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone">
    <title>Erstellen einer Master-Zone</title>
    <important>
     <para>
      Zonen müssen auf einem Ceph Object-Gateway-Knoten erstellt werden, der sich innerhalb der Zone befindet.
     </para>
    </important>
    <para>
     Erstellen Sie eine neue Master-Zone für die Konfiguration für mehrere Standorte. Öffnen Sie dazu eine Kommandozeilenschnittstelle auf einem Host, der für die Master-Zonengruppe und -Zone identifiziert wurde. Führen Sie Folgendes aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --rgw-zone=us-east-1 \
--endpoints=http://rgw1:80 --access-key=<replaceable>SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>SYSTEM_SECRET_KEY</replaceable></screen>
    <note>
     <para>
      Die Optionen <option>--access-key</option> und <option>--secret</option> sind im obigen Beispiel nicht angegeben. Diese Einstellungen werden der Zone hinzugefügt, wenn im nächsten Abschnitt der Benutzer erstellt wird.
     </para>
    </note>
    <para>
     Nach dem Erstellen der Master-Zone gibt <command>radosgw-admin</command> die Zonenkonfiguration zurück. Beispiel:
    </para>
<screen>
  {
      "id": "56dfabbb-2f4e-4223-925e-de3c72de3866",
      "name": "us-east-1",
      "domain_root": "us-east-1.rgw.meta:root",
      "control_pool": "us-east-1.rgw.control",
      "gc_pool": "us-east-1.rgw.log:gc",
      "lc_pool": "us-east-1.rgw.log:lc",
      "log_pool": "us-east-1.rgw.log",
      "intent_log_pool": "us-east-1.rgw.log:intent",
      "usage_log_pool": "us-east-1.rgw.log:usage",
      "reshard_pool": "us-east-1.rgw.log:reshard",
      "user_keys_pool": "us-east-1.rgw.meta:users.keys",
      "user_email_pool": "us-east-1.rgw.meta:users.email",
      "user_swift_pool": "us-east-1.rgw.meta:users.swift",
      "user_uid_pool": "us-east-1.rgw.meta:users.uid",
      "otp_pool": "us-east-1.rgw.otp",
      "system_key": {
          "access_key": "1555b35654ad1656d804",
          "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
      },
      "placement_pools": [
          {
              "key": "us-east-1-placement",
              "val": {
                  "index_pool": "us-east-1.rgw.buckets.index",
                  "storage_classes": {
                      "STANDARD": {
                          "data_pool": "us-east-1.rgw.buckets.data"
                      }
                  },
                  "data_extra_pool": "us-east-1.rgw.buckets.non-ec",
                  "index_type": 0
              }
          }
      ],
      "metadata_heap": "",
      "realm_id": ""
  }</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-deldefzonegrp">
    <title>Löschen der Standardzone und -gruppe</title>
    <important>
     <para>
      Die folgenden Schritte gehen von einer Konfiguration für mehrere Standorte mit neu installierten Systemen aus, in denen noch keine Daten gespeichert sind. <emphasis role="bold">Löschen Sie nicht</emphasis> die Standardzone und ihre Pools, wenn Sie sie bereits zum Speichern von Daten verwenden. Ansonsten werden die Daten gelöscht und können nicht wiederhergestellt werden.
     </para>
    </important>
    <para>
     Die Standardinstallation von Object Gateway erstellt die Standard-Zonengruppe namens <literal>default</literal>. Löschen Sie die Standardzone, falls sie vorhanden ist. Stellen Sie sicher, dass Sie sie zuerst aus der Standard-Zonengruppe entfernen.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup delete --rgw-zonegroup=default</screen>
    <para>
     Löschen Sie die Standard-Pools in Ihrem Ceph-Speichercluster, falls sie vorhanden sind:
    </para>
    <important>
     <para>
      Im folgenden Schritt wird von einer Konfiguration für mehrere Standorte mit neu installierten Systemen ausgegangen, in denen aktuell noch keine Daten gespeichert sind. <emphasis role="bold">Löschen Sie nicht</emphasis> die Standard-Zonengruppe, wenn Sie sie bereits zum Speichern von Daten verwenden.
     </para>
    </important>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.control default.rgw.control --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.data.root default.rgw.data.root --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.gc default.rgw.gc --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.log default.rgw.log --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.meta default.rgw.meta --yes-i-really-really-mean-it</screen>
    <warning>
     <para>
      Wenn Sie die Standard-Zonengruppe löschen, löschen Sie auch den Systembenutzer. Wenn Ihre Admin-Benutzerschlüssel nicht verteilt sind, schlägt die Object-Gateway-Verwaltungsfunktion des Ceph Dashboards fehl. Wenn Sie mit diesem Schritt fortfahren, machen Sie mit dem nächsten Abschnitt zum Neuerstellen des Systembenutzers weiter.
     </para>
    </warning>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone-createuser">
    <title>Erstellen von Systembenutzern</title>
    <para>
     Die <systemitem class="daemon">ceph-radosgw</systemitem>-Daemons müssen sich authentifizieren, bevor sie Bereichs- und Zeitrauminformationen abrufen. Erstellen Sie in der Master-Zone einen Systembenutzer, um die Authentifizierung zwischen den Daemons zu vereinfachen:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin user create --uid=zone.user \
--display-name="Zone User" --access-key=<replaceable>SYSTEM_ACCESS_KEY</replaceable> \
--secret=<replaceable>SYSTEM_SECRET_KEY</replaceable> --system</screen>
    <para>
     Notieren Sie sich den <option>access_key</option> und den <option>secret_key</option>, da die sekundären Zonen sie zur Authentifizierung bei der Master-Zone benötigen.
    </para>
    <para>
     Fügen Sie den Systembenutzer zur Master-Zone hinzu:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zone=us-east-1 \
--access-key=<replaceable>ACCESS-KEY</replaceable> --secret=<replaceable>SECRET</replaceable></screen>
    <para>
     Aktualisieren Sie die Periode, damit die Änderungen wirksam werden:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone-updateperiod">
    <title>Aktualisieren Sie den Zeitraum mit</title>
    <para>
     Aktualisieren Sie nach der Aktualisierung der Master-Zonenkonfiguration den Zeitraum:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
    <para>
     Nach dem Aktualisieren des Zeitraums gibt <command>radosgw-admin</command> die Zeitraumkonfiguration zurück. Beispiel:
    </para>
<screen>{
  "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "epoch": 1, "predecessor_uuid": "", "sync_status": [], "period_map":
  {
    "id": "09559832-67a4-4101-8b3f-10dfcd6b2707", "zonegroups": [], "short_zone_ids": []
  }, "master_zonegroup": "", "master_zone": "", "period_config":
  {
     "bucket_quota": {
     "enabled": false, "max_size_kb": -1, "max_objects": -1
     }, "user_quota": {
       "enabled": false, "max_size_kb": -1, "max_objects": -1
     }
  }, "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7", "realm_name": "gold", "realm_epoch": 1
}</screen>
    <note>
     <para>
      Durch Aktualisieren des Zeitraums wird die Epoche geändert und sichergestellt, dass andere Zonen die aktualisierte Konfiguration erhalten.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-masterzone-startrgw">
    <title>Starten des Gateways</title>
    <para>
     Starten und aktivieren Sie den Ceph Object-Gateway-Service auf dem Object-Gateway-Host. Ermitteln Sie mit dem Kommando <command>ceph fsid</command> die eindeutige FSID des Clusters. Ermitteln Sie den Namen des Object-Gateway-Daemons mit dem Kommando <command>ceph orch ps --hostname <replaceable>HOSTNAME</replaceable></command>.
    </para>
<screen><prompt>cephuser@ogw &gt; </prompt>systemctl start ceph-<replaceable>FSID</replaceable>@<replaceable>DAEMON_NAME</replaceable>
<prompt>cephuser@ogw &gt; </prompt>systemctl enable ceph-<replaceable>FSID</replaceable>@<replaceable>DAEMON_NAME</replaceable></screen>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-config-secondaryzone">
   <title>Konfigurieren sekundärer Zonen</title>
   <para>
    In den Zonen einer Zonengruppe werden alle Daten reproduziert, sodass gewährleistet ist, dass alle Zonen dieselben Daten umfassen. Beim Erstellen der sekundären Zone führen Sie alle nachfolgenden Operationen auf einem Host aus, der für die sekundäre Zone vorgesehen ist.
   </para>
   <note>
    <para>
     Gehen Sie zum Hinzufügen einer dritten Zone genauso vor wie beim Hinzufügen der zweiten Zone. Verwenden Sie einen anderen Zonennamen.
    </para>
   </note>
   <important>
    <para>
     Sie müssen Metadatenvorgänge, wie beispielsweise die Erstellung von Benutzern, auf einem Host innerhalb der Master-Zone ausführen. Die Master-Zone und die sekundäre Zone können Bucket-Vorgänge empfangen, doch die sekundäre Zone leitet Bucket-Vorgänge an die Master-Zone weiter. Wenn die Master-Zone inaktiv ist, schlagen Bucket-Vorgänge fehl.
    </para>
   </important>
   <sect3 xml:id="ceph-rgw-pull-realm">
    <title>Importieren des Bereichs</title>
    <para>
     Importieren Sie die Bereichskonfiguration mit dem URL-Pfad, dem Zugriffsschlüssel und dem Geheimnis der Masterzone in der Master-Zonengruppe auf den Host. Geben Sie zum Importieren eines nicht standardmäßigen Bereichs den Bereich mit den Konfigurationsoptionen <option>--rgw-realm</option> oder <option>--realm-id</option> an.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin realm pull --url=<replaceable>url-to-master-zone-gateway</replaceable> --access-key=<replaceable>access-key</replaceable> --secret=<replaceable>secret</replaceable></screen>
    <note>
     <para>
      Durch Importieren des Bereichs wird auch die aktuelle Zeitraumkonfiguration des entfernten Hosts abgerufen und zum aktuellen Zeitraum auch auf diesem Host gemacht.
     </para>
    </note>
    <para>
     Wenn dieser Bereich der Standardbereich oder der einzige Bereich ist, machen Sie den Bereich zum Standardbereich.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin realm default --rgw-realm=<replaceable>REALM-NAME</replaceable></screen>
   </sect3>
   <sect3 xml:id="cceph-rgw-create-secondaryzone">
    <title>Erstellen einer sekundären Zone</title>
    <para>
     Erstellen Sie eine neue sekundäre Zone für die Konfiguration für mehrere Standorte. Öffnen Sie dazu eine Kommandozeilenschnittstelle auf einem Host, der für die sekundäre Zone identifiziert wurde. Geben Sie die Zonengruppen-ID, den neuen Zonennamen und einen Endpunkt für die Zone an. <emphasis>Verwenden Sie nicht</emphasis> das Flag <option>--master</option>. Alle Zonen werden standardmäßig in einer Aktiv/Aktiv-Konfiguration ausgeführt. Wenn die sekundäre Zone keine Schreibvorgänge akzeptieren soll, geben Sie das Flag <option>--read-only</option> an. Dadurch wird eine Aktiv/Passiv-Konfiguration zwischen der Master-Zone und der sekundären Zone erstellt. Geben Sie zusätzlich den <option>access_key</option> und den <option>secret_key</option> des generierten Systembenutzers an, der in der Master-Zone der Master-Zonengruppe gespeichert ist. Führen Sie Folgendes aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=<replaceable>ZONE-GROUP-NAME</replaceable>\
                            --rgw-zone=<replaceable>ZONE-NAME</replaceable> --endpoints=<replaceable>URL</replaceable> \
                            --access-key=<replaceable>SYSTEM-KEY</replaceable> --secret=<replaceable>SECRET</replaceable>\
                            --endpoints=http://<replaceable>FQDN</replaceable>:80 \
                            [--read-only]</screen>
    <para>
     Beispiel:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone create --rgw-zonegroup=us --endpoints=http://rgw2:80 \
--rgw-zone=us-east-2 --access-key=<replaceable>SYSTEM_ACCESS_KEY</replaceable> --secret=<replaceable>SYSTEM_SECRET_KEY</replaceable>
{
  "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
  "name": "us-east-2",
  "domain_root": "us-east-2.rgw.data.root",
  "control_pool": "us-east-2.rgw.control",
  "gc_pool": "us-east-2.rgw.gc",
  "log_pool": "us-east-2.rgw.log",
  "intent_log_pool": "us-east-2.rgw.intent-log",
  "usage_log_pool": "us-east-2.rgw.usage",
  "user_keys_pool": "us-east-2.rgw.users.keys",
  "user_email_pool": "us-east-2.rgw.users.email",
  "user_swift_pool": "us-east-2.rgw.users.swift",
  "user_uid_pool": "us-east-2.rgw.users.uid",
  "system_key": {
      "access_key": "1555b35654ad1656d804",
      "secret_key": "h7GhxuBLTrlhVUyxSPUKUV8r\/2EI4ngqJxD7iBdBYLhwluN30JaT3Q=="
  },
  "placement_pools": [
      {
          "key": "default-placement",
          "val": {
              "index_pool": "us-east-2.rgw.buckets.index",
              "data_pool": "us-east-2.rgw.buckets.data",
              "data_extra_pool": "us-east-2.rgw.buckets.non-ec",
              "index_type": 0
          }
      }
  ],
  "metadata_heap": "us-east-2.rgw.meta",
  "realm_id": "815d74c2-80d6-4e63-8cfc-232037f7ff5c"
}</screen>
    <important>
     <para>
      Die folgenden Schritte gehen von einer Konfiguration für mehrere Standorte mit neu installierten Systemen aus, in denen noch keine Daten gespeichert sind. <emphasis role="bold">Löschen Sie nicht</emphasis> die Standardzone und ihre Pools, wenn Sie sie bereits zum Speichern von Daten verwenden. Andernfalls gehen die Daten verloren und können nicht wiederhergestellt werden.
     </para>
    </important>
    <para>
     Löschen Sie die Standardzone, falls erforderlich:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone rm --rgw-zone=default</screen>
    <para>
     Löschen Sie die Standard-Pools in Ihrem Ceph-Speichercluster, falls erforderlich:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.control default.rgw.control --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.data.root default.rgw.data.root --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.gc default.rgw.gc --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.log default.rgw.log --yes-i-really-really-mean-it
<prompt>cephuser@adm &gt; </prompt>ceph osd pool rm default.rgw.users.uid default.rgw.users.uid --yes-i-really-really-mean-it</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-secondzone-update-config">
    <title>Aktualisieren der Ceph-Konfigurationsdatei</title>
    <para>
     Aktualisieren Sie die Ceph-Konfigurationsdatei auf den Hosts der sekundären Zone. Fügen Sie dazu die Konfigurationsoption <literal>rgw_zone</literal> und den Namen der sekundären Zone zum Instanzeintrag hinzu.
    </para>
    <para>
     Führen Sie hierzu folgendes Kommando aus:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set <replaceable>SERVICE_NAME</replaceable> rgw_zone us-west</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-secondzone-updateperiod">
    <title>Aktualisieren des Zeitraums</title>
    <para>
     Aktualisieren Sie nach der Aktualisierung der Master-Zonenkonfiguration den Zeitraum:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit
{
  "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
  "epoch": 2,
  "predecessor_uuid": "09559832-67a4-4101-8b3f-10dfcd6b2707",
  "sync_status": [ "[...]"
  ],
  "period_map": {
      "id": "b5e4d3ec-2a62-4746-b479-4b2bc14b27d1",
      "zonegroups": [
          {
              "id": "d4018b8d-8c0d-4072-8919-608726fa369e",
              "name": "us",
              "api_name": "us",
              "is_master": "true",
              "endpoints": [
                  "http:\/\/rgw1:80"
              ],
              "hostnames": [],
              "hostnames_s3website": [],
              "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "zones": [
                  {
                      "id": "83859a9a-9901-4f00-aa6d-285c777e10f0",
                      "name": "us-east-1",
                      "endpoints": [
                          "http:\/\/rgw1:80"
                      ],
                      "log_meta": "true",
                      "log_data": "false",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  },
                  {
                      "id": "950c1a43-6836-41a2-a161-64777e07e8b8",
                      "name": "us-east-2",
                      "endpoints": [
                          "http:\/\/rgw2:80"
                      ],
                      "log_meta": "false",
                      "log_data": "true",
                      "bucket_index_max_shards": 0,
                      "read_only": "false"
                  }

              ],
              "placement_targets": [
                  {
                      "name": "default-placement",
                      "tags": []
                  }
              ],
              "default_placement": "default-placement",
              "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7"
          }
      ],
      "short_zone_ids": [
          {
              "key": "83859a9a-9901-4f00-aa6d-285c777e10f0",
              "val": 630926044
          },
          {
              "key": "950c1a43-6836-41a2-a161-64777e07e8b8",
              "val": 4276257543
          }

      ]
  },
  "master_zonegroup": "d4018b8d-8c0d-4072-8919-608726fa369e",
  "master_zone": "83859a9a-9901-4f00-aa6d-285c777e10f0",
  "period_config": {
      "bucket_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      },
      "user_quota": {
          "enabled": false,
          "max_size_kb": -1,
          "max_objects": -1
      }
  },
  "realm_id": "4a367026-bd8f-40ee-b486-8212482ddcd7",
  "realm_name": "gold",
  "realm_epoch": 2
}</screen>
    <note>
     <para>
      Durch Aktualisieren des Zeitraums wird die Epoche geändert und sichergestellt, dass andere Zonen die aktualisierte Konfiguration erhalten.
     </para>
    </note>
   </sect3>
   <sect3 xml:id="ceph-rgw-fed-secondzone-startrgw">
    <title>Starten des Object Gateways</title>
    <para>
     Starten und aktivieren Sie auf dem Object-Gateway-Host den Ceph Object-Gateway-Service:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch start rgw.us-east-2
</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-check-sync-status">
    <title>Prüfen des Synchronisierungsstatus</title>
    <para>
     Prüfen Sie den Synchronisierungsstatus, wenn die sekundäre Zone aktiv ist. Durch die Synchronisierung werden Benutzer und Buckets, die in der Master-Zone erstellt wurden, in die sekundäre Zone kopiert.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin sync status</screen>
    <para>
     Die Ausgabe gibt den Status der Synchronisierungsvorgänge an. Beispiel:
    </para>
<screen>realm f3239bc5-e1a8-4206-a81d-e1576480804d (gold)
    zonegroup c50dbb7e-d9ce-47cc-a8bb-97d9b399d388 (us)
         zone 4c453b70-4a16-4ce8-8185-1893b05d346e (us-west)
metadata sync syncing
              full sync: 0/64 shards
              metadata is caught up with master
              incremental sync: 64/64 shards
    data sync source: 1ee9da3e-114d-4ae3-a8a4-056e8a17f532 (us-east)
                      syncing
                      full sync: 0/128 shards
                      incremental sync: 128/128 shards
                      data is caught up with source</screen>
    <note>
     <para>
      Sekundäre Zonen akzeptieren zwar Bucket-Vorgänge, leiten allerdings Bucket-Vorgänge an die Master-Zone um. Dann synchronisieren sie sich mit der Master-Zone, um das Ergebnis der Bucket-Vorgänge zu erhalten. Wenn die Master-Zone inaktiv ist, schlagen Bucket-Vorgänge, die in der sekundären Zone ausgeführt werden, fehl. Objektvorgänge sollten jedoch erfolgreich sein.
     </para>
    </note>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-maintenance">
   <title>Allgemeine Objekt-Gateway-Wartung</title>
   <sect3 xml:id="ceph-rgw-check-sync">
    <title>Prüfen des Synchronisierungsstatus</title>
    <para>
     Informationen über den Reproduktionsstatus einer Zone können abgefragt werden mit:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin sync status
        realm b3bc1c37-9c44-4b89-a03b-04c269bea5da (gold)
    zonegroup f54f9b22-b4b6-4a0e-9211-fa6ac1693f49 (us)
         zone adce11c9-b8ed-4a90-8bc5-3fc029ff0816 (us-west)
        metadata sync syncing
              full sync: 0/64 shards
              incremental sync: 64/64 shards
              metadata is behind on 1 shards
              oldest incremental change not applied: 2017-03-22 10:20:00.0.881361s
data sync source: 341c2d81-4574-4d08-ab0f-5a2a7b168028 (us-east)
                  syncing
                  full sync: 0/128 shards
                  incremental sync: 128/128 shards
                  data is caught up with source
          source: 3b5d1a3f-3f27-4e4a-8f34-6072d4bb1275 (us-3)
                  syncing
                  full sync: 0/128 shards
                  incremental sync: 128/128 shards
                  data is caught up with source</screen>
   </sect3>
   <sect3 xml:id="ceph-rgw-metadata-master">
    <title>Ändern der Metadaten-Master-Zone</title>
    <important>
     <para>
      Seien Sie vorsichtig, wenn Sie die Zone ändern, die der Metadaten-Master ist. Wenn eine Zone die Synchronisierung der Metadaten mit der aktuellen Master-Zone noch nicht abgeschlossen hat, kann sie bei der Hochstufung zum Master keine verbleibenden Einträge mehr verarbeiten und diese Änderungen gehen verloren. Aus diesem Grund empfehlen wir, zu warten, bis der <command>radosgw-admin</command>-Synchronisierungsstatus einer Zone die Metadaten-Synchronisierung abgeschlossen hat, bevor sie zum Master hochgestuft wird. Ähnlich verhält es sich, wenn Änderungen an Metadaten von der aktuellen Master-Zone verarbeitet werden, während eine andere Zone zum Master hochgestuft wird. Diese Änderungen gehen wahrscheinlich verloren. Um dies zu vermeiden, empfehlen wir, alle Object-Gateway-Instanzen in der vorherigen Master-Zone herunterzufahren. Nach dem Hochstufen einer anderen Zone kann deren neuer Zeitraum mit <command>radosgw-admin</command> abgerufen werden und die Gateways können neu gestartet werden.
     </para>
    </important>
    <para>
     Führen Sie zum Hochstufen einer Zone (z. B. Zone <literal>us-west</literal> in der Zonengruppe <literal>us</literal>) zum Metadaten-Master folgende Kommandos für diese Zone aus:
    </para>
<screen><prompt>cephuser@ogw &gt; </prompt>radosgw-admin zone modify --rgw-zone=us-west --master
<prompt>cephuser@ogw &gt; </prompt>radosgw-admin zonegroup modify --rgw-zonegroup=us --master
<prompt>cephuser@ogw &gt; </prompt>radosgw-admin period update --commit</screen>
    <para>
     Dadurch wird ein neuer Zeitraum generiert, und die Object-Gateway-Instanzen in der Zone <literal>us-west</literal> senden diesen Zeitraum an andere Zonen.
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="ceph-rgw-failover-dr">
   <title>Durchführen von Failover und Disaster Recovery</title>
   <para>
    Falls die Master-Zone ausfällt, führen Sie zum Zweck eines Disaster Recovery ein Failover zur sekundären Zone durch.
   </para>
   <procedure>
    <step>
     <para>
      Machen Sie die sekundäre Zone zur Master- und Standardzone. Beispiel:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --master --default</screen>
     <para>
      Standardmäßig wird das Ceph Object Gateway in einer Aktiv/Aktiv-Konfiguration ausgeführt. Wenn der Cluster zur Ausführung in einer Aktiv/Passiv-Konfiguration konfiguriert wurde, ist die sekundäre Zone eine schreibgeschützte Zone. Entfernen Sie den Status <option>‑‑read-only</option>, damit die Zone Schreibvorgänge empfangen kann. Beispiel:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --master --default \
                                                   --read-only=false
</screen>
    </step>
    <step>
     <para>
      Aktualisieren Sie die Periode, damit die Änderungen wirksam werden:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
    </step>
    <step>
     <para>
      Starten Sie das Ceph Object Gateway neu:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch restart rgw</screen>
    </step>
   </procedure>
   <para>
    Wenn die frühere Master-Zone wiederhergestellt ist, setzen Sie die Operation zurück.
   </para>
   <procedure>
    <step>
     <para>
      Rufen Sie in der wiederhergestellten Zone den Zeitraum von der aktuellen Master-Zone ab.
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin realm pull --url=<replaceable>URL-TO-MASTER-ZONE-GATEWAY</replaceable> \
                           --access-key=<replaceable>ACCESS-KEY</replaceable> --secret=<replaceable>SECRET</replaceable>
</screen>
    </step>
    <step>
     <para>
      Machen Sie die wiederhergestellte Zone zur Master- und Standardzone:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --master --default</screen>
    </step>
    <step>
     <para>
      Aktualisieren Sie die Periode, damit die Änderungen wirksam werden:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
    </step>
    <step>
     <para>
      Starten Sie das Ceph Object Gateway in der wiederhergestellten Zone neu:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch restart rgw@rgw</screen>
    </step>
    <step>
     <para>
      Wenn die sekundäre Zone eine schreibgeschützte Konfiguration sein muss, aktualisieren Sie die sekundäre Zone:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify --rgw-zone=<replaceable>ZONE-NAME</replaceable> --read-only</screen>
    </step>
    <step>
     <para>
      Aktualisieren Sie die Periode, damit die Änderungen wirksam werden:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
    </step>
    <step>
     <para>
      Starten Sie das Ceph Object Gateway in der sekundären Zone neu:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch restart@rgw</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
</chapter>
