<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_monitoring_alerting.xml" version="5.0" xml:id="monitoring-alerting">
 <title>Monitoramento e alerta</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sim</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  No SUSE Enterprise Storage 7, o cephadm implanta uma pilha de monitoramento e alerta. Os usuários precisam definir os serviços (como Prometheus, Alertmanager e Grafana) que desejam implantar com o cephadm em um arquivo de configuração YAML ou eles podem usar a CLI para implantá-los. Quando vários serviços do mesmo tipo são implantados, uma configuração altamente disponível é implantada. O exportador de nós é uma exceção a essa regra.
 </para>
 <para>
  É possível usar o cephadm para implantar os seguintes serviços de monitoramento:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    <emphasis role="bold">Prometheus</emphasis> é o kit de ferramentas de monitoramento e alerta. Ele coleta os dados fornecidos pelos exportadores do Prometheus e dispara alertas pré-configurados se os limites predefinidos forem atingidos.
   </para>
  </listitem>
  <listitem>
   <para>
    O <emphasis role="bold">Alertmanager</emphasis> processa os alertas enviados pelo servidor Prometheus. Ele elimina a duplicação, agrupa e roteia os alertas para o receptor correto. Por padrão, o Ceph Dashboard será configurado automaticamente como o receptor.
   </para>
  </listitem>
  <listitem>
   <para>
    <emphasis role="bold">Grafana</emphasis> é o software de visualização e alerta. A funcionalidade de alerta do Grafana não é usada por esta pilha de monitoramento. Para alertas, o Alertmanager é usado.
   </para>
  </listitem>
  <listitem>
   <para>
    O <emphasis role="bold">exportador de nós</emphasis> do Prometheus é que fornece os dados sobre o nó em que ele está instalado. É recomendável instalar o exportador de nós em todos os nós.
   </para>
  </listitem>
 </itemizedlist>
 <para>
  O Módulo do Gerenciador do Prometheus inclui um exportador do Prometheus para transmitir os contadores de desempenho do Ceph do ponto de coleta no <literal>ceph-mgr</literal>.
 </para>
 <para>
  A configuração do Prometheus, incluindo os destinos de <emphasis>scrape</emphasis> (daemons que extraem métricas), é definida automaticamente pelo cephadm. O cephadm também implanta uma lista de alertas padrão, por exemplo, <literal>erro de saúde</literal>, <literal>10% dos OSDs inativos</literal> ou <literal>páginas inativas</literal>.
 </para>
 <para>
  Por padrão, o tráfego para o Grafana é criptografado com TLS. Você pode fornecer seu próprio certificado TLS ou usar um certificado autoassinado. Se nenhum certificado personalizado foi configurado antes da implantação do Grafana, um certificado autoassinado é criado e configurado automaticamente para o Grafana.
 </para>
 <para>
  É possível usar os seguintes comandos para configurar certificados personalizados para o Grafana:
 </para>
<screen>
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_key -i $PWD/key.pem
<prompt>cephuser@adm &gt; </prompt> ceph config-key set mgr/cephadm/grafana_crt -i $PWD/certificate.pem
  </screen>
 <para>
  O Alertmanager processa os alertas enviados pelo servidor Prometheus. Ele cuida da eliminação de duplicação, do agrupamento e do processamento deles para o receptor correto. É possível usar o Alertmanager para silenciar os alertas, mas as configurações de silenciamento também podem ser gerenciadas no Ceph Dashboard.
 </para>
 <para>
  Recomendamos que o <systemitem class="daemon">Exportador de nós</systemitem> seja implantado em todos os nós. Isso pode ser feito usando o arquivo <filename>monitoring.yaml</filename> com o tipo de serviço <literal>node-exporter</literal>. Consulte o <xref linkend="deploy-cephadm-day2-service-monitoring"/> para obter mais informações sobre como implantar serviços.
 </para>
 <sect1 xml:id="monitoring-custom-images">
  <title>Configurando imagens personalizadas ou locais</title>

  <tip>
   <para>
    Esta seção descreve como mudar a configuração das imagens de container usadas quando os serviços são implantados ou atualizados. Ela não inclui os comandos necessários para implantar ou reimplantar os serviços.
   </para>
   <para>
    O método recomendado para implantar a pilha de monitoramento é aplicando a respectiva especificação, conforme descrito no <xref linkend="deploy-cephadm-day2-service-monitoring"/>.
   </para>
  </tip>

  <para>
   Para implantar imagens de container personalizadas ou locais, elas precisam ser definidas no cephadm. Para fazer isso, você precisa executar o seguinte comando:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable> <replaceable>VALUE</replaceable></screen>

  <para>
   Em que <replaceable>OPTION_NAME</replaceable> é qualquer um dos seguintes nomes:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     container_image_prometheus
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_node_exporter
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_alertmanager
    </para>
   </listitem>
   <listitem>
    <para>
     container_image_grafana
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Se nenhuma opção for definida ou se a configuração for removida, as seguintes imagens serão usadas como <replaceable>VALUE</replaceable>:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-server:2.18.0
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-node-exporter:0.18.1
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/caasp/v4.5/prometheus-alertmanager:0.16.2
    </para>
   </listitem>
   <listitem>
    <para>
     registry.suse.com/ses/7/ceph/grafana:7.0.3
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Por exemplo:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/container_image_prometheus prom/prometheus:v1.4.1</screen>

  <note>
   <para>
    Ao definir uma imagem personalizada, o valor padrão será anulado (mas não sobregravado). O valor padrão muda quando as atualizações ficam disponíveis. Ao definir uma imagem personalizada, você não poderá atualizar o componente para o qual definiu a imagem personalizada automaticamente. Você precisará atualizar manualmente a configuração (nome e tag da imagem) para poder instalar as atualizações.
   </para>
   <para>
    Em vez disso, se você seguir as recomendações, poderá redefinir a imagem personalizada. Após esse procedimento, o valor padrão será usado novamente. Use <command>ceph config rm</command> para redefinir a opção de configuração:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/<replaceable>OPTION_NAME</replaceable></screen>
   <para>
    Por exemplo:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config rm mgr mgr/cephadm/container_image_prometheus</screen>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-applying-updates">
  <title>Atualizando os serviços de monitoramento</title>

  <para>
   Conforme mencionado na <xref linkend="monitoring-custom-images"/>, o cephadm é fornecido com os URLs das imagens de container recomendadas e testadas, e eles são usados por padrão.
  </para>

  <para>
   Quando há atualizações dos pacotes do Ceph, novas versões desses URLs podem ser fornecidas. Isso apenas atualiza o local de onde as imagens de container são extraídas, mas não atualiza os serviços.
  </para>

  <para>
   Depois que os URLs para as novas imagens de container forem atualizados, seja manualmente (conforme descrito na <xref linkend="monitoring-custom-images"/>) ou automaticamente por meio de uma atualização do pacote do Ceph, os serviços de monitoramento poderão ser atualizados.
  </para>

  <para>
   Para fazer isso, use <command>ceph orch redeploy</command> da seguinte maneira:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy prometheus
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph orch redeploy grafana
</screen>

  <para>
   Atualmente, não existe um único comando para atualizar todos os serviços de monitoramento. A ordem em que esses serviços são atualizados não é importante.
  </para>

  <note>
   <para>
    Se você usar imagens de container personalizadas, os URLs especificados para os serviços de monitoramento não serão automaticamente modificados se os pacotes do Ceph forem atualizados. Se você especificou imagens de container personalizadas, precisa especificar os URLs das novas imagens de container manualmente. Esse poderá ser o caso se você usar um registro de container local.
   </para>
   <para>
    Você encontra os URLs das imagens de container recomendadas para uso na seção <xref linkend="monitoring-custom-images"/>.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="monitoring-stack-disable">
  <title>Desabilitando o monitoramento</title>

  <para>
   Para desabilitar a pilha de monitoramento, execute os seguintes comandos:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch rm grafana
<prompt>cephuser@adm &gt; </prompt>ceph orch rm prometheus --force   # this will delete metrics data collected so far
<prompt>cephuser@adm &gt; </prompt>ceph orch rm node-exporter
<prompt>cephuser@adm &gt; </prompt>ceph orch rm alertmanager
<prompt>cephuser@adm &gt; </prompt>ceph mgr module disable prometheus
      </screen>
 </sect1>
 <sect1 xml:id="monitoring-grafana-config">
  <title>Configurando o Grafana</title>

  <para>
   O back end do Ceph Dashboard requer que o URL do Grafana possa verificar a existência de Grafana Dashboards antes mesmo de serem carregados pelo front end. Devido à natureza da implementação do Grafana no Ceph Dashboard, isso significa que duas conexões de trabalho são necessárias para poder ver os gráficos do Grafana no Ceph Dashboard:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     O back end (módulo MGR do Ceph) precisa verificar a existência do gráfico solicitado. Se essa solicitação for bem-sucedida, ela informará ao front end que ele pode acessar o Grafana com segurança.
    </para>
   </listitem>
   <listitem>
    <para>
     Em seguida, o front end solicita os gráficos do Grafana diretamente do browser do usuário usando um <literal>iframe</literal>. A instância do Grafana é acessada diretamente sem qualquer desvio pelo Ceph Dashboard.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Agora, talvez seja o caso de o seu ambiente dificultar o acesso direto do browser do usuário ao URL configurado no Ceph Dashboard. Para resolver esse problema, é possível configurar um URL separado que será usado exclusivamente para informar ao front end (o browser do usuário) qual URL ele deve usar para acessar o Grafana.
  </para>

  <para>
   Para mudar o URL que é retornado ao front end, execute o seguinte comando:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph dashboard set-grafana-frontend-api-url <replaceable>GRAFANA-SERVER-URL</replaceable></screen>

  <para>
   Se nenhum valor for definido para essa opção, ela simplesmente retornará para o valor da opção <replaceable>GRAFANA_API_URL</replaceable>, que é definida automaticamente e atualizada com frequência pelo cephadm. Se definida, ela instruirá o browser a usar esse URL para acessar o Grafana.
  </para>
 </sect1>
 <sect1 xml:id="monitoring-cephadm-config">
  <title>Configurando o módulo do gerenciador do Prometheus</title>

  <para>
   O Módulo do Gerenciador do Prometheus é um módulo do Ceph que estende a funcionalidade do Ceph. O módulo lê os (meta)dados do Ceph sobre seu estado e saúde, fornecendo os dados (extraídos) em um formato consumível pelo Prometheus.
  </para>

  <note>
   <para>
    O Módulo do Gerenciador do Prometheus precisa ser reiniciado para que as mudanças de configuração sejam aplicadas.
   </para>
  </note>

  <sect2 xml:id="monitoring-http-requests">
   <title>Configurando a interface de rede</title>
   <para>
    Por padrão, o Módulo do Gerenciador do Prometheus aceita solicitações HTTP na porta 9283 em todos os endereços IPv4 e IPv6 no host. A porta e o endereço de escuta podem ser configurados usando o <option>ceph config-key set</option>, com as chaves <option>mgr/prometheus/server_addr</option> e <option>mgr/prometheus/server_port</option>. Essa porta está registrada no registro do Prometheus.
   </para>
   <para>
    Para atualizar o <literal>server_addr</literal>, execute o seguinte comando:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_addr <replaceable>0.0.0.0</replaceable>
      </screen>
   <para>
    Para atualizar o <literal>server_port</literal>, execute o seguinte comando:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/server_port <replaceable>9283</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-scrape-intervals">
   <title>Configurando o <literal>scrape_interval</literal></title>
   <para>
    Por padrão, o Módulo do Gerenciador do Prometheus está configurado com um intervalo de extração de 15 segundos. Não é recomendável usar um intervalo de extração abaixo de 10 segundos. Para definir um intervalo de extração diferente no módulo do Prometheus, defina <literal>scrape_interval</literal> com o valor desejado:
   </para>
   <important>
    <para>
     Para funcionar corretamente e não causar problemas, o <literal>scrape_interval</literal> desse módulo deve ser definido sempre com o mesmo valor do intervalo de extração do Prometheus. 
    </para>
   </important>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/scrape_interval <replaceable>15</replaceable>
      </screen>
  </sect2>

  <sect2 xml:id="monitoring-stale-cache">
   <title>Configurando o cache</title>
   <para>
    Em clusters grandes (mais de 1.000 OSDs), o tempo para buscar as métricas pode aumentar significativamente. Sem o cache, o Módulo do Gerenciador do Prometheus pode sobrecarregar o gerenciador e fazer com que as instâncias do Ceph Manager não respondam ou travem. Como resultado, o cache é habilitado por padrão e não pode ser desabilitado, mas isso significa que o cache pode se tornar obsoleto. O cache é considerado obsoleto quando o tempo para buscar as métricas do Ceph excede o <literal>scrape_interval</literal> configurado.
   </para>
   <para>
    Se esse for o caso, um aviso será registrado e o módulo:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Responderá com um código de status HTTP 503 (serviço não disponível).
     </para>
    </listitem>
    <listitem>
     <para>
      Retornará o conteúdo do cache, mesmo que ele seja obsoleto.
     </para>
    </listitem>
   </itemizedlist>
   <para>
    Esse comportamento pode ser configurado usando os comandos <command>ceph config set</command>.
   </para>
   <para>
    Para instruir o módulo a responder com dados possivelmente obsoletos, defina-o como <literal>return</literal>:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy return</screen>
   <para>
    Para instruir o módulo a responder com <literal>serviço não disponível</literal>, defina-o como <literal>fail</literal>:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/stale_cache_strategy fail</screen>
  </sect2>

  <sect2 xml:id="monitoring-rbd-image">
   <title>Habilitando o monitoramento de imagens RBD</title>
   <para>
    O Módulo do Gerenciador do Prometheus pode coletar estatísticas de E/S por imagem RBD habilitando contadores de desempenho OSD dinâmicos. As estatísticas são coletadas de todas as imagens nos pools especificados no parâmetro de configuração <literal>mgr/prometheus/rbd_stats_pools</literal>.
   </para>
   <para>
    O parâmetro é uma lista separada por vírgulas ou espaços de entradas <literal>pool[/namespace]</literal>. Se o namespace não for especificado, as estatísticas serão coletadas para todos os namespaces no pool.
   </para>
   <para>
    Por exemplo:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools "<replaceable>pool1,pool2,poolN</replaceable>"
      </screen>
   <para>
    O módulo explora os pools e namespaces especificados, cria uma lista de todas as imagens disponíveis e a atualiza periodicamente. É possível configurar o intervalo usando o parâmetro <literal>mgr/prometheus/rbd_stats_pools_refresh_interval</literal> (em segundos). O padrão é 300 segundos (cinco minutos).
   </para>
   <para>
    Por exemplo, se você mudou o intervalo de sincronização para 10 minutos:
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/prometheus/rbd_stats_pools_refresh_interval <replaceable>600</replaceable>
      </screen>
  </sect2>
 </sect1>
 <sect1 xml:id="prometheus-security-model">
  <title>Modelo de segurança do Prometheus</title>

  <para>
   O modelo de segurança do Prometheus presume que os usuários não confiáveis têm acesso ao endpoint HTTP e aos registros do Prometheus. Os usuários não confiáveis têm acesso a todos os (meta)dados que o Prometheus coleta que estão contidos no banco de dados, além de uma variedade de informações operacionais e de depuração.
  </para>

  <para>
   No entanto, a API HTTP do Prometheus é limitada a operações apenas leitura. As configurações não podem ser mudadas usando a API, e os segredos não são expostos. Além disso, o Prometheus tem algumas medidas incorporadas para mitigar o impacto dos ataques de negação de serviço.
  </para>
 </sect1>
 <sect1 xml:id="prometheus-webhook-snmp">
  <title>Webhook SNMP do Alertmanager do Prometheus</title>

  <para>
   Para ser notificado sobre alertas do Prometheus por meio de detecções de SNMP, você pode instalar o webhook SNMP do Alertmanager do Prometheus por meio do cephadm. Para fazer isso, você precisa criar um arquivo de especificação de serviço e posicionamento com o seguinte conteúdo:
  </para>

  <note>
   <para>
    Para obter mais informações sobre arquivos de serviço e posicionamento, consulte o <xref linkend="cephadm-service-and-placement-specs"/>.
   </para>
  </note>

<screen>
service_type: container
service_id: prometheus-webhook-snmp
placement:
    <replaceable>ADD_PLACEMENT_HERE</replaceable>
image: registry.suse.com/ses/7/prometheus-webhook-snmp:latest
args:
    - "--publish 9099:9099"
envs:
    - ARGS="--debug --snmp-host=<replaceable>ADD_HOST_GATEWAY_HERE</replaceable>"
    - RUN_ARGS="--metrics"
EOF
</screen>

  <para>
   Use essa especificação de serviço para executar o serviço com as configurações padrão.
  </para>

  <para>
   Você precisa publicar a porta de escuta do receptor do Prometheus usando o argumento de linha de comando <literal>--publish <replaceable>HOST_PORT</replaceable>:<replaceable>CONTAINER_PORT</replaceable></literal> ao executar o serviço, porque o container não a expõe automaticamente. Para fazer isso, adicione as seguintes linhas à especificação:
  </para>

<screen>
args:
    - "--publish 9099:9099"
</screen>

  <para>
   Se preferir, conecte o container à rede do host usando o argumento da linha de comando <literal>‑‑network=host</literal>.
  </para>

<screen>
args:
    - "--network=host"
</screen>

  <para>
   Se o receptor de detecção de SNMP não estiver instalado no mesmo host que o container, você também deverá especificar o FQDN do host SNMP. Use o gateway de rede do container para receber detecções de SNMP fora do container/host:
  </para>

<screen>
envs:
    - ARGS="--debug --snmp-host=<replaceable>CONTAINER_GATEWAY</replaceable>"
</screen>

  <sect2 xml:id="configure-prometheus-webhook-snmp">
   <title>Configurando o serviço  <literal>prometheus-webhook-snmp</literal></title>
   <para>
    É possível configurar o container usando variáveis de ambiente ou um arquivo de configuração.
   </para>
   <para>
    No caso das variáveis de ambiente, use <literal>ARGS</literal> para definir as opções globais e <literal>RUN_ARGS</literal> para as opções do comando <command>run</command>. Você precisa adaptar a especificação de serviço da seguinte maneira:
   </para>
<screen>
envs:
    - ARGS="--debug --snmp-host=<replaceable>CONTAINER_GATEWAY</replaceable>"
    - RUN_ARGS="--metrics --port=9101"
</screen>
   <para>
    Para usar um arquivo de configuração, a especificação de serviço deve ser adaptada da seguinte maneira:
   </para>
<screen>
files:
    etc/prometheus-webhook-snmp.conf:
        - "debug: True"
        - "snmp_host: <replaceable>ADD_HOST_GATEWAY_HERE</replaceable>"
        - "metrics: True"
volume_mounts:
    etc/prometheus-webhook-snmp.conf: /etc/prometheus-webhook-snmp.conf
</screen>
   <para>
    Para implantação, execute o seguinte comando:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>SERVICE_SPEC_FILE</replaceable></screen>
   <para>
    Consulte o <xref linkend="deploy-cephadm-day2-services"/> para obter mais informações.
   </para>
  </sect2>

  <sect2 xml:id="configure-prometheus-alertmanager-for-snmp">
   <title>Configurando o Alertmanager do Prometheus para SNMP</title>
   <para>
    Por fim, o Alertmanager do Prometheus precisa ser configurado especificamente para as detecções de SNMP. Se esse serviço ainda não foi implantado, crie um arquivo de especificação de serviço. Você precisa substituir <literal>IP_OR_FQDN</literal> pelo endereço IP ou FQDN do host em que o webhook SNMP do Alertmanager do Prometheus foi instalado. Por exemplo:
   </para>
   <note>
    <para>
     Se você já implantou esse serviço, para garantir que o Alertmanager esteja configurado corretamente para SNMP, reimplante-o com as configurações a seguir.
    </para>
   </note>
<screen>
  service_type: alertmanager
  placement:
    hosts:
    - <replaceable>HOSTNAME</replaceable>
  webhook_configs:
    - 'http://<replaceable>IP_OR_FQDN</replaceable>:9099/'
</screen>
   <para>
    Aplique a especificação de serviço com o seguinte comando:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>SERVICE_SPEC_FILE</replaceable></screen>
  </sect2>
 </sect1>
</chapter>
