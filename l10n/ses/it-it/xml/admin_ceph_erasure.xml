<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_erasure.xml" version="5.0" xml:id="cha-ceph-erasure">
 <title>Pool con codice di cancellazione</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sì</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Ceph fornisce un'alternativa alla replica normale dei dati nei pool
  denominata pool <emphasis>di cancellazione</emphasis> o <emphasis>con codice
  di cancellazione</emphasis>. I pool di cancellazione non forniscono le
  funzionalità complete dei pool <emphasis>replicati</emphasis> (ad esempio,
  non sono in grado di memorizzare i metadati dei pool RBD), ma richiedono meno
  spazio di storage nominale. Un pool di cancellazione di default con 1 TB di
  storage di dati richiede 1,5 TB di spazio di storage nominale e prevede un
  solo errore del disco. Si tratta sicuramente di un vantaggio rispetto al pool
  replicato, che richiede 2 TB di spazio di storage nominale per lo stesso
  scopo.
 </para>
 <para>
  Per ulteriori informazioni sul codice di cancellazione, vedere
  <link xlink:href="https://en.wikipedia.org/wiki/Erasure_code"/>.
 </para>
 <para>
  Per un elenco dei valori del pool relativo ai pool EC, fare riferimento a
  <xref linkend="pool-values-ec"/>.
 </para>
 <sect1 xml:id="ec-prerequisite">
  <title>Prerequisiti dei pool con codice di cancellazione</title>

  <para>
   Per utilizzare il codice di cancellazione, è necessario:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Definire una regola di cancellazione nella mappa CRUSH.
    </para>
   </listitem>
   <listitem>
    <para>
     Definire un profilo con codice di cancellazione che specifichi l'algoritmo
     da utilizzare.
    </para>
   </listitem>
   <listitem>
    <para>
     Creare un pool utilizzando la regola e il profilo menzionati in
     precedenza.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Tenere presente che non sarà possibile modificare il profilo e i relativi
   dettagli in seguito alla creazione del pool e all'aggiunta di dati.
  </para>

  <para>
   Assicurarsi che le regole CRUSH per i <emphasis>pool di
   cancellazione</emphasis> utilizzino <literal>indep</literal> per
   <literal>step</literal>. Per informazioni, vedere
   <xref linkend="datamgm-rules-step-mode"/>.
  </para>
 </sect1>
 <sect1 xml:id="cha-ceph-erasure-default-profile">
  <title>Creazione di un pool con codice di cancellazione di esempio</title>

  <para>
   Il pool con codice di cancellazione più semplice equivale a RAID5 e richiede
   almeno tre host. In questa procedura è illustrato come creare un pool ai
   fini del test.
  </para>

  <procedure>
   <step>
    <para>
     Il comando <command>ceph osd pool create</command> viene utilizzato per
     creare un pool di tipo <emphasis>cancellazione</emphasis>.
     <literal>12</literal> sta per il numero di gruppi di posizionamento. Con i
     parametri di default, il pool è in grado di gestire gli errori di un OSD.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool create ecpool 12 12 erasure
pool 'ecpool' created</screen>
   </step>
   <step>
    <para>
     La stringa <literal>ABCDEFGHI</literal> viene scritta in un oggetto
     denominato <literal>NYAN</literal>.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>echo ABCDEFGHI | rados --pool ecpool put NYAN -</screen>
   </step>
   <step>
    <para>
     Ai fini del test, adesso è possibile disabilitare gli OSD, ad esempio
     disconnettendoli dalla rete.
    </para>
   </step>
   <step>
    <para>
     Per verificare se il pool è in grado di gestire gli errori dei
     dispositivi, è possibile accedere al contenuto del file mediante il
     comando <command>rados</command>.
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>rados --pool ecpool get NYAN -
ABCDEFGHI</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="cha-ceph-erasure-erasure-profiles">
  <title>Profili dei codici di cancellazione</title>

  <para>
   Quando si richiama il comando <command>ceph osd pool create</command> per
   creare un <emphasis>pool di cancellazione</emphasis>, viene utilizzato il
   profilo di default a meno che non se ne specifichi un altro. I profili
   definiscono la ridondanza dei dati. A tal fine impostare due parametri,
   denominati arbitrariamente <literal>k</literal> ed <literal>m</literal>. k
   ed m definiscono il numero di <literal>porzioni</literal> in cui vengono
   suddivisi i dati e quante porzioni di codifica vengono create. Le porzioni
   ridondanti vengono quindi memorizzate in OSD diversi.
  </para>

  <para>
   Definizioni necessarie per i profili dei pool di cancellazione:
  </para>

  <variablelist>
   <varlistentry>
    <term>chunk</term>
    <listitem>
     <para>
      quando si richiama la funzione di codifica, vengono restituite porzioni
      della stessa dimensione: le porzioni di dati che è possibile concatenare
      per ricostruire l'oggetto originale e le porzioni di codifica che è
      possibile utilizzare per ricompilare una porzione persa.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>k</term>
    <listitem>
     <para>
      il numero di porzioni di dati, ovvero il numero di porzioni in cui è
      suddiviso l'oggetto originale. Ad esempio, se <literal>k = 2</literal>,
      un oggetto da 10 KB verrà suddiviso in <literal>k</literal> oggetti da 5
      KB ciascuno. Il valore <literal>min_size</literal> di default nei pool
      con codice di cancellazione è <literal>k + 1</literal>. Tuttavia, si
      consiglia di impostare il valore <literal>min_size</literal> su almeno
      <literal>k + 2</literal> per evitare la perdita di dati e operazioni di
      scrittura.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>m</term>
    <listitem>
     <para>
      il numero di porzioni di codifica, ovvero il numero di porzioni
      aggiuntive calcolato dalle funzioni di codifica. Esistono 2 porzioni di
      codifica, vale a dire che 2 OSD possono essere fuori senza perdere dati.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>crush-failure-domain</term>
    <listitem>
     <para>
      definisce a quali dispositivi vengono distribuite le porzioni. È
      necessario impostare come valore un tipo di compartimento. Per tutti i
      tipi di compartimenti, vedere <xref linkend="datamgm-buckets"/>. Se il
      dominio dell'errore è <literal>rack</literal>, le porzioni saranno
      memorizzate in rack diversi al fine di aumentare la resilienza in caso di
      errore dei rack. Tenere presente che ciò richiede dei rack k+m.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

  <para>
   Con il profilo con codice di cancellazione di default utilizzato in
   <xref linkend="cha-ceph-erasure-default-profile"/>, i dati del cluster non
   andranno persi in caso di errore di un singolo OSD o di un host. Pertanto,
   per memorizzare 1 TB di dati è necessario uno spazio di memorizzazione
   effettivo di altri 0,5 TB. Ciò vuol dire che per 1 TB di dati sono necessari
   1,5 TB di spazio di storage nominale (perché k=2, m=1). Ciò equivale a una
   normale configurazione RAID 5. Un pool replicato necessita invece di 2 TB di
   spazio di storage nominale per memorizzare 1 TB di dati.
  </para>

  <para>
   È possibile visualizzare le impostazioni del profilo di default con:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd erasure-code-profile get default
directory=.libs
k=2
m=1
plugin=jerasure
crush-failure-domain=host
technique=reed_sol_van</screen>

  <para>
   È importante scegliere il profilo giusto perché non è possibile modificarlo
   dopo la creazione del pool. È necessario creare un nuovo pool con un profilo
   diverso e trasferirvi tutti gli oggetti del pool precedente (vedere la
   <xref linkend="pools-migration"/>).
  </para>

  <para>
   I parametri più importanti del profilo sono <literal>k</literal>,
   <literal>m</literal> e <literal>crush-failure-domain</literal> in quanto
   definiscono l'overhead di memorizzazione e la durata dei dati. Ad esempio,
   se l'architettura desiderata deve sostenere la perdita di due rack con un
   overhead di storage del 66%, è possibile definire il profilo seguente.
   Tenere presente che ciò si applica solo alle mappe CRUSH contenenti
   compartimenti di tipo "rack":
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd erasure-code-profile set <replaceable>myprofile</replaceable> \
   k=3 \
   m=2 \
   crush-failure-domain=rack</screen>

  <para>
   È possibile ripetere l'esempio della
   <xref linkend="cha-ceph-erasure-default-profile"/> con questo nuovo profilo:
  </para>

<screen><prompt>cephuser@adm &gt; </prompt>ceph osd pool create ecpool 12 12 erasure <replaceable>myprofile</replaceable>
<prompt>cephuser@adm &gt; </prompt>echo ABCDEFGHI | rados --pool ecpool put NYAN -
<prompt>cephuser@adm &gt; </prompt>rados --pool ecpool get NYAN -
ABCDEFGHI</screen>

  <para>
   L'oggetto NYAN verrà diviso in tre (<literal>k=3</literal>) e verranno
   create due porzioni aggiuntive (<literal>m=2</literal>). Il valore di
   <literal>m</literal> definisce quanti OSD è possibile perdere
   simultaneamente senza perdere alcun dato. Con il comando
   <literal>crush-failure-domain=rack</literal> verrà creato un set di regole
   CRUSH che garantisce che le due porzioni non vengano memorizzate nello
   stesso rack.
  </para>

  <informalfigure>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="ceph_erasure_obj.png" width="80%"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="ceph_erasure_obj.png" width="60%"/>
    </imageobject>
   </mediaobject>
  </informalfigure>

  <sect2 xml:id="ec-create">
   <title>Creazione di un nuovo profilo con codice di cancellazione</title>
   <para>
    Il comando seguente consente di creare un nuovo profilo con codice di
    cancellazione:
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd erasure-code-profile set <replaceable>NAME</replaceable> \
 directory=<replaceable>DIRECTORY</replaceable> \
 plugin=<replaceable>PLUGIN</replaceable> \
 stripe_unit=<replaceable>STRIPE_UNIT</replaceable> \
 <replaceable>KEY</replaceable>=<replaceable>VALUE</replaceable> ... \
 --force
</screen>
   <variablelist>
    <varlistentry>
     <term>DIRECTORY</term>
     <listitem>
      <para>
       Opzionale. Impostare il nome della directory da cui viene caricato il
       plug-in del codice di cancellazione. Quello di default è
       <filename>/usr/lib/ceph/erasure-code</filename>.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>PLUGIN</term>
     <listitem>
      <para>
       Opzionale. Utilizzare il plug-in del codice di cancellazione per
       calcolare le porzioni di codifica e recuperare quelle mancanti. I
       plug-in disponibili sono "jerasure", "isa", "lrc" e "shes". Il plug-in
       di default è "jerasure".
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>STRIPE_UNIT</term>
     <listitem>
      <para>
       Opzionale. La quantità di dati in una porzione di dati per segmento. Ad
       esempio, un profilo con 2 porzioni di dati e stripe_unit=4K inserisce
       l'intervallo 0-4K nella porzione 0, 4K-8K nella porzione 1 e quindi
       8K-12K nuovamente nella porzione 0. Per le migliori prestazioni, deve
       essere un multiplo di 4K. Il valore di default viene estrapolato
       dall'opzione di configurazione di monitoraggio
       <option>osd_pool_erasure_code_stripe_unit</option> al momento della
       creazione di un pool. Il valore "stripe_width" di un pool che utilizza
       questo profilo sarà il numero delle porzioni di dati moltiplicato per
       questo valore di "stripe_unit".
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>KEY=VALUE</term>
     <listitem>
      <para>
       Le coppie di opzioni di chiavi/valori specifiche per il plug-in del
       codice di cancellazione selezionato.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>--force</term>
     <listitem>
      <para>
       Opzionale. Ignora un profilo esistente con lo stesso nome e consente
       l'impostazione di una stripe_unit non allineata a 4K.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
  </sect2>

  <sect2 xml:id="ec-rm">
   <title>Rimozione di un profilo con codice di cancellazione</title>
   <para>
    Il comando seguente consente di rimuovere un profilo con codice di
    cancellazione identificato dal relativo nome
    (<replaceable>NAME</replaceable>):
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd erasure-code-profile rm <replaceable>NAME</replaceable>
</screen>
   <important>
    <para>
     Se è presente un pool che fa riferimento al profilo, l'eliminazione non
     riesce.
    </para>
   </important>
  </sect2>

  <sect2 xml:id="ec-get">
   <title>Visualizzazione dei dettagli di un profilo con codice di cancellazione</title>
   <para>
    Il comando seguente consente di visualizzare i dettagli di un profilo con
    codice di cancellazione identificato dal relativo nome
    (<replaceable>NAME</replaceable>):
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd erasure-code-profile get <replaceable>NAME</replaceable>
</screen>
  </sect2>

  <sect2 xml:id="ec-ls">
   <title>Elenco dei profili con codice di cancellazione</title>
   <para>
    Il comando seguente consente di visualizzare un elenco dei nomi di tutti i
    profili con codice di cancellazione:
   </para>
<screen>
<prompt role="root">root # </prompt>ceph osd erasure-code-profile ls
</screen>
  </sect2>
 </sect1>
 <sect1 xml:id="ec-rbd">
  <title>Contrassegno dei pool con codice di cancellazione con il dispositivo di blocco RADOS (RADOS Block Device, RBD)</title>

  <para>
   Per contrassegnare un pool EC come pool RBD, applicare il rispettivo tag:
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>ceph osd pool application enable rbd <replaceable>ec_pool_name</replaceable>
</screen>

  <para>
   RBD può memorizzare <emphasis>data</emphasis> immagine nei pool EC.
   Tuttavia, l'intestazione di immagine e i metadati devono comunque essere
   memorizzati in un pool replicato. A tal fine, presupporre di disporre di un
   pool denominato "rbd":
  </para>

<screen>
<prompt>cephuser@adm &gt; </prompt>rbd create rbd/<replaceable>image_name</replaceable> --size 1T --data-pool <replaceable>ec_pool_name</replaceable>
</screen>

  <para>
   È possibile utilizzare normalmente l'immagine come qualsiasi altra, con la
   differenza che tutti i dati saranno memorizzati nel pool
   <replaceable>ec_pool_name</replaceable> al posto del pool "rbd".
  </para>
 </sect1>
</chapter>
