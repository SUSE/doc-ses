<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_upgrade.xml" version="5.0" xml:id="cha-ceph-upgrade">
 <title>Upgrade da SUSE Enterprise Storage 6 a 7.1</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>yes</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  Questo capitolo descrive le procedure per eseguire l&apos;upgrade di SUSE Enterprise Storage 6 alla versione 7.1.
 </para>
 <para>
  L&apos;upgrade include i task seguenti:
 </para>
 <itemizedlist>
  <listitem>
   <para>
    Esecuzione dell&apos;upgrade da Ceph Nautilus a Pacific.
   </para>
  </listitem>
  <listitem>
   <para>
    Passaggio dall&apos;installazione ed esecuzione di Ceph tramite pacchetti RPM all&apos;esecuzione in container.
   </para>
  </listitem>
  <listitem>
   <para>
    Rimozione completa di DeepSea e sostituzione con <systemitem class="resource">ceph-salt</systemitem> e cephadm.
   </para>
  </listitem>
 </itemizedlist>
 <warning>
  <para>
   Le informazioni sull&apos;upgrade contenute in questo capitolo si applicano <emphasis>soltanto</emphasis> agli upgrade da DeepSea a cephadm. Non seguire queste istruzioni se si desidera distribuire SUSE Enterprise Storage sulla piattaforma SUSE CaaS.
  </para>
 </warning>
 <important>
  <para>
   L&apos;upgrade dalle versioni di SUSE Enterprise Storage precedenti alla 6 non è supportato. Innanzitutto, è necessario eseguire l&apos;upgrade alla versione più recente di SUSE Enterprise Storage 6, quindi seguire le procedure descritte in questo capitolo.
  </para>
 </important>
 <sect1 xml:id="before-upgrade">
  <title>Attività preparatorie all&apos;upgrade</title>

  <para>
   Prima di avviare l&apos;upgrade, <emphasis>occorre</emphasis> completare i task seguenti. È possibile eseguire l&apos;upgrade da SUSE Enterprise Storage 6 in qualsiasi momento.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     La migrazione dell&apos;OSD da FileStore a BlueStore <emphasis>deve</emphasis> avvenire prima dell&apos;aggiornamento poiché FileStore non è supportato in SUSE Enterprise Storage 7.1. Ulteriori dettagli su BlueStore e su come migrare da FileStore sono disponibili all&apos;indirizzo <link xlink:href="https://documentation.suse.com/ses/6/single-html/ses-deployment/#filestore2bluestore"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se è in esecuzione una versione precedente del cluster in cui sono ancora utilizzati OSD <literal>ceph-disk</literal>, è <emphasis>necessario</emphasis> passare a <literal>ceph-volume</literal> prima dell&apos;upgrade. Ulteriori dettagli sono disponibili in <link xlink:href="https://documentation.suse.com/ses/6/single-html/ses-deployment/#upgrade-osd-deployment"/>.
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="upgrade-consider-points">
   <title>Aspetti da considerare</title>
   <para>
    Prima di eseguire l&apos;upgrade, leggere per intero le sezioni seguenti per comprendere tutti i task che devono essere completati.
   </para>
   <itemizedlist>
    <listitem>
     <para>
      <emphasis>Lettura delle note di rilascio</emphasis>. Nelle note, è possibile trovare informazioni aggiuntive sulle modifiche apportate rispetto alla release precedente di SUSE Enterprise Storage. Controllare le note di rilascio per vedere se:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        l&apos;hardware necessita di considerazioni speciali;
       </para>
      </listitem>
      <listitem>
       <para>
        i pacchetti software utilizzati hanno subito modifiche significative;
       </para>
      </listitem>
      <listitem>
       <para>
        è necessario adottare precauzioni speciali per l&apos;installazione.
       </para>
      </listitem>
     </itemizedlist>
     <para>
      Le note di rilascio forniscono inoltre informazioni che non si è fatto in tempo a riportare nel manuale. Contengono anche alcune note su problemi noti.
     </para>
     <para>
      All&apos;indirizzo <link xlink:href="https://www.suse.com/releasenotes/"/> è possibile trovare le note di rilascio di SES 7.1.
     </para>
     <para>
      Inoltre, dopo aver installato il pacchetto <package>release-notes-ses</package> dall&apos;archivio di SES 7.1, individuare localmente le note di rilascio nella directory <filename>/usr/share/doc/release-notes</filename> oppure online all&apos;indirizzo <link xlink:href="https://www.suse.com/releasenotes/"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Leggere la <xref linkend="ses-deployment"/> per acquisire dimestichezza con <systemitem class="resource">ceph-salt</systemitem> e con l&apos;utilità di coordinamento Ceph, in particolare con le informazioni sulle specifiche del servizio.
     </para>
    </listitem>
    <listitem>
     <para>
      L&apos;upgrade del cluster può richiedere diverso tempo, circa lo stesso necessario per eseguire l&apos;upgrade di un computer moltiplicato per il numero di nodi del cluster.
     </para>
    </listitem>
    <listitem>
     <para>
      Eseguire innanzitutto l&apos;upgrade del Salt Master, quindi sostituire DeepSea con <systemitem class="resource">ceph-salt</systemitem> e cephadm. Finché non sarà stato completato l&apos;upgrade di almeno tutti i nodi di Ceph Manager, <emphasis>non</emphasis> sarà possibile iniziare a utilizzare il modulo dell&apos;utilità di coordinamento cephadm.
     </para>
    </listitem>
    <listitem>
     <para>
      L&apos;aggiornamento dall&apos;utilizzo degli RPM di Nautilus all&apos;utilizzo dei container di Pacific deve avvenire in un unico passaggio. Pertanto, occorre eseguire l&apos;upgrade di un intero nodo alla volta, e non di un daemon alla volta.
     </para>
    </listitem>
    <listitem>
     <para>
      I servizi di base (MON, MGR, OSD) vengono aggiornati per ordine e rimangono disponibili durante l&apos;upgrade. Al termine dell&apos;operazione, occorre ripetere la distribuzione dei servizi del gateway (Metadata Server, Object Gateway, NFS Ganesha, iSCSI Gateway). Ciascuno dei servizi riportati di seguito subirà un tempo di fermo:
     </para>
     <itemizedlist>
      <listitem>
       <important>
        <para>
         I Metadata Server e gli Object Gateway sono disattivi dall&apos;inizio dell&apos;upgrade dei nodi da SUSE Linux Enterprise Server 15 SP1 a SUSE Linux Enterprise Server 15 SP3 fino alla ridistribuzione dei servizi al termine della procedura di upgrade. È un aspetto particolarmente importante da tenere presente se questi servizi sono in co-location con MON, MGR oppure OSD, poiché potrebbero essere inattivi per tutta la durata dell&apos;upgrade del cluster. Se questo rappresenta un problema, valutare di distribuire separatamente tali servizi su nodi aggiuntivi prima di procedere con l&apos;upgrade, in modo che rimangano inattivi per il minor tempo possibile, ovvero per la durata dell&apos;upgrade dei nodi del gateway, e non dell&apos;intero cluster.
        </para>
       </important>
      </listitem>
      <listitem>
       <para>
        NFS Ganesha e gli iSCSI Gateway sono inattivi solo per il riavvio dei nodi durante l&apos;upgrade da SUSE Linux Enterprise Server 15 SP1 a SUSE Linux Enterprise Server 15 SP3 e nuovamente per breve tempo durante la ridistribuzione di ciascun servizio nella modalità in container.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="upgrade-backup-config-data">
   <title>Backup della configurazione e dei dati del cluster</title>
   <para>
    Si consiglia vivamente di eseguire il backup completo della configurazione e dei dati del cluster prima di avviare l&apos;upgrade a SUSE Enterprise Storage 7.1. Per istruzioni su come eseguire il backup di tutti i dati, vedere <link xlink:href="https://documentation.suse.com/ses/6/single-html/ses-admin/#cha-deployment-backup"/>.
   </para>
  </sect2>

  <sect2 xml:id="verify-previous-upgrade">
   <title>Verifica dei passaggi dell&apos;upgrade precedente</title>
   <para>
    Se in precedenza è stato eseguito l&apos;upgrade dalla versione 5, verificare che l&apos;upgrade alla versione 6 sia stato completato correttamente:
   </para>
   <para>
    Controllare se il file <filename>/srv/salt/ceph/configuration/files/ceph.conf.import</filename> è presente.
   </para>
   <para>
    Questo file è creato dal processo engulf durante l&apos;upgrade da SUSE Enterprise Storage 5 a 6. L&apos;opzione <option>configuration_init: default-import</option> è impostata in <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename>.
   </para>
   <para>
    Se l&apos;opzione <option>configuration_init</option> è ancora impostata su <option>default-import</option>, come file di configurazione il cluster utilizza <filename>ceph.conf.import</filename> e non la configurazione <filename>ceph.conf</filename> di default di DeepSea, compilata dai file in <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/</filename>.
   </para>
   <para>
    Pertanto, è necessario analizzare <filename>ceph.conf.import</filename> per rilevare eventuali configurazioni personalizzate e possibilmente spostare la configurazione in uno dei file in <filename>/srv/salt/ceph/configuration/files/ceph.conf.d/</filename>.
   </para>
   <para>
    Quindi, rimuovere la riga <option>configuration_init: default-import</option> da <filename>/srv/pillar/ceph/proposals/config/stack/default/ceph/cluster.yml</filename>.
   </para>
  </sect2>

  <sect2 xml:id="verify-previous-upgrade-patch">
   <title>Aggiornamento dei nodi del cluster e verifica dell&apos;integrità del cluster</title>
   <para>
    Verificare che tutti gli ultimi aggiornamenti di SUSE Linux Enterprise Server 15 SP1 e SUSE Enterprise Storage 6 siano stati applicati a tutti i nodi del cluster:
   </para>
<screen><prompt role="root"># </prompt>zypper refresh &amp;&amp; zypper patch</screen>
   <tip>
    <para>
     Per informazioni dettagliate sull&apos;aggiornamento dei nodi del cluster, fare riferimento a <link xlink:href="https://documentation.suse.com/ses/6/html/ses-all/storage-salt-cluster.html#deepsea-rolling-updates"/>.
    </para>
   </tip>
   <para>
    Dopo aver applicato gli aggiornamenti, riavviare il Salt Master, sincronizzare i nuovi moduli Salt e controllare l&apos;integrità del cluster:
   </para>
<screen>
<prompt>root@master # </prompt>systemctl restart salt-master.service
<prompt>root@master # </prompt>salt '*' saltutil.sync_all
<prompt>cephuser@adm &gt; </prompt>ceph -s
</screen>
   <sect3 xml:id="upgrade-disable-insecure">
    <title>Disabilitazione dei client non sicuri</title>
    <para>
     Dalla versione v14.2.20 di Nautilus, è stato introdotto un nuovo avviso sullo stato di integrità che informa che i client non sicuri possono unirsi al cluster. Per default, questo avviso è <emphasis>attivo</emphasis>. Il Ceph Dashboard mostrerà il cluster nello stato <literal>HEALTH_WARN</literal>. La riga di comando verifica lo stato del cluster nel modo seguente:
    </para>
<screen>
 <prompt>cephuser@adm &gt; </prompt>ceph status
 cluster:
   id:     3fe8b35a-689f-4970-819d-0e6b11f6707c
   health: HEALTH_WARN
   mons are allowing insecure global_id reclaim
 [...]
 </screen>
    <para>
     L&apos;avviso indica che i Ceph Monitor stanno ancora consentendo ai client meno recenti, e privi di patch, di connettersi al cluster. Questo assicura la possibilità di connessione dei client esistenti durante l&apos;upgrade del cluster, ma segnala la presenza di un problema che deve essere risolto. Dopo aver completato l&apos;upgrade del cluster e di tutti i client all&apos;ultima versione di Ceph, disattivare i client privi di patch mediante il seguente comando:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mon auth_allow_insecure_global_id_reclaim false</screen>
   </sect3>
  </sect2>

  <sect2 xml:id="verify-previous-upgrade-patch-repos">
   <title>Verifica dell&apos;accesso agli archivi software e alle immagini del container</title>
   <para>
    Verificare che ogni nodo del cluster disponga dell&apos;accesso agli archivi software di SUSE Linux Enterprise Server 15 SP3 e SUSE Enterprise Storage 7.1, oltre che al registro delle immagini del container.
   </para>
   <sect3 xml:id="verify-previous-upgrade-patch-repos-repos">
    <title>Archivi software</title>
    <para>
     Se tutti i nodi sono registrati su SCC, sarà possibile eseguire l&apos;upgrade con il comando <command>zypper migration</command>. Per ulteriori dettagli, fare riferimento a <link xlink:href="https://documentation.suse.com/sles/15-SP3/html/SLES-all/cha-upgrade-online.html#sec-upgrade-online-zypper"/>.
    </para>
    <para>
     Se i nodi <emphasis role="bold">non</emphasis> sono registrati su SCC, disabilitare tutti gli archivi software esistenti e aggiungere gli archivi <literal>Pool</literal> e <literal>Updates</literal> per ciascuna delle estensioni seguenti:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       SLE-Product-SLES/15-SP3
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Basesystem/15-SP3
      </para>
     </listitem>
     <listitem>
      <para>
       SLE-Module-Server-Applications/15-SP3
      </para>
     </listitem>
     <listitem>
      <para>
       SUSE-Enterprise-Storage-7.1
      </para>
     </listitem>
    </itemizedlist>
   </sect3>
   <sect3 xml:id="verify-previous-upgrade-patch-repos-images">
    <title>Immagini del container</title>
    <para>
     Tutti i nodi del cluster necessitano dell&apos;accesso al registro delle immagini del container. Nella maggior parte dei casi, viene utilizzato il registro SUSE pubblico all&apos;indirizzo <literal>registry.suse.com</literal>. Sono necessarie le immagini seguenti:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       registry.suse.com/ses/7.1/ceph/ceph
      </para>
     </listitem>
     <listitem>
      <para>
       registry.suse.com/ses/7.1/ceph/grafana
      </para>
     </listitem>
     <listitem>
      <para>
       registry.suse.com/ses/7.1/ceph/prometheus-server
      </para>
     </listitem>
     <listitem>
      <para>
       registry.suse.com/ses/7.1/ceph/prometheus-node-exporter
      </para>
     </listitem>
     <listitem>
      <para>
       registry.suse.com/ses/7.1/ceph/prometheus-alertmanager
      </para>
     </listitem>
    </itemizedlist>
    <para>
     In alternativa, ad esempio per le distribuzioni Air-gap, configurare un registro locale e verificare di disporre dell&apos;insieme di immagini del container corretto. Fare riferimento alla <xref linkend="deploy-cephadm-configure-registry"/> per ulteriori dettagli sulla configurazione di un registro delle immagini del container locale.
    </para>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-salt-master">
  <title>Esecuzione dell&apos;upgrade del Salt Master</title>

  <para>
   Di seguito è descritta la procedura di upgrade del Salt Master:
  </para>

  <procedure>
   <step>
    <para>
     Eseguire l&apos;upgrade del sistema operativo sottostante a SUSE Linux Enterprise Server 15 SP3:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Per i cluster con i nodi registrati su SCC, eseguire <command>zypper migration</command>.
      </para>
     </listitem>
     <listitem>
      <para>
       Per i cluster i cui nodi dispongono di archivi software assegnati manualmente, eseguire <command>zypper dup</command> seguito da <command>reboot</command>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     Disabilitare le fasi di DeepSea per evitare usi accidentali. Aggiungere il contenuto seguente a <filename>/srv/pillar/ceph/stack/global.yml</filename>:
    </para>
<screen>
stage_prep: disabled
stage_discovery: disabled
stage_configure: disabled
stage_deploy: disabled
stage_services: disabled
stage_remove: disabled
</screen>
    <para>
     Salvare il file e applicare le modifiche:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.pillar_refresh</screen>
   </step>
   <step>
    <para>
     Se le immagini del container in uso <emphasis role="bold">non</emphasis> provengono da <literal>registry.suse.com</literal>, ma dal registro configurato in locale, modificare <filename>/srv/pillar/ceph/stack/global.yml</filename> per comunicare a DeepSea quale immagine del container e registro Ceph utilizzare. Ad esempio, per utilizzare <literal>192.168.121.1:5000/my/ceph/image</literal> aggiungere le righe seguenti:
    </para>
<screen>
ses7_container_image: 192.168.121.1:5000/my/ceph/image
ses7_container_registries:
  - location: 192.168.121.1:5000
</screen>
    <para>
     Se è necessario specificare le informazioni di autenticazione per il registro, aggiungere il blocco <literal>ses7_container_registry_auth:</literal>; ad esempio:
    </para>
<screen>
ses7_container_image: 192.168.121.1:5000/my/ceph/image
ses7_container_registries:
  - location: 192.168.121.1:5000
ses7_container_registry_auth:
  registry: 192.168.121.1:5000
  username: <replaceable>USER_NAME</replaceable>
  password: <replaceable>PASSWORD</replaceable>
</screen>
    <para>
     Salvare il file e applicare le modifiche:
    </para>
<screen><prompt>root@master # </prompt>salt '*' saltutil.refresh_pillar</screen>
   </step>
   <step>
    <para>
     Assimilare la configurazione esistente:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config assimilate-conf -i /etc/ceph/ceph.conf</screen>
   </step>
   <step>
    <para>
     Verificare lo stato dell&apos;upgrade. L&apos;output potrebbe essere diverso a seconda della configurazione del cluster:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run upgrade.status
The newest installed software versions are:
 ceph: ceph version 16.2.7-640-gceb23c7491b (ceb23c7491bd96ab7956111374219a4cdcf6f8f4) pacific (stable)
 os: SUSE Linux Enterprise Server 15 SP3

Nodes running these software versions:
 admin.ceph (assigned roles: master, prometheus, grafana)

Nodes running older software versions must be upgraded in the following order:
 1: mon1.ceph (assigned roles: admin, mon, mgr)
 2: mon2.ceph (assigned roles: admin, mon, mgr)
 3: mon3.ceph (assigned roles: admin, mon, mgr)
 4: data4.ceph (assigned roles: storage, mds)
 5: data1.ceph (assigned roles: storage)
 6: data2.ceph (assigned roles: storage)
 7: data3.ceph (assigned roles: storage)
 8: data5.ceph (assigned roles: storage, rgw)
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-mon-mgr-nodes">
  <title>Esecuzione dell&apos;upgrade dei nodi MON, MGR e OSD</title>

  <para>
   Eseguire l&apos;upgrade dei nodi Ceph Monitor, Ceph Manager e OSD uno alla volta. Per ogni servizio, seguire la procedura indicata di seguito:
  </para>

  <procedure>
   <step>
    <para>
     Prima di adottare eventuali nodi OSD, effettuare una conversione di formato dei nodi OSD per migliorare la gestione dei dati OMAP. A tale scopo, eseguire il seguente comando sul nodo admin:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set osd bluestore_fsck_quick_fix_on_mount true</screen>
    <para>
     I nodi OSD verranno convertiti automaticamente al termine della relativa adozione.
    </para>
    <note>
     <para>
      La conversione può richiedere un tempo variabile da minuti a ore, a seconda della quantità di dati OMAP contenuti nel relativo disco rigido. Per ulteriori informazioni, fare riferimento al <link xlink:href="https://docs.ceph.com/en/latest/releases/pacific/#upgrading-non-cephadm-clusters"/>.
     </para>
    </note>
   </step>
   <step>
    <para>
     Durante l&apos;upgrade di un nodo OSD, fare in modo che l&apos;OSD non sia contrassegnato con <literal>out</literal> eseguendo il comando seguente:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd add-noout <replaceable>SHORT_NODE_NAME</replaceable></screen>
    <para>
     Sostituire <replaceable>SHORT_NODE_NAME</replaceable> con il nome abbreviato del nodo così come viene visualizzato nell&apos;output del comando <command>ceph osd tree</command>. Nell&apos;input seguente, i nomi host abbreviati sono <literal>ses-min1</literal> e <literal>ses-min2</literal>.
    </para>
<screen>
<prompt>root@master # </prompt>ceph osd tree
ID   CLASS  WEIGHT   TYPE NAME       STATUS  REWEIGHT  PRI-AFF
 -1         0.60405  root default
-11         0.11691      host ses-min1
  4    hdd  0.01949          osd.4       up   1.00000  1.00000
  9    hdd  0.01949          osd.9       up   1.00000  1.00000
 13    hdd  0.01949          osd.13      up   1.00000  1.00000
[...]
 -5         0.11691      host ses-min2
  2    hdd  0.01949          osd.2       up   1.00000  1.00000
  5    hdd  0.01949          osd.5       up   1.00000  1.00000
[...]
</screen>
   </step>
   <step>
    <para>
     Eseguire l&apos;upgrade del sistema operativo sottostante a SUSE Linux Enterprise Server 15 SP3:
    </para>
    <itemizedlist>
     <listitem>
      <para>
       Se tutti i nodi del cluster sono registrati su SCC, eseguire <command>zypper migration</command>.
      </para>
     </listitem>
     <listitem>
      <para>
       Se i nodi del cluster dispongono di archivi software assegnati manualmente, eseguire <command>zypper dup</command> seguito da <command>reboot</command>.
      </para>
     </listitem>
    </itemizedlist>
   </step>
   <step>
    <para>
     In seguito al riavvio del nodo, inserire in container tutti i daemon MON, MGR e OSD esistenti sul nodo eseguendo il comando seguente sul Salt Master:
    </para>
<screen><prompt>root@master # </prompt>salt <replaceable>MINION_ID</replaceable> state.apply ceph.upgrade.ses7.adopt</screen>
    <para>
     Sostituire <replaceable>MINION_ID</replaceable> con l&apos;ID del minion di cui si sta eseguendo l&apos;upgrade. È possibile ottenere l&apos;elenco degli ID dei minion eseguendo il comando <command>salt-key -L</command> sul Salt Master.
    </para>
    <tip>
     <para>
      Per vedere lo stato e l&apos;avanzamento del processo di <emphasis>adozione</emphasis>, controllare il Ceph Dashboard o eseguire uno dei comandi seguenti sul Salt Master:
     </para>
<screen>
<prompt>root@master # </prompt>ceph status
<prompt>root@master # </prompt>ceph versions
<prompt>root@master # </prompt>salt-run upgrade.status
</screen>
    </tip>
   </step>
   <step>
    <para>
     Al termine dell&apos;adozione, annullare l&apos;impostazione del flag <literal>noout</literal> se il nodo di cui si sta eseguendo l&apos;upgrade è un nodo OSD:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd rm-noout <replaceable>SHORT_NODE_NAME</replaceable></screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-gateway-nodes">
  <title>Esecuzione dell&apos;upgrade dei nodi del gateway</title>

  <para>
   Successivamente, eseguire l&apos;upgrade dei nodi del gateway separati (gateway Samba, Metadata Server, Object Gateway, NFS Ganesha o iSCSI Gateway). Eseguire l&apos;upgrade del sistema operativo sottostante a SUSE Linux Enterprise Server 15 SP3 per ogni nodo:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Se tutti i nodi del cluster sono registrati su SUSE Customer Center, eseguire il comando <command>zypper migration</command>.
    </para>
   </listitem>
   <listitem>
    <para>
     Se i nodi del cluster dispongono di archivi software assegnati manualmente, eseguire il comando <command>zypper dup</command> seguito dal comando <command>reboot</command>.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   Questo passaggio si applica anche ai nodi che fanno parte del cluster, ma a cui non è stato ancora assegnato nessun ruolo (in caso di dubbi, controllare l&apos;elenco degli host sul Salt Master fornito dal comando <command>salt-key -L</command> e confrontarlo con l&apos;output del comando <command>salt-run upgrade.status</command>).
  </para>

  <para>
   Dopo che l&apos;upgrade del sistema operativo è stato eseguito su tutti i nodi del cluster, il passaggio successivo consiste nell&apos;installare il pacchetto <package>ceph-salt</package> e nell&apos;applicare la configurazione del cluster. I servizi del gateway effettivi vengono ridistribuiti nella modalità in container alla fine della procedura di upgrade.
  </para>

  <note>
   <para>
    I servizi Metadata Server e Object Gateway non sono disponibili dall&apos;inizio dell&apos;upgrade a SUSE Linux Enterprise Server 15 SP3 fino alla ridistribuzione al termine della procedura di upgrade.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="upgrade-cephsalt">
  <title>Installazione di <systemitem class="resource">ceph-salt</systemitem> e applicazione della configurazione del cluster</title>

  <para>
   Prima di avviare la procedura di installazione di <systemitem class="resource">ceph-salt</systemitem> e di applicazione della configurazione del cluster, verificare lo stato del cluster e dell&apos;upgrade eseguendo i comandi seguenti:
  </para>

<screen>
<prompt>root@master # </prompt>ceph status
<prompt>root@master # </prompt>ceph versions
<prompt>root@master # </prompt>salt-run upgrade.status
</screen>

  <procedure>
   <step>
    <para>
     Rimuovere i processi cron <literal>rbd_exporter</literal> e <literal>rgw_exporter</literal> creati da DeepSea. Sul Salt Master con il ruolo di <systemitem class="username">root</systemitem>, eseguire il comando <command>crontab -e</command> per modificare la crontab. Eliminare gli elementi seguenti, se presenti:
    </para>
<screen>
# SALT_CRON_IDENTIFIER:deepsea rbd_exporter cron job
*/5 * * * * /var/lib/prometheus/node-exporter/rbd.sh &gt; \
 /var/lib/prometheus/node-exporter/rbd.prom 2&gt; /dev/null
# SALT_CRON_IDENTIFIER:Prometheus rgw_exporter cron job
*/5 * * * * /var/lib/prometheus/node-exporter/ceph_rgw.py &gt; \
 /var/lib/prometheus/node-exporter/ceph_rgw.prom 2&gt; /dev/null
</screen>
   </step>
   <step>
    <para>
     Esportare la configurazione del cluster da DeepSea eseguendo i comandi seguenti:
    </para>
<screen>
<prompt>root@master # </prompt>salt-run upgrade.ceph_salt_config &gt; ceph-salt-config.json
<prompt>root@master # </prompt>salt-run upgrade.generate_service_specs &gt; specs.yaml
</screen>
   </step>
   <step>
    <para>
     Disinstallare DeepSea e installare <systemitem class="resource">ceph-salt</systemitem> sul Salt Master:
    </para>
<screen>
<prompt>root@master # </prompt>zypper remove 'deepsea*'
<prompt>root@master # </prompt>zypper install ceph-salt
</screen>
   </step>
   <step>
    <para>
     Riavviare il Salt Master e sincronizzare i moduli Salt:
    </para>
<screen>
<prompt>root@master # </prompt>systemctl restart salt-master.service
<prompt>root@master # </prompt>salt \* saltutil.sync_all
</screen>
   </step>
   <step>
    <para>
     Importare la configurazione del cluster di DeepSea in <systemitem class="resource">ceph-salt</systemitem>:
    </para>
<screen><prompt>root@master # </prompt>ceph-salt import ceph-salt-config.json</screen>
   </step>
   <step>
    <para>
     Generare le chiavi SSH per la comunicazione tra i nodi e il cluster:
    </para>
<screen><prompt>root@master # </prompt>ceph-salt config /ssh generate</screen>
    <tip>
     <para>
      Verificare che la configurazione del cluster sia stata importata da DeepSea e specificare le potenziali opzioni ignorate:
     </para>
<screen><prompt>root@master # </prompt>ceph-salt config ls</screen>
     <para>
      Per una descrizione completa della configurazione del cluster, fare riferimento alla <xref linkend="deploy-cephadm-configure"/>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Applicare la configurazione e abilitare cephadm:
    </para>
<screen><prompt>root@master # </prompt>ceph-salt apply</screen>
   </step>
   <step>
    <para>
     Se è necessario specificare l&apos;URL del registro del container locale e le credenziali di accesso, seguire la procedura descritta nella <xref linkend="deploy-cephadm-configure-registry"/>.
    </para>
   </step>
   <step>
    <para>
     Se le immagini del container in uso <emphasis role="bold">non</emphasis> provengono da <literal>registry.suse.com</literal>, ma dal registro configurato in locale, comunicare a Ceph quale immagine del container utilizzare eseguendo
    </para>
<screen><prompt>root@master # </prompt>ceph config set global container_image <replaceable>IMAGE_NAME</replaceable></screen>
    <para>
     Ad esempio:
    </para>
<screen><prompt>root@master # </prompt>ceph config set global container_image 192.168.121.1:5000/my/ceph/image</screen>
   </step>
   <step>
    <para>
     Interrompere e disabilitare i daemon <systemitem class="daemon">ceph-crash</systemitem> di SUSE Enterprise Storage 6. I nuovi moduli in container di tali daemon saranno avviati automaticamente in un secondo momento.
    </para>
<screen>
<prompt>root@master # </prompt>salt '*' service.stop ceph-crash
<prompt>root@master # </prompt>salt '*' service.disable ceph-crash
</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-cephsalt-monitoring">
  <title>Esecuzione dell&apos;upgrade e adozione dello stack di monitoraggio</title>

  <para>
   La procedura descritta di seguito adotta tutti i componenti dello stack di monitoraggio (vedere <xref linkend="monitoring-alerting"/> per ulteriori dettagli).
  </para>

  <procedure>
   <step>
    <para>
     Sospendere l&apos;utilità di coordinamento:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch pause</screen>
   </step>
   <step>
    <para>
     Eseguire i comandi seguenti su qualsiasi nodo su cui sono in esecuzione Prometheus, Grafana e Alertmanager (il Salt Master di default):
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>cephadm adopt --style=legacy --name prometheus.$(hostname)
<prompt>cephuser@adm &gt; </prompt>cephadm adopt --style=legacy --name alertmanager.$(hostname)
<prompt>cephuser@adm &gt; </prompt>cephadm adopt --style=legacy --name grafana.$(hostname)
</screen>
    <tip>
     <para>
      Se <emphasis role="bold">non</emphasis> è in esecuzione il registro delle immagini del container di default <literal>registry.suse.com</literal>, è necessario specificare l&apos;immagine da utilizzare per ogni comando, ad esempio:
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>cephadm --image 192.168.121.1:5000/ses/7.1/ceph/prometheus-server:2.32.1 \
  adopt --style=legacy --name prometheus.$(hostname)
<prompt>cephuser@adm &gt; </prompt>cephadm --image 192.168.121.1:5000/ses/7.1/ceph/prometheus-alertmanager:0.21.0 \
  adopt --style=legacy --name alertmanager.$(hostname)
<prompt>cephuser@adm &gt; </prompt>cephadm --image 192.168.121.1:5000/ses/7.1/ceph/grafana:7.5.12 \
 adopt --style=legacy --name grafana.$(hostname)
</screen>
     <para>
      Le immagini del container richieste e le relative versioni sono elencate in <xref linkend="monitoring-custom-images"/>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Rimuovere il node-exporter da <emphasis role="bold">tutti</emphasis> i nodi. Non è necessario eseguire la migrazione del node-exporter, che verrà reinstallato come container quando verrà applicato il file <filename>specs.yaml</filename>.
    </para>
<screen><prompt>&gt; </prompt><command>sudo</command> zypper rm golang-github-prometheus-node_exporter</screen>
    <para>
     In alternativa, è possibile rimuovere il node-exporter contemporaneamente da tutti i nodi usando Salt sul nodo admin:
    </para>
<screen><prompt>root@master # </prompt>salt '*' pkg.remove golang-github-prometheus-node_exporter</screen>
   </step>
   <step>
    <para>
     Applicare le specifiche del servizio esportate in precedenza da DeepSea:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i specs.yaml</screen>
    <tip>
     <para>
      Se <emphasis role="bold">non</emphasis> è in esecuzione il registro delle immagini del container di default <literal>registry.suse.com</literal>, ma un registro del container locale, prima di distribuire il node-exporter, configurare cephadm in modo che utilizzi l&apos;immagine del container dal registro locale per la distribuzione del node-exporter. Diversamente, è possibile saltare questo passaggio e ignorare l&apos;avviso successivo.
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mgr mgr/cephadm/container_image_node_exporter <replaceable>QUALIFIED_IMAGE_PATH</replaceable></screen>
     <para>
      Assicurarsi che tutte le immagini del container per i servizi di monitoraggio puntino al registro locale, non solo a quello per il node-exporter. Il precedente passaggio di verifica è richiesto solo per il node-exporter, ma a questo punto si consiglia di impostare tutte le immagini del container di monitoraggio in cephadm in modo che puntino al registro locale.
     </para>
     <para>
      In caso contrario, le nuove distribuzioni dei servizi di monitoraggio, nonché le ridistribuzioni, utilizzeranno la configurazione cephadm di default ed è possibile che non si sia in grado di distribuire i servizi (nel caso di distribuzioni con air gap) o che si distribuiscano servizi con versioni miste.
     </para>
     <para>
      La modalità con cui cephadm deve essere configurato per utilizzare le immagini del container provenienti dal registro locale è descritta nel <xref linkend="monitoring-custom-images"/>.
     </para>
    </tip>
   </step>
   <step>
    <para>
     Riprendere l&apos;utilità di coordinamento:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch resume</screen>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="upgrade-gateways">
  <title>Ridistribuzione del servizio del gateway</title>

  <sect2 xml:id="upgrade-ogw">
   <title>Esecuzione dell&apos;upgrade di Object Gateway</title>
   <para>
    In SUSE Enterprise Storage 7.1, gli Object Gateway sono sempre configurati con un dominio per consentire l&apos;uso della funzionalità multisito (vedere <xref linkend="ceph-rgw-fed"/> per ulteriori dettagli) in un secondo momento. Se Object Gateway è stato configurato in modalità sito singolo in SUSE Enterprise Storage 6, seguire la procedura indicata di seguito per aggiungere un dominio. Se non si prevede di utilizzare la funzionalità multisito, è possibile utilizzare il valore <literal>default</literal> per il nome del dominio, del gruppo di zone e della zona.
   </para>
   <procedure>
    <step>
     <para>
      Creare un nuovo dominio:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin realm create --rgw-realm=<replaceable>REALM_NAME</replaceable> --default</screen>
    </step>
    <step>
     <para>
      Facoltativamente, rinominare il gruppo di zone e la zona di default.
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup rename \
 --rgw-zonegroup default \
 --zonegroup-new-name=<replaceable>ZONEGROUP_NAME</replaceable>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone rename \
 --rgw-zone default \
 --zone-new-name <replaceable>ZONE_NAME</replaceable> \
 --rgw-zonegroup=<replaceable>ZONEGROUP_NAME</replaceable>
</screen>
    </step>
    <step>
     <para>
      Configurare il gruppo di zone master:
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zonegroup modify \
 --rgw-realm=<replaceable>REALM_NAME</replaceable> \
 --rgw-zonegroup=<replaceable>ZONEGROUP_NAME</replaceable> \
 --endpoints http://<replaceable>RGW.EXAMPLE.COM</replaceable>:80 \
 --master --default
</screen>
    </step>
    <step>
     <para>
      Configurare la zona master: A tale scopo, saranno necessarie la chiave di accesso (ACCESS_KEY) e la chiave segreta (SECRET_KEY) dell&apos;utente Object Gateway con il flag <option>system</option> abilitato. In genere, si tratta dell&apos;utente <literal>admin</literal>. Per ottenere la chiave di accesso (ACCESS_KEY) e la chiave segreta (SECRET_KEY), eseguire <command>radosgw-admin user info --uid admin --rgw-zone=<replaceable>ZONE_NAME</replaceable></command>.
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>radosgw-admin zone modify \
 --rgw-realm=<replaceable>REALM_NAME</replaceable> \
 --rgw-zonegroup=<replaceable>ZONEGROUP_NAME</replaceable> \
 --rgw-zone=<replaceable>ZONE_NAME</replaceable> \
 --endpoints http://<replaceable>RGW.EXAMPLE.COM</replaceable>:80 \
 --access-key=<replaceable>ACCESS_KEY</replaceable> \
 --secret=<replaceable>SECRET_KEY</replaceable> \
 --master --default
</screen>
    </step>
    <step>
     <para>
      Eseguire il commit della configurazione aggiornata:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>radosgw-admin period update --commit</screen>
    </step>
   </procedure>
   <para>
    Per inserire il servizio Object Gateway in container, creare il file della specifica corrispondente come descritto nella <xref linkend="deploy-cephadm-day2-service-ogw"/> e applicarlo.
   </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>RGW</replaceable>.yml
</screen>
  </sect2>

  <sect2 xml:id="upgrade-ganesha">
   <title>Esecuzione dell&apos;upgrade di NFS Ganesha</title>
   
<important>
 <para>
  NFS Ganesha supporta NFS versione 4.1 e versioni successive. Non supporta NFS versione 3.
 </para>
</important>

   <para>
    Di seguito viene mostrato come eseguire la migrazione di un servizio NFS Ganesha esistente su cui è in esecuzione Ceph Nautilus a un container NFS Ganesha su cui è in esecuzione Ceph Octopus.
   </para>
   <warning>
    <para>
     Nella documentazione seguente si presuppone che l&apos;utente abbia già eseguito correttamente l&apos;upgrade dei servizi Ceph di base.
    </para>
   </warning>
   <para>
    NFS Ganesha memorizza la configurazione aggiuntiva di ogni daemon e la esporta in un pool RADOS. È possibile individuare il pool RADOS configurato nella riga <literal>watch_url</literal> del blocco <literal>RADOS_URLS</literal> nel file <filename>ganesha.conf</filename>. Per default, questo pool sarà denominato <literal>ganesha_config</literal>.
   </para>
   <para>
    Prima di tentare qualsiasi migrazione, si consiglia vivamente di eseguire una copia degli oggetti di configurazione del daemon e dell&apos;esportazione ubicati nel pool RADOS. Per individuare il pool RADOS configurato, eseguire il seguente comando:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>grep -A5 RADOS_URLS /etc/ganesha/ganesha.conf</screen>
   <para>
    Per elencare i contenuti del pool RADOS:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>rados --pool ganesha_config --namespace ganesha ls | sort
  conf-node3
  export-1
  export-2
  export-3
  export-4</screen>
   <para>
    Per copiare gli oggetti RADOS:
   </para>
<screen><prompt>cephuser@adm &gt; </prompt>RADOS_ARGS="--pool ganesha_config --namespace ganesha"
<prompt>cephuser@adm &gt; </prompt>OBJS=$(rados $RADOS_ARGS ls)
<prompt>cephuser@adm &gt; </prompt>for obj in $OBJS; do rados $RADOS_ARGS get $obj $obj; done
<prompt>cephuser@adm &gt; </prompt>ls -lah
total 40K
drwxr-xr-x 2 root root 4.0K Sep 8 03:30 .
drwx------ 9 root root 4.0K Sep 8 03:23 ..
-rw-r--r-- 1 root root 90 Sep 8 03:30 conf-node2
-rw-r--r-- 1 root root 90 Sep 8 03:30 conf-node3
-rw-r--r-- 1 root root 350 Sep 8 03:30 export-1
-rw-r--r-- 1 root root 350 Sep 8 03:30 export-2
-rw-r--r-- 1 root root 350 Sep 8 03:30 export-3
-rw-r--r-- 1 root root 358 Sep 8 03:30 export-4</screen>
   <para>
    Su ogni singolo nodo, occorre interrompere eventuali servizi NFS Ganesha esistenti e sostituirli con un container gestito da cephadm.
   </para>
   <procedure>
    <step>
     <para>
      Interrompere e disabilitare il servizio NFS Ganesha esistente:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>systemctl stop nfs-ganesha
<prompt>cephuser@adm &gt; </prompt>systemctl disable nfs-ganesha
</screen>
    </step>
    <step>
     <para>
      In seguito all&apos;interruzione del servizio NFS Ganesha esistente, è possibile distribuirne uno nuovo in un container tramite cephadm. A tale scopo, è necessario creare una specifica del servizio contenente un <literal>service_id</literal> che verrà utilizzato per identificare questo nuovo cluster NFS, il nome host del nodo di cui si sta eseguendo la migrazione indicato come host nella specifica di posizionamento e lo spazio dei nomi e il pool RADOS contenente gli oggetti di esportazione NFS configurati. Esempio:
     </para>
<screen>service_type: nfs
service_id: <replaceable>SERVICE_ID</replaceable>
placement:
  hosts:
  - node2
  pool: ganesha_config
  namespace: ganesha
</screen>
     <para>
      Per ulteriori informazioni sulla creazione di una specifica di posizionamento, vedere <xref linkend="cephadm-service-and-placement-specs"/>.
     </para>
    </step>
    <step>
     <para>
      Applicare la specifica di posizionamento:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch apply -i <replaceable>FILENAME</replaceable>.yaml</screen>
    </step>
    <step>
     <para>
      Verificare che il daemon NFS Ganesha sia in esecuzione sull&apos;host:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph orch ps --daemon_type nfs
NAME           HOST   STATUS         REFRESHED  AGE  VERSION  IMAGE NAME                                IMAGE ID      CONTAINER ID
nfs.foo.node2  node2  running (26m)  8m ago     27m  3.3      registry.suse.com/ses/7.1/ceph/ceph:latest  8b4be7c42abd  c8b75d7c8f0d</screen>
    </step>
    <step>
     <para>
      Ripetere questi passaggi per ogni nodo NFS Ganesha. Non è necessario creare una specifica del servizio separata per ogni nodo. È sufficiente aggiungere il nome host di ciascun nodo alla specifica del servizio NFS esistente e riapplicarla.
     </para>
    </step>
   </procedure>
   <para>
    È possibile eseguire la migrazione delle esportazioni esistenti in due modi diversi:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Ricrearle manualmente o riassegnarle tramite il Ceph Dashboard.
     </para>
    </listitem>
    <listitem>
     <para>
      Copiare manualmente i contenuti di ogni oggetto RADOS di ciascun daemon nella configurazione comune di NFS Ganesha appena creata.
     </para>
    </listitem>
   </itemizedlist>
   <procedure>
    <title>Copia manuale delle esportazioni nel file di configurazione comune di NFS Ganesha</title>
    <step>
     <para>
      Creare l&apos;elenco degli oggetti RADOS di ciascun daemon:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>RADOS_ARGS="--pool ganesha_config --namespace ganesha"
<prompt>cephuser@adm &gt; </prompt>DAEMON_OBJS=$(rados $RADOS_ARGS ls | grep 'conf-')</screen>
    </step>
    <step>
     <para>
      Creare una copia degli oggetti RADOS di ciascun daemon:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>for obj in $DAEMON_OBJS; do rados $RADOS_ARGS get $obj $obj; done
<prompt>cephuser@adm &gt; </prompt>ls -lah
total 20K
drwxr-xr-x 2 root root 4.0K Sep 8 16:51 .
drwxr-xr-x 3 root root 4.0K Sep 8 16:47 ..
-rw-r--r-- 1 root root 90 Sep 8 16:51 conf-nfs.<replaceable>SERVICE_ID</replaceable>
-rw-r--r-- 1 root root 90 Sep 8 16:51 conf-node2
-rw-r--r-- 1 root root 90 Sep 8 16:51 conf-node3</screen>
    </step>
    <step>
     <para>
      Ordinare e fondere gli elementi in un singolo elenco di esportazioni:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>cat conf-* | sort -u &gt; conf-nfs.<replaceable>SERVICE_ID</replaceable>
<prompt>cephuser@adm &gt; </prompt>cat conf-nfs.foo
%url "rados://ganesha_config/ganesha/export-1"
%url "rados://ganesha_config/ganesha/export-2"
%url "rados://ganesha_config/ganesha/export-3"
%url "rados://ganesha_config/ganesha/export-4"</screen>
    </step>
    <step>
     <para>
      Scrivere sul nuovo file di configurazione comune di NFS Ganesha:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>rados $RADOS_ARGS put conf-nfs.<replaceable>SERVICE_ID</replaceable> conf-nfs.<replaceable>SERVICE_ID</replaceable></screen>
    </step>
    <step>
     <para>
      Inviare una notifica al daemon NFS Ganesha:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>rados $RADOS_ARGS notify conf-nfs.<replaceable>SERVICE_ID</replaceable> conf-nfs.<replaceable>SERVICE_ID</replaceable></screen>
     <note>
      <para>
       Tramite questa azione, il daemon ricaricherà la configurazione.
      </para>
     </note>
    </step>
   </procedure>
   <para>
    Al termine della migrazione, è possibile rimuovere il servizio NFS Ganesha basato su Nautilus.
   </para>
   <procedure>
    <step>
     <para>
      Rimuovere NFS Ganesha:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>zypper rm nfs-ganesha
Reading installed packages...
Resolving package dependencies...
The following 5 packages are going to be REMOVED:
  nfs-ganesha nfs-ganesha-ceph nfs-ganesha-rados-grace nfs-ganesha-rados-urls nfs-ganesha-rgw
5 packages to remove.
After the operation, 308.9 KiB will be freed.
Continue? [y/n/v/...? shows all options] (y): y
(1/5) Removing nfs-ganesha-ceph-2.8.3+git0.d504d374e-3.3.1.x86_64 .................................................................................................................................................................................................................................................................................................[done]
(2/5) Removing nfs-ganesha-rgw-2.8.3+git0.d504d374e-3.3.1.x86_64 ..................................................................................................................................................................................................................................................................................................[done]
(3/5) Removing nfs-ganesha-rados-urls-2.8.3+git0.d504d374e-3.3.1.x86_64 ...........................................................................................................................................................................................................................................................................................[done]
(4/5) Removing nfs-ganesha-rados-grace-2.8.3+git0.d504d374e-3.3.1.x86_64 ..........................................................................................................................................................................................................................................................................................[done]
(5/5) Removing nfs-ganesha-2.8.3+git0.d504d374e-3.3.1.x86_64 ......................................................................................................................................................................................................................................................................................................[done]
Additional rpm output:
warning: /etc/ganesha/ganesha.conf saved as /etc/ganesha/ganesha.conf.rpmsave</screen>
    </step>
    <step>
     <para>
      Rimuovere le impostazioni esistenti del cluster dal Ceph Dashboard:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph dashboard reset-ganesha-clusters-rados-pool-namespace
</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-mds">
   <title>Esecuzione dell&apos;upgrade del Metadata Server</title>
   <para>
    Diversamente dai servizi MON, MGR e OSD, il Metadata Server non può essere adottato sul posto. Al contrario, è necessario ridistribuirlo in container tramite l&apos;utilità di coordinamento Ceph.
   </para>
   <procedure>
    <step>
     <para>
      Eseguire il comando <command>ceph fs ls</command> per ottenere il nome del file system, ad esempio:
     </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph fs ls
name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]
</screen>
    </step>
    <step>
     <para>
      Creare un nuovo file della specifica del servizio <filename>mds.yml</filename>, come descritto nella <xref linkend="deploy-cephadm-day2-service-mds"/>, utilizzando il nome del file system come <option>service_id</option> e specificando gli host su cui verranno eseguiti i daemon MDS. Esempio:
     </para>
<screen>
service_type: mds
service_id: cephfs
placement:
  hosts:
  - ses-min1
  - ses-min2
  - ses-min3
</screen>
    </step>
    <step>
     <para>
      Eseguire il comando <command>ceph orch apply -i mds.yml</command> per applicare la specifica del servizio e avviare i daemon MDS.
     </para>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="upgrade-igw">
   <title>Esecuzione dell&apos;upgrade di iSCSI Gateway</title>
   <para>
    Per eseguire l&apos;upgrade di iSCSI Gateway, è necessario ridistribuire tale servizio nei container tramite l&apos;utilità di coordinamento Ceph. Se sono presenti più iSCSI Gateway, occorre ridistribuirli uno per uno per ridurre il tempo di fermo del servizio.
   </para>
   <procedure>
    <step>
     <para>
      Interrompere e disabilitare i daemon iSCSI esistenti su ciascun nodo iSCSI Gateway:
     </para>
<screen>
<prompt>&gt; </prompt><command>sudo</command> systemctl stop rbd-target-gw
<prompt>&gt; </prompt><command>sudo</command> systemctl disable rbd-target-gw
<prompt>&gt; </prompt><command>sudo</command> systemctl stop rbd-target-api
<prompt>&gt; </prompt><command>sudo</command> systemctl disable rbd-target-api
</screen>
    </step>
    <step>
     <para>
      Creare una specifica del servizio per l&apos;iSCSI Gateway come descritto nella <xref linkend="deploy-cephadm-day2-service-igw"/>. A tale scopo, sono necessarie le impostazioni <option>pool</option>, <option>trusted_ip_list</option> e <option>api_*</option> del file <filename>/etc/ceph/iscsi-gateway.cfg</filename> esistente. Se il supporto per SSL è abilitato (<literal>api_secure = true</literal>), sono necessari inoltre il certificato (<filename>/etc/ceph/iscsi-gateway.crt</filename>) e la chiave (<filename>/etc/ceph/iscsi-gateway.key</filename>) SSL.
     </para>
     <para>
      Ad esempio, se <filename>/etc/ceph/iscsi-gateway.cfg</filename> contiene quanto segue:
     </para>
<screen>
[config]
cluster_client_name = client.igw.ses-min5
pool = iscsi-images
trusted_ip_list = 10.20.179.203,10.20.179.201,10.20.179.205,10.20.179.202
api_port = 5000
api_user = admin
api_password = admin
api_secure = true
</screen>
     <para>
      È necessario creare il file della specifica del servizio <filename>iscsi.yml</filename> seguente:
     </para>
<screen>
service_type: iscsi
service_id: igw
placement:
  hosts:
  - ses-min5
spec:
  pool: iscsi-images
  trusted_ip_list: "10.20.179.203,10.20.179.201,10.20.179.205,10.20.179.202"
  api_port: 5000
  api_user: admin
  api_password: admin
  api_secure: true
  ssl_cert: |
    -----BEGIN CERTIFICATE-----
    MIIDtTCCAp2gAwIBAgIYMC4xNzc1NDQxNjEzMzc2MjMyXzxvQ7EcMA0GCSqGSIb3
    DQEBCwUAMG0xCzAJBgNVBAYTAlVTMQ0wCwYDVQQIDARVdGFoMRcwFQYDVQQHDA5T
    [...]
    -----END CERTIFICATE-----
  ssl_key: |
    -----BEGIN PRIVATE KEY-----
    MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC5jdYbjtNTAKW4
    /CwQr/7wOiLGzVxChn3mmCIF3DwbL/qvTFTX2d8bDf6LjGwLYloXHscRfxszX/4h
    [...]
    -----END PRIVATE KEY-----
</screen>
     <note>
      <para>
       Le impostazioni <option>pool</option>, <option>trusted_ip_list</option>, <option>api_port</option>, <option>api_user</option>, <option>api_password</option>, <option>api_secure</option> sono identiche a quelle del file <filename>/etc/ceph/iscsi-gateway.cfg</filename>. I valori <option>ssl_cert</option> e <option>ssl_key</option> possono essere copiati dai file di chiave e certificato SSL esistenti. Verificare che il rientro sia corretto e che il carattere della <emphasis>barra verticale</emphasis> <literal>|</literal> venga visualizzato alla fine delle righe <literal>ssl_cert:</literal> e <literal>ssl_key:</literal> (vedere il contenuto del file <filename>iscsi.yml</filename> riportato sopra).
      </para>
     </note>
    </step>
    <step>
     <para>
      Eseguire il comando <command>ceph orch apply -i iscsi.yml</command> per applicare la specifica del servizio e avviare i daemon iSCSI Gateway.
     </para>
    </step>
    <step>
     <para>
      Rimuovere il pacchetto <package>ceph-iscsi</package> meno recente da ciascuno dei nodi iSCSI Gateway esistenti:
     </para>
<screen><prompt>cephuser@adm &gt; </prompt>zypper rm -u ceph-iscsi</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="upgrade-post-cleanup">
  <title>Pulizia successiva all&apos;upgrade</title>

  <para>
   In seguito all&apos;upgrade, seguire la procedura di pulizia indicata di seguito:
  </para>

  <procedure>
   <step>
    <para>
     Verificare che l&apos;upgrade del cluster sia riuscito correttamente controllando la versione corrente di Ceph:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph versions</screen>
   </step>
   <step>
    <para>
     Assicurarsi che nessun OSD precedente si unisca al cluster:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd require-osd-release pacific</screen>
   </step>
   <step>
    <para>
     Se necessario, impostare l&apos;opzione <option>pg_autoscale_mode</option> dei pool esistenti:
    </para>
    <important>
     <para>
      Per default, in SUSE Enterprise Storage 6, l&apos;opzione <option>pg_autoscale_mode</option> era impostata su <option>warn</option> per i pool. L&apos;opzione generava un messaggio di avviso se il numero dei gruppi di posizionamento non era ottimale, senza però avviare il dimensionamento automatico. Per default, in SUSE Enterprise Storage 7.1, l&apos;opzione <option>pg_autoscale_mode</option> è impostata su <option>on</option> per i nuovi pool e i gruppi di posizionamento vengono effettivamente sottoposti a dimensionamento automatico. Il processo di upgrade non modifica automaticamente l&apos;opzione <option>pg_autoscale_mode</option> dei pool esistenti. Se si desidera modificarla su <option>on</option> per sfruttare tutti i vantaggi dell&apos;utilità di dimensionamento automatico, vedere le istruzioni nel <xref linkend="op-pgs-autoscaler"/>.
     </para>
    </important>
    <para>
     Ulteriori dettagli sono disponibili nel <xref linkend="op-pgs-autoscaler"/>.
    </para>
   </step>
   <step>
    <para>
     Impedire i client precedenti a Luminous:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph osd set-require-min-compat-client luminous</screen>
   </step>
   <step>
    <para>
     Abilitare il modulo dell&apos;utilità di bilanciamento:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph balancer mode upmap
<prompt>cephuser@adm &gt; </prompt>ceph balancer on
</screen>
    <para>
     Ulteriori dettagli sono disponibili nel <xref linkend="mgr-modules-balancer"/>.
    </para>
   </step>
   <step>
    <para>
     Facoltativamente, abilitare il modulo di telemetria:
    </para>
<screen>
<prompt>cephuser@adm &gt; </prompt>ceph mgr module enable telemetry
<prompt>cephuser@adm &gt; </prompt>ceph telemetry on
 </screen>
    <para>
     Ulteriori dettagli sono disponibili nel <xref linkend="mgr-modules-telemetry"/>.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
