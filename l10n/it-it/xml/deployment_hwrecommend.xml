<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_hwrecommend.xml" version="5.0" xml:id="storage-bp-hwreq">
 <title>Requisiti hardware e raccomandazioni</title>
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:translation>sì</dm:translation>
   <dm:release>SES 7</dm:release>
  </dm:docmanager>
 </info>
 <para>
  I requisiti hardware di Ceph dipendono strettamente dal carico di lavoro degli IO. Tenere presente i seguenti requisiti hardware e raccomandazioni come base di partenza per una pianificazione dettagliata.
 </para>
 <para>
  In generale, le raccomandazioni date sono riferite a un processo. Se sullo stesso computer sono ubicati più processi, occorre sommare i requisiti di CPU, RAM, disco e rete.
 </para>
 <sect1 xml:id="network-overview">
  <title>Panoramica sulla rete</title>

  <para>
   Ceph dispone di diverse reti logiche:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Una rete di front-end, la <literal>rete pubblica</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     Una rete interna affidabile, ovvero la rete di back-end o <literal>rete di cluster</literal>. Si tratta di una procedura opzionale.
    </para>
   </listitem>
   <listitem>
    <para>
     Una o più reti client per i gateway. Si tratta di reti facoltative che non rientrano nell'ambito del presente capitolo.
    </para>
   </listitem>
  </itemizedlist>

  <para>
   La rete pubblica è la rete su cui i daemon Ceph comunicano tra di loro e con i client, ciò significa che tutto il traffico del cluster Ceph passa su questa rete, tranne nel caso in cui sia configurata una rete di cluster.
  </para>

  <para>
   La rete di cluster è la rete di back-end tra i nodi OSD per la replica, il ribilanciamento e il recupero. Se adeguatamente configurata, questa rete facoltativa può fornire fino al doppio della larghezza di banda della rete pubblica con la replica a tre vie di default, dal momento che viene utilizzata dall'OSD primario per inviare due copie agli altri OSD. La rete pubblica consente a client e gateway di comunicare con monitor, manager, nodi MDS e nodi OSD. È inoltre utilizzata da monitor, manager e nodi MDS per la comunicazione con i nodi OSD.
  </para>

  <figure xml:id="network-overview-figure">
   <title>Panoramica sulla rete</title>
   <mediaobject>
    <imageobject role="html">
     <imagedata fileref="network-overview-diagram.png" width="70%" format="PNG"/>
    </imageobject>
   </mediaobject>
  </figure>

  <sect2 xml:id="ceph-install-ceph-deploy-network">
   <title>Raccomandazioni di rete</title>
   <para>
    Si consiglia di utilizzare una singola rete a tolleranza di errore con larghezza di banda sufficiente per soddisfare i propri requisiti. Per l'ambiente di rete pubblica Ceph, si consigliano due interfacce di rete associate da 25 GbE (o più veloci) associate tramite 802.3ad (LACP). Questa è considerata come la configurazione di base di Ceph. Se si utilizza anche una rete di cluster, si consigliano quattro interfacce di rete associate da 25 GbE. L'associazione di due o più interfacce di rete offre migliore velocità effettiva tramite l'aggregazione dei collegamenti e, in caso di collegamenti e switch ridondanti, maggiore tolleranza agli errori e gestibilità.
   </para>
   <para>
    È possibile inoltre creare VLAN per isolare diversi tipi di traffico su un'associazione. Ad esempio, è possibile creare un'associazione per fornire due interfacce VLAN, una per la rete pubblica e una per la rete di cluster. Tuttavia, ciò <emphasis>non</emphasis> è necessario durante la configurazione delle reti Ceph. All'indirizzo <link xlink:href="https://documentation.suse.com/sles/15-SP2/html/SLES-all/cha-network.html#sec-network-iface-bonding"/> sono disponibili ulteriori dettagli sull'associazione delle interfacce.
   </para>
   <para>
    Isolando i componenti nei domini di errore, si aumenta la tolleranza agli errori. Per ottenere una maggiore tolleranza agli errori della rete, è possibile associare un'interfaccia a due NIC (Network Interface Card) separate, qualora si verificasse un errore su una. Analogamente, associare due switch diversi fornisce maggiore protezione, nel caso si verificasse un errore su uno. Rivolgersi al fornitore delle apparecchiature di rete per impostare il livello adeguato di tolleranza agli errori.
   </para>
   <important>
    <title>rete di amministrazione non supportata</title>
    <para>
     La configurazione della rete di amministrazione aggiuntiva, che consente ad esempio la separazione delle reti SSH, Salt o DNS, non è né testata né supportata.
    </para>
   </important>
   <tip>
    <title>nodi configurati tramite DHCP</title>
    <para>
     Se i nodi di storage sono configurati tramite DHCP, i timeout default possono non essere sufficienti per configurare correttamente la rete prima dell'avvio dei vari daemon Ceph. Se ciò avviene, i Ceph MON e OSD non si avvieranno in modo corretto (l'esecuzione di <command>systemctl status ceph\*</command> genererà errori di associazione). Per evitare questo problema, si consiglia di aumentare il timeout del client DHCP ad almeno 30 secondi su ciascun nodo nel cluster di memorizzazione. È possibile fare questo modificando le impostazioni seguenti su ogni nodo:
    </para>
    <para>
     In <filename>/etc/sysconfig/network/dhcp</filename>, impostare
    </para>
<screen>DHCLIENT_WAIT_AT_BOOT="30"</screen>
    <para>
     In <filename>/etc/sysconfig/network/config</filename>, impostare
    </para>
<screen>WAIT_FOR_INTERFACES="60"</screen>
   </tip>
   <sect3 xml:id="storage-bp-net-private">
    <title>Aggiunta di una rete privata a un cluster in esecuzione</title>
    <para>
     Se non si specifica una rete di cluster durante la distribuzione, Ceph presume un ambiente di rete pubblica singola. Mentre Ceph funziona bene con una rete pubblica, le sue prestazioni e sicurezza aumentano quando si imposta una seconda rete di cluster privata. Per supportare due reti, ogni nodo Ceph deve avere almeno due schede di rete.
    </para>
    <para>
     Occorre applicare le seguenti modifiche a ogni nodo Ceph. È relativamente rapido farlo con un piccolo cluster, ma può essere necessario molto tempo in caso di cluster contenente centinaia o migliaia di nodi.
    </para>
    <procedure>
     <step>
      <para>
       Impostare la rete di cluster utilizzando il comando seguente:
      </para>
<screen><prompt role="root">root # </prompt>ceph config set global cluster_network <replaceable>MY_NETWORK</replaceable></screen>
      <para>
       Riavviare gli OSD per eseguire l'associazione alla rete di cluster specificata:
      </para>
<screen><prompt role="root">root # </prompt>systemctl restart ceph-*@osd.*.service</screen>
     </step>
     <step>
      <para>
       Verificare che la rete di cluster privata funzioni come previsto al livello del SO.
      </para>
     </step>
    </procedure>
   </sect3>
   <sect3 xml:id="storage-bp-net-subnets">
    <title>Nodi di monitoraggio su sottoreti diverse</title>
    <para>
     Se i nodi monitor sono su sottoreti diverse, ad esempio si trovano in stanze diverse e sono serviti da switch differenti, occorre specificare l'indirizzo di rete pubblica nella notazione CIDR:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mon public_network "<replaceable>MON_NETWORK_1</replaceable>, <replaceable>MON_NETWORK_2</replaceable>, <replaceable>MON_NETWORK_N</replaceable></screen>
    <para>
     Esempio:
    </para>
<screen><prompt>cephuser@adm &gt; </prompt>ceph config set mon public_network "192.168.1.0/24, 10.10.0.0/16"</screen>
    <warning>
     <para>
      Se si specifica più di un segmento di rete per la rete pubblica (o di cluster) come descritto in questa sezione, ciascuna di queste sottoreti deve essere in grado di eseguire l'instradamento a tutte le altre, altrimenti i MON e gli altri daemon Ceph su segmenti di rete diversi non potranno comunicare e verrà generato un cluster suddiviso. Inoltre, se si utilizza un firewall, assicurarsi di includere ogni indirizzo IP o sottorete nelle iptables e aprire le porte per questi ultimi su tutti i nodi in base alle esigenze.
     </para>
    </warning>
   </sect3>
  </sect2>
 </sect1>
 <sect1 xml:id="multi-architecture">
  <title>Configurazioni ad architettura multipla</title>

  <para>
   SUSE Enterprise Storage supporta le architetture x86 e Arm. Durante la valutazione di ciascuna architettura, è importante osservare che dalla prospettiva dei core per OSD, frequenza e RAM, non esistono reali differenze tra le architetture CPU in termini di ridimensionamento.
  </para>

  <para>
   Come per i processori x86 (non-server) di dimensioni più piccole, i core basati su Arm a prestazioni ridotte potrebbero non fornire un'esperienza ottimale, soprattutto se utilizzati per i pool con codice di cancellazione.
  </para>

  <note>
   <para>
    Nella documentazione, <replaceable>SYSTEM-ARCH</replaceable> è utilizzato al posto di x86 o Arm.
   </para>
  </note>
 </sect1>
 <sect1 xml:id="ses-hardware-config">
  <title>Configurazione hardware</title>

  <para>
   La configurazione del cluster consigliata garantisce la migliore esperienza utente con il prodotto. Per i cluster di test o con requisiti di prestazioni inferiori, è descritta la configurazione minima supportata.
  </para>

  <sect2 xml:id="ses-bp-minimum-cluster">
   <title>Configurazione minima del cluster</title>
   <para>
    La configurazione minima del cluster è costituita da:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Almeno quattro nodi fisici (nodi OSD) con la co-location dei servizi;
     </para>
    </listitem>
    <listitem>
     <para>
      Ethernet Dual-10 Gb come rete associata;
     </para>
    </listitem>
    <listitem>
     <para>
      Un nodo admin separato (può essere virtualizzato su un nodo esterno).
     </para>
    </listitem>
   </itemizedlist>
   <para>
    La configurazione dettagliata prevede:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Nodo admin separato con 4 GB di RAM, quattro core, capacità di memorizzazione di 1 TB. In genere questo è il nodo Salt Master. I servizi e i gateway Ceph, come Ceph Monitor, Metadata Server, Ceph OSD, Object Gateway o NFS Ganesha non sono supportati sul nodo admin poiché quest'ultimo deve coordinare i processi di upgrade e aggiornamento del cluster in modo indipendente.
     </para>
    </listitem>
    <listitem>
     <para>
      Almeno quattro nodi OSD fisici, con otto dischi OSD ciascuno; vedere la <xref linkend="sysreq-osd"/> per i requisiti.
     </para>
     <para>
      La capacità complessiva del cluster deve essere ridimensionata per fare in modo che, anche nel caso di mancata disponibilità di un nodo, la capacità complessiva in uso (inclusa la ridondanza) non superi l'80%.
     </para>
    </listitem>
    <listitem>
     <para>
      Tre istanze di Ceph Monitor. Per ragioni di latenza, i monitor devono essere eseguiti dallo storage SSD/NVMe e non da HDD.
     </para>
    </listitem>
    <listitem>
     <para>
      Monitor, Metadata Server e gateway possono trovarsi in co-location sui nodi OSD; vedere la <xref linkend="ses-bp-diskshare"/> per informazioni sulla co-location dei monitor. In caso di co-location dei servizi, occorre aggiungere i requisiti di memoria e CPU.
     </para>
    </listitem>
    <listitem>
     <para>
      iSCSI Gateway, Object Gateway e Metadata Server richiedono almeno 4 GB di RAM incrementale e quattro core.
     </para>
    </listitem>
    <listitem>
     <para>
      Se si utilizzano CephFS, S3/Swift e iSCSI, per garantire ridondanza e disponibilità sono necessarie almeno due istanze dei rispettivi ruoli (Metadata Server, Object Gateway, iSCSI).
     </para>
    </listitem>
    <listitem>
     <para>
      I nodi devono essere dedicati a SUSE Enterprise Storage e non devono essere utilizzati per altri workload fisici, in container o virtualizzati.
     </para>
    </listitem>
    <listitem>
     <para>
      Se i gateway (iSCSI, Object Gateway, NFS Ganesha, Metadata Server ecc.) sono distribuiti all'interno di macchine virtuali, queste ultime non devono essere ospitate sulle macchine fisiche che servono altri ruoli del cluster (ciò non è necessario, poiché sono supportati come servizi in co-location).
     </para>
    </listitem>
    <listitem>
     <para>
      Se si esegue la distribuzione dei servizi come macchine virtuali su Hypervisor all'esterno del cluster fisico principale, occorre rispettare i domini di errore per assicurare la ridondanza.
     </para>
     <para>
      Ad esempio, non distribuire più ruoli dello stesso tipo sullo stesso Hypervisor (come più istanze MDS o MON).
     </para>
    </listitem>
    <listitem>
     <para>
      Se si esegue la distribuzione all'interno delle macchine virtuali, è particolarmente importante verificare che la connettività di rete dei nodi sia ottimale e che l'orario venga sincronizzato correttamente.
     </para>
    </listitem>
    <listitem>
     <para>
      I nodi dell'Hypervisor devono avere dimensioni adeguate per evitare interferenze provenienti da altri workload che consumano risorse di CPU, RAM, rete e storage.
     </para>
    </listitem>
   </itemizedlist>
   <figure>
    <title>Configurazione minima del cluster</title>
    <mediaobject>
     <imageobject role="fo">
      <imagedata fileref="minimal-ses.png" width="100%" format="PNG"/>
     </imageobject>
     <imageobject role="html">
      <imagedata fileref="minimal-ses.png" width="100%" format="PNG"/>
     </imageobject>
    </mediaobject>
   </figure>
  </sect2>

  <sect2 xml:id="ses-bp-production-cluster">
   <title>Configurazione del cluster di produzione consigliata</title>
   <para>
    Con la crescita del cluster, si consiglia di ricollocare i Ceph Monitor, i Metadata Server e i gateway per separare i nodi e ottenere una maggiore tolleranza agli errori.
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Sette nodi Storage oggetto
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Nessun singolo nodo eccede ~15% dello storage totale.
       </para>
      </listitem>
      <listitem>
       <para>
        La capacità complessiva del cluster deve essere ridimensionata per fare in modo che, anche nel caso di mancata disponibilità di un nodo, la capacità complessiva in uso (inclusa la ridondanza) non superi l'80%.
       </para>
      </listitem>
      <listitem>
       <para>
        Ethernet da 25 Gb o superiore, con associazione per la rete pubblica esterna e di cluster interna.
       </para>
      </listitem>
      <listitem>
       <para>
        56+ OSD per cluster di storage.
       </para>
      </listitem>
      <listitem>
       <para>
        Vedere la <xref linkend="sysreq-osd"/> per ulteriori raccomandazioni.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      Nodi infrastruttura fisica dedicata.
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Tre nodi Ceph Monitor: 4 GB RAM, processore a 4 core, SSD RAID 1 per disco.
       </para>
       <para>
        Vedere la <xref linkend="sysreq-mon"/> per ulteriori raccomandazioni.
       </para>
      </listitem>
      <listitem>
       <para>
        Nodi Object Gateway: 32 GB RAM, processore 8 core, SSD RAID 1 per disco.
       </para>
       <para>
        Vedere la <xref linkend="sysreq-rgw"/> per ulteriori raccomandazioni.
       </para>
      </listitem>
      <listitem>
       <para>
        Nodi iSCSI Gateway: 16 GB RAM, processore 8 core, SSD RAID 1 per disco.
       </para>
       <para>
        Vedere la <xref linkend="sysreq-iscsi"/> per ulteriori raccomandazioni.
       </para>
      </listitem>
      <listitem>
       <para>
        Nodi Metadata Server (uno attivo/uno hot standby): 32 GB RAM, processore 8 core, SSD RAID 1 per disco.
       </para>
       <para>
        Vedere la <xref linkend="sysreq-mds"/> per ulteriori raccomandazioni.
       </para>
      </listitem>
      <listitem>
       <para>
        Un nodo admin SES: 4 GB di RAM, processore 4 core, SSD RAID 1 per disco.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="deployment-hw-multipath">
   <title>Configurazione multipath</title>
   <para>
    Se si desidera utilizzare l'hardware multipath, assicurarsi che LVM visualizzi <literal>multipath_component_detection = 1</literal> nella sezione <literal>devices</literal> del file di configurazione. È possibile verificare questa istruzione tramite il comando <command>lvm config</command>.
   </para>
   <para>
    In alternativa, assicurarsi che LVM filtri i componenti mpath di un dispositivo tramite la configurazione di filtro LVM. Si tratta di un'impostazione specifica per l'host.
   </para>
   <note>
    <para>
     Questa procedura non è consigliata e deve essere presa in considerazione soltanto se non è possibile impostare <literal>multipath_component_detection = 1</literal>.
    </para>
   </note>
   <para>
    Per ulteriori informazioni sulla configurazione multipath, vedere <link xlink:href="https://documentation.suse.com/sles/15-SP2/html/SLES-all/cha-multipath.html#sec-multipath-lvm"/>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="deployment-osd-recommendation">
  <title>Nodi storage oggetto</title>

  <sect2 xml:id="sysreq-osd">
   <title>Requisiti minimi</title>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      Le seguenti raccomandazioni sulla CPU si applicano ai dispositivi indipendentemente dall'utilizzo di Ceph:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        1 thread CPU da 2 GHz per unità a rotazione.
       </para>
      </listitem>
      <listitem>
       <para>
        2 thread CPU da 2 GHz per SSD.
       </para>
      </listitem>
      <listitem>
       <para>
        4 thread CPU da 2 GHz per NVMe.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      Reti 10 GbE (pubbliche/client e interne) separate: 4 da 10 GbE obbligatorie, 2 da 25 GbE consigliate.
     </para>
    </listitem>
    <listitem>
     <para>
      RAM totale richiesta = numero di OSD x (1 GB + <option>osd_memory_target</option>) + 16 GB
     </para>
     <para>
      Per ulteriori dettagli su <option>osd_memory_target</option>, consultare questo riferimento: <xref linkend="config-auto-cache-sizing"/>.
     </para>
    </listitem>
    <listitem>
     <para>
      Dischi OSD nelle configurazioni JBOD o configurazioni RAID-0 individuali.
     </para>
    </listitem>
    <listitem>
     <para>
      Il giornale di registrazione OSD può risiedere sul disco OSD.
     </para>
    </listitem>
    <listitem>
     <para>
      I dischi OSD devono essere utilizzati esclusivamente da SUSE Enterprise Storage.
     </para>
    </listitem>
    <listitem>
     <para>
      SSD e disco dedicato per il sistema operativo, preferibilmente in una configurazione RAID 1.
     </para>
    </listitem>
    <listitem>
     <para>
      Allocare almeno altri 4 GB di RAM se questo host OSD ospiterà parte di un pool di cache utilizzato per la suddivisione in livelli della cache.
     </para>
    </listitem>
    <listitem>
     <para>
      Monitor Ceph, gateway e Metadata Server possono risiedere sui nodi storage oggetto.
     </para>
    </listitem>
    <listitem>
     <para>
      Per motivi legati alle prestazioni del disco, i nodi OSD sono nodi bare metal. Nessun altro workload deve essere eseguito su un nodo OSD a meno che non si tratti di una configurazione minima di Ceph Monitor e Ceph Manager.
     </para>
    </listitem>
    <listitem>
     <para>
      SSD per giornale di registrazione con rapporto 6:1 tra giornale SSD e OSD.
     </para>
    </listitem>
   </itemizedlist>
     <note>
       <para>
         Assicurarsi che i nodi OSD non dispongano di dispositivi di blocco di rete mappati, come immagini iSCSI o dispositivi di blocco RADOS (RADOS Block Device, RBD).
       </para>
     </note>
  </sect2>

  <sect2 xml:id="ses-bp-mindisk">
   <title>Dimensioni minime del disco</title>
   <para>
    Vi sono due tipi di spazi su disco necessari per l'esecuzione su OSD: lo spazio per il dispositivo WAL/DB e lo spazio primario per i dati memorizzati. Il valore minimo (e di default) per il dispositivo WAL/DB è 6 GB. Lo spazio minimo per i dati è pari a 5 GB, in quanto a partizioni più piccole di 5 GB viene assegnato automaticamente il peso di 0.
   </para>
   <para>
    Perciò, sebbene lo spazio minimo su disco per un OSD sia 11 GB, si sconsigliano dischi inferiori a 20 GB, anche per scopi di test.
   </para>
  </sect2>

  <sect2 xml:id="rec-waldb-size">
   <title>Dimensioni consigliate per il dispositivo DB e WAL di BlueStore</title>
   <tip>
    <title>ulteriori informazioni</title>
    <para>
     Per ulteriori informazioni su BlueStore, consultare <xref linkend="about-bluestore"/>.
    </para>
   </tip>
   <itemizedlist>
    <listitem>
     <para>
      Si consiglia di prenotare 4 GB per il dispositivo WAL. Le dimensioni consigliate per il dispositivo DB sono 64 GB per la maggior parte dei workload.
     </para>
     <important>
      <para>
       Per le distribuzioni a carico elevato, soprattutto in caso di elevato utilizzo di RGW o CephFS, si consigliano volumi di database maggiori. Riservare una parte di capacità (slot) per l'installazione di altro hardware per disporre di ulteriore spazio sul database, se necessario.
      </para>
     </important>
    </listitem>
    <listitem>
     <para>
      Se si intende mettere il dispositivo WAL e DB sullo stesso disco, si consiglia di utilizzare una singola partizione per entrambi i dispositivi, invece di avere una partizione separata per ciascuno. Ciò consente a Ceph di utilizzare il dispositivo DB anche per il funzionamento di WAL. La gestione dello spazio del disco è quindi più efficace in quanto Ceph utilizza la partizione DB per WAL solo se serve. Un altro vantaggio è che le probabilità che la partizione WAL si riempia sono molto basse e, quando questa non è utilizzata completamente, il suo spazio non viene sprecato ma utilizzato per le operazioni del dispositivo DB.
     </para>
     <para>
      Per condividere il dispositivo DB con WAL, <emphasis>non</emphasis> specificare il dispositivo WAL e specificare solo il dispositivo DB.
     </para>
     <para>
      Nel <xref linkend="drive-groups"/> è possibile trovare ulteriori informazioni su come specificare un layout OSD.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>

  <sect2 xml:id="ses-bp-share-ssd-journal">
   <title>SSD per partizioni WAL/DB</title>
   <para>
    Le unità a stato solido (SSD) non hanno parti in movimento. Ciò riduce il tempo di accesso casuale e la latenza di lettura accelerando il throughput dei dati. Poiché il loro prezzo per 1MB è sensibilmente maggiore rispetto al prezzo dei dischi rigidi classici, le SSD sono adatte solo per storage di piccole dimensioni.
   </para>
   <para>
    Gli OSD possono avere un significativo miglioramento delle prestazioni grazie alla memorizzazione delle relative partizioni WAL/DB su un disco SSD e dei dati oggetto su un disco rigido separato.
   </para>
   <tip>
    <title>condivisione di un disco SSD con più partizioni WAL/DB</title>
    <para>
     Dal momento che le partizioni WAL/DB occupano relativamente poco spazio, è possibile condividere un disco SSD con più partizioni WAL/DB. Tenere presente che con ogni partizione WAL/DB, le prestazioni del disco SSD diminuiscono. Si consiglia di non condividere più di sei partizioni WAL/DB sullo stesso disco SSD e 12 sui dischi NVMe.
    </para>
   </tip>
  </sect2>

  <sect2 xml:id="maximum-count-of-disks-osd">
   <title>Numero massimo di dischi consigliato</title>
   <para>
    Il server può contenere tutti i dischi consentiti. Quando si pianifica il numero di dischi per server, vi sono alcuni elementi da tenere presente:
   </para>
   <itemizedlist mark="bullet" spacing="normal">
    <listitem>
     <para>
      <emphasis>Ampiezza della banda di rete.</emphasis> Più dischi sono presenti in un server, più dati occorre trasferire tramite scheda di rete per le operazioni di scrittura sul disco.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Memoria.</emphasis> Viene utilizzata una RAM superiore a 2 GB per la cache BlueStore. Con l'opzione <option>osd_memory_target</option> di default di 4 GB, il sistema dispone di dimensioni iniziali della cache ragionevoli per i supporti a rotazione. Se si utilizzano SSD o NVME, prendere in considerazione di aumentare le dimensioni della cache e l'allocazione della RAM per ogni OSD per ottimizzare le prestazioni.
     </para>
    </listitem>
    <listitem>
     <para>
      <emphasis>Tolleranza agli errori.</emphasis> In caso di guasto del server completo, più dischi sono presenti, più OSD vengono persi temporaneamente dal cluster. Inoltre, per mantenere in esecuzione le regole di replicazione, occorre copiare tutti i dati dal server guasto negli altri nodi nel cluster.
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="sysreq-mon">
  <title>Nodi monitor</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     Sono richiesti almeno tre nodi MON. Il numero di monitor deve sempre essere dispari (1+2n).
    </para>
   </listitem>
   <listitem>
    <para>
     4 GB di RAM.
    </para>
   </listitem>
   <listitem>
    <para>
     Processore con quattro core logici.
    </para>
   </listitem>
   <listitem>
    <para>
     Si consiglia un'unità SSD o altro tipo di storage sufficientemente veloce per i monitor, in particolare per il percorso <filename>/var/lib/ceph</filename> su ogni nodo monitor, in quanto il quorum potrebbe essere instabile con alte latenze del disco. Si consigliano due dischi in configurazione RAID 1 per ridondanza. Si consiglia di utilizzare dischi separati o almeno partizioni del disco separate per i processi monitor per proteggere lo spazio su disco disponibile del monitor da elementi come file di registro che diventano troppo grandi.
    </para>
   </listitem>
   <listitem>
    <para>
     Deve essere presente solo un processo monitor per nodo.
    </para>
   </listitem>
   <listitem>
    <para>
     È possibile combinare nodi OSD, MON oppure Object Gateway solo se sono disponibili sufficienti risorse hardware. Ciò significa che si devono sommare i requisiti per tutti i servizi.
    </para>
   </listitem>
   <listitem>
    <para>
     Due interfacce di rete associate a più switch.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sysreq-rgw">
  <title>Nodi Object Gateway</title>

  <para>
   I nodi Object Gateway devono disporre di almeno sei core CPU e 32 GB di RAM. Se nello stesso computer sono co-ubicati altri processi, occorre sommare i loro requisiti.
  </para>
 </sect1>
 <sect1 xml:id="sysreq-mds">
  <title>Nodi Metadata Server</title>

  <para>
   Il corretto dimensionamento dei nodi Metadata Server dipende dal caso d'uso specifico. In genere, il numero di file aperti che deve gestire il Metadata Server è proporzionale alla quantità di CPU e RAM richiesta. Di seguito sono riportati i requisiti minimi:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     4 GB di RAM per ogni daemon del server di metadati.
    </para>
   </listitem>
   <listitem>
    <para>
     Interfaccia di rete vincolata.
    </para>
   </listitem>
   <listitem>
    <para>
     CPU da 2,5 GHz con almeno 2 core.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
 <sect1 xml:id="sysreq-admin-node">
  <title>Nodo admin</title>

  <para>
   Richiesti almeno 4 GB di RAM e una CPU quad-core. Ciò include l'esecuzione del Salt Master sul nodo admin. Per i grandi cluster con centinaia di nodi, consigliati 6 GB di RAM.
  </para>
 </sect1>
 <sect1 xml:id="sysreq-iscsi">
  <title>Nodi iSCSI Gateway</title>

  <para>
   I nodi iSCSI Gateway devono disporre di almeno sei core CPU e 16 GB di RAM.
  </para>
 </sect1>
 <sect1 xml:id="req-ses-other">
  <title>SES e altri prodotti SUSE</title>

  <para>
   Questa sezione contiene informazioni importanti sull'integrazione di SES con altri prodotti SUSE.
  </para>

  <sect2 xml:id="req-ses-suma">
   <title>SUSE Manager</title>
   <para>
    SUSE Manager e SUSE Enterprise Storage non sono integrati, perciò SUSE Manager non è in grado attualmente di gestire un cluster SES.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sysreq-naming">
  <title>Limitazioni di denominazione</title>

  <para>
   Ceph non supporta in genere i caratteri non ASCII nei file di configurazione, nei nomi di pool, nomi utente e così via. Quando si configura un cluster Ceph, si consiglia di utilizzare solo caratteri alfanumerici semplici (A-Z, a-z, 0-9) e punteggiatura minima (".", "-", "_") in tutti i nomi di configurazione/oggetto Ceph.
  </para>
 </sect1>
 <sect1 xml:id="ses-bp-diskshare">
  <title>Condivisione di un server da parte di OSD e monitor</title>

  <para>
   Sebbene sia tecnicamente possibile eseguire OSD e MON sullo stesso server in ambienti di test, si consiglia la presenza di un server separato per ogni nodo monitor in produzione. Il motivo principale sono le prestazioni: più OSD si trovano nel cluster, più operazioni di I/O devono essere eseguite dai nodi MON. Quando un server è condiviso tra un nodo MON e OSD, le operazioni di I/O OSD sono un fattore limitante per il nodo monitor.
  </para>

  <para>
   Un'altra considerazione è relativa alla condivisione dei dischi tra un OSD, un nodo MON e il sistema operativo sul server. La risposta è semplice: se possibile, dedicare un disco separato all'OSD e un server separato a un nodo monitor.
  </para>

  <para>
   Sebbene Ceph supporti OSD basati su directory, un OSD deve sempre avere un disco dedicato diverso da quello per il sistema operativo.
  </para>

  <tip>
   <para>
    Se è <emphasis>davvero</emphasis> necessario eseguire il nodo MON e OSD sullo stesso server, eseguire il MON su un disco separato montando il disco sulla directory <filename>/var/lib/ceph/mon</filename> per prestazioni leggermente migliori.
   </para>
  </tip>
 </sect1>
</chapter>
