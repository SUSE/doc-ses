<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="admin_ceph_troubleshooting.xml" version="5.0" xml:id="storage-troubleshooting">
 <title>疑難排解</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:translation>yes</dm:translation>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  本章描述您在操作 Ceph 叢集時可能會遇到的數種問題。
 </para>
 <sect1 xml:id="storage-bp-report-bug">
  <title>報告軟體問題</title>

  <para>
   如果您在執行 SUSE Enterprise Storage 時遇到了與它的某些元件 (例如 Ceph 或物件閘道) 相關的問題，請將問題報告給 SUSE 技術支援。建議使用 <command>supportconfig</command> 公用程式來報告問題。
  </para>

  <tip>
   <para>
    由於 <command>supportconfig</command> 是模組化軟體，因此請確定已安裝 <systemitem>supportutils-plugin-ses</systemitem> 套件。
   </para>
<screen>rpm -q supportutils-plugin-ses</screen>
   <para>
    如果 Ceph 伺服器上缺少此套件，可使用以下指令安裝
   </para>
<screen>zypper ref &amp;&amp; zypper in supportutils-plugin-ses</screen>
  </tip>

  <para>
   儘管您可以在指令行中使用 <command>supportconfig</command>，但我們建議使用相關的 YaST 模組。<link xlink:href="https://www.suse.com/documentation/sles-12/singlehtml/book_sle_admin/book_sle_admin.html#sec.admsupport.supportconfig"/> 上提供了有關 <command>supportconfig</command> 的詳細資訊。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-cluster-mntc-rados-striping">
  <title>使用 <command>rados</command> 傳送大型物件失敗，並顯示「OSD 已滿」</title>

  <para>
   <command>rados</command> 是用於管理 RADOS 物件儲存的指令行公用程式。如需詳細資訊，請參閱 <command>man 8 rados</command>。
  </para>

  <para>
   如果您使用 <command>rados</command> 公用程式將大型物件傳送到 Ceph 叢集，例如
  </para>

<screen>rados -p mypool put myobject /file/to/send</screen>

  <para>
   該物件可能會填滿所有相關的 OSD 空間，並導致叢集效能出現嚴重問題。
  </para>
 </sect1>
 <sect1 xml:id="ceph-xfs-corruption">
  <title>XFS 檔案系統損毀</title>

  <para>
   在極少見的情況下 (例如出現核心錯誤，或硬體損毀/設定不當)，OSD 用來儲存資料的基礎檔案系統 (XFS) 可能會損毀或無法掛接。
  </para>

  <para>
   如果您確定硬體沒有問題並且系統設定正確，請報告 SUSE Linux Enterprise Server 核心的 XFS 子系統出現了錯誤，並將特定的 OSD 標示為停機︰
  </para>

<screen>ceph osd down <replaceable>OSD identification</replaceable></screen>

  <warning>
   <title>不要格式化或修改損毀的裝置</title>
   <para>
    儘管使用 <command>xfs_repair</command> 來修復檔案系統問題看似合理，但它會修改檔案系統，因此請勿使用該指令。OSD 可以啟動，但它的執行可能會受到影響。
   </para>
  </warning>

  <para>
   現在，請執行以下指令抹除基礎磁碟，並重新建立 OSD︰
  </para>

<screen>ceph-disk prepare --zap $OSD_DISK_DEVICE $OSD_JOURNAL_DEVICE"</screen>

  <para>
   例如：
  </para>

<screen>ceph-disk prepare --zap /dev/sdb /dev/sdd2</screen>
 </sect1>
 <sect1 xml:id="storage-bp-recover-toomanypgs">
  <title>「每個 OSD 的 PG 數過多」狀態訊息</title>

  <para>
   如果您在執行 <command>ceph status</command> 後收到<literal>每個 OSD 的 PG 數過多</literal>訊息，則表示超出了 <option>mon_pg_warn_max_per_osd</option> 值 (預設值為 300)。系統會將此值與每個 OSD 的 PG 數比率進行比較。這意味著叢集設定並不是最佳的。
  </para>

  <para>
   建立池後，便不能減少 PG 數。您可以放心地刪除尚不包含任何資料的池，然後重新建立包含較少 PG 的池。如果池中已包含資料，則唯一的解決方法是將 OSD 新增至叢集，使每個 OSD 的 PG 數比率變低。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-stuckinactive">
  <title>「<emphasis>nn</emphasis> pg 停滯在非使用中狀態」狀態訊息</title>

  <para>
   如果您在執行 <command>ceph status</command> 後收到<literal>停滯在非使用中狀態</literal>狀態訊息，則表示 Ceph 不知道要將儲存的資料複製到何處，因此無法遵循複製規則。在完成初始 Ceph 設定不久後可能會發生此問題，並且系統可自動修復。在其他情況下出現此問題可能需要進行手動互動，例如啟動已中止的 OSD，或者將新的 OSD 新增至叢集。在極少見的情況下，降低複製層級可能有所幫助。
  </para>

  <para>
   如果放置群組一直處於停滯狀態，則您需要檢查 <command>ceph osd tree</command> 的輸出。輸出採用的應該是樹狀結構，類似於<xref linkend="storage-bp-recover-osddown"/>中的範例。
  </para>

  <para>
   如果 <command>ceph osd tree</command> 的輸出結構相對扁平，如以下範例中所示
  </para>

<screen>ceph osd tree
ID WEIGHT TYPE NAME    UP/DOWN REWEIGHT PRIMARY-AFFINITY
-1      0 root default
 0      0 osd.0             up  1.00000          1.00000
 1      0 osd.1             up  1.00000          1.00000
 2      0 osd.2             up  1.00000          1.00000</screen>

  <para>
   您應該檢查相關的 CRUSH 地圖是否包含樹狀結構。如果 CRUSH 地圖也是扁平的，或者不包含上面範例中所示的主機，則可能表示叢集中的主機名稱解析未正常運作。
  </para>

  <para>
   如果階層不正確 (例如，根包含主機，但 OSD 位於頂層，並且自身未指定到主機)，您需要將 OSD 移到階層中的正確位置。可以使用 <command>ceph osd crush move</command> 和/或 <command>ceph osd crush set</command> 指令實現此目的。如需更多詳細資料，請參閱<xref linkend="op-crush"/>。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osdweight">
  <title>OSD 權數為 0</title>

  <para>
   當 OSD 啟動時，系統會給它指定一個權數。權數越高，叢集向該 OSD 寫入資料的幾率就越大。可在叢集 CRUSH 地圖中指定該權數，或者透過 OSD 的啟動程序檔計算得出。
  </para>

  <para>
   在某些情況下，計算出的 OSD 權數值可能會捨位到零。這表示不會排程該 OSD 儲存資料，因此不會向其寫入資料。發生此情況的原因通常是相應的磁碟太小 (小於 15GB)，應該更換為更大的磁碟。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-osddown">
  <title>OSD 停機</title>

  <para>
   OSD 精靈的狀態要麼是執行中，要麼是已停止/已停機。導致 OSD 停機的原因一般有以下三種︰
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     硬碟故障。
    </para>
   </listitem>
   <listitem>
    <para>
     OSD 已當機。
    </para>
   </listitem>
   <listitem>
    <para>
     伺服器已當機。
    </para>
   </listitem>
  </itemizedlist>

  <para>
   您可以執行以下指令來查看 OSD 的詳細狀態
  </para>

<screen>ceph osd tree
# id  weight  type name up/down reweight
 -1    0.02998  root default
 -2    0.009995   host doc-ceph1
 0     0.009995      osd.0 up  1
 -3    0.009995   host doc-ceph2
 1     0.009995      osd.1 up  1
 -4    0.009995   host doc-ceph3
 2     0.009995      osd.2 down  1</screen>

  <para>
   範例清單顯示 <literal>osd.2</literal> 已停機。然後，您可以檢查是否已掛接 OSD 所在的磁碟︰
  </para>

<screen>lsblk -f
 [...]
 vdb
 ├─vdb1               /var/lib/ceph/osd/ceph-2
 └─vdb2</screen>

  <para>
   您可以透過檢查 OSD 的記錄檔案 <filename>/var/log/ceph/ceph-osd.2.log</filename> 來追蹤其停機原因。找到並解決 OSD 未執行的原因之後，請使用以下指令將它啟動
  </para>

<screen>sudo systemctl start ceph-osd@2.service</screen>

  <para>
   請記得用已停止 OSD 的實際編號取代 <literal>2</literal>。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-slowosd">
  <title>尋找執行緩慢的 OSD</title>

  <para>
   調校叢集效能時，識別叢集中執行緩慢的儲存/OSD 非常重要。原因在於，如果將資料寫入 (最) 緩慢的磁碟，則會拖慢整個寫入操作，因為它永遠要等待在所有相關磁碟上的操作全部完成。
  </para>

  <para>
   找到儲存瓶頸並非無足輕重。您需要檢查每一個 OSD 才能找出使寫入程序減慢的 OSD。若要針對單個 OSD 執行基準測試，請執行︰
  </para>

<screen role="ceph_tell_osd_bench"><command>ceph tell</command> osd.<replaceable>OSD_ID_NUMBER</replaceable> bench</screen>

  <para>
   例如︰
  </para>

<screen><prompt>root # </prompt>ceph tell osd.0 bench
 { "bytes_written": 1073741824,
   "blocksize": 4194304,
   "bytes_per_sec": "19377779.000000"}</screen>

  <para>
   然後，您需要在每個 OSD 上執行此指令，並與 <literal>bytes_per_sec</literal> 值進行比較，以找出 (最) 緩慢的 OSD。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-recover-clockskew">
  <title>解決時鐘偏差警告</title>

  <para>
   所有叢集節點中的時間資訊都必須是同步的。如果某個節點的時間未完全同步，在檢查叢集狀態時，您可能會收到時鐘偏差警告。
  </para>

  <para>
   可使用 NTP 來管理時間同步 (請參閱 <link xlink:href="http://en.wikipedia.org/wiki/Network_Time_Protocol"/>)。設定每個節點，使其時間與一或多部 NTP 伺服器同步，最好是與同一群組的 NTP 伺服器同步。如果節點上仍然出現時間偏差，請執行以下步驟予以修復︰
  </para>

<screen>systemctl stop ntpd.service
systemctl stop ceph-mon.target
systemctl start ntpd.service
systemctl start ceph-mon.target</screen>

  <para>
   然後，可以查詢 NTP 對等伺服器，並使用 <command>sudo ntpq -p</command> 檢查時間偏移。
  </para>

  <para>
   Ceph monitor 的時鐘需要同步，彼此之間的偏差必須控制在 0.05 秒以內。如需詳細資訊，請參閱<xref linkend="Cluster-Time-Setting"/>。
  </para>
 </sect1>
 <sect1 xml:id="storage-bp-performance-net-issues">
  <title>網路問題導致叢集效能不佳</title>

  <para>
   導致叢集效能變差的原因有很多，其中之一可能是網路問題。在這種情況下，您可能會發現叢集即將達到仲裁數、OSD 和監控程式節點離線、資料傳輸耗費很長時間，或者嘗試了很多次重新連接。
  </para>

  <para>
   若要檢查叢集效能下降是否因網路問題導致，請檢查 <filename>/var/log/ceph</filename> 目錄中的 Ceph 記錄檔案。
  </para>

  <para>
   若要解決叢集上的網路問題，請重點關注以下幾點︰
  </para>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     基本網路診斷。嘗試使用 DeepSea 診斷工具執行器 <literal>net.ping</literal> 在叢集節點之間執行 ping 指令，以確定個別介面是否可以連接到特定的介面，並瞭解平均回應時間。此指令還會報告比平均值要慢得多的所有特定回應時間。例如︰
    </para>
<screen><prompt>root@master # </prompt>salt-run net.ping
  Succeeded: 8 addresses from 7 minions average rtt 0.15 ms</screen>
    <para>
     嘗試在啟用巨型框架的情況下驗證所有介面︰
    </para>
<screen><prompt>root@master # </prompt>salt-run net.jumbo_ping
  Succeeded: 8 addresses from 7 minions average rtt 0.26 ms</screen>
   </listitem>
   <listitem>
    <para>
     網路效能基準測試。嘗試使用 DeepSea 的網路效能執行器 <literal>net.iperf</literal> 來測試節點間的網路頻寬。在某個給定的叢集節點上，有許多 <command>iperf</command> 程序 (具體視 CPU 核心數而定) 是做為伺服器啟動的。其餘的叢集節點將做為用戶端來產生網路流量。執行器會報告單個節點上所有 <command>iperf</command> 程序的累積頻寬。此值應該能反映所有叢集節點上可達到的最大網路輸送量。例如︰
    </para>
<screen><prompt>root@master # </prompt>salt-run net.iperf cluster=ceph output=full
192.168.128.1:
    8644.0 Mbits/sec
192.168.128.2:
    10360.0 Mbits/sec
192.168.128.3:
    9336.0 Mbits/sec
192.168.128.4:
    9588.56 Mbits/sec
192.168.128.5:
    10187.0 Mbits/sec
192.168.128.6:
    10465.0 Mbits/sec</screen>
   </listitem>
   <listitem>
    <para>
     檢查叢集節點上的防火牆設定。確定這些設定不會封鎖 Ceph 運作所需的連接埠/通訊協定。如需防火牆設定的詳細資訊，請參閱<xref linkend="storage-bp-net-firewall"/>。
    </para>
   </listitem>
   <listitem>
    <para>
     檢查網路卡、纜線或交換器等網路硬體是否正常運作。
    </para>
   </listitem>
  </itemizedlist>

  <tip>
   <title>獨立網路</title>
   <para>
    為確保在叢集節點之間進行快速安全的網路通訊，請設定一個專供叢集 OSD 和監控程式節點使用的獨立網路。
   </para>
  </tip>
 </sect1>
 <sect1 xml:id="trouble-jobcache">
  <title><filename>/var</filename> 空間不足</title>

  <para>
   依預設，Salt Master 會在其<emphasis>工作快取</emphasis>中儲存每個 Minion 針對每個工作傳回的內容。以後便可使用快取來查閱先前工作的結果。快取目錄預設為 <filename>/var/cache/salt/master/jobs/</filename>。
  </para>

  <para>
   每個 Minion 針對每個工作傳回的內容都儲存在一個檔案中。久而久之，此目錄會變得非常大，具體大小取決於發佈的工作數量和 <filename>/etc/salt/master</filename> 檔案中 <option>keep_jobs</option> 選項的值。<option>keep_jobs</option> 用於設定應將過去的 Minion 工作的相關資訊保留多少小時 (預設值為 24)。
  </para>

<screen>keep_jobs: 24</screen>

  <important>
   <title>請勿<option>將 keep_jobs 設定為 0</option></title>
   <para>
    如果將 <option>keep_jobs</option> 設定為「0」，則工作快取清除工具<emphasis>永不</emphasis>執行，可能會導致分割區變滿。
   </para>
  </important>

  <para>
   若要停用工作快取，請將 <option>job_cache</option> 設定為「False」︰
  </para>

<screen>job_cache: False</screen>

  <tip>
   <title>還原因工作快取而變滿的分割區</title>
   <para>
    當由於 <option>keep_jobs</option> 設定不當而導致包含工作快取檔案的分割區變滿時，請執行以下步驟來釋放磁碟空間並改進工作快取設定︰
   </para>
   <procedure>
    <step>
     <para>
      停止 Salt Master 服務︰
     </para>
<screen><prompt>root@master # </prompt>systemctl stop salt-master</screen>
    </step>
    <step>
     <para>
      透過編輯 <filename>/etc/salt/master</filename> 來變更與工作快取相關的 Salt Master 組態︰
     </para>
<screen>job_cache: False
keep_jobs: 1</screen>
    </step>
    <step>
     <para>
      清除 Salt Master 工作快取︰
     </para>
<screen>rm -rfv /var/cache/salt/master/jobs/*</screen>
    </step>
    <step>
     <para>
      啟動 Salt Master 服務︰
     </para>
<screen><prompt>root@master # </prompt>systemctl start salt-master</screen>
    </step>
   </procedure>
  </tip>
 </sect1>
</chapter>
