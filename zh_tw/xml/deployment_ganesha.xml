<?xml version="1.0" encoding="UTF-8"?>
<chapter xmlns="http://docbook.org/ns/docbook" xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:xlink="http://www.w3.org/1999/xlink" xml:base="deployment_ganesha.xml" version="5.0" xml:id="cha.as.ganesha">

 <title>安裝 NFS Ganesha</title>
 <info>
      <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
        <dm:maintainer>tbazant@suse.com</dm:maintainer>
        <dm:status>編輯</dm:status>
        <dm:deadline/>
        <dm:priority/>
        <dm:translation>yes</dm:translation>
        <dm:languages/>
        <dm:release>SES 5</dm:release>
      </dm:docmanager>
    </info>
    <para>
  使用 NFS Ganesha 可透過 NFS 存取物件閘道或 CephFS。SUSE Enterprise Storage 5 支援 NFS 版本 3 和 4。NFS Ganesha 在使用者空間而不是核心空間中執行，直接與物件閘道或 CephFS 互動。
 </para>
 <sect1 xml:id="sec.as.ganesha.preparation">
  <title>準備</title>

  <sect2 xml:id="sec.as.ganesha.preparation.general">
   <title>一般資訊</title>
   <para>
    若要成功部署 NFS Ganesha，需要將 <literal>role-ganesha</literal> 新增到 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename>。如需詳細資料，請參閱<xref linkend="policy.configuration"/>。若要使用 NFS Ganesha，還需要在 <filename>policy.cfg</filename> 中指定 <literal>role-rgw</literal> 或 <literal>role-mds</literal>。
   </para>
   <para>
    儘管可以在現有的 Ceph 節點上安裝並執行 NFS Ganesha 伺服器，但還是建議您在能夠存取 Ceph 叢集的專屬主機上執行該伺服器。用戶端主機一般不是叢集的一部分，但需要能夠透過網路存取 NFS Ganesha 伺服器。
   </para>
   <para>
    若要在完成啟始安裝後隨時啟用 NFS Ganesha 伺服器，請將 <literal>role-ganesha</literal> 新增至 <filename>policy.cfg</filename>，並至少重新執行 DeepSea 階段 2 和 4。如需詳細資料，請參閱<xref linkend="ceph.install.stack"/>。
   </para>
   <para>
    NFS Ganesha 是透過 NFS Ganesha 節點上的 <filename>/etc/ganesha/ganesha.conf</filename> 檔案設定的。但是，每次執行 DeepSea 階段 4，都會覆寫此檔案。因此，建議您編輯 Salt 使用的範本，即 Salt Master 上的 <filename>/srv/salt/ceph/ganesha/files/ganesha.conf.j2</filename> 檔案。如需組態檔案的詳細資料，請參閱<xref linkend="ceph.nfsganesha.config"/>。
   </para>
  </sect2>

  <sect2 xml:id="sec.as.ganesha.preparation.requirements">
   <title>要求摘要</title>
   <para>
    在執行 DeepSea 階段 2 和 4 來安裝 NFS Ganesha 之前，必須滿足以下要求︰
   </para>
   <itemizedlist>
    <listitem>
     <para>
      至少為一個節點指定 <literal>role-ganesha</literal>。
     </para>
    </listitem>
    <listitem>
     <para>
      對於每個 Minion，只能定義一個 <literal>role-ganesha</literal>。
     </para>
    </listitem>
    <listitem>
     <para>
      NFS Ganesha 需要物件閘道或 CephFS 才能正常運作。
     </para>
    </listitem>
    <listitem>
     <para>
      如果 NFS Ganesha 預期要使用物件閘道來連接叢集，則需要填入 Salt Master 上的 <filename>/srv/pillar/ceph/rgw.sls</filename>。
     </para>
    </listitem>
   </itemizedlist>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.as.ganesha.basic_example">
  <title>範例安裝</title>

  <para>
   此程序提供了一個範例安裝，該範例使用 NFS Ganesha 的物件閘道和 CephFS 檔案系統抽象層 (FSAL)。
  </para>

  <procedure>
   <step>
    <para>
     先要執行 DeepSea 階段 0 和 1 (如果您尚未執行)，然後才能繼續執行此程序。
    </para>
<screen><prompt>root # </prompt><command>salt-run</command> state.orch ceph.stage.0
<prompt>root # </prompt><command>salt-run</command> state.orch ceph.stage.1</screen>
   </step>
   <step>
    <para>
     執行 DeepSea 的階段 1 之後，編輯 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> 並新增下行
    </para>
<screen>role-ganesha/cluster/<replaceable>NODENAME</replaceable></screen>
    <para>
     使用叢集中某個節點的名稱取代 <replaceable>NODENAME</replaceable>。
    </para>
    <para>
     另外，請確定已指定 <literal>role-mds</literal> 和 <literal>role-rgw</literal>。
    </para>
   </step>
   <step>
    <para>
     建立檔案 <filename>/srv/pillar/ceph/rgw.sls</filename> 並插入以下內容︰
    </para>
<screen>rgw_configurations:
  rgw:
    users:
      - { uid: "demo", name: "Demo", email: "demo@demo.nil" }
      - { uid: "demo1", name: "Demo1", email: "demo1@demo.nil" }</screen>
    <para>
     系統稍後會將這些使用者建立為物件閘道使用者，並產生 API 金鑰。稍後，您可在物件閘道節點上執行 <command>radosgw-admin user list</command> 以列出所有已建立的使用者，並執行 <command>radosgw-admin user info --uid=demo</command> 取得個別使用者的詳細資料。
    </para>
    <para>
     DeepSea 可確保物件閘道和 NFS Ganesha 都能接收 <filename>rgw.sls</filename> 的 <literal>rgw</literal> 區段中所列全部使用者的身分證明。
    </para>
    <para>
     輸出的 NFS 將在檔案系統的第一層級上使用這些使用者名稱；在本範例中，將輸出路徑 <filename>/demo</filename> 和 <filename>/demo1</filename>。
    </para>
   </step>
   <step>
    <para>
     至少執行 DeepSea 的階段 2 和 4。建議執行中間的階段 3。
    </para>
<screen><prompt>root # </prompt><command>salt-run</command> state.orch ceph.stage.2
<prompt>root # </prompt><command>salt-run</command> state.orch ceph.stage.3 # optional but recommended
<prompt>root # </prompt><command>salt-run</command> state.orch ceph.stage.4</screen>
   </step>
   <step>
    <para>
     透過從用戶端節點掛接 NFS 共用來驗證 NFS Ganesha 是否正常運作︰
    </para>
<screen><prompt>root # </prompt><command>mount</command> -o sync -t nfs <replaceable>GANESHA_NODE</replaceable>:/ /mnt
<prompt>root # </prompt><command>ls</command> /mnt
cephfs  demo  demo1</screen>
    <para>
     <filename>/mnt</filename> 應包含所有已輸出的路徑。應存在 CephFS 和兩個物件閘道使用者的目錄。對於使用者擁有的每個桶，將輸出路徑 <filename>/mnt/<replaceable>USERNAME</replaceable>/<replaceable>BUCKETNAME</replaceable></filename>。
    </para>
   </step>
  </procedure>
 </sect1>
 <sect1 xml:id="sec.as.ganesha.ha-ap">
  <title>高可用性主動-被動組態</title>

  <para>
   本節提供一個範例來展示如何設定 NFS Ganesha 伺服器的雙節點主動-被動組態。該設定需要 SUSE Linux Enterprise High Availability Extension。兩個節點分別名為 <systemitem class="domainname">earth</systemitem> 和 <systemitem class="domainname">mars</systemitem>。
  </para>

  <para>
   如需 SUSE Linux Enterprise High Availability Extension 的詳細資料，請參閱 <link xlink:href="https://www.suse.com/documentation/sle-ha-12/"/>。
  </para>

  <sect2 xml:id="sec.as.ganesha.ha-ap.basic">
   <title>基本安裝</title>
   <para>
    在此設定中，<systemitem class="domainname">earth</systemitem> 的 IP 位址為 <systemitem class="ipaddress">192.168.1.1</systemitem>，<systemitem class="domainname">mars</systemitem> 的位址為 <systemitem class="ipaddress">192.168.1.2</systemitem>。
   </para>
   <para>
    此外，使用兩個浮動的虛擬 IP 位址，可讓用戶端都可連接到服務，而不管該服務在哪個實體節點上執行。<systemitem class="ipaddress">192.168.1.10</systemitem> 用於透過 Hawk2 進行叢集管理，<systemitem class="ipaddress">192.168.2.1</systemitem> 專門用於 NFS 輸出。如此可讓日後能更輕鬆地套用安全性限制。
   </para>
   <para>
    以下程序說明範例安裝。<link xlink:href="https://www.suse.com/documentation/sle-ha-12/install-quick/data/install-quick.html"/> 上提供了更多詳細資料。
   </para>
   <procedure xml:id="proc.as.ganesha.ha-ap">
    <step>
     <para>
      在 Salt Master 上準備 NFS Ganesha 節點︰
     </para>
     <substeps>
      <step>
       <para>
        在 Salt Master 上執行 DeepSea 階段 0 和 1。
       </para>
<screen>
<prompt>root@master # </prompt><command>salt-run</command> state.orch ceph.stage.0
<prompt>root@master # </prompt><command>salt-run</command> state.orch ceph.stage.1
</screen>
      </step>
      <step>
       <para>
        在 <filename>/srv/pillar/ceph/proposals/policy.cfg</filename> 中為節點 <systemitem class="domainname">earth</systemitem> 和 <systemitem class="domainname">mars</systemitem> 指定 <literal>role-ganesha</literal>︰
       </para>
<screen>role-ganesha/cluster/earth*.sls
role-ganesha/cluster/mars*.sls</screen>
      </step>
      <step>
       <para>
        在 Salt Master 上執行 DeepSea 階段 3 和 4。
       </para>
<screen><prompt>root@master # </prompt><command>salt-run</command> state.orch ceph.stage.3
<prompt>root@master # </prompt><command>salt-run</command> state.orch ceph.stage.4</screen>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      在 <systemitem class="domainname">earth</systemitem> 和 <systemitem class="domainname">mars</systemitem> 上註冊 SUSE Linux Enterprise High Availability Extension。
     </para>
<screen>
<prompt>root # </prompt><command>SUSEConnect</command> -r <replaceable>ACTIVATION_CODE</replaceable> -e <replaceable>E_MAIL</replaceable>
</screen>
    </step>
    <step>
     <para>
      在兩個節點上安裝 <package>ha-cluster-bootstrap</package> ︰
     </para>
<screen><prompt>root # </prompt><command>zypper</command> in ha-cluster-bootstrap</screen>
    </step>
    <step>
     <substeps>
      <step>
       <para>
        在 <systemitem class="domainname">earth</systemitem> 上啟始化叢集︰
       </para>
<screen><prompt>root@earth # </prompt><command>ha-cluster-init</command></screen>
      </step>
      <step>
       <para>
        讓 <systemitem class="domainname">mars</systemitem> 加入該叢集︰
       </para>
<screen><prompt>root@mars # </prompt><command>ha-cluster-join</command> -c earth</screen>
      </step>
     </substeps>
    </step>
    <step>
     <para>
      檢查叢集的狀態。您應該會看到兩個節點都已新增到叢集中︰
     </para>
<screen><prompt>root@earth # </prompt><command>crm</command> status</screen>
    </step>
    <step>
     <para>
      在這兩個節點上，停用開機時自動啟動 NFS Ganesha 服務的功能︰
     </para>
<screen><prompt>root # </prompt><command>systemctl</command> disable nfs-ganesha</screen>
    </step>
    <step>
     <para>
      在 <systemitem class="domainname">earth</systemitem> 上啟動 <command>crm</command> 外圍程序︰
     </para>
<screen><prompt>root@earth # </prompt><command>crm</command> configure</screen>
     <para>
      後續指令在 crm 外圍程序中執行。
     </para>
    </step>
    <step>
     <para>
      在 <systemitem class="domainname">earth</systemitem> 上，執行 crm 外圍程序來執行以下指令，以便將 NFS Ganesha 精靈的資源設定為 systemd 資源類型的複製︰
     </para>
<screen>
<prompt>crm(live)configure# </prompt>primitive nfs-ganesha-server systemd:nfs-ganesha \
op monitor interval=30s
<prompt>crm(live)configure# </prompt>clone nfs-ganesha-clone nfs-ganesha-server meta interleave=true
<prompt>crm(live)configure# </prompt>commit
<prompt>crm(live)configure# </prompt>status
    2 nodes configured
    2 resources configured

    Online: [ earth mars ]

    Full list of resources:
         Clone Set: nfs-ganesha-clone [nfs-ganesha-server]
         Started:  [ earth mars ]</screen>
    </step>
    <step>
     <para>
      使用 crm 外圍程序建立一個原始 IPAddr2︰
     </para>
<screen>
<prompt>crm(live)configure# </prompt>primitive ganesha-ip IPaddr2 \
params ip=192.168.2.1 cidr_netmask=24 nic=eth0 \
op monitor interval=10 timeout=20

<prompt>crm(live)# </prompt>status
Online: [ earth mars  ]
Full list of resources:
 Clone Set: nfs-ganesha-clone [nfs-ganesha-server]
     Started: [ earth mars ]
 ganesha-ip    (ocf::heartbeat:IPaddr2):    Started earth</screen>
    </step>
    <step>
     <para>
      為了在 NFS Ganesha 伺服器與浮動虛擬 IP 之間建立關係，我們使用了併置和順序約束。
     </para>
<screen>
<prompt>crm(live)configure# </prompt>colocation ganesha-ip-with-nfs-ganesha-server inf: ganesha-ip nfs-ganesha-clone
<prompt>crm(live)configure# </prompt>order ganesha-ip-after-nfs-ganesha-server Mandatory: nfs-ganesha-clone ganesha-ip
</screen>
    </step>
    <step>
     <para>
      從用戶端使用 <command>mount</command> 指令，以確定完成叢集設定︰
     </para>
<screen><prompt>root # </prompt><command>mount</command> -t nfs -v -o sync,nfsvers=4 192.168.2.1:/ /mnt</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec.as.ganesha.ha-ap.cleanup">
   <title>清理資源</title>
   <para>
    如果其中一個節點 (例如 <systemitem class="domainname">earth</systemitem>) 上發生 NFS Ganesha 故障，請解決問題並清理資源。如果 NFS Ganesha 在 <systemitem class="domainname">mars</systemitem> 上發生故障，則只有在清理資源之後，該資源才能錯誤回復至 <systemitem class="domainname">earth</systemitem>。
   </para>
   <para>
    若要清理資源，請執行以下指令︰
   </para>
<screen><prompt>root@earth # </prompt><command>crm</command> resource cleanup nfs-ganesha-clone earth
<prompt>root@earth # </prompt><command>crm</command> resource cleanup ganesha-ip earth</screen>
  </sect2>

  <sect2 xml:id="sec.as.ganesha.ha-ap.ping-resource">
   <title>設定 Ping 資源</title>
   <para>
    有時，伺服器可能由於網路問題而無法連接用戶端。Ping 資源可以偵測並緩解此問題。設定此資源的操作是選擇性的。
   </para>
   <procedure>
    <step>
     <para>
      定義 ping 資源︰
     </para>
<screen><prompt>crm(live)configure# </prompt>primitive ganesha-ping ocf:pacemaker:ping \
        params name=ping dampen=3s multiplier=100 host_list="<replaceable>CLIENT1</replaceable> <replaceable>CLIENT2</replaceable>" \
        op monitor interval=60 timeout=60 \
        op start interval=0 timeout=60 \
        op stop interval=0 timeout=60</screen>
     <para>
      <literal>host_list</literal> 是以空格字元分隔的 IP 位址清單。系統將會定期 ping 這些 IP 位址，以檢查網路中斷問題。如果某個用戶端必須永遠能夠存取 NFS 伺服器，請將該用戶端新增到 <literal>host_list</literal>。
     </para>
    </step>
    <step>
     <para>
      建立複製︰
     </para>
<screen><prompt>crm(live)configure# </prompt>clone ganesha-ping-clone ganesha-ping \
        meta interleave=true</screen>
    </step>
    <step>
     <para>
      以下指令會建立 NFS Ganesha 服務的約束。當 <literal>host_list</literal> 不可存取時，此約束會強制服務轉移到另一節點。
     </para>
<screen><prompt>crm(live)configure# </prompt>location nfs-ganesha-server-with-ganesha-ping
        nfs-ganesha-clone \
        rule -inf: not_defined ping or ping lte 0</screen>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="ganesha_ha_deepsea">
   <title>NFS Ganesha HA 和 DeepSea</title>
   <para>
    DeepSea 不支援設定 NFS Ganesha HA。為了防止在設定 NFS Ganesha HA 之後 DeepSea 發生故障，請從 DeepSea 階段 4 中排除 NFS Ganesha 服務的啟動和停止操作︰
   </para>
   <procedure>
    <step>
     <para>
      將 <filename>/srv/salt/ceph/ganesha/default.sls</filename> 複製到 <filename>/srv/salt/ceph/ganesha/ha.sls</filename>。
     </para>
    </step>
    <step>
     <para>
      從 <filename>/srv/salt/ceph/ganesha/ha.sls</filename> 中移除 <literal>.service</literal> 項目，如下所示︰
     </para>
<screen>include:
- .keyring
- .install
- .configure</screen>
    </step>
    <step>
     <para>
      將下行新增到 <filename>/srv/pillar/ceph/stack/global.yml</filename>︰
     </para>
<screen>ganesha_init: ha</screen>
    </step>
   </procedure>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.as.ganesha.info">
  <title>更多資訊</title>

  <para>
   如需詳細資訊，請參閱<xref linkend="cha.ceph.nfsganesha"/>。
  </para>
 </sect1>
</chapter>
